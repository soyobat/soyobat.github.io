{"meta":{"title":"soyo的跨机房部署、同城双活、异地多活、9个9高可用博客yuque笔记同步site","subtitle":"ε=(´ο｀*)))唉，学Java的这辈子有了","description":"","author":"lkl","url":"https://www.soyorin.online","root":"/"},"pages":[{"title":"404","text":"","path":"404/index.html","date":"11-05","excerpt":""},{"title":"search","text":"","path":"search/index.html","date":"11-05","excerpt":""},{"title":"categories","text":"","path":"categories/index.html","date":"11-05","excerpt":""},{"title":"tags","text":"","path":"tags/index.html","date":"11-05","excerpt":""},{"title":"aboutme","text":"","path":"aboutme/index.html","date":"11-05","excerpt":""}],"posts":[{"title":"豆包神","text":"","path":"2025/10/25/ai 应用相关/豆包神/","date":"10-25","excerpt":"","tags":[]},{"title":"prompt生成网站","text":"","path":"2025/10/23/ai 应用相关/prompt生成网站/","date":"10-23","excerpt":"","tags":[]},{"title":"文件打开和关闭过程","text":"当用户进程想打开文件，就像向操作系统申请通行证，通过 open() 系统调用，提供文件名和打开模式。 内核拿到请求，首先得验证权限，就像门卫一样，检查进程是否有权访问，比如用户ID和组ID是否匹配，权限位是否允许等。 没权限就返回错误，直接拒绝。 权限过了，内核就要在文件系统里找对应的 inode，就像在档案室里找文件。 如果文件不存在，但打开模式允许创建，就创建一个新的 inode。 找到 inode 后，内核会在进程的文件描述符表中找个空位，文件描述符就像是借阅卡，每个进程都有自己的卡。 然后，内核会创建一个文件对象，也叫文件句柄，维护文件的状态信息，比如读写位置。文件对象是系统级的，可以被多个进程共享。 最后，内核建立连接，将文件描述符指向文件对象，文件对象指向 inode。这样，进程就可以通过文件描述符访问文件了。 open() 成功后，返回文件描述符给用户进程，进程就能用它读写文件了。 关闭文件也很有意思。进程调用 close()，内核首先验证文件描述符是否有效。 有效的话，内核把它从进程的文件描述符表中移除，这样这个描述符就能被下次打开文件重用了。同时，内核减少文件对象的引用计数。因为文件对象可能被多个进程共享，只有当引用计数为零时，才会真正释放。 释放文件对象时，内核会把文件缓冲区的数据写回磁盘，保证数据不丢失，然后释放文件对象占用的内存。 如果这是最后一个指向 inode 的链接，且文件被删除了，内核还会释放 inode 和文件数据块占用的空间。 总的来说，文件的打开和关闭过程保证了文件访问的安全性、效率以及资源的合理利用。","path":"2025/10/22/操作系统/文件打开和关闭过程/","date":"10-22","excerpt":"","tags":[]},{"title":"顺序写为什么这么快？","text":"顺序写快的原因有很多。 最重要的一个原因则是寻址问题，也就是要找到写入的磁盘空间，而后将磁头移动到对应的位置。很显然，随机写是每一次写入都要重新寻址，而顺序写则是找到一个位置之后就可以连绵不绝写下去。 除了这个最根源的原因以外，还有两个原因：一个是充分利用写缓冲，这也是局部性原理的一个体现。另外一个则是现代的文件系统会有意识地将偏向并且优化顺序写的性能。 简述随机写寻址慢，局部性差，文件系统支持不友好 引导局部性原理 当然，当下广泛使用的 SSD 也有类似的特性，但是原理上有些区别。这其中比较大的一个差异是虽然 SSD 也要寻址，但是没有机械硬盘那么慢，也不需要挪动磁头。 SSD 顺序写快的原因主要是局部性原理的应用，这源自两方面，一个是 SSD 写入是以页为单位的，也就是你写 1B 还是写入 1KB，都是按照页来写入的。另外一个是 SSD 同样会有缓存，顺序写也能更加好的利用这些缓存。","path":"2025/10/22/操作系统/顺序写为什么这么快？/","date":"10-22","excerpt":"","tags":[]},{"title":"交换区","text":"交换区是硬盘上的一块特殊区域，用于存储那些当前不使用的内存页，这样可以在物理内存紧张时，将这些页换出到硬盘上，从而释放物理内存供其他进程使用。 交换区的作用是扩展系统的可用内存空间，它允许操作系统在物理内存不足时，将不常用的内存页换出到硬盘上，这样就可以在不增加物理内存的情况下，支持更多的进程运行，提高内存的使用效率。 所以，显而易见使用交换区会导致性能变差。因此在性能优化里面，一个常见的措施就是尽可能减少交换区的使用。举个例子来说，在使用 Kafka 之类的中间件的时候，我们会将它的最大内存设置为不大于物理内存。一般都是让中间件使用的内存加上操作系统占用的内存，不大于物理内存。 这样可以确保很少触发换入换出，也就是避免使用交换区。 当然，类似的另外一个手段是调整 Linux 下的 vm.swapness 的值。例如说调整到 1，也就是尽可能规避使用交换区。 这两种手段是可以混合使用的。例如说在 Kafka 的服务器上，同时限制住 Kafka 的堆大小，以及 Kafka 所在 Linux 系统的 vm.swapness 参数到一个极小的值，例如说 1。","path":"2025/10/22/操作系统/交换区/","date":"10-22","excerpt":"","tags":[]},{"title":"页面置换算法","text":"简单的说就是物理内存页淘汰算法 它其实就是我们在虚拟内存里面提到的，当物理内存不够的时候，要将一部分物理页的内容写到交换区中。页面替换算法就是用来计算，究竟哪些页应该写到交换区上。 有很多种算法，每种算法都有自己的特色。 第一种是先进先出（FIFO）算法：这是最简单的页面替换算法。它基于“先进先出”的原则，即最早进入内存的页面将首先被替换。这种算法易于实现，但可能不适合实际的工作负载，因为它不考虑页面的使用频率。 第二种是最近最少使用（LRU）算法：LRU算法认为过去一段时间内最少被使用的页面，在未来的使用概率也相对较低。因此，当需要替换页面时，它会选择最长时间未被使用的页面进行替换。 第三种是最久未使用（LFU）算法：LFU算法是基于页面访问频率来替换页面的。它替换掉访问次数最少的页面，认为这些页面在将来可能也不常被使用。 第四种是最优（OPT）算法：这是一种理想化的算法，但在实际中很难实现。OPT算法在每次页面请求时都会选择将来最长时间内不会被访问的页面进行替换，因此它也被称为“未来导向”的算法。 第五种是时钟（Clock）算法：这是一种简单并且实用的近似算法，用来模拟OPT算法。它通过一个循环的列表来跟踪页面，给每个页面一个“访问位”。当需要替换时，它会检查访问位，如果未被访问过，则替换这个页面；如果已被访问，则重新标记并继续。 第六种是第二次机会（SCR）算法：这是对FIFO算法的一种改进。在FIFO的基础上，每个页面都有一个引用位。如果页面被访问，则设置引用位。在替换页面时，如果页面的引用位是0，则替换；如果是1，则将其置为0并给它“第二次机会”。 第七种是老化（Aging）算法：用于模拟LFU算法，但避免了LFU算法中可能出现的页面饥饿问题。它通过一组位来表示页面的使用情况，并定期右移这些位，以减少旧的使用记录的影响。 第八种是WSClock算法：结合了LRU和Clock算法的特点，使用一个钟表算法的列表来选择可能的页面替换候选，然后检查这些页面的引用位来决定是否替换。 Linux内核使用了多种页面替换算法的组合，主要是基于LRU的变种，同时考虑了文件页面和匿名页面的不同特性。它不是一个固定的算法，而是根据系统负载和内存使用模式动态调整的策略。随着内核版本的更新，页面替换算法也在不断地得到改进和优化。 进一步来说，LRU 算法虽然简单，但是 LRU 其实深刻反应了计算机的时间局部性和空间局部性，所以在计算机里面应用非常广泛。最典型的就是缓存淘汰算法，比如说本地缓存已经满了，但是还需要继续放入内容，那么就需要淘汰一部分缓存，以腾出空间。","path":"2025/10/22/操作系统/页面置换算法/","date":"10-22","excerpt":"","tags":[]},{"title":"进程调度","text":"从理论上来说，有很多种调度策略。 第一种是先来先服务，也就是按照到达就绪队列的顺序来调度。优点是简单易实现，缺点就是就绪队列尾部的进程可能会出现饥饿。 第二种是短作业优先。也就是优先调度预计执行时间最短的。优点是可以减少平均等待时间，但是缺点是长作业会饥饿。 第三种是优先级调度，也就是优先级高的先调度，显然缺点是优先级低的任务可能会饥饿。 第四种是时间片轮转，也就是说每个进程轮流运行一段时间，到点之后不管有没有结束，都要让出 CPU，显然这种算法公平性比较好。 第五种是多级反馈队列。简单来说就是分成多个队列，每个队列代表一个优先级。操作系统会动态调整进程的优先级，保证进程都能得到调度。这个算法是一个综合性的算法，综合考虑了非常多的因素，所以总体来说调度效率和公平性都比较好。缺点就是实现会比较复杂。 第六种是最短时间优先，也就是优先调度剩余执行时间最短的任务。它和短作业优先的区别是，短作业优先考虑的是整个任务的执行时间，而这个算法考虑的是剩余执行时间。 第七种是保证公平调度，也就是每个用户或者用户组的 CPU 时间是相同的。 第八种事基于需求调度，也就是根据进程需要的资源来执行调度。 大多数操作系统并不会使用单一的调度策略，而是多种策略混合使用。 比如说 Linux 使用的就是所谓的 CFS，完全公平调度策略。它的核心在于确保每个进程都能公平地分享CPU时间。它通过一个叫做虚拟运行时间的东西来决定哪个进程该运行，并且用一个红黑树来管理这些进程。重要的是，它能够动态地调整每个进程的运行时间，确保系统既高效又公平。 简而言之，CFS让每个进程都有机会得到CPU的运行时间，而且还能根据实际情况灵活调整。","path":"2025/10/22/操作系统/进程调度/","date":"10-22","excerpt":"","tags":[]},{"title":"临界区","text":"临界区是指一个访问共享资源（如变量、数据结构、文件等）的程序片段，在这个片段中，多个进程或线程不能同时执行，否则可能会导致数据不一致或竞态条件。 具体来说，临界区有四个特点。 第一个是互斥性，即同一时间只能有一个进程或线程进入临界区，其他进程或线程必须等待； 第二个是有限等待，进程或线程在有限时间内能够进入临界区，不会无限期等待； 第三个是让权等待，即如果进程或线程不能立即进入临界区，它应该释放CPU，让其他进程或线程运行。 第三个是空闲让进，即如果没有进程或线程在临界区中执行，那么请求进入临界区的进程或线程应该被允许进入。 和临界区这个概念紧密联系的就是并发编程了，比如说可以站在并发编程的角度重新看这四个特性。 互斥性其实不是必须满足的特性。比如说读写锁就没有严格遵循互斥性，读锁本身是允许多个线程加锁的。 而有限等待更多体现为超时控制。最为典型的例子就是在使用并发队列的时候，入队出队都可以增加超时控制，如果要是在时限内都没有操作成功，则返回错误。 让权等待则是体现为如果要是没有拿到锁之类的，就会阻塞，从而让出了 CPU。当然有一些场景下为了优化性能，会引入自旋机制，看看能不能在自旋的时候就获得锁，或者操作成功。 空闲让进则意味着线程或者协程的调度机制，必须要在锁让出的时候，唤醒阻塞的线程或者协程，进一步执行。","path":"2025/10/22/操作系统/临界区/","date":"10-22","excerpt":"","tags":[]},{"title":"CDN","text":"CDN（Content Delivery Network），也就是内容分发网络，其实就是在全球不同地区部署了大量“边缘节点”服务器，把网站上的静态资源（比如图片、视频、CSS、JavaScript 等）预先缓存起来。这样，当用户访问这些内容时，就能就近从最接近的节点获得资源，无须每次都回到源站取数据，整个访问过程会变得又快又稳定。 在具体运作上，用户在访问网站时，首先会通过 DNS 解析域名，CDN 的智能 DNS 根据用户 IP 返回最近的节点地址。 然后，如果该节点本身已经缓存了用户需要的文件，那就会直接把这些文件提供给用户。要是没有缓存，就会去源站拉取资源，保存到节点里，再把文件返回给用户。等到下次访问时，同一资源就可以直接从缓存里取，进一步提升访问速度。 有些 CDN 还会采用负载均衡，把不同的请求分配给不同的服务器，这样能避免个别节点负载过高而导致访问变慢。要进一步提速，CDN 系统往往会做包括智能路由（选择更高效的网络路径）、压缩和优化（例如开启 GZIP 或针对图片做无损压缩）等额外处理，通过尽可能减小数据的体积，或者避开网络访问中的拥堵区，让传输效率提升到更高的水平。除此之外，CDN 常常也会提供一定的安全防护功能，例如抵御 DDoS 攻击、提供 Web 应用防火墙（WAF）等，这样不仅能保证性能，还能守护源站不被恶意攻击击破。 总的来说，CDN通过地理分布的边缘节点、缓存机制和智能调度，把网站和应用的内容有效地送到全球用户手里，既能缩短加载时间，又能抵御突发的大流量冲击，对业务的稳定性和用户体验都有显著的提升效果。","path":"2025/10/22/计网/CDN/","date":"10-22","excerpt":"","tags":[]},{"title":"粘包拆包","text":"粘包的意思是，发送方发送的多个数据包在接收方被合并成了一个数据包。比如，发送方分别发送了两条消息“Hello”和“World”，但接收方可能一次性收到“HelloWorld”。而拆包则是相反的情况，发送方发送了一条完整的消息，比如“HelloWorld”，但接收方可能分两次接收到“Hello”和“World”。这两种情况都会导致接收方无法正确解析数据。 TCP 的粘包和拆包问题其实并不是 TCP 本身的缺陷，而是由它的传输特性和应用层协议的交互方式共同导致的。粘包和拆包的产生原因主要有以下几个方面。 首先，TCP 是一个面向字节流的协议，它只负责把数据可靠地传输到对方，但并不关心数据的边界。数据在传输过程中，TCP 会根据网络状况和缓冲区大小动态调整数据包的大小，这就可能导致粘包或拆包。 其次，TCP 的 Nagle 算法也会合并多个小数据包以提高传输效率，这也是粘包的一个常见原因。 还有一种情况是接收方处理数据的速度跟不上发送方的发送速度，导致多个数据包堆积在缓冲区里，一起被读取。 拆包的原因则更多是因为数据包的大小受限，比如 TCP 的 MSS（最大分段大小）或者网络的 MTU（最大传输单元）。如果发送的数据包超过了这些限制，就会被拆分成多个小包传输。 要解决粘包和拆包问题，关键在于在应用层定义清晰的数据边界。常见的解决方法有以下几种： 第一种是消息定长。也就是说，每条消息的长度是固定的，接收方只需要按照固定的长度读取数据就可以了。这种方法实现起来很简单，解析速度也很快，但缺点是灵活性差，无法适应不同长度的消息。 第二种方法是添加分隔符。在每条消息的末尾加一个特定的分隔符，比如换行符 \\n 或者空字符 \\0，接收方通过识别分隔符来区分消息。这种方法比较灵活，适合不同长度的消息，但需要确保分隔符不会出现在消息内容中，或者对消息内容进行转义处理。 第三种方法是“消息头 + 消息体”。在每条消息的开头加一个固定长度的字段，用来表示消息的总长度。接收方先读取消息头，知道消息体的长度后，再根据这个长度读取完整的消息。这种方法既灵活又高效，能够准确地确定消息边界，但需要设计好消息头的格式和解析逻辑。 总的来说，粘包和拆包是 TCP 编程中非常常见的问题。为了让应用层能够正确解析消息，必须在应用层设计合适的协议机制，比如固定长度、分隔符或者长度字段的方式。具体选择哪种方法，还是要根据实际的应用场景和需求来决定。 这种“消息头+消息体”的协议设计模式方式非常常见，比如我之前参与的DBproxy项目中，需要对接MySQL协议。而MySQL协议大体上也遵循这个协议模式。","path":"2025/10/22/计网/TCP和UDP/TCP传输发生粘包or拆包的原因/粘包拆包/","date":"10-22","excerpt":"","tags":[]},{"title":"如果已经建立了连接，但是客户端出现故障了怎么办？","text":"这要分成两种情况。 第一种情况是服务端发数据给客户端，因为客户端此时已经崩溃了，所以没办法 ACK 服务端的报文。那么会触发服务端的重试功能，在超过重试上限之后，服务端会判定连接不可用，直接关闭连接。 第二种情况是，服务端和客户端之间没有啥报文要发的，而且开启了保活机制，那么超过保活期限，那么服务端也会关闭连接。 具体来说，TCP 设有一个保活计时器。服务器每收到一次客户端的数据，都会重新复位这个计时器，时间通常是设置为 2 小时。若 2 小时还没有收到客户端的任何数据，服务器就开始重试：每隔 75 分钟发送一个探测报文段，若一连发送 10 个探测报文后客户端依然没有回应，那么服务器就认为连接已经断开了。 服务端最终认定客户端崩了，关闭连接；","path":"2025/10/21/计网/TCP和UDP/如果已经建立了连接，但是客户端出现故障了怎么办？/","date":"10-21","excerpt":"","tags":[]},{"title":"方法区的gc","text":"通过可达性分析算法判定对象是否存活： 通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”，如果某个对象到GC Roots间没有任何引用链相连，或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此对象是不可能再被使用的。 在Java技术体系里面，固定可作为GC Roots的对象包括以下几种： 在虚拟机栈（栈帧中的本地变量表）中引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等 在方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量 在方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用 在本地方法栈中JNI（即通常所说的Native方法）引用的对象 Java 虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象 （比如NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器 所有被同步锁（synchronized关键字）持有的对象 反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。 在JDK 1.2版之后，Java对引用的概念进行了扩充，将引用分为强引用（Strongly Re-ference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）4 种 强引用是最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似“Object obj&#x3D;new Object()”这种引用关系。无论任何情况下，只要强引用关系还存在， 垃圾收集器就永远不会回收掉被引用的对象，即使OOM。 软引用是用来描述一些还有用，但非必须的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK 1.2版之后提供了 SoftReference 类来实现软引用。 弱引用也是用来描述那些非必须对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止。当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK 1.2版之后提供了 WeakReference 类来实现弱引用。 虚引用是最弱的一种引用关系。虚引用和引用队列联合使用，用来追踪对象的回收情况。虚拟机回收对象时，如果发现对象还存在虚引用，会在回收对象后将引用加入到关联的引用队列中。程序可以通过观察引用队列的方式，来感知对象即将被垃圾回收的时机。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。在JDK 1.2版之后提供了PhantomReference类来实现虚引用。 对象自救： 即使在可达性分析算法中判定为不可达的对象，也不是“非死不可”的，这时候它们暂时还处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记，随后进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。假如对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，那么虚拟机将这两种情况都视为“没有必要执行”，没有必要执行则直接回收。 如果这个对象被判定为确有必要执行finalize()方法，那么该对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低调度优先级的 Finalizer 线程去执行它们的 finalize() 方法。 finalize()方法是对象逃脱死亡命运的最后一次机会，稍后收集器将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的要被回收了","path":"2025/10/21/JVM/方法区的gc/","date":"10-21","excerpt":"","tags":[]},{"title":"jit","text":"Java 代码首先被编译为字节码（.class），JVM 在运行时通过解释器执行字节码。当某部分的代码被频繁执行时，JIT 会将这些热点代码编译为机器码，以此来提高程序的执行效率。 那为什么 JIT 就能提高程序的执行效率呢，解释器不也是将字节码翻译为机器码交给操作系统执行吗？ 解释器在执行程序时，对于每一条字节码指令，都需要进行一次解释过程，然后执行相应的机器指令。这个过程在每次执行时都会重复进行，因为解释器不会记住之前的解释结果。 与此相对，JIT 会将频繁执行的字节码编译成机器码。这个过程只发生一次。一旦字节码被编译成机器码，之后每次执行这部分代码时，直接执行对应的机器码，无需再次解释。 除此之外，JIT 生成的机器码更接近底层，能够更有效地利用 CPU 和内存等资源，同时，JIT 能够在运行时根据实际情况对代码进行优化（如内联、循环展开、分支预测优化等），这些优化是在机器码级别上进行的，可以显著提升执行效率。 Java 的执行过程分为两步，第一步由 javac 将源码编译成字节码，在这个过程中会进行词法分析、语法分析、语义分析。 第二步，解释器会逐行解释字节码并执行，在解释执行的过程中，JVM 会对程序运行时的信息进行收集，在这些信息的基础上，JIT 会逐渐发挥作用，它会把字节码编译成机器码，但不是所有的代码都会被编译，只有被 JVM 认定为热点代码，才会被编译。 JVM 中有一个阈值，当方法或者代码块的在一定时间内的调用次数超过这个阈值时就会被认定为热点代码，然后编译存入 codeCache 中。当下次执行时，再遇到这段代码，就会从 codeCache 中直接读取机器码，然后执行，以此来提升程序运行的性能。 为什么不一开始就把所有字节码翻译成机器码？ 首先JVM是运行字节码的，这是他能够跨平台运行的核心，所以必须运行字节码，而运行字节码的过程中，如果遇到一条字节码就把他翻译成机器码并存储下来，这是需要空间存储的，如果是冷门代码，得不偿失 JIT优化手段： 锁消除：如果synchronized锁住的区域经过JIT分析发现不会产生线程安全问题，会把锁消除掉 标量替换：某对象没有逃逸出方法，那么这个对象的字段可以拆成标量 栈上分配：对象没有逃逸出方法，就可以在栈上分配，本质其实是标量替换 方法内联：简单的方法可以直接内联到调用处 逃逸分析： 全局逃逸：对象超出方法或线程范围，比如存储在静态字段或者作为方法的返回值 参数逃逸：对象被作为参数传毒，但方法调用期间不会全局逃逸 无逃逸：对象没有逃逸出方法","path":"2025/10/21/JVM/jit/","date":"10-21","excerpt":"","tags":[]},{"title":"内存资源","text":"未关闭的资源，如文件、数据库连接、网络连接，使用完后没正确关闭 集合是静态的，此时静态集合无法被垃圾回收，里面的对象也无法被回收，例如ThreadLocalMap 不正确的引用，A-&gt;B，此时B不需要了，但A没取消对B的引用，B无法释放 线程池没终止，线程对象无法被回收","path":"2025/10/21/JVM/内存资源/","date":"10-21","excerpt":"","tags":[]},{"title":"volatile源码","text":"","path":"2025/10/21/JUC/juc源码/volatile源码/","date":"10-21","excerpt":"","tags":[]},{"title":"集群","text":"Redis集群由多个节点组成，每个节点都是一个主从集群。整体结构如下： 在这种结构之下，现在就会有一个问题，当我存放一个键值对的时候，放哪个节点上？ 对此 Redis Cluster 用的是槽映射的解决方案。Redis Cluster 将所有的key 按照 CRC16 算法映射到16384个槽，这些槽会被分配到这些节点上。大多数情况下槽是均匀分配的，但是小部分情况并不会均匀分配。 整个结构如下图： 所以 Redis 的高可用就源自两方面： 如果节点内的主节点崩溃了，那么从节点经过主从选举就可以顶上； 如果某个节点全崩溃了，那么还有别的节点可以用。虽然会损失数据，但是不至于完全不可用； 对于sentinel和cluster应该选哪种，单机无瓶颈就选sentinel，单机有瓶颈就选cluster Redis Cluster 是一个对等结构和主从结构的混合架构。Redis Cluster 由多个节点组成，这些节点之间地位是平等的，也就是说它们构成了一个对等结构。 但是从细节上来说，每一个节点都是一个主从集群，也就是说每一个节点都是类似于 Redis Sentinel 模式，并借此来保证高可用。 Redis Cluster 借鉴一致性哈希的思想，利用 CRC16 将 key 分散到 16384 个槽（哈希槽就相当于一致性哈希中的虚拟节点）上面，而后再次将这些槽分配给不同的节点。可以平均分，也可以不是平均分。 通过这种混合模式，Redis 能有效应对各种问题。 首先是从对等结构上来说，就算是某个节点彻底不可用，也不会影响到别的节点，整个集群还是能够提供有损服务的。 而从主从结构上来说，通过数据同步和主从选举，这样即便主节点崩溃了， 也能选举出来一个新的从节点顶上。 Redis Cluster 能够撑住极高的并发，并且能够提供极高的可用性，所以已经成了当下大规模分布式系统里面的核心组件。 二、pipeline 是什么 pipeline 是客户端的一种 批量发送命令 的方式： 它允许客户端一次性把多个命令发到 Redis 服务器，然后 Redis 一次性返回结果。减少了网络往返（RTT），因此性能更高。 ✅ 在单机 Redis 下，pipeline 可以极大提高性能。❌ 但在 Redis Cluster 下，有一个问题： 但是 Redis Cluster 并不是毫无缺点，最大的问题就是难以处理跨槽的问题。 这最典型的例子就是 pipeline。例如说在 pipeline 里面要处理分散在不同槽上的多个 key，那么pipeline 就会返回错误，这需要客户端进行处理。而有些语言的 Redis 客户端其实没有那么智能。 从我个人使用经验上来说，在使用 Redis Cluster 的时候，就要避免跨槽的问题。即便使用 Redis pipeline，如果跨槽其实意义就不大了，毕竟我用 pipeline 就是为了高性能，即便我的客户端能帮我处理跨槽的问题，但是性能还是损耗极大。 所以我即便要操作跨槽的 key，也更加倾向于自己将 key 分组，落到同一个节点上的 key 作为一组，而后分批操作。这样分组之后，用 pipeline 也就没有跨槽的问题了。 Redis Cluster 这种对等集群和主从集群的混合模式，在别的中间件里面也能看到类似的设计，甚至于可以说现代的大规模分布式软件的高可用都是通过这种设计来保证的。 举个例子来说，Kafka 的一个 Topic 有多个分区，这些分区之间地位是平等的，所以可以看做是对等结构。而每一个分区本身也是一个主从结构，也有数据复制和主从选举。所以Kafka 就算一个分区出问题，或者逻辑分区的主分区出现问题，依旧能够正常对外提供服务。 再举个例子来说，MySQL 的分库分表也可以看做是这种形态。一个逻辑表被分库分表之后，每一个物理表地位都是平等的，也就是可以看做是对等结构。而每一个物理表都是存储在 MySQL 主从集群上的，那么也就是说物理表本身也有主表和从表。通过这种混合模式可以保证极高的可用性。","path":"2025/10/21/Redis/Redis高可用/集群/","date":"10-21","excerpt":"","tags":[]},{"title":"Object方法","text":"clone：用于克隆对象 equals：用于比较两个对象是否相同 getClass：获取到对象的类对象，也就是Class对象 hashCode：获取到对象的hash值 toString：返回对象的字符串表示形式，一般交给子类重写 notify：当对象被当作锁时使用，让出锁使用权，随机唤醒一个阻塞线程 notifyAll：同上，但会唤醒所有线程竞争锁 wait：当对象被当作锁时使用，让出锁使用权，阻塞等待 finalize：用于对象垃圾回收自救，子类重写，将自己和引用链搭上关系，垃圾回收器会调用该方法，搭上关系了就不再清理该对象，但只会调用一次，即如果调用了一次，搭上关系了，后面关系断了，又被垃圾回收器盯上了，那么直接回收，不再给自救的机会。当然也可以用作其它作用，比如清理释放一些资源，当对象被垃圾回收时，finalize中进行一些善后处理，但finalize的调用时机是由垃圾回收器决定的，可能并不会在对象成为垃圾后立马被调用，所以不推荐这种方式，该方法jdk9被标记为过时 为什么finalize方法非常不好，非常影响性能？ 非常不好： FinalizerThread是守护线程，代码很有可能还没来得及执行完，线程就结束了，造成资源没有正确释放 finalize方法中的异常会被吞掉，不抛出，可能不能判断有没有在释放资源时发送错误 影响性能： 重写了finalize方法的对象在第一次被gc时，不能及时释放内存，需要等待FinalizerThread调用完finalize，第二次gc时才能真正释放内存 gc时说明内存本就不足，finalize调用又慢（涉及到队列的移除等操作），finalize中可能还有释放连接资源等耗时操作，不能及时释放内存，这可能会让对象移到老年代（内存担保机制），老年代积累垃圾过多，可能触发full gc hashCode依赖的字段最好是不变的，如果易变，可能出现这种情况：把一个对象放入map中，然后更改这个对象的属性，那么这个对象的hashCode也会变，那么再get时，就get不出来了！","path":"2025/10/21/JavaSE/Object方法/","date":"10-21","excerpt":"","tags":[]},{"title":"静态方法为什么不能调用非静态成员？","text":"静态方法是属于类的，在类加载的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。 在类的非静态成员不存在的时候静态方法就已经存在了，此时调用在内存中还不存在的非静态成员，属于非法操作。","path":"2025/10/20/JavaSE/静态方法为什么不能调用非静态成员？/","date":"10-20","excerpt":"","tags":[]},{"title":"为什么成员变量有默认值而局部变量没有","text":"先不考虑变量类型，如果没有默认值会怎样？变量存储的是内存地址对应的任意随机值，程序读取该值运行会出现意外。 默认值有两种设置方式：手动和自动，根据第一点，没有手动赋值一定要自动赋值。那么编译器是希望我们手动赋值，还是帮我们自动赋值呢？我觉得应该是前者，因为这能很好让我们程序员在写代码的时候先初始化再使用一个变量，很清楚的知道使用一个变量时，它的值是多少，这才是比较好的规范。 所以成员变量和局部变量都应该是没有默认值的，我们需要先手动赋值，再使用变量。 对于编译器（javac）来说，局部变量没手动赋值很好判断，因为就在一个方法代码块中。没有手动赋值可以直接报错。 而成员变量可能是运行时手动赋值，编译器不知道在哪个方法就被赋值了，甚至在哪个地方可能反射给它赋值，这就无法判断是先使用还是先赋值初始化，而误报“没默认值”又会影响用户体验（都tm运行了你和我说我代码有问题？为什么编译不帮我检查出来？），所以采用自动赋默认值 kotlin就得强制赋值","path":"2025/10/20/JavaSE/为什么成员变量有默认值而局部变量没有/","date":"10-20","excerpt":"","tags":[]},{"title":"字符串常量池","text":"字符串常量池在运行时常量池中，jdk7开始字符串常量池则被移入到堆中，就是说jdk7开始字符串常量池和常量池分开了。 当在双引号””中有字面量时，就会在串池创建一个该对象，如出现“a”，就会在串池中有个”a”，又如String s &#x3D; “b”；那么串池中就有个”b”，这里注意，除了后面说的一种特殊情况，其它正常来说只要在双引号有字面量，就会在串池创建对象，如String s &#x3D; new String(“c”)；这里既有双引号，又有关键字new，就会在串池和堆中分别创建”c”和一个字符串对象”c”，这句话创建了两个对象！但s的引用是指向堆中的字符串对象。 当要在串池中创建对象时，会去检查串池中有没有该对象，没有才创建，如String s1 &#x3D; “a”;String s2 &#x3D; “a”，则s1和s2的地址是一样的，都是指向串池中的”a”，但如果是String s1 &#x3D; new String(“a”);String s2 &#x3D; new String(“a”)，则s1和s2的地址是不一样的，因为两者分别指向堆中的两个不同的字符串对象，当然，在创建s1的时候在串池中创建”a”，但创建s2时发现串池中已经有”a”了，就不会再创建。 字符串拼接有两种，一种是字符串常量拼接，另一种是字符串变量拼接。当加号+左右都是常量时才是常量拼接，当出现一个变量或加号左右都是变量时就是变量拼接 编译器在编译期间（javac）会先把所有常量拼接好，换句话说class文件中只有变量拼接。先说字符串常量拼接吧，字符串常量拼接原理是编译器优化，如有String s1 &#x3D; “ab”；String s2 &#x3D; “a” + “b”；这里s2是由两个常量拼接来的，在编译器这句话就会变成String s2 &#x3D; “ab”；也就是说在class文件就没有”a”和”b”了，这就是之前说的特殊情况，java文件中的双引号中有字面量，但不会在串池中创建对象，因为被编译器优化了，实际上在class文件中没有”a”和”b”，故这里s1和s2都是串池中的”ab”，是同一个串池对象。 再说字符串变量拼接，字符串变量拼接原理是StringBuilder，就是说有String s1 &#x3D; “a”；String s2 &#x3D; “b”；String s3 &#x3D; s1 +s2；那么这句话本质其实是，String s3 &#x3D; new StringBuilder().append(“a”).append(“b”).toString()；可以理解为String s3 &#x3D; new String(“ab”)，但这里不会往串池中放入”ab”，因为这是拼接后的结果，class文件中没有”ab”。最终结果是：串池中有”a”,”b”，堆中有个字符串对象”ab”，过程中出现了个StringBuilder对象。当然，串池从jdk7开始也是在堆中，但只是堆单独划出的一部分，没有和堆融合。再补充一点，被final修饰的变量可以当常量处理。 那么，String s &#x3D; new String(“a”) + new String(“b”)；这句话创建了几个对象呢，首先有双引号，双引号中有字面量”a”,”b”，所以会在串池中创建两个对象”a”,”b”，因为还有两个new，所以会在堆中创建两个字符串对象，对象的值也分别为”a”,”b”，但和串池中的不是同一个，一个在串池，一个在堆中。又因为这是字符串变量拼接，所以还有new一个StringBuilder对象，最后结果是String s &#x3D; new String(“ab”)；又在堆中创建了一个字符串对象”ab”，所以一句话总共创建了六个对象，串池中”a”,”b”，堆中”a”,”b”,”ab”还有一个StringBuilder。 String s &#x3D; new String(“a”) +”a”+”b”；这句话创建了几个对象？5个（串池中a，ab，堆中a，aab，stringBuilder） intern方法会将一个字符串对象主动放入串池： 如果串池中已经有这个字符串： 那么就不会再放入，并返回串池中该对象的引用。 如果串池中没有该字符串： jdk7以前：新建一个字符串对象放入串池，也就是说串池和堆中的对象不是同一个，然后会返回串池里的那个的引用。 jdk7开始：把堆中的引用放入串池，即串池和堆中的对象是同一个，方法返回串池中的引用。即这里串池中的地址，堆中的地址和返回的地址是同一个，都源自于堆中的那个对象。 比如有String s1 &#x3D; “a”；String s2 &#x3D; s1.intern()；那么s1&#x3D;&#x3D;s2的，因为串池中已经有”a”了，intern()返回的是串池中的引用。 再比如String s1 &#x3D; new String(“a”) + new String(“b”)；String s2 &#x3D; s1.intern()，在jdk7以前，s1 !&#x3D; s2，因为intern是串池中创建新的对象，两个”ab”是不同的；jdk7开始s1&#x3D;&#x3D;s2，因为intern是把堆中的地址放入串池，串池和堆中的”ab”是同一个对象。","path":"2025/10/20/JavaSE/字符串常量池/","date":"10-20","excerpt":"","tags":[]},{"title":"limit","text":"SELECT * FROM users ORDER BY id LIMIT 10, 20; 从偏移量为10开始，返回20行记录，即第11到第30行记录 如果是limit 20000000 10，那会把前两千万条数据查出来，然后丢弃，然后从第20000001行开始返回10行，性能极低，这就是深度分页问题 深度分页优化： 可以把每次查询到的最大id记录下来，下次从这个id开始继续查： SELECT * FROM users WHERE id &gt; last_max_id ORDER BY id LIMIT 10; 但这种方案不能往回查，只能一页一页往后查，且查询过程中不能有新增 id不能重复，不然就会陷入死循环，比如一页的10条，ID全是12，last_max_id也为12，那么下一页的查询还是&gt;&#x3D; 12 覆盖索引 + 子查询： SELECT * FROM users WHERE id &gt; (SELECT id FROM users ORDER BY id LIMIT 20000000, 1) ORDER BY id LIMIT 10; 子查询在主键索引上查询，不需要回表，得到第20000001的id，然后主查询根据id进行范围查询 使用ES，ES也有深分页问题，但影响比MySQL小点 【【IT老齐074】从76237到753毫秒,海量数据大页码MySQL查询该如何优化？】https://www.bilibili.com/video/BV1PL411g7Vj?vd_source&#x3D;cae07b1dce3e6abe67fcf72c43031ede 产品上解决问题：","path":"2025/10/20/MySQL/limit/","date":"10-20","excerpt":"","tags":[]},{"title":"架构","text":"旧表拆分为分库分表过程： 双写读老阶段：通过中间件，对write sql同时进行两次转发，也就是双写，保持新数据一致，同时开始历史数据拷贝。本阶段建议施行一周； 双写双读阶段：采用灰度策略，一部分流量读老表，一部分流量读新表，读新表的部分在一开始，还可以同时多读一次老表数据，进行比对检查，观察无误后，随着时间慢慢切量到新表。本阶段建议施行至少两周； 双写读新阶段：此时基本已经稳定，可以只读新表，为了安全保证，建议还是多双写一段时间，防止有问题遗漏。本阶段建议周期一个月； 写新读新阶段：此时已经完成了分表的迁移，老表数据可以做个冷备 MySQL主从复制 MySQL的主从是由从节点主动去读主节点的binlog，然后保存到自己的中转日志处Relay Log，并在本地执行。此时不管Slave是否已接收binlog, Slave写relay log失败、重新执行SQL语句失败等异常情况并不会被Master感知，所以数据一致性无法得到有效保障 MySQL 5.5版本提供了半同步复制模式：Master在提交事务前，会等待Slave接收binlog, 当至少有一个Slave确认接收了binlog后，Master才提交事务。具体来说，Slave在收到binlog并将其写入relay log后，会向Master发送ACK响应；Master在收到ACK响应后， 认为响应发送方Slave已经在relay log中保存了事务，这时才进行事务的提交 Master会因为向过多的Slave复制数据而压力倍增，这个问题被称为“复制风暴”。所 以实际的主从模式架构可能是一些Slave向Slave复制数据，以减轻Master的复制压力， 一主多从，从挂从","path":"2025/10/20/MySQL/架构/","date":"10-20","excerpt":"","tags":[]},{"title":"后台线程","text":"Master Thread： 非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性。包括脏页的刷新、刷盘redo、合并插入缓冲和undo页的回收等 IO Thread： InnoDB中大量使用了异步IO，IO Thread主要负责这些IO请求的回调处理。分有write、read、insert buffer和log Thread Purge Thread：InnoDB 1.1加入，回收undo页，减轻Master Thread负担 Page Cleaner Thread：InnoDB 1.2.x版本中加入，刷新脏页，减轻Master Thread负担 InnoDB 1.0.x 版本之前的Master Thread： 由多个循环（loop）组成：主循环（loop）、后台循环（background loop）、刷新循环（flush loop）、暂停循环（suspend loop） 主循环（loop）： 每秒的操作：日志缓冲刷新到磁盘（总是，即使这个事务还没提交） 合并插入缓冲（如果前一秒内的IO次数小于5次才执行这个操作） 至多刷新100个脏页到磁盘（脏页比例超过innodb_max_dirty_pages_pct（默认90，代表90%）的话执行这个操作） 切换到background loop循环（如果当前没有用户活动的话） 每十秒的操作：刷新100个脏页到磁盘（如果过去十秒内的IO次数少于200次的话） 合并至多5个插入缓冲（总是） 将日志缓冲刷新到磁盘（总是） 删除无用的undo（总是，最多尝试回收20个） 刷新100个或者10个脏页到磁盘（总是，如果脏页比例超过70%，刷100个，否则刷10个） 后台循环（background loop）： 删除无用的undo（总是） 合并20个插入缓冲（总是） 切换到flush loop循环（如果当前空闲的话） 跳回到主循环（如果当前不空闲的话） 刷新循环（flush loop）： 不断刷新100个脏页直到脏页比例小于innodb_max_dirty_pages_pct 切换到suspend loop循环 暂停循环（suspend loop）： 将Master Thread挂起，等待事件发生，有事件发生切换到loop主循环 InnoDB1.2.x版本之前的Master Thread： InnoDB1.0.x之前的Master Thread做了许多硬编码，把参数写死了，InnoDB1.0.x开始提供了参数innodb_io_capacity，默认值200 在合并插入缓冲时，合并的数量为innodb_io_capacity的5% 刷新脏页时，刷新脏页的数量为innodb_io_capacity innodb_max_dirty_pages_pct默认值从90调为75 新增参数innodb_adaptive_flushing（自适应地刷新，默认为on，打开），通过redo log的产生速度决定最合适的刷新脏页数量，当脏页比例小于innodb_max_dirty_pages_pct时也会刷新一定量的脏页 新增参数innodb_purge_batch_size，默认值20，每次回收undo页的数量由该值决定 当数据库压力大时，Master Thread的主循环并不总是等待一秒，会加快速度 InnoDB1.2.x版本的Master Thread： 刷新脏页的操作分离到单独的Page Cleaner Thread线程","path":"2025/10/20/MySQL/后台线程/","date":"10-20","excerpt":"","tags":[]},{"title":"结合deepWiki阅读源码","text":"","path":"2025/10/17/ai 应用相关/结合deepWiki阅读源码/","date":"10-17","excerpt":"","tags":[]},{"title":"链表","text":"合并两个有序链表[306]1","path":"2025/10/16/Codetop刷题/链表/","date":"10-16","excerpt":"","tags":[]},{"title":"InnoDB关键特性","text":"插入缓冲当要插入数据时，对于唯一索引来说： 若索引页在内存的话，则往内存插入。若不在，则先把对应的索引页加载到内存，然后判断是否重，然后插入 对于非唯一索引而言，对应的索引页在内存的话，同上，然后写redo。 而对于不在的情况，则是将“插入xxx数据”记录到insert buffer（其实insert buffer是一个 b+树）里，同时将 写 insert buffer这个行为写一条日志到redo log（此时的redo就不是传统意义上的物理日志），整个操作没 有磁盘IO change buffer是InnoDB1.0x对insert buffer的升级，扩展了delete buffer（标记删除），purge buffer（真 正删除）。change buffer不仅可以缓冲插入，更改和删除也可以。change buffer位于buffer pool中，大小 由innodb_change_buffer_max_size。默认为25，最多占buffer pool的25%，最大有效值可为50，超50还是 50 insert buffer 里有个bitmap用来追踪每个二级索引页的可用空间 什么时候合并insert pool到真正的二级索引页中？1. 当二级索引页加载时，通过bitmap发现内存存在了，这时候就会合并 2. 发现二级索引页缓冲的数据占用已经小于1/32，则会强制从磁盘里读数据然后合并数据 3. master Thead 后台线程每10秒一次 4. 数据库正常关闭 什么时候change buffer落盘1. 数据库空闲时，后台进程落盘 2. 缓冲池不够用了 3. 数据库正常关闭时 4. redo写满了 为什么要把change buffer中的记录写redo同样也是为了持久化么。当使用到change buffer意味着内存还没有这数据，如果这时候宕机了，数据就没了 这时候做redo就是为了宕机重启后可以恢复内存数据。 当宕机重启时： 先看事务是否提交，无提交直接回滚。提交了就看change buffer是否落盘，有，则直接使用change buffer 恢复数据；没有就通过redo 恢复changbuffer，再通过change buffer恢复数据 可以不使用change buffer，只使用redo记录吗PS：（虽然说redo log是顺序磁盘IO，某种情况是要比change buffer的随机内存速度快的）。change只是记 录了插入这个操作，并没有真正地插入到真正的索引页上！！！ 不行，因为change buffer里维护了insert bit map。用来快速追踪哪些页是需要合并插入缓冲的，当这些页 被加载到内存时，就可以被合并了。如果单靠redo log的话，当被合并的页加载到内存是无法感知的。而且 redo log是循环记载，会被加载到磁盘，也就是写入磁盘前必须** 合并插入缓冲区（因为redo log里有change ** buffer的插入记录），这会加重redo log的负担 Change Buffer &#x3D; 存着很多“等待插入索引页的记录”那么“哪些页需要合并”就是 哪些页已经有“待插入的缓存记录”但还没真正写入。 合并（Merge） &#x3D; 把 Change Buffer 中某页的缓存记录，真正插入到该页中。 写了redo log，为什么buffer pool还要落盘？缓冲池大小有限，如果需要insert的页一直没被加载，insert pool会一直积累，需要落盘腾空间 两次写？double write由两个部分组成，一个double buffer位于内存，2mb，另外一个位于磁盘上，buffer area上， 同样也是2mb 刷新脏页时，并不是直接把脏页数据直接刷到磁盘对应的表空间，而是先copy到double write buffer。然后 由double write buffer顺序写入double write area（这时候意味着这些页数据已经被持久化了）。然后再从 double write buffer执行fsync 将里的数据刷到各自的表空间，多了两个步骤 1.脏页数据被copy到了double write buffer 2.直接落到各自的表空间前顺序写入到了double write area里 为什么要这么搞？如果刷脏页，一个脏页16kb，如果写一半宕机了，就会出现磁盘的表数据人不人鬼不鬼的。 有了double write area后，如果宕机重启后，会检查double write area是否有对应完整页数据，如果有的话就完整恢复 没有的话，则意味着没落盘。（其实细想的话也是一种先写日志的操作） 那么这种丢失能否通过redo恢复？答案是不行！因为redo是物理日志，记录要对页文件进行的物理修改，它记载了：对xx页偏移量500的位置写入aaa、将xx页偏移量650的位置的数据由bbb改为ccc。但现在的问题是，你的页是缺失或者只更改了一部分的！页已经发生了损坏，再对其重做是没有意义的 如果脏页在从内存中的doublewrite buffer 写入到磁盘中的doublewrite 中发生了宕机怎么办？ 没有影响，这说明你还没向磁盘中刷新脏页，磁盘中的数据是完整的，宕机重启后可以根据redolog进行数据恢复 为什么要双写 问题 Doublewrite 帮你解决什么？ 写盘时崩溃可能导致页“写了一半” 有 Doublewrite 做缓冲区，保证每个页要么完整写入，要么完整回滚 随机写很慢 先顺序写到 doublewrite area → 再随机写本体，提升整体效率 两次写默认打开，可通过innodb_doublewrite关闭 自适应hash索引InnoDB自动根据访问的频率和模式自动地为某些热点页建立哈希索引 异步IO刷盘和从磁盘加载页数据都是异步IO，且会根据实际情况进行IO merge，如发现读取的页是连续的，就会连 续读取，而不是一页页读 刷新邻接页： 刷新一个脏页时，会检测该页所在区的所有页，如果是脏页，一起刷新，多次IO合并为一个IO，但可能有以下问题： 是否将不怎么脏的页刷新了？该页很快又变脏了 固态硬盘有较高的IOPS，是否还需要这个特性？ 为此，InnoDB1.2.x版本开始提供参数innodb_flush_neighbors决定是否启动该功能，默认为0，不启动","path":"2025/10/14/MySQL/引擎/InnoDB/InnoDB关键特性/","date":"10-14","excerpt":"","tags":[]},{"title":"说说MySql的一条SQL的执行过程","text":"如一条简单的查询语句：&lt;font style=&quot;color:rgba(25, 26, 31, 0.9);&quot;&gt;select * from users where age=&#39;18&#39; and name=&#39;Hollis&#39;;&lt;/font&gt; 执行过程如下图： 结合上面的说明，我们分析下这个语句的执行流程： ①使用连接器，通过客户端&#x2F;服务器通信协议与 MySQL 建立连接。并查询是否有权限 ②Mysql8.0之前检查是否开启缓存，开启了 Query Cache 且命中完全相同的 SQL 语句，则将查询结果直接返回给客户端； ③由解析器（分析器）进行语法分析和语义分析，并生成解析树。如查询是select、表名users、条件是age&#x3D;’18’ and name&#x3D;’Hollis’，预处理器则会根据 MySQL 规则进一步检查解析树是否合法。比如检查要查询的数据表或数据列是否存在等。 ④由优化器生成执行计划。根据索引看看是否可以优化 ⑤执行器来执行SQL语句，这里具体的执行会操作MySQL的存储引擎来执行 SQL 语句，根据存储引擎类型，得到查询结果。若开启了 Query Cache，则缓存，否则直接返回。","path":"2025/10/14/MySQL/SQL语句执行过程/说说MySql的一条SQL的执行过程/","date":"10-14","excerpt":"","tags":[]},{"title":"数据库扫表任务如何避免出现死循环","text":"假如我们有一张表case_event，其中有一个字段state，它有三个值，分布是INIT、SUCCESS、以及 FAILED。 那么在定时任务中，我们需要把 INIT 的数据扫描出来进行执行，一般来说是这么写的 SQL： 12345SELECT * FROM case_eventWHERE STATE = &#x27;INIT&#x27; ORDER BY ID LIMIT 200;//以上的数据拿出来执行 那么这时候状态就会变成 success 或者 Fail 这个 SQL 看上去没啥问题，其实就是每次扫描200条记录处理。 但是这个SQL其实是一个典型的 bad case，因为他会出现一个致命的问题，那就是可能会导致扫描任务一直无法执行。 因为上述的 SQL 相当于默认了每一条记录执行之后，都能把状态推进到 SUCCESS 或者 FAILED。但是事实上并不一定的，尤其是在一些有很复杂的业务逻辑，或者一些外部调用的时候，这个地方就变成了一个分布式事务，我们没办法保证最后的 INIT-&gt;SUCCESS 或者 INIT-&gt;FAILED 一定能成功。即还是INIT 那如果不能成功，就会导致一部分失败的状态一直处于 INIT 状态，那么他就会每次都会被扫描起来（因为他还在前200条之内），然后还是不成功，下次还会被扫描出来。 这样一方面会大大降低任务的效率，一直在重复执行这些不断失败的任务，另一方面，一旦失败的条数达到了200条，那么就意味着每次扫出来的数据都是这200条，导致后面的任务永远无法被执行到。 这里的失败指的是没法推进状态 以及 执行失败 而如果你的SQL 是这么写的，那么这个问题就更大了： 1234SELECT * FROM case_eventWHERE STATE in (&#x27;INIT&#x27; ,&#x27;FAILED&#x27;)ORDER BY ID LIMIT 200; 相当于你在不断的重复执行那些固定的任务，而后面的很多任务一直无法被执行。 一直在重复执行者两百条永远执行失败的任务，而后面的任务就管了一点了 如何解决这个问题呢，有一个方式，那就是增加一个游标，让你的每次查询都往后移动，如： 12select * from task where status = &#x27;init&#x27; and id &gt; #&#123;id&#125;order by id limit 200 这里每次查询的时候，都把上一次的查询结果中的最大id 带过来，然后就可以避免再次扫描到重复的任务了，就可以让本次任务调度正常完成执行。","path":"2025/10/13/MySQL/数据库扫表任务如何避免出现死循环/","date":"10-13","excerpt":"","tags":[]},{"title":"MySQL的varchar(50)和varchar(500)区别?","text":"https://juejin.cn/post/7350228838151847976 这个的话，如果说是磁盘占用其实都是一样的，比如说你一个字段为20，那么磁盘所占用的一定是20 但如果从内存占用来说，这两个就有比较大的区别的了。你把这个字段读到内存时，为这个字段申请的内存是根据varchar（xx）这东西来确定的，因为我们操作系统本身为数据申请内存，都有预申请的一个过程，一次申请多少呢。 总结的核心结论： &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR&lt;/font&gt;的“可变长度”特性主要体现在磁盘存储上，使其能节省空间。 在内存中，为了性能和简化数据读取流程，MySQL 会为 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR&lt;/font&gt;列预先分配其定义的最大长度 (**&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;**) 所需的空间。 这种内存分配机制意味着过度定义**** **&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR&lt;/font&gt;**的最大长度 (**&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;**) 会直接导致内存浪费，这种浪费是普遍存在的（不仅限于排序操作）。 因此，在定义 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR&lt;/font&gt;字段时，务必根据实际业务需求，选择一个足够用但又不会过度冗余的最大长度 (**&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;**)，以平衡磁盘空间节省和内存使用效率。&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(255)&lt;/font&gt;的流行与其在单字节长度前缀下的存储效率优化有关。 磁盘存储（节省空间）： &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR&lt;/font&gt;在磁盘上存储的是实际数据 + 一个或两个字节的长度前缀。 长度前缀指示了该字段值实际占用的字节数。 因此，磁盘空间占用是可变的，只取决于实际存储的数据长度（加上很小的长度前缀开销）。定义的最大长度 (&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(N)&lt;/font&gt;) 只限制了能存储多少数据，不影响实际存储空间（除非数据达到最大长度）。 内存分配（固定大小）： 当 MySQL 从磁盘读取一行数据到内存时，它需要预先为每一列分配内存空间。 在读取具体数据内容之前，MySQL 只知道该列的定义：它是一个 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR&lt;/font&gt;，并且其最大允许长度是**** **&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;**字节。 MySQL 无法在读取数据之前知道该字段在这一行中的实际长度是多少（是 10 还是 20？）。这个实际长度信息是存储在数据本身的开头（长度前缀）。 为了能够安全地接收从磁盘读取出来的整行数据（包括所有列），MySQL 必须为每个 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR&lt;/font&gt;列分配足够容纳其最大可能长度 (**&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;**) 的内存空间。 关键原因：性能。 如果每次读取一行时，都尝试先读取长度前缀，再根据这个长度精确申请内存，然后再读取实际数据，会导致大量的、细碎的内存分配操作和额外的 I&#x2F;O 定位。这会极大地降低数据读取的性能。预先按最大长度分配内存虽然可能浪费一些空间，但避免了频繁的内存申请开销，是性能与内存利用之间的权衡。 定义长度 (**&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;**) 的重要性： 正因为内存分配是按定义的最大长度 (&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;) 进行的，所以 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(N)&lt;/font&gt;中的 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;直接影响内存消耗。 即使你存储的实际数据很短（比如 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(255)&lt;/font&gt;只存了 10 个字符），MySQL 在内存中也会为该字段预留 255 字节（或根据字符集计算出的最大字节数）的空间。 过度定义**** **&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;**(如**** **&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(1000)&lt;/font&gt;**但实际只用 10 字节) 会导致严重的内存浪费。 这种浪费不仅发生在排序等需要临时表的操作中（如原文所述），也发生在任何将行数据读入内存的操作中（如简单的 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;SELECT&lt;/font&gt;查询、连接操作、在内存中更新数据等）。这就是为什么强调“即使不排序，也可能有其它内存不够的问题出现”。 255 字节的特殊性： 长度前缀需要占用空间。对于最大长度 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;&lt;&#x3D; 255 字节的 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR&lt;/font&gt;，长度前缀只需要 1 个字节。 对于最大长度 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;N&lt;/font&gt;&gt; 255 字节的 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR&lt;/font&gt;，长度前缀需要 2 个字节。 因此，&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(255)&lt;/font&gt;是一个非常常见的定义： 它充分利用了单字节长度前缀能表示的最大长度（255）。 定义 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(256)&lt;/font&gt;会导致长度前缀变成 2 字节，而实际能存储的数据只比 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(255)&lt;/font&gt;多 1 字节（256 vs 255），但长度前缀开销翻倍（2字节 vs 1字节）。从存储效率角度看，&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(255)&lt;/font&gt;是单字节长度前缀下的最优选择。 注意： 这里的 255&#x2F;256 指的是字节数，不是字符数。对于多字节字符集（如 UTF8MB4），一个字符可能占用多个字节，&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;VARCHAR(255)&lt;/font&gt;能存储的字符数会少于 255。","path":"2025/10/13/MySQL/MySQL的varchar(50)和varchar(500)区别/","date":"10-13","excerpt":"","tags":[]},{"title":"开放式数据量级问题","text":"TOPK 堆排序维护一个 n &#x3D; k 的堆 PriorityQueue，for i &lt; 数据量级来元素就加进去，如果超过了 k，就poll 堆顶元素 时间复杂度就是 数据量级 log K 空间复杂度，因为堆本质其实就是一数组，空间为 O k 类似快排法使用hash对于这种问题 字典树混合查询 有一批文件，每个文件里面有很多单词，如何快速统计所有单词的出现次数?数据重复、是否存在问题位图bitmap 其实就是对HashSet或者数组的一个压缩版 Java的BItSet 海量数据的极致优化还有 压缩位图 布隆过滤器解决 return true 就表示 可能在 和 return false 就表示 一定不在的 解决的业务问题： 找出排名前500的数 方法 思路 时间复杂度 空间复杂度 优劣 方法1：逐个归并（维护 top500） 先取第一个数组的后500个，然后与后续数组逐个合并，再保留最大500个 每次合并 500 + 500 → O(500)，共 10000 次 → O(10000 × 500) &#x3D; 5×10⁶ ≈ 5M O(500) 简单稳定 方法2：多路堆（K 路最大堆） 每个数组取最后一个元素（最大值）放入大顶堆，每次弹出一个并往回移动指针 每次堆操作 log10000，执行500次 → O(500 × log10000) ≈ 500 × 14 &#x3D; 7000，外加初始化堆 10000 → 10000log10000≈ 140000 → 总约 15 万 O(10000 + 500) 性能最优 堆本质上就是一颗完全二叉树 多路堆，最优解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.util.*;public class Top500FromSortedArrays &#123; static class Node &#123; int value; // 元素值 int row; // 来自哪个数组 int index; // 在该数组中的下标（倒序移动） Node(int value, int row, int index) &#123; this.value = value; this.row = row; this.index = index; &#125; &#125; public static List&lt;Integer&gt; top500(int[][] arrs) &#123; int k = arrs.length; // 数组个数 (10000) PriorityQueue&lt;Node&gt; maxHeap = new PriorityQueue&lt;&gt;( (a, b) -&gt; b.value - a.value // 大顶堆 ); // 初始化：每个数组的最后一个元素入堆 for (int i = 0; i &lt; k; i++) &#123; int lastIndex = arrs[i].length - 1; maxHeap.offer(new Node(arrs[i][lastIndex], i, lastIndex)); &#125; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); // 存前500 for (int count = 0; count &lt; 500 &amp;&amp; !maxHeap.isEmpty(); count++) &#123; Node top = maxHeap.poll(); result.add(top.value); // 往前移动一个位置，继续加入该数组的下一个大值 if (top.index - 1 &gt;= 0) &#123; maxHeap.offer(new Node(arrs[top.row][top.index - 1], top.row, top.index - 1)); &#125; &#125; return result; &#125; public static void main(String[] args) &#123; // 构造一个简单的测试用例 (真实情况是10000×500，这里只演示) int[][] data = &#123; &#123;1, 3, 5, 7, 9&#125;, &#123;2, 4, 6, 8, 10&#125;, &#123;11, 12, 13, 14, 15&#125; &#125;; System.out.println(top500(data)); // 输出最大的前5个 &#125;&#125; 两个大文件中找出共同URL 64 byte * 50 亿 ，一个文件 320g 全加载到内存 建立Hash表，那肯定是不现实的。 还是 分治 对A ：hash(url) % 1000 -&gt; 1000个小文件 命名为 a0,a1,a2….. a999 对B：同样，hash一定得相同 那么a99 和 b99里面可能存在相同的。但a99和a98里面的就不可能出现相同的 然后再把小文件加载到内存，建立hashmap","path":"2025/10/11/场景题/开放式数据量级问题/","date":"10-11","excerpt":"","tags":[]},{"title":"SQL面试题","text":"语法基础CURD1234INSERT INTO TABLE (XXX)VALUE( XX,XX)SELECT XX FROM TABLE UPDATE TABLE SET &#x27;XX&#x27; = XX WHEREDELETE FROM TABLE WHERE 查询DISTINCT(去重)12SELECT DISTINCT name, city FROM users;对(name,city) 所有列去重，即sql语句里写的 LIMIT()限制返回的行数。第一个参数为起始行，从 0 开始；第二个参数为返回的总行数 123456//返回前5行SELECT city,name FROM TABLE LIMIT 5;SELECT city,name FROM TABLE LIMIT 0,5;//返回2-5行SELECT city,name FROM TABLE LIMIT 2,3; 排序 ASC：升序 DESC：降序 可以按多个列进行排序，并且为每个列指定不同的排序方式: 123SELECT *FROM mytableORDER BY col1 DESC, col2 ASC; 过滤 操作符 示例 SQL 说明 = SELECT * FROM students WHERE city = &#39;北京&#39;; 等于 &lt; SELECT * FROM students WHERE age &lt; 20; 小于 &gt; SELECT * FROM students WHERE score &gt; 90; 大于 &lt;&gt; 或 != SELECT * FROM students WHERE city &lt;&gt; &#39;北京&#39;; 不等于 &lt;= &#x2F; !&gt; SELECT * FROM students WHERE age &lt;= 18; 小于等于 &gt;= &#x2F; !&lt; SELECT * FROM students WHERE score &gt;= 90; 大于等于 BETWEEN SELECT * FROM students WHERE score BETWEEN 80 AND 90; 在两值之间（包含边界） IS NULL SELECT * FROM students WHERE remark IS NULL; 是 NULL IS NOT NULL SELECT * FROM students WHERE remark IS NOT NULL; 不是 NULL AND SELECT * FROM students WHERE age &gt; 18 AND score &gt; 80; 同时满足两个条件 OR SELECT * FROM students WHERE city = &#39;北京&#39; OR city = &#39;上海&#39;; 满足任一条件 () 优先级 SELECT * FROM students WHERE city=&#39;北京&#39; OR (age &lt; 20 AND score &gt; 80); 加括号调整逻辑 IN SELECT * FROM students WHERE city IN (&#39;北京&#39;, &#39;上海&#39;); 等价于多个 OR IN (SELECT ...) SELECT * FROM students WHERE id IN (SELECT id FROM scores WHERE score&gt;90); 从子查询匹配 NOT SELECT * FROM students WHERE NOT city = &#39;北京&#39;; 否定条件 通配符 通配符 示例 SQL 说明 %（&gt;&#x3D;0 个字符） SELECT * FROM students WHERE name LIKE &#39;张%&#39;; 匹配所有以“张”开头的名字，例如“张三”、“张小明” %abc% SELECT * FROM students WHERE city LIKE &#39;%京%&#39;; 匹配包含“京” 的城市，例如“北京”、“南京” _（&#x3D;1 个字符） SELECT * FROM students WHERE name LIKE &#39;_三&#39;; 匹配第二个字是“三”的两个字名字，如“张三”，但不匹配“王小三” [ab] SELECT * FROM students WHERE name LIKE &#39;[李王]%&#39;; (部分数据库支持，如 SQL Server) 匹配姓李或姓王的学生 [^ab] SELECT * FROM students WHERE name LIKE &#39;[^李王]%&#39;; 匹配不姓李也不姓王的学生 计算字段 函数汇总(重要) 汇总函数 作用 示例 SQL 示例结果 COUNT(*) 计算总行数（包含 NULL） SELECT COUNT(*) FROM students; 5 COUNT(col) 统计非 NULL 的个数 SELECT COUNT(score) FROM students; 4（NULL 被忽略） AVG(col) 计算平均值（忽略 NULL） SELECT AVG(score) FROM students; (85+90+75+95) / 4 = 86.25 SUM(col) 求和（忽略 NULL） SELECT SUM(score) FROM students; 85+90+75+95 = 345 MAX(col) 最大值 SELECT MAX(score) FROM students; 95 MIN(col) 最小值 SELECT MIN(score) FROM students; 75 1234567AVGSUMMINMAXCOUNT(*) //统计全部COUNT(col) //统计非空 、 1ACG( DISTINCT col) 只会对不同的col做汇总 日期&amp;文本数组处理分组!(重要)分组 其实就是把相同的数据值的行放到同一组中 通过我们会要求 返回的是每一组的一个汇总情况 指定的分组字段除了能按该字段进行分组，也会自动按该字段进行排序。即group by会自动排序 WHERE 过滤行，HAVING 过滤分组，行过滤应当先于分组过滤。 12345SELECT cal,SUM(age) AS cnt FROM TABLE WHERE name LIKE &#x27;XX%&#x27; GROUP BY cal ORDER BY xxx HAVING cnt &gt; 2 规则 除了那个汇总字段外，select里出现的字段都应该在 group by中给出 order by 应该在 group by之后 NULL 的行会单独分为一组； MySQL 的group by不支持blog text，其实大多数 SQL 实现不支持 GROUP BY 列具有可变长度的数据类型。PS：char()为固定，varchar()为可变 子查询！！！子查询只能返回一个字段的数据 可以将子查询的结果作为 WHRER 语句的过滤条件: 1234SELECT *FROM mytable1WHERE col1 IN (SELECT col2 FROM mytable2); 下面的语句可以检索出客户的订单数量，子查询语句会对第一个查询检索出的每个客户执行一次: 123456SELECT cust_name, (SELECT COUNT(*) FROM Orders WHERE Orders.cust_id = Customers.cust_id) AS orders_numFROM CustomersORDER BY cust_name; 标量子查询1️⃣ 结构分析 外层 SELECT 1SELECT (子查询) AS SecondHighestSalary 外层 SELECT 里只有一个表达式：一个 标量子查询 标量子查询（scalar subquery）返回 单个值 即使没有匹配的行，MySQL 也会返回一行，值为 NULL 子查询 1SELECT salary FROM Rank_S WHERE sRank = 2 LIMIT 1 查找 sRank = 2 的工资 如果存在多行（同一工资多个员工），LIMIT 1 保证只取 一行 如果不存在第二高工资（比如表里只有一条记录），子查询 不返回任何行 → 标量子查询自动返回 NULL 2️⃣ 为什么保证一行输出 外层 SELECT 不依赖表，只是用标量子查询生成一列 MySQL 规则： 标量子查询如果没有返回值 → 结果为 NULL 外层 SELECT 至少会输出一行（列名 SecondHighestSalary，值为 NULL 或工资值） 3️⃣ 对比普通子查询1SELECT salary FROM Rank_S WHERE sRank = 2; 直接查询，没找到行 → 返回 0 行 不是标量子查询，外层没有包裹 → 可能没有任何结果行 4️⃣ 总结 标量子查询 + 外层 SELECT → 总是返回一行 LIMIT 1 保证即使有多行，也只取一行 没有匹配值 → 返回 NULL ✅ 这就是为什么你写法“即使没有第二名，也会返回一行结果” 连接连接用于连接多个表，使用 JOIN 关键字，并且条件语句使用 ON 而不是 WHERE。 连接可以替换子查询，并且比子查询的效率一般会更快。 可以用 AS 给列名、计算字段和表名取别名，给表名取别名是为了简化 SQL 语句以及连接相同表 其实就是根据某个条件把两张表的数据给拼接到一起 内连接eg： 1234SELECT A.value AS A_value, B.value AS B_valueFROM tablea AS AINNER JOIN tableb AS BON A.key = B.key; 可以不明确使用 INNER JOIN，而使用普通查询并在 WHERE 中将两个表中要连接的列用等值方法连接起来。 123SELECT A.value, B.valueFROM tablea AS A, tableb AS BWHERE A.key = B.key; 在没有条件语句的情况下返回笛卡尔积 PS：内连接；在没有条件语句的情况下返回笛卡尔积。 自连接自连接可以看成内连接的一种，只是连接的表是自身而已。 一张员工表，包含员工姓名和员工所属部门，要找出与 Jim 处在同一部门的所有员工姓名。 子查询版本 123456SELECT nameFROM employeeWHERE department = ( SELECT department FROM employee WHERE name = &quot;Jim&quot;); 自连接版本 1234SELECT e1.nameFROM employee AS e1 INNER JOIN employee AS e2ON e1.department = e2.department AND e2.name = &quot;Jim&quot;; 12ON e1.department = e2.department AND e2.name = &quot;Jim&quot; 解释： e1.department &#x3D; e2.department：找和某人同部门的员工 e2.name &#x3D; “Jim”：指定 e2 这一行是 “Jim” 换句话说，就是：查找和 Jim 在同一个部门的所有员工。 外连接外连接保留了没有关联的那些行。分为左外连接，右外连接以及全外连接，左外连接就是保留左表没有关联的行。 检索所有顾客的订单信息，包括还没有订单信息的顾客。 123SELECT Customers.cust_id, Orders.order_numFROM Customers LEFT OUTER JOIN OrdersON Customers.cust_id = Orders.cust_id; customers 表: cust_id cust_name 1 a 2 b 3 c orders 表: order_id cust_id 1 1 2 1 3 3 4 3 结果: cust_id cust_name order_id 1 a 1 1 a 2 3 c 3 3 c 4 2 b Null 组合查询使用 UNION 来组合两个查询，如果第一个查询返回 M 行，第二个查询返回 N 行，那么组合查询的结果一般为 M+N 行。 每个查询必须包含相同的列、表达式和聚集函数。 默认会去除相同行，如果需要保留相同行，使用 UNION ALL。 只能包含一个 ORDER BY 子句，并且必须位于语句的最后。 总结： 合并两个或多个 SELECT 查询的结果 默认会 去掉重复行 如果想保留重复行，用 UNION ALL 要求： 每个查询的列数必须相同 对应列的数据类型要兼容 ORDER BY 只能在最后使用一次 可以理解为把查询结果 “上下拼接在一起” 1234567SELECT colFROM mytableWHERE col = 1UNIONSELECT colFROM mytableWHERE col =2; MYSQL 8 窗口函数（重要）MySQL六种窗口函数用法案例 - 白露~ - 博客园 窗口函数（Window Function）是 SQL 中用于在不分组的前提下对行进行计算的强大功能，尤其适用于排名、累计求和、移动平均等场景。 常用窗口函数 分类 函数 常见用途 累计&#x2F;聚合 SUM(), AVG(), COUNT(), MAX(), MIN() 累计和 &#x2F; 移动平均 排序 &#x2F; 排名 ROW_NUMBER(), RANK(), DENSE_RANK() Top N、去重排序 偏移比较 LAG(), LEAD() 比较当前行与上一&#x2F;下一行 统计总数 NTILE() 分组分位（如四分位） 窗口函数细则 分类 函数 典型语法 说明 累计 &#x2F; 聚合 SUM(expr) SUM(weight) OVER (ORDER BY turn) 累积求和 AVG(expr) AVG(score) OVER (PARTITION BY class) 组内平均 COUNT(expr) COUNT(*) OVER (ORDER BY date) 累计计数 MAX(expr) MAX(salary) OVER (PARTITION BY dept) 每组最大值 MIN(expr) MIN(salary) OVER () 全局最小值 排序 &#x2F; 排名 ROW_NUMBER() ROW_NUMBER() OVER (PARTITION BY dept ORDER BY salary DESC) 连续排名（无并列） RANK() RANK() OVER (ORDER BY score DESC) 有并列，跳号 DENSE_RANK() DENSE_RANK() OVER (ORDER BY score DESC) 有并列，不跳号 偏移比较 LAG(expr, offset, default) LAG(salary, 1, 0) OVER (ORDER BY id) 取上一行数据 LEAD(expr, offset, default) LEAD(salary) OVER (ORDER BY id) 取下一行数据 分布统计 NTILE(n) NTILE(4) OVER (ORDER BY score DESC) 分成 4 份（四分位） PERCENT_RANK() PERCENT_RANK() OVER (ORDER BY score) 百分比排名 CUME_DIST() CUME_DIST() OVER (ORDER BY score) 累计分布比例 位置 &#x2F; 首尾 FIRST_VALUE(expr) FIRST_VALUE(salary) OVER (PARTITION BY dept ORDER BY salary) 组内第一个 LAST_VALUE(expr) LAST_VALUE(salary) OVER (...) 默认要配 frame 子句 NTH_VALUE(expr, n) NTH_VALUE(score, 2) OVER (...) 取第 n 个 OVER语法OVER，OVER 里只能出现 PARTITION BY 和 ORDER BY 写法 含义 OVER() 不分组也不排序，整个表算 OVER(PARTITION BY ...) 在每个组内计算 OVER(ORDER BY ...) 按顺序逐行累积 OVER(PARTITION BY ... ORDER BY ...) 分组后再排序计算 大厂真题百度2021年11月每天的人均浏览文章时长_牛客题霸_牛客网统计2021年11月每天的人均浏览文章时长（秒数），结果保留1位小数，并按时长由短到长排序 分析： :::info sum(out_time - in_time) &#x2F; count(distinct uid) as avg_time where 月份 group by day order by avg_time函数使用： 人均：sum(out_time - in_time) &#x2F; count(distinct uid) 每天的：group by day 2021年11月：where date_time() &#x3D; “” 保留1位小数：Round( value,1) ::: 1 SQL 50","path":"2025/10/11/SQL面试题/","date":"10-11","excerpt":"","tags":[]},{"title":"无标题文档","text":"","path":"2025/10/11/手写系列/无标题文档/","date":"10-11","excerpt":"","tags":[]},{"title":"Redisson延迟队列","text":"","path":"2025/10/09/Redis/Redisson/Redisson延迟队列/","date":"10-09","excerpt":"","tags":[]},{"title":"Redisson","text":"","path":"2025/10/09/Redis/Redisson/","date":"10-09","excerpt":"","tags":[]},{"title":"用户体验：如何解决流式传输与JSON结构化的矛盾","text":"在前面的内容里，我们讨论了一些让大模型高质量输出内容的方法。其中让大模型输出 JSON 格式的数据，是一个非常有效且方便的方法。但是，当我们要进一步改善用户体验，希望通过流式传输减少等待时间时，就会发现 JSON 数据格式本身存在一个问题。对于从事前端行业的你来说，JSON 应该并不陌生，它是一种封闭的数据结构，通常以左花括号“{”开头，右花括号“}”结尾。封闭的数据结构，意味着一般情况下，前端对 JSON 的解析必须等待 JSON 数据全部传输完成，否则会因为 JSON 数据不完整而导致解析报错。这就导致一个问题，即使我们在前端用流式获取 JSON 数据，我们也得等待 JSON 完成后才能解析数据并更新 UI，这就让原本流式数据快速响应的特性失效了。那么有没有办法解决这个问题呢？JSON 的流式解析办法是有的。为了解决这个问题，有些人主张规范大模型的输出，比如采取 NDJSON（Newline-Delimited JSON）的方式，要求大模型输出的内容分为多行，每一行是一个独立的 JSON。但是这么做对大模型的输出进行了限制，不够灵活，而且很可能会影响大模型推理的准确性，有点得不偿失。另外一些人则使用 JSONStream 库，根据大模型输出的 JSON 配合 JSONStream 使用，这样能一定程度上解决问题，但是也不够通用，必须要事先针对大模型输出的特定结构进行处理，而且只能在 Server 端进行处理，没法直接在前端使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@RestController@RequestMapping(&quot;/api/travel&quot;)public class TravelController &#123; private final ChatClient chatClient; public TravelController(ChatClient chatClient) &#123; this.chatClient = chatClient; &#125; @GetMapping(value = &quot;/stream&quot;, produces = MediaType.TEXT_EVENT_STREAM_VALUE) public Flux&lt;Map&lt;String, Object&gt;&gt; streamScenicSpots() &#123; String prompt = &quot;&quot;&quot; 请依次介绍中国的5个著名景点。 每个景点单独输出一个JSON对象，不要合并。 格式如下： &#123;&quot;name&quot;: &quot;景点名&quot;, &quot;desc&quot;: &quot;简介&quot;&#125; 每个景点之间用字符串 &lt;END&gt; 分隔。 &quot;&quot;&quot;; StringBuilder buffer = new StringBuilder(); return chatClient.prompt() .user(prompt) .stream() .flatMap(chunk -&gt; &#123; String text = chunk.getOutput().getContent(); buffer.append(text); // 按 &lt;END&gt; 分割 List&lt;Map&lt;String, Object&gt;&gt; ready = new ArrayList&lt;&gt;(); int idx; while ((idx = buffer.indexOf(&quot;&lt;END&gt;&quot;)) != -1) &#123; String jsonChunk = buffer.substring(0, idx).trim(); buffer.delete(0, idx + &quot;&lt;END&gt;&quot;.length()); try &#123; Map&lt;String, Object&gt; json = new ObjectMapper().readValue(jsonChunk, Map.class); ready.add(json); &#125; catch (Exception e) &#123; // 不完整的JSON先跳过 &#125; &#125; // 返回所有完整JSON块 return Flux.fromIterable(ready); &#125;); &#125;&#125;","path":"2025/10/09/ai 应用相关/用户体验：如何解决流式传输与JSON结构化的矛盾/","date":"10-09","excerpt":"","tags":[]},{"title":"八股面经","text":"计网小红书日常二面HTTP传输最小的一个字节，是多大的数据包? :::info“在 HTTP 层，理论上可以只发送 1 个字节的数据，例如一个非常小的响应体。但是 HTTP 是基于 TCP 的，而 TCP 又基于 IP，所以在网络上传输时，会被封装成 TCP&#x2F;IP 数据包。 TCP 报文段最小有 20 字节 TCP 头 + 20 字节 IP 头，总共至少 40 字节。 如果是在以太网环境下，以太网帧最小长度是 64 字节，低于这个长度会自动填充。 所以即便 HTTP 只发送 1 个字节，网络层实际传输的最小数据包大约是 64 字节。总结来说，HTTP 层最小可以 1 字节，但网络上实际传输受到协议栈和以太网最小帧限制。” 假设你在浏览器访问网站，发送了一个 HTTP GET 请求，只有 1 个字节的响应体（比如返回 “A”）： HTTP 层：响应内容是 “A”，只有 1 字节 TCP&#x2F;IP 层：加上 TCP 头 20B + IP 头 20B → 40B 以太网层：以太网帧最小 64B，不够 64B → 自动填充 结果：即使 HTTP 只传 1 字节，实际在网线上传输的也是 64 字节的帧 所以“以太网帧”就是你电脑和路由器之间实际在网线里流动的数据单元。 ::: HTTPS的原理?和HTTP区别? :::infoHTTPS 的原理，其实就是在应用层和传输层之间加了一层 TLS&#x2F;SSL，用于对 HTTP 传输的数据进行加密。 它涉及几个关键点： 握手过程 首先客户端发起请求，同时发送一个随机数、支持的密码套件，以及椭圆曲线相关参数（基点等）。 客户端本地生成一个临时私钥，并计算出对应的公钥发送给服务端。 服务端响应 服务端收到请求后，生成一个随机数，选择密码套件，也生成一个临时私钥。 每次请求都会生成新的临时私钥，以保证前向安全性（即每次会话的密钥都是唯一的，不使用固定私钥）。 密钥协商 双方通过椭圆曲线的基点、各自的私钥以及对方发送的公钥，计算出本次会话的对称加密密钥。 这个密钥之后用于加密 HTTP 传输的数据。 握手确认 第一次握手：客户端发起请求 第二次握手：服务端返回公钥和选择的密码套件 第三次握手：客户端确认并生成会话密钥 第四次握手（可选）：服务端确认信息完整 通过这几次握手，双方最终确认一个安全的会话密钥，用于本次 HTTPS 会话 HTTP 与 HTTPS 的区别 HTTP：TCP 三次握手后即可直接发送请求，传输的是明文数据。 HTTPS：除了 TCP 三次握手，还要经过 TLS 握手（大约 3~4 次），建立安全的加密会话，所以传输速度略慢，但安全性高。 ::: 传输是对称加密还是非对称加密? :::info 生成密钥后的通信就是 对称加密了 生成密钥前就是 使用的是非对称加密。对称用的密钥就是 ::: 淘天暑期网络里面交换机和路由器区别? 常见网络协议? 介绍下HTTP? 操作系统美团暑期二面操作系统里的LRU算法? :::info面试官你是想问我们在那个页面置换里面的那个吗。 其实是说，在我们因为我们的操作系统它的内存是有限的么，它就是说如果我们内存到了一定的紧张程度的话，它就是需要我们通过一个算法把这个用不到的页面置换出去，操作系统底层用的是LRU算法，但它可以选择不同算法，但是不同的内核版本，它应该有不同的一个实现然后它就是说把最久没使用的页面给淘汰出去。 这个的话，它其实是可能会有一个问题，就是说我们如果一次性加载了多个页面进来后，它可能会把以前的一个老页面给顶出去，它可能会有就是其实我们所谓的一个缓存污染这么一个问题，所以说，操作系统它底层对我们这个LRU是进行了一个改进的就是说，它通过我们一个其实跟mysql的Bufferpool算法有点类似，就是分old 和 yong区分，然后他们大概是3,7分。然后它淘汰的时候，它也是优先投入小的区域，然后直到你这个小数据被访问，它才会放到我们的一个old区，就是避免一次性读取大量数据，然后把一些老的反而真正常用数据给顶掉。所以说，我觉得这是他对LRU改进最大的一个地方，也是比较核心的一个点么 ::: a.LRU的思想是什么? :::info它就是出于一种局部性原理，就操作系统他其实有这么一个概念，一种是时间局部性，比如说你在一定时间内访问了某个数据，未来的一段时间内，你对这个数据的访问频率可能会更大，然后还有一个就是空间局部性，就是说你访问了所谓的一个数据，然后接下来，你访问这个数据的概率也是比较大的。所以说，它就是说优先淘汰掉我们以前比较久远的一个数据吧，我觉得是这样子淘汰的一个思想嗯。 ::: 用Java常见数据结构如何设计一个LRU?操作时间复杂度?线程安全性? :::info额如果用现成的话，我就会直接用jdk collection里自带的一个LInkedHashMap，其实说白了底层就是用HashMap+双向链表这样子。要详细说一下，然后Map就是作为我们的一个Key查询，因为我们缓存的根本目的还是希望通过一个key来实现O1复杂的查询么。所以说，我们肯定是得通过一个Map来进行一个 存储我们的缓存数据，然后LRU，比较好的数据结构就是双向链表么，它的目的就是说把访问的数据放到我们的一个头部么，然后把尾部的数据，就是我们不经常访问的数据，然后一旦我们的数据size大于我们的limit，就把这个尾部的数据delete掉么 Map&lt;String,Node&gt; Node1 &lt;&#x3D;&gt; Node2 插入的话是Map插一次，然后插到头结点，都是O1。 查找的话一个就是从Map里面查，容纳后就是从双向链表里找到节点，然后把它，因为它只涉及到指针的移动，所以也是O1 线程安全这一块的话，我觉得得看你怎么实现吧，如果你要简单粗暴的话，就是一把synchronized或者对象锁直接对增删改查进行加锁，这时候就是只允许一个线程进行增删改查。它这样就肯定是线程安全的么，但就是锁的粒度太大了，我们可以尝试把它放小，比如读写锁，只有写操作才加锁，读的话就没报要加锁了，但就是后面的链表指针的移动这些我觉得还是得加了。就具体看我们要怎么实现 ::: 线程池美团暑期二面h.IO耗时长，吞吐上不来，cpu又吃不满，如何优化吞吐量? 7.Go和Java最大的区别? a.协程和线程区别? b.JDK也有类似协程的东西，你知道吗?8.如何理解“全异步链路”的?(网关介绍里的)a.做过这个事，那为什么不用异步解决刚刚说的优化吞吐的事? 场景字节暑期ZSet做排行榜，需要展示前1000人的榜单，1001-1500展示实际排名，1500以后展示1000+，如何处理 Bigkey? mysql13.自己举例一个SQL，说说MySQL是如何查数据的? 14.表中有status和isDelete字段，where status&#x3D;’已完成and isDelete &#x3D;’N’超时，但数据量不大，只有一两百万条，可能是什么原因?如何解决? :::info举个例子，在数据库索引信息里有一个字段，比如叫 Cardinality，意思就是这个索引列里面有多少个不同的值，也就是索引的区分度。 一般来说，这个值越接近表里的总行数，说明每一行的数据都不一样，区分度就越高，索引效果就越好。 但如果某个字段是状态字段，比如只有 success 和 fail 两种值，各占一半，那不管你怎么建索引，这个索引的区分度都很低，因为查询 status=&#39;success&#39; 仍然会匹配表里 50% 的数据。 这种情况下数据库优化器可能会觉得“既然要扫一半，我干脆直接全表扫描就好了”，所以这个索引就不一定会被真正用上。 解决方案： “虽然表只有一两百万条数据，但 status 和 isDelete 是低区分度字段，优化器认为即使用索引过滤也要扫描大部分行，所以退化为全表扫描导致超时。解决方式是建立联合索引提升选择性或者使用覆盖索引，必要时强制优化器使用索引。” 解决方案：分页出来的数据order by limit + 内存里根据主键查询 数据 过滤出想要的数据 :::","path":"2025/09/28/八股面经/","date":"09-28","excerpt":"","tags":[]},{"title":"producor","text":"1","path":"2025/09/26/kafka/源码/producor/","date":"09-26","excerpt":"","tags":[]},{"title":"树","text":"二叉树问题思考角度就是站到ROOT节点，思考我要让左右节点返回给我什么信息。然后思考我有了这个信息后要干什么 路径总和 III[12]数组情况：和为k的子数组 思路： 暴力，以每个节点为起点出发，然后直接遍历到终点。两层for循环 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; //暴力 int res = 0; long targetSum = 0; public int pathSum(TreeNode root, int _targetSum) &#123; //暴力搜索，类似于我们 普通前缀和的 两层for循环 targetSum = (long)_targetSum; t1(root); return res; &#125; public void t1(TreeNode root)&#123; if(root == null) return; //起点 traverse(root, 0); t1(root.left); t1(root.right); &#125; public void traverse(TreeNode root,long curSum)&#123; if(root == null)&#123; return; &#125; curSum+=root.val; if(curSum == targetSum) res++; traverse(root.left, curSum); traverse(root.right, curSum); &#125;&#125; 前缀和+ 两数之和 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; //暴力 int res = 0; long targetSum = 0; //只针对单一个数 //k：前缀和 v：相同前缀和的个数 Map&lt;Long, Integer&gt; preSumCounter = new HashMap&lt;&gt;(); public int pathSum(TreeNode root, int _targetSum) &#123; //前缀和 + 两数之和 targetSum = (long) _targetSum; preSumCounter.put(0L, 1); // 前缀和为0的次数为1 traverse(root, 0); return res; &#125; public void traverse(TreeNode root, long curSum) &#123; if (root == null) &#123; return; &#125; curSum += root.val; // preSum - xx = targetSum // preSum - targetSum = xx //即在map里找是否有 树为 presum + (-targetSum) res += preSumCounter.getOrDefault(curSum + (-targetSum), 0); //更新前缀和 preSumCounter.put(curSum, preSumCounter.getOrDefault(curSum, 0) + 1); traverse(root.left, curSum); traverse(root.right, curSum); //回退 preSumCounter.put(curSum, preSumCounter.get(curSum) - 1); &#125;&#125; 二叉树中的最大路径和[173]思路 站在ROOT节点思考左右节点要返回给我什么信息？我希望左子节点返回给我左子树的最大路径和。右节点类似 思考有了这个信息要干什么。无非就是求出最大路径和四种情况leftSum + cur.val rightSum + cur.val cur.val cur.val + leftSum + rightSum 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; int res = Integer.MIN_VALUE; public int maxPathSum(TreeNode root) &#123; dfs(root); return res; &#125; public int dfs(TreeNode cur)&#123; if(cur == null) return 0; int leftSum = dfs(cur.left); int rightSum = dfs(cur.right); //子树的返回 int ret = Math.max(cur.val, Math.max(leftSum,rightSum) + cur.val); //最终结果 res = Math.max(res, Math.max(ret, cur.val + leftSum + rightSum)); return ret; &#125;&#125; 二叉树的最近公共祖先[251]思路： 法一：DFS 123456789101112131415161718192021222324252627282930313233/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; //法一 dfs return dfs(root, p, q); &#125; public TreeNode dfs(TreeNode root, TreeNode p, TreeNode q) &#123; if (root == null) &#123; return root; &#125; if (root == p || root == q) return root; TreeNode left = dfs(root.left, p, q); TreeNode right = dfs(root.right, p, q); if (left == null) return right; if (right == null) return left; if (left == right) return root; //p,q都没找到 return root; &#125;&#125; 法二：Map存子节点-&gt;父节点，然后转换成相交链表问题 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; //k：子节点 v：父节点 Map&lt;TreeNode, TreeNode&gt; map = new HashMap&lt;&gt;(); public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; dfs(root, null); //q节点的祖先 集合 Set&lt;TreeNode&gt; qZX = new HashSet&lt;&gt;(); while (q != null) &#123; qZX.add(q); q = map.get(q); &#125; while (p != null) &#123; //相交节点 if (qZX.contains(p)) &#123; return p; &#125; p = map.get(p); &#125; return null; &#125; // public void dfs(TreeNode cur, TreeNode par) &#123; if (cur == null) &#123; return; &#125; map.put(cur, par); dfs(cur.left, cur); dfs(cur.right, cur); &#125;&#125; 时间复杂度都是O( N ) 对称二叉树[91]思路： 1. 1234567891011121314151617181920212223242526272829303132class Solution &#123; public boolean isSymmetric(TreeNode root) &#123; if(root==null) &#123; return true; &#125; //调用递归函数，比较左节点，右节点 return dfs(root.left,root.right); &#125; boolean dfs(TreeNode left, TreeNode right) &#123; //递归的终止条件是两个节点都为空 //或者两个节点中有一个为空 //或者两个节点的值不相等 if(left==null &amp;&amp; right==null) &#123; return true; &#125; if(left==null || right==null) &#123; return false; &#125; if(left.val!=right.val) &#123; return false; &#125; //再递归的比较 左节点的左孩子 和 右节点的右孩子 //以及比较 左节点的右孩子 和 右节点的左孩子 return dfs(left.left,right.right) &amp;&amp; dfs(left.right,right.left); &#125;&#125;作者：王尼玛链接：https://leetcode.cn/problems/symmetric-tree/solutions/46560/dong-hua-yan-shi-101-dui-cheng-er-cha-shu-by-user7/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 翻转二叉树[67]思路： 翻转左右子节点就好，然后就交给递归函数了 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; public TreeNode invertTree(TreeNode root) &#123; return dfs(root); &#125; public TreeNode dfs(TreeNode root) &#123; if (root == null) return null; TreeNode left = dfs(root.left); TreeNode right = dfs(root.right); //在根节点 交换左右子节点即可 root.left = right; root.right = left; return root; &#125;&#125; 二叉树的最大深度[87]思路（DFS）： if(root.left &#x3D;&#x3D; null &amp;&amp; root.right &#x3D;&#x3D; null) 结果更新时 思路（BFS）: 层序遍历，每过一层 depth++ 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; //int cnt = 0; int res = Integer.MIN_VALUE; public int maxDepth(TreeNode root) &#123; if(root != null)&#123; dfs(root,1); return res; &#125; return 0; &#125; public void dfs(TreeNode root,int cnt)&#123; if(root == null) &#123; return ; &#125; if(root.left == null &amp;&amp; root.right == null)&#123; res = Math.max(res,cnt); return; &#125; dfs(root.left,cnt + 1); dfs(root.right,cnt + 1); &#125;&#125; BFS 1234567891011121314151617181920212223242526272829303132333435363738/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; public int maxDepth(TreeNode root) &#123; ArrayDeque&lt;TreeNode&gt; q = new ArrayDeque(); if (root != null) q.add(root); int depth = 0; while (!q.isEmpty()) &#123; int size = q.size(); while (size &gt; 0) &#123; TreeNode cur = q.remove(); if (cur.left != null) &#123; q.add(cur.left); &#125; if (cur.right != null) &#123; q.add(cur.right); &#125; size--; &#125; depth++; &#125; return depth; &#125;&#125; 二叉树的直径[79]思路 12345678910111213141516171819202122232425262728293031323334/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; int res = 0; public int diameterOfBinaryTree(TreeNode root) &#123; dfs(root); return res; &#125; //也是站在当前根节点 思考 左右子节点要给我返回什么 public int dfs(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int lM = dfs(root.left); int rM = dfs(root.right); res = Math.max(lM + rM, res); // 这个 1 是指Cur节点返回给上一级的时候，要把cur节点 加上去 return Math.max(lM, rM) + 1; &#125;&#125; 验证二叉搜索树[79]思路： 二叉搜索树 中序遍历 为 单调递增数组 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; List&lt;Integer&gt; list = new ArrayList(); public boolean isValidBST(TreeNode root) &#123; f1(root); for (int i = 1; i &lt; list.size(); i++) &#123; if (list.get(i) &lt;= list.get(i - 1)) &#123; return false; &#125; &#125; return true; &#125; //二叉搜索树 中序遍历 为 单调递增数组 public void f1(TreeNode root) &#123; if (root == null) &#123; return; &#125; f1(root.left); list.add(root.val); f1(root.right); &#125;&#125; 二叉树的序列化与反序列化[57]思路： 序列化容易，就是前序遍历，转成字符串，或者层序遍历 反序列化比较难，一种是bfs，一种是dfs 就是你序列化以BFS，你反序列化就是要BFS。DFS同样 题目其实就是给你root，序列化成字符串，然后再根据字符串反序列为树 DFS 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */public class Codec &#123; StringBuilder serRes = new StringBuilder(); // Encodes a tree to a single string. public String serialize(TreeNode root) &#123; f1(root); return serRes.toString(); &#125; public void f1(TreeNode root)&#123; if(root == null)&#123; serRes.append(&quot;null,&quot;); return; &#125; else serRes.append(root.val + &quot;,&quot;); f1(root.left); f1(root.right); &#125; // Decodes your encoded data to tree. public TreeNode deserialize(String data) &#123; String []datas = data.split(&quot;,&quot;); return builder(datas); &#125; //构建树 int index = 0; public TreeNode builder(String[] data)&#123; //看示例1 即 从上到下，从右倒左遍历 String curV = data[index]; index++; //当前节点 TreeNode curNode = null; if(curV.equals(&quot;null&quot;))&#123; return curNode; &#125; else &#123; int curVN = Integer.parseInt(curV); curNode = new TreeNode(curVN); //左右子节点 交给子树去构造，相信递归 curNode.left = builder(data); curNode.right = builder(data); &#125; return curNode; &#125;&#125;// Your Codec object will be instantiated and called as such:// Codec ser = new Codec();// Codec deser = new Codec();// TreeNode ans = deser.deserialize(ser.serialize(root)); BFS 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */public class Codec &#123; StringBuilder serRes = new StringBuilder(); // Encodes a tree to a single string. public String serialize(TreeNode root) &#123; Queue&lt;TreeNode&gt; q = new LinkedList&lt;&gt;(); q.add(root); while (!q.isEmpty()) &#123; TreeNode cur = q.poll(); if (cur != null) &#123; serRes.append(cur.val).append(&quot;,&quot;); q.add(cur.left); q.add(cur.right); &#125; else &#123; serRes.append(&quot;null,&quot;); &#125; &#125; return serRes.toString(); &#125; // Decodes your encoded data to tree. public TreeNode deserialize(String data) &#123; String[] datas = data.split(&quot;,&quot;); return builder(datas); &#125; //构建树 public TreeNode builder(String[] data) &#123; if (data.length == 0 || data[0].equals(&quot;null&quot;)) &#123; return null; &#125; TreeNode res = new TreeNode(Integer.parseInt(data[0])); Queue&lt;TreeNode&gt; q = new LinkedList&lt;&gt;(); q.add(res); int index = 1; while (!q.isEmpty()) &#123; TreeNode curNode = q.poll(); if (!data[index].equals(&quot;null&quot;)) &#123; curNode.left = new TreeNode(Integer.parseInt(data[index])); q.add(curNode.left); &#125; index++; if (!data[index].equals(&quot;null&quot;)) &#123; curNode.right = new TreeNode(Integer.parseInt(data[index])); q.add(curNode.right); &#125; index++; &#125; return res; &#125;&#125;// Your Codec object will be instantiated and called as such:// Codec ser = new Codec();// Codec deser = new Codec();// TreeNode ans = deser.deserialize(ser.serialize(root)); 二叉树展开为链表[43]思路： 1234567891011121314151617181920212223242526272829303132/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; TreeNode pre=null; public void flatten(TreeNode root) &#123; if(root==null) return; if(pre!=null)&#123; pre.right=root; &#125; //提前保存一下即可，防止丢失子树 TreeNode tmp=root.right; pre=root; flatten(root.left); flatten(tmp); root.left=null; &#125;&#125; 不同的二叉搜索树[31]背诵题 思路： 找规律，先找出 比如 1个节点（n&#x3D;1），2,….的时候，这时候有多少种二叉搜索树 然后再找 n和n-1的关系，即递归公式 明确它的一个dp数组含义了，即 第i个节点 有多少种二叉搜索树 12345678910111213141516171819202122232425class Solution &#123; public int numTrees(int n) &#123; //1: 1 //2: 2 //3: 5 //dp数组含义：n = i时有多少种二叉搜索树 ////如果整数1 ~ n中的 k 作为根节点值，则 1 ~ k-1 会去构建左子树，k+1 ~ n 会去构建右子树。!!! if( n &lt;= 2) return n; int []dp = new int[n+1]; dp[0] = 1; dp[1] = 1; for(int i = 2;i &lt;= n;i++)&#123; //在 i 范围内，当前节点val = k //如果整数1 ~ i中的 k 作为根节点值，则 1 ~ k-1 会去构建左子树，k+1 ~ i 会去构建右子树。!!! //此时 for(int k = 0;k &lt;= i - 1;k++)&#123; //左 和 右 组合 //为什么组合这里是乘法？ dp[i] += dp[k] * dp[i - k - 1]; &#125; &#125; return dp[n]; &#125;&#125; 1️⃣ 为什么是 乘法？我们考虑： 如果整数 1 ~ i 中选 k 作为根节点，左子树可以用 1 ~ k-1 构建，右子树可以用 k+1 ~ i 构建。 假设： 左子树可以构建 L = dp[k] 种不同的 BST 右子树可以构建 R = dp[i - k - 1] 种不同的 BST 总的 BST 数量 &#x3D; 左子树方案数 × 右子树方案数 为什么是乘法？因为每一种左子树都可以和每一种右子树组合成一个新的 BST。这是经典的排列组合思想：左 * 右。 比如小明有4个苹果，小红有5个香蕉。他们组合是多少，那肯定是4*5 举个小例子： k=2，左子树用 1 构建 → 1 种方案 右子树用 3,4 构建 → 2 种方案 总的 BST 数 &#x3D; 1 * 2 = 2 种。 2️⃣ dp[k] 和 dp[i - k - 1] 分别是左子树和右子树 dp[k] → 左子树的方案数因为左子树包含 k 左边的 k 个节点（1 ~ k），所以 dp[k] dp[i - k - 1] → 右子树的方案数因为右子树包含剩下的 i - k - 1 个节点（k+1 ~ i），所以 dp[i - k - 1] ⚠️ 注意下标关系： i &#x3D; 当前节点总数 k &#x3D; 左子树节点数（或根节点下标？在你的循环中，k是左子树节点数） 右子树节点数 &#x3D; i - k - 1 打家劫舍 III[19]路径总和 III[]实现 Trie (前缀树)[34]思路： 构造26叉树 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Trie &#123; private static class Node &#123; Node[] son = new Node[26]; boolean end = false; &#125; private final Node root = new Node(); public Trie() &#123; &#125; public void insert(String word) &#123; Node cur = root; for (char c : word.toCharArray()) &#123; int index = c - &#x27;a&#x27;; //无路可走？ new 出来 if (cur.son[index] == null) &#123; cur.son[index] = new Node(); &#125; cur = cur.son[index]; &#125; cur.end = true; &#125; public boolean search(String word) &#123; return find(word) == 2; &#125; public boolean startsWith(String prefix) &#123; return find(prefix) != 0; &#125; public int find(String word) &#123; Node cur = root; for (char c : word.toCharArray()) &#123; int index = c - &#x27;a&#x27;; if (cur.son[index] == null) return 0; cur = cur.son[index]; &#125; //2为找到了 1为找到前缀 return cur.end ? 2 : 1; &#125;&#125;/** * Your Trie object will be instantiated and called as such: * Trie obj = new Trie(); * obj.insert(word); * boolean param_2 = obj.search(word); * boolean param_3 = obj.startsWith(prefix); */ 把二叉搜索树转换为累加树[4]思路： 利用二叉搜索树的特性，中序遍历为 有序数组 然后算出中序遍历后的数组的每个的元素的后缀和 然后再次中序遍历更改 树节点的val 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; List&lt;Integer&gt; l = new ArrayList(); int index = 0; public TreeNode convertBST(TreeNode root) &#123; traverse(root); //System.out.println(l); //每个节点 node 的新值 等于 原树中大于或等于 node.val 的值之和 int sum = 0; for(int i = 0;i &lt; l.size(); i++)&#123; sum += l.get(i); &#125; int preSum = 0; for(int i = 0; i &lt; l.size(); i++)&#123; int temp = l.get(i); l.set(i, sum - preSum); preSum += temp; &#125; generate(root); //System.out.println(l); return root; &#125; public void traverse(TreeNode root)&#123; if(root == null) return; traverse(root.left); l.add(root.val); traverse(root.right); &#125; public void generate(TreeNode root)&#123; if(root == null) return; generate(root.left); root.val = l.get(index); index++; generate(root.right); &#125;&#125; 合并二叉树[]思路 前序遍历，但这样是错误，在merge时，root1 &#x3D; root2，改变的不是引用！ 123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; public TreeNode mergeTrees(TreeNode root1, TreeNode root2) &#123; dfs(root1, root2); return root1; &#125; public void dfs(TreeNode root1,TreeNode root2)&#123; if(root1 == null &amp;&amp; root2 == null)&#123; return; &#125; else if(root1 == null &amp;&amp; root2 != null)&#123; root1 = root2; return; &#125; else if(root1 != null &amp;&amp; root2 == null)&#123; return; &#125; else if(root1 != null &amp;&amp; root2 != null)&#123; root1.val += root2.val; &#125; dfs(root1.left,root2.left); dfs(root1.right,root2.right); &#125;&#125; 正确的做法： 123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; public TreeNode mergeTrees(TreeNode root1, TreeNode root2) &#123; return build(root1, root2); &#125; //返回节点 public TreeNode build(TreeNode root1, TreeNode root2)&#123; if(root1 == null &amp;&amp; root2 == null)&#123; return null; &#125; if(root1 != null &amp;&amp; root2 == null)&#123; return root1; &#125; if(root1 == null &amp;&amp; root2 != null)&#123; return root2; &#125; TreeNode res = new TreeNode(); if(root1 != null &amp;&amp; root2 != null) res.val = root1.val + root2.val; res.left = build(root1.left, root2.left); res.right = build(root1.right, root2.right); return res; &#125;&#125;","path":"2025/09/25/Codetop刷题/树/","date":"09-25","excerpt":"","tags":[]},{"title":"滑动窗口","text":"无重复字符的最长子串[1005]滑动窗口最大值[134]思路： 固定窗口 单调递减队列（队列头到队列尾）来维护区间最大值 这是一个降本增笑的故事： 如果新员工比老员工强（或者一样强），把老员工裁掉。（元素进入窗口） 如果老员工 35 岁了，也裁掉。（元素离开窗口） 裁员后，资历最老（最左边）（队列头）的人就是最强的员工了。 1234567891011121314151617181920212223242526272829303132class Solution &#123; public int[] maxSlidingWindow(int[] nums, int k) &#123; int l = 0, r = 0; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); Deque&lt;Integer&gt; dq = new ArrayDeque&lt;&gt;(); // 单调队列，存下标，保持递减 for (; r &lt; nums.length; r++) &#123; // 移除队尾比当前元素小的下标 while (!dq.isEmpty() &amp;&amp; nums[dq.peekLast()] &lt; nums[r]) &#123; dq.pollLast(); &#125; dq.offerLast(r); // 当窗口长度 &gt;= k if (r - l + 1 &lt; k) &#123; continue; &#125; // 队头就是最大值 res.add(nums[dq.peekFirst()]); // 移除队头已经滑出窗口的下标 if (!dq.isEmpty() &amp;&amp; dq.peekFirst() == l) &#123; dq.pollFirst(); &#125; l++; &#125; return res.stream().mapToInt(Integer::intValue).toArray(); &#125;&#125; 最小覆盖子串[114]","path":"2025/09/25/Codetop刷题/滑动窗口/","date":"09-25","excerpt":"","tags":[]},{"title":"排序","text":"排序数组[321]思路 快排，堆，计数，归并 快排 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public static Random random = new Random(); public int[] sortArray(int[] nums) &#123; sort(nums, 0, nums.length - 1); return nums; &#125; public void sort(int []nums, int l, int r)&#123; if( l &gt;= r) return; int indexX = partition(nums, l, r); //l....indexX sort(nums, l ,indexX - 1); //indeX...r sort(nums, indexX + 1, r); &#125; public int partition(int []nums, int l, int r)&#123; int i = l + random.nextInt( r - l + 1); int x = nums[i]; swap(nums, l, i); int curL = l + 1; int curR = r; while(true)&#123; while(curL &lt;= curR &amp;&amp; nums[curL] &lt; x)&#123; curL++; &#125; while(curL &lt;= curR &amp;&amp; nums[curR] &gt; x)&#123; curR--; &#125; if(curL &gt;= curR) break; swap(nums, curL, curR); curL++; curR--; &#125; swap(nums, l, curR); return curR; &#125; public void swap(int []nums, int i, int j)&#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125; 题目特殊性，时间复杂度为O(N)的解法，采用计数排序 https://leetcode.cn/problems/sort-an-array/solutions/179210/dang-wo-tan-pai-xu-shi-wo-zai-tan-xie-shi-yao-by-s/ 12345678910111213141516171819202122232425class Solution &#123; public int[] sortArray(int[] nums) &#123; int max = 50001; int min = -50001; int[] counter = new int[max - min + 1]; for (int num : nums) &#123; counter[num - min]++; &#125; int index = 0; //index 为 数组值 value为 数组值的个数 for (int i = min; i &lt;= max; i++) &#123; int cnt = counter[i - min]; // cnt &gt; 0说明存在 while (cnt &gt; 0) &#123; nums[index] = i; cnt--; index++; &#125; &#125; return nums; &#125;&#125; 归并排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123; public int[] sortArray(int[] nums) &#123; sort(nums, 0, nums.length - 1); return nums; &#125; //归并排序 public void sort(int []nums, int l, int r)&#123; if(l &gt;= r) return; int mid = l + (r - l) / 2; sort(nums, l, mid); sort(nums, mid + 1, r); //合并 [l...mid] [mid + 1....r] merge(nums, l, mid, mid + 1, r); &#125; public void merge(int []nums, int s1, int e1, int s2, int e2)&#123; // [s1...e1] [s1 ... e2] int i = s1; int j = s2; // [2,4] [1,5] // [1,2,4,] int []temp = new int[e2 - s1 + 1]; int n = temp.length; int k = 0; while(i &lt;= e1 || j &lt;= e2)&#123; while( i &gt; e1 &amp;&amp; j &lt;= e2)&#123; temp[k] = nums[j]; k++; j++; &#125; while(j &gt; e2 &amp;&amp; i &lt;= e1)&#123; temp[k] = nums[i]; k++; i++; &#125; if(k &gt;= n) break; //谁小谁先移动 if(nums[i] &gt; nums[j])&#123; temp[k] = nums[j]; k++; j++; &#125; else &#123; temp[k] = nums[i]; k++; i++; &#125; &#125; System.arraycopy(temp, 0, nums, s1, temp.length); &#125; public void swap(int[] nums, int i, int j)&#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125; 字典序排数[13]思路： 123456789101112131415161718192021class Solution &#123; public List&lt;Integer&gt; lexicalOrder(int n) &#123; //256 // 1 10 100 101...109 11 List&lt;Integer&gt; res = new ArrayList(); for (int i = 0, j = 1; i &lt; n; i++) &#123; res.add(j); if (j * 10 &lt;= n) &#123; j = j * 10; &#125; else &#123; // 1 10 100 101...109 11 or 1,2 // 109 -&gt; 11 ,2 -&gt; 3 while (j % 10 == 9 || j + 1 &gt; n) &#123; j = j / 10; &#125; j++; &#125; &#125; return res; &#125;&#125; 排序链表[133]思路： 归并排序head….tail-&gt; head….mid mid…tail 不断分，然后并起来 归：对链表进行分割，直到每个链表只有一个 元素 并：对链表进行升序合并 链表取中点（快慢指针），并切割 快排（容易超时） 图（归并） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode() &#123;&#125; * ListNode(int val) &#123; this.val = val; &#125; * ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125; * &#125; */class Solution &#123; public ListNode sortList(ListNode head) &#123; return sort(head); &#125; //从中间分开 public ListNode divide(ListNode head) &#123; ListNode fast = head; ListNode slow = head; ListNode pre = head; while (fast != null &amp;&amp; fast.next != null) &#123; pre = slow; fast = fast.next.next; slow = slow.next; &#125; pre.next = null; return slow; &#125; //归并排序 public ListNode sort(ListNode head1) &#123; if (head1 == null || head1.next == null) &#123; return head1; &#125; //拆成两部分，并返回后部门的头结点 ListNode head2 = divide(head1); //mid(4→2→1→3) ---&gt; 分成两部分 //head1: 4 → 2 → null //head2: 1 → 3 → null head1 = sort(head1); head2 = sort(head2); return merge(head1, head2); &#125; //两链表合并，要有序 // head1 .... // head2 .... public ListNode merge(ListNode head1, ListNode head2) &#123; ListNode res = new ListNode(); ListNode cur = res; while (head1 != null || head2 != null) &#123; if (head2 == null) &#123; cur.next = head1; break; &#125; if (head1 == null) &#123; cur.next = head2; break; &#125; if (head1.val &gt; head2.val) &#123; cur.next = head2; head2 = head2.next; &#125; else &#123; cur.next = head1; head1 = head1.next; &#125; cur = cur.next; &#125; return res.next; &#125;&#125; 时间复杂度：NlogN 空间复杂度：logN 合并K个排序链表[221]思路： 归并排序 堆（可能需要手写）排序 12345678910111213141516171819202122232425262728293031323334/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode() &#123;&#125; * ListNode(int val) &#123; this.val = val; &#125; * ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125; * &#125; */class Solution &#123; public ListNode mergeKLists(ListNode[] lists) &#123; if(lists.length == 0) return null; //最小堆，堆顶为最小值 PriorityQueue&lt;ListNode&gt; pq = new PriorityQueue&lt;&gt;((a, b) -&gt; a.val - b.val); //先将最小的放进来 for(ListNode head: lists)&#123; if(head == null) continue; pq.add(head); &#125; ListNode dummyHead = new ListNode(); ListNode res = dummyHead; while(!pq.isEmpty())&#123; ListNode minNode = pq.poll(); res.next = minNode; res = res.next; if(minNode.next != null)&#123; pq.add(minNode.next); &#125; &#125; return dummyHead.next; &#125;&#125; 时间复杂度：O(Llogm)，其中 m 为 lists 的长度，L 为所有链表的长度之和。 数组中的第K个最大元素[550]题目： 要求时间复杂度为O(N) 思路： 维护size &#x3D;&#x3D; k的最小堆（但不符合题意）时间复杂度：nums.length log(k) 1234567891011121314class Solution &#123; public int findKthLargest(int[] nums, int k) &#123; if(nums.length == 1) return nums[0]; PriorityQueue&lt;Integer&gt; pq = new PriorityQueue(); for(int i: nums)&#123; pq.add(i); if(pq.size() &gt; k)&#123; pq.poll(); &#125; &#125; //System.out.println(pq); return pq.isEmpty()?-1:pq.poll(); &#125;&#125; 快速选择 思路： 构建partition函数，里面干的就是 数组随机取一个 x，然后划分 x 如何划分！？1、小技巧，先将 l 和 x交换，方便后面处理 2、curL–&gt; …. &lt;—curR，while把curL和curR推进到需要交换的位置，然后swap，交换后，重复这个过程 外层while(true) 内层while 推进curL,curR。若curR&lt;&#x3D;curL退出全部循环 3、将x放回正确位置，—&gt; swap(l,curR) 经过划分我们可以得到x。那么这个时候判断x的index 和 targetIndex( n - k)的位置 若 index &#x3D; targertIdex 就是找到答案了，直接返回。若index &gt; targetIndex 则说明targetIndex在右边，那么这个时候让r &#x3D; index缩小范围，反之，让l &#x3D; index 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465class Solution &#123; private static final Random rand = new Random(); public int findKthLargest(int[] nums, int k) &#123; //选一个基准 元素 x // &lt;x.... x... &gt;x //如果 i = n - k ,那么 res = i //如果 i &gt; n - k, 那么res在左侧，我们在其中寻找，重复第一步 //如果 i &lt; n - k, 那么res在右侧，我们在其中寻找，重复第一步 if(nums.length &lt; k) return -1; int n = nums.length; int l = 0; int r = n - 1; int targetIndex = n - k; while(true)&#123; int resIndex = partition(nums, l, r); if(resIndex == targetIndex)&#123; return nums[resIndex]; &#125; //redIndex 在 targetIndex右边 说明 targetIndex的数在 l...resIndex 中 else if(resIndex &gt; targetIndex)&#123; r = resIndex - 1; &#125; else &#123; l = resIndex + 1; &#125; &#125; &#125; public int partition(int []nums, int l, int r)&#123; int i = l + rand.nextInt(r - l + 1); int x = nums[i]; //System.out.println(x); //交换左边界元素 和 x，方便后面实现 swap(nums, l, i); //System.out.println(Arrays.toString(nums)); int curL = l + 1; int curR = r; //处理示意图： (&lt; x) curL-&gt; (没处理的元素) &lt;-curR ( &gt; x) while(true)&#123; while(curL &lt;= curR &amp;&amp; nums[curL] &lt; x)&#123; curL++; &#125; //经过上面的while循环此时 nums[curL] &gt;= x while(curL &lt;= curR &amp;&amp; nums[curR] &gt; x)&#123; curR--; &#125; //经过上面的while循环此时 nums[curL] &lt;= x if(curL &gt;= curR) break; swap(nums, curL, curR); curR--; curL++; &#125; //System.out.println(Arrays.toString(nums)); swap(nums, l, curR); //System.out.println(Arrays.toString(nums)); return curR; &#125; // 交换 nums[i] 与 nums[j] private void swap(int[] nums, int i, int j) &#123; int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; &#125;&#125; 颜色分类[41]思路： 三路快排（三指针法）。0…zero i two…n -1 1234567891011121314151617181920212223242526272829303132333435class Solution &#123; public void sortColors(int[] nums) &#123; int n = nums.length; int i = 0; int zero = 0; int two = n - 1; //[0 zero] 全为 0 //[zero i] 全为 1 //[two, n-1] 全为 2 // 0 1 2 while(i &lt;= two)&#123; if(nums[i] == 0)&#123; swap(nums, i, zero); zero++; i++; &#125; else if(nums[i] == 1)&#123; i++; &#125; else &#123; swap(nums, i, two); two--; &#125; &#125; &#125; public void swap(int[] nums, int i, int j)&#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125; 或者计数排序 1234567891011121314151617class Solution &#123; public void sortColors(int[] nums) &#123; int[] counter = new int[3]; for(int i: nums)&#123; counter[i]++; &#125; int index = 0; for(int i = 0; i &lt; 3; i++)&#123; int cnt = counter[i]; while(cnt &gt; 0) &#123; nums[index] = i; index++; cnt--; &#125; &#125; &#125;&#125;","path":"2025/09/25/Codetop刷题/排序/","date":"09-25","excerpt":"","tags":[]},{"title":"Linux内存管理","text":"函数 malloc&#x2F;calloc&#x2F;realloc，free 封装得太好，内存对于程序员来说就是一黑箱操作 内存碎片问题很烦 随机的bug大概率跟 内存有关系 如何避免内存碎片的产生？ 内存池。 第一个版本，分配的块用链表串起来 分配：找到一个flag&#x3D;0的块就使用，没有就新建 释放： 第二个版本，解决第一个版本的缺点：内存利用率以及查找性能问题 比链表查找效率高的组件：rbtree,skiplist,btree,hash 根据大小查找 key为内存大小 以下做法buffer出不了while循环 以下做法会出现大量的1k 内存块 解决以上问题，需要引入大块拆成大块，小块拆成大块的做法","path":"2025/09/23/操作系统/Linux内存管理/","date":"09-23","excerpt":"","tags":[]},{"title":"什么是Kafka的重平衡机制？","text":"它是指当我们的Consumer数量发生变动时，kafka会重新分配topic partition给Consumer，以保证每个 Consumer的分区数量尽可能均衡 简单地说就是实现消费者负载均衡 重平衡的3个触发机制： 1、Consumer数量发送变化 2、订阅的partition发生变化 3、订阅的topic发生变化 当kafka集群要出发重平衡机制时，大致的步骤 暂停消费 计算分区分配方案 通知消费者 重新飞陪分区 恢复消费 重平衡会造成 Consumer的 STW，我们应该尽量避免触发它","path":"2025/09/19/kafka/什么是Kafka的重平衡机制？/","date":"09-19","excerpt":"","tags":[]},{"title":"ISR","text":"ISR，In-Sync Replicas 同步副本拿到意思 在每个kafka中，每个topic partition可以有多个replica。ISR是与Leader replica保持同步的follower replica集合 可以说ISR机制就是确保数据的可靠性和一致性的 当消息被sender线程发送后，它会先被写入Leader副本，然后再由follower主动轮询Leader同步消息 只有ISR中的所有副本成功接收到并确认了消息后，主副本才会认为消息已经成功提交 ISR列表维护什么时候follower会被移除出ISR列表 replica.lag.max.messages 在0.9x之前是，表示follower落后Leader这个数就会被移除 这个就有大问题，如果高并发场景，Leader一下子收到几万条消息，那么所有follower都会被驱逐 在0.9x后， 新增了replica.lag.max.ms 表示follower的LEO一直落后Leader超过这个replica.lag.max.ms时间，才会被移除出境","path":"2025/09/19/kafka/ISR/","date":"09-19","excerpt":"","tags":[]},{"title":"Kafka的保存流程 ？ 副本同步相关的HW 、 LEO?","text":"HW高水平位，用于控制哪些消息是对Consumer可读的。一个普通消费者只能“看到”Leader副本上介于Log Start Offset和HW（不含）之间的所有消息。follower同步完消息后会更新HW 也就是说在HW之前的数据都是已经被所有的Follower所同步，比较安全 HW取自于所有follower副本的 LEO LEOLog End Offset。消息的末尾偏移，表示日志下一条待插入消息的位移值。比如当时log文件里有10条 日志，位移值从0开始，那么，第10条消息的位移值就是9。此时，LEO &#x3D; 10。 follower故障：follower长时间没和Leader同步，就会被提出ISR（follower同步集合）。待follower恢复后，会读取本地的H W，然后截取Log上大于HW的部分，进行同步。当该follower的LEO大于HW，即代表follower追上Leader就 会重新加入ISR Leader故障Leader故障后，由Controller从 ISR中选取一个follower成为新的Leader。之后为了保证多个follower副本数 剧一致性，其余的follower会将log中高于新Leader的LEO的部分截掉，然后从新的Leader同步数据 比如一个Leader现在有 3个follower，F1：读到了3，F2：读到了5，F3：读到了4。此时HW&#x3D;min()&#x3D;3 然后这时候Leader宕机了，F1成为了新的Leader，F2就会丢弃3-5的消息，F4丢弃4-5的消息 那如果F2成为了Leader呢？F1和F2就不会丢？","path":"2025/09/19/kafka/Kafka的保存流程 ？ 副本同步相关的HW 、 LEO/","date":"09-19","excerpt":"","tags":[]},{"title":"为什么使用双端队列？","text":"双端队列区别于普通的队列，可以直接往队列头塞元素，这样可以满足分区内数据有序性，再尝试发送。 DQ由RecordAccumulator维护 一个topic里的partition都会对应一个DQ 123456789101112131415161718192021222324252627282930313233/** ：:方法内容 -&gt; ： 方法调用方法**/sendProducerRequest(): //回调 RequestCompletionHandler callback = response -&gt; handleProduceResponse(response, recordsByPartition, time.milliseconds()); -&gt; handleProduceResponse() -&gt; completeBatch() : if (canRetry(batch, response, now)) &#123; //...... //消息从新入队 reenqueueBatch(batch, now); &#125; reenqueueBatch: this.accumulator.reenqueue(batch, currentTimeMs);/*** Re-enqueue the given record batch in the accumulator. In Sender.completeBatch method, we check* whether the batch has reached deliveryTimeoutMs or not. Hence we do not do the delivery timeout check here.*/public void reenqueue(ProducerBatch batch, long now) &#123; batch.reenqueued(now); Deque&lt;ProducerBatch&gt; deque = getOrCreateDeque(batch.topicPartition); synchronized (deque) &#123; if (transactionManager != null) insertInSequenceOrder(deque, batch); else deque.addFirst(batch); &#125;&#125;","path":"2025/09/19/kafka/为什么使用双端队列？/","date":"09-19","excerpt":"","tags":[]},{"title":"bfs","text":"除法求值","path":"2025/09/19/Codetop刷题/bfs/","date":"09-19","excerpt":"","tags":[]},{"title":"dfs","text":"必看回溯模版的解释 1234567891011121314//向数组中的每个整数前添加 &#x27;+&#x27; 或 &#x27;-&#x27;//对于每个节点两种选择： + or -。不能硬套模版/**fun dfs(): for(int i = 0; i &lt; nums.length; i++)&#123; add dfs delete &#125;以上是因为每个节点都有多选择 比如 排列，组合 */ 岛屿数量[289]思路： 1. 123456789101112131415161718192021222324252627282930313233class Solution &#123; int [][]direct=&#123;&#123;1,0&#125;,&#123;0,1&#125;,&#123;-1,0&#125;,&#123;0,-1&#125;&#125;; public int numIslands(char[][] grid) &#123; int res=0; for(int i=0;i&lt;grid.length;i++)&#123; for(int j=0;j&lt;grid[0].length;j++)&#123; if(grid[i][j]==&#x27;1&#x27;)&#123; res++; dfs(grid,i,j); &#125; &#125; &#125; return res; &#125; public void dfs(char [][]grid,int x,int y)&#123; if(x&lt;0||y&lt;0||x&gt;=grid.length||y&gt;=grid[0].length)&#123; return; &#125; if(grid[x][y]==&#x27;0&#x27;)&#123; return; &#125; else &#123; //用海水把陆地淹掉，相当于valid数组的作用 grid[x][y]=&#x27;0&#x27;; &#125; for(int i=0;i&lt;4;i++)&#123; //四个方向 int nextX=x+direct[i][0]; int nextY=y+direct[i][1]; dfs(grid,nextX,nextY); &#125; &#125;&#125; @週刊少年 时间复杂度BFS会低一点，空间复杂度感觉DFS会好一点（但是要考虑递归调用的堆栈的空间就不好说了） 被问到深度优先和广度优先的差别、计算时间空间复杂度面试用BFS写出来了，然后让我用并查集再写一个，字节 全排列[277]思路： used[i] 用于控制 防止走回头路 123456789101112131415161718192021222324252627class Solution &#123; List&lt;List&lt;Integer&gt;&gt; res=new ArrayList&lt;&gt;(); //存放路径 List&lt;Integer&gt; path=new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; boolean []used=new boolean[nums.length]; dfs(nums,used); return res; &#125; public void dfs(int []nums,boolean []used)&#123; if(path.size()==nums.length)&#123; res.add(new ArrayList&lt;&gt;(path)); &#125; for(int i=0;i&lt;nums.length;i++)&#123; if(used[i])&#123; continue; &#125; //递归 path.add(nums[i]); used[i]=true; dfs(nums,used); //回溯 path.removeLast(); used[i]=false; &#125; &#125;&#125; 时间复杂度： 问题类型 是否需要 startIndex 控制逻辑 示例 排列 Permutation ❌ 不需要 用 used[i] 防止重复选 [1,2] vs [2,1] 都算不同 组合 Combination ✅ 必须 用 startIndex 防止重复，为了防止来回选，必须 保证后面的选择只能从当前元素后面开始。 [1,2] 和 [2,1] 视为相同 全排列 II[57]去重版的全排列 I，用HashSet存结果集即可 课程表[56]思路： spring 1234567891011121314151617181920212223242526272829303132class Solution &#123; //k： Map&lt;Integer, List&lt;Integer&gt;&gt; graph = new HashMap&lt;&gt;(); Set&lt;Integer&gt; wait = new HashSet&lt;&gt;(); // 当前正在修的课程（类似 wait 集合） Set&lt;Integer&gt; completed = new HashSet&lt;&gt;(); // 已确认可修完的课程（类似缓存） public boolean canFinish(int numCourses, int[][] prerequisites) &#123; // 构建依赖图 for(int i=0;i&lt;numCourses;i++) graph.put(i, new ArrayList&lt;&gt;()); for(int[] pre : prerequisites) graph.get(pre[1]).add(pre[0]); // 遍历所有课程 for(int i=0;i&lt;numCourses;i++) if(!completed.contains(i) &amp;&amp; !dfs(i)) return false; return true; &#125; private boolean dfs(int course) &#123; if(wait.contains(course)) return false; // 当前路径已出现 → 有环 if(completed.contains(course)) return true; // 已确认可完成 wait.add(course); // 加入 wait 集合（正在修） for(int next : graph.get(course)) &#123; if(!dfs(next)) return false; // 依赖课程不可修完 → 当前也不可修 &#125; wait.remove(course); // 移出 wait 集合 completed.add(course); // 加入已完成缓存 return true; &#125;&#125; 交错字符串[27]单词拆分[64]思路： DFS + 记忆化搜索 还是得把回溯树给画出来，才清晰易懂！！！（明天来搞） https://leetcode.cn/problems/word-break/solutions/302779/shou-hui-tu-jie-san-chong-fang-fa-dfs-bfs-dong-tai/ 竟然可以记忆化，说明可以转成DP 判断可能性大概率是 DP 12345678910111213141516171819202122232425262728class Solution &#123; Boolean []memory ; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; memory = new Boolean[s.length()]; return dfs(s, 0, wordDict); &#125; //leetcode7 //leet code public boolean dfs(String s,int startIndex,List&lt;String&gt; wordDict)&#123; if(startIndex == s.length()) return true; if(memory[startIndex] != null)&#123; return memory[startIndex]; &#125; for(String word: wordDict)&#123; int nextStartIndex = startIndex + word.length(); if(nextStartIndex &gt; s.length())&#123; continue; &#125; //startsWith：s中startIndex开头的子串是否以word开头 if(s.startsWith(word, startIndex) &amp;&amp; dfs(s,nextStartIndex,wordDict))&#123; memory[startIndex] = true; return true; &#125; &#125; memory[startIndex] = false; return false; &#125;&#125; 电话号码的字母组合[19]思路： 回溯，最基础的题了。可以细想一下这个递归，最容易的一次 12345678910111213141516[abc][iop]交叉相乘，笛卡尔集排列何尝不是一种算 笛卡尔集合[a b c][a b c][a b c]abb 只不过递归的集合不断为自己本身for (int i = 0; i &lt; t.get(tIndex).length(); i++) &#123; path.append(t.get(tIndex).charAt(i)); dfs(tIndex + 1); path.deleteCharAt(path.length() - 1);&#125; 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; Map&lt;Integer, String&gt; map = new HashMap(); List&lt;String&gt; t = new ArrayList(); List&lt;String&gt; res = new ArrayList(); StringBuilder path = new StringBuilder(); public List&lt;String&gt; letterCombinations(String digits) &#123; map.put(1, &quot;&quot;); map.put(2, &quot;abc&quot;); map.put(3, &quot;def&quot;); map.put(4, &quot;ghi&quot;); map.put(5, &quot;jkl&quot;); map.put(6, &quot;mno&quot;); map.put(7, &quot;pqrs&quot;); map.put(8, &quot;tuv&quot;); map.put(9, &quot;wxyz&quot;); for (char c : digits.toCharArray()) &#123; t.add(map.get(c - &#x27;0&#x27;)); &#125; dfs(0); return res; &#125; public void dfs(int tIndex) &#123; if (path.length() == t.size()) &#123; res.add(path.toString()); return; &#125; for (int i = 0; i &lt; t.get(tIndex).length(); i++) &#123; path.append(t.get(tIndex).charAt(i)); dfs(tIndex + 1); path.deleteCharAt(path.length() - 1); &#125; &#125;&#125; 删除无效的括号[18]思路 将左右括号 -+化 对于path，则在参数中update 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class Solution &#123; Set&lt;String&gt; res = new HashSet(); int max = 0; String s; int n; //最大路径长度 int maxPathLen = 0; public List&lt;String&gt; removeInvalidParentheses(String _s) &#123; //左右括号 int l = 0; int r = 0; s = _s; n = s.length(); for(char c: s.toCharArray())&#123; if(c == &#x27;(&#x27;) l++; else if(c == &#x27;)&#x27;) r++; &#125; //max：最大括号数（单括号） max = Math.max(l, r); dfs(0, &quot;&quot;, 0); return new ArrayList(res); &#125; /** * 遍历 _s 字符串，记录有效路径 * @param curCharIndex 当前遍历的字符下标 * @param path 遍历时的路径（括号组合字符串） * @param score 分数，用于标记左右括号的得分，左则+1，右则-1 */ public void dfs(int curCharIndex, String path, int score)&#123; //不合法情况，0 &lt;= score &lt;= max if(score &lt; 0 || score &gt; max) return; //当下标等于字符串长度，即遍历完时，则说明搜索完成，保存合法结果到 set if(curCharIndex == n)&#123; //只有score == 0结果才合法，并且当前路径长度要大于最大路径子串的长度才记录或者更新 //小于最长路径子串就不用更新了 if(score == 0 &amp;&amp; path.length() &gt;= maxPathLen)&#123; //为什么要有这一步，因为题目要求 删除最小数量的无效括号，换句话说，就是你结果集里的合法字符串要为最长的 //如果有更长的了，就把前面的clear掉 if(path.length() &gt; maxPathLen) res.clear(); //更新最大路径子串 maxPathLen = path.length(); res.add(path); &#125; return; &#125; //当前字符 char c = s.charAt(curCharIndex); //对于( ) 都有选和不选两种选择 if(c == &#x27;(&#x27;)&#123; // 选左括号，score + 1；不选score不变 dfs(curCharIndex + 1, path + c, score + 1); dfs(curCharIndex + 1, path, score); &#125; else if(c == &#x27;)&#x27;)&#123;// 选左括号，score - 1；不选score不变 dfs(curCharIndex + 1, path + c, score - 1); dfs(curCharIndex + 1, path, score); &#125;//选正确字符不变 else dfs(curCharIndex + 1, path + c, score); &#125;&#125; 戳气球思路 dfs + 回溯，有一个n层的数组，然后我往下走，戳当前i节点，并在下次递归之前把当前节点置为 -1，防止重复选，curLevel &#x3D;&#x3D; n时更新结果。但超时，得进行记忆化 回溯树： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123; int n; int res = 0; public int maxCoins(int[] nums) &#123; n = nums.length; dfs(nums, 0, 0); return res; &#125; public void dfs(int[] nums, int curLevel, int curCoin)&#123; //回溯：一个n层的数组，我们从第一层走到底n层 //nums[i] = -1来防止 重复选 //为什么不是startIndex，这个主要是决定 选元素只能从startINdex后开始选，而不能往回选，对于组合这种 1 2和 2 1是一样的 if(curLevel == n)&#123; res = Math.max(res, curCoin); return; &#125; for(int i = 0; i &lt; nums.length; i++)&#123; if(nums[i] == -1)&#123; continue; &#125; int midQ = nums[i]; //左测的气球编号 int lQ = 1; //右侧的气球编号 int rQ = 1; int l = i - 1; int r = i + 1; while(l &gt;= 0 &amp;&amp; nums[l] == -1)&#123; l--; &#125; if(l &lt; 0) lQ = 1; else lQ = nums[l]; while(r &lt; nums.length &amp;&amp; nums[r] == -1)&#123; r++; &#125; if(r &gt;= nums.length) rQ = 1; else rQ = nums[r]; int add = lQ * midQ * rQ; nums[i] = -1; //右侧的气球 dfs(nums, curLevel + 1, curCoin + add); nums[i] = midQ; &#125; &#125;&#125; 时间复杂度 &#x3D; O(n! × n) dp，dp[i][j] 表示 i 到 j能获得的最大金币 dp[i][j] &#x3D; 区间内的最大。那么dp[i][i + len] &#x3D; res; 123456789101112131415161718192021222324252627282930class Solution &#123; public int maxCoins(int[] nums) &#123; int n = nums.length; // 创建一个辅助数组，并在首尾各添加1，方便处理边界情况 int[] temp = new int[n+2]; temp[0] = 1; temp[n+1] = 1; for(int i=0; i&lt;n; i++)&#123; temp[i+1] = nums[i]; &#125; int[][] dp = new int[n+2][n+2]; // len表示开区间长度 for(int len=3; len&lt;=n+2; len++)&#123; // i表示开区间左端点 for(int i=0; i&lt;=n+2-len; i++)&#123; int res = 0; // k为开区间内的索引 for(int k = i+1; k&lt;i+len-1; k++)&#123; int left = dp[i][k]; int right = dp[k][i+len-1]; //dp[i][j] 表示 i 到 j能获得的最大金币 //(i....k) k (k.... i + len -1) res = Math.max(res, left + temp[i]*temp[k]*temp[i+len-1] + right); &#125; dp[i][i+len-1] = res; &#125; &#125; return dp[0][n+1]; &#125;&#125; 目标和[22]思路 DFS 每个节点两种选择 + or - 比较简单的回溯，和普通的回溯的区别，就是在循环过程中，如果是像组合排列这些题，就需要往后遍历找，即树的宽度不定，而这题则树宽为 1，每次直接一个数递归下去即可，不用循环。 123456789101112131415161718192021222324252627282930class Solution &#123; int res = 0; public int findTargetSumWays(int[] nums, int target) &#123; dfs(nums, target, 0, 0); return res; &#125; public void dfs(int[] nums, int target, int numIndex, int sum)&#123; if(numIndex == nums.length)&#123; if(target == sum) res++; return ; &#125; //向数组中的每个整数前添加 &#x27;+&#x27; 或 &#x27;-&#x27; //对于每个节点两种选择： + or -。不能硬套模版 /** fun dfs(): for(int i = 0; i &lt; nums.length; i++)&#123; add dfs delete &#125; 以上是因为每个节点都有多选择 比如 排列，组合 */ dfs(nums, target, numIndex + 1, sum + nums[numIndex]); dfs(nums, target, numIndex + 1, sum - nums[numIndex]); &#125;&#125; 路径总和 II[75]题目： 求叶子节点到根节点 路径和 为target的路径 思路： dfs 回溯。 注意！！！ 叶子结点定义，root.left &#x3D;&#x3D; null &amp;&amp; root.right &#x3D;&#x3D; null 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int targetSum) &#123; if(root == null) return new ArrayList(res); dfs(root, targetSum, 0, new ArrayList()); return res; &#125; public void dfs(TreeNode root, int targetSum, int sum, List&lt;Integer&gt; path) &#123; if (root == null) &#123; // if (sum == targetSum) // // res.add(path.chars() // // .map(e -&gt; e - &#x27;0&#x27;) // // .boxed() // // .collect(Collectors.toList())); // res.add(new ArrayList(path)); // return; return ; &#125; sum += root.val; //System.out.println(sum); path.add(root.val); //System.out.println(path); //到达叶子节点 if(root.left == null &amp;&amp; root.right == null)&#123; if (sum == targetSum) res.add(new ArrayList(path)); //return; 肯定不能return啊，因为它是叶子结点到根节点 &#125; dfs(root.left, targetSum, sum, path); dfs(root.right, targetSum, sum, path); //回溯 path.remove(path.size() - 1); &#125;&#125;","path":"2025/09/19/Codetop刷题/dfs/","date":"09-19","excerpt":"","tags":[]},{"title":"TCP函数","text":"close() accept() listen() socket() read() write()","path":"2025/09/18/计网/TCP和UDP/TCP函数/","date":"09-18","excerpt":"","tags":[]},{"title":"有没有遇到过跨域的问题。你知道跨域是啥意思？","text":"跨域就是指跨 同一个协议，域名，端口进行数据请求，常见在现在前后端分离部署的场景。这主要是浏览器的一个安全策略，就是防止钓鱼网站携带像你的cookie像你的bank网站请求。然后我们正常开发要解决这种跨域问题，一般就得在服务端的响应头里CORS相关字段 1234567HTTP/1.1 204 No Content// 相信的前端页面网址，也就只有这个网址，服务端能放行Access-Control-Allow-Origin: https://app.bank-partner.com Access-Control-Allow-Methods: GET, POST, PUT, DELETEAccess-Control-Allow-Headers: Content-Type, AuthorizationAccess-Control-Allow-Credentials: true","path":"2025/09/18/计网/有没有遇到过跨域的问题。你知道跨域是啥意思？/","date":"09-18","excerpt":"","tags":[]},{"title":"TCP 协议通信排查工具","text":"Wireshark（图形化抓包工具） ，通过过滤工具定位到 具体ACK连接，查看各自包体来排查","path":"2025/09/18/计网/TCP和UDP/TCP 协议通信排查工具/","date":"09-18","excerpt":"","tags":[]},{"title":"tcp基础","text":"TCP是怎么保证可靠的TCP协议通过多种机制来保证数据的可靠传输。 首先，它使用确认应答机制，确保每个数据包都被接收方确认。 其次，序列号用于数据的有序传输，接收方可以根据序列号来检测丢失或重复的数据包。 第三，超时重传机制允许发送方在未收到确认应答时重新发送数据包。 第四，流量控制机制使用滑动窗口机制来进行流量控制，避免发送方过快发送数据导致接收方来不及处理 第五，使用拥塞控制算法，如慢启动、拥塞避免、快重传、快恢复，避免网络拥塞，确保数据包的可靠传输 第六，错误检测机制通过校验和来检测数据传输中的错误。 最后，TCP强大的状态机确保了连接的可靠建立和释放。 这些机制共同作用，使得TCP协议能够提供可靠的数据传输服务。 简述ACK确认序列号，超时重传防丢包； 流量拥塞双控制，校验连接保可靠； 引导滑动窗口算法；慢启动；拥塞控制；拥塞避免；快重传和快恢复； 最近流行的所谓的基于 UDP 的可靠传输，差不多也是靠这些机制。比如说 QUIC 协议也同样有序列号、确认应答、重传机制、流量控制、拥塞控制、快重传和快恢复这些机制。 简述传输可靠性，做法都一样； 引导QUIC；","path":"2025/09/18/计网/TCP和UDP/tcp基础/","date":"09-18","excerpt":"","tags":[]},{"title":"有HTTP了为什么还要WebSocket","text":"TCP连接的两端，同一时间，双方都可以互相主动发送消息。这种就是所谓的全双工 而早期的HTTP&#x2F;1.1，同一时间下客户端和服务端就只能一方发送数据，也就是基于TCP的HTTP协议把全双工给干废了，完成了半双工 这个主要是因为早期HTTP设计的时候，考虑的是看看网页文本的场景，能做到客户端发起请求再由服务器响应，就够了。而对于后面页游的出现，就需要这种客户端和服务端能互相发送大量消息的需求 所以为了支持这种场景，我们就需要另外一个基于TCP的协议 于是新的应用层协议websocket就被设计出来了。 浏览器在TCP三次握手建立连接后，都统一使用HTTP协议进行一次通信 如果此时是普通的HTTP请求，就还是老样子 如果想走websocket协议，就会在HTTP带上一些特殊的header，如果服务器正好支持升级为websocket，那就会走websocket握手流程 HTTP2,3均未实现 全双工通信","path":"2025/09/18/计网/HTTP/有HTTP了为什么还要WebSocket/","date":"09-18","excerpt":"","tags":[]},{"title":"有HTTP了为什么还要RPC","text":"这个其实是先出现的RPC，然后才有的HTTP 在CS 架构上，客户端大多调用自家服务端的接口，这时候就可以用RPC 但在BS架构上，需要由浏览器调用各家公司的服务器，这时候就需要统一的标准协议，方便调用，就出现了HTTP 那为什么出现了HTTP后，不废除RPC呢 在公司内部，RPC调用内部接口比HTTP更加方便，不需要携带各种复杂的头，还有就是不需要考虑重定向之类的情况 基于历史原因，还是保留了RPC CS 系统里，客户端和服务端通常由同一家公司开发和维护，他们可以完全控制协议格式。 浏览器和服务器都是由不同厂商、不同团队开发的，如果没有统一的通信协议，就会出现“这个浏览器只能访问某些网站”的情况。","path":"2025/09/18/计网/HTTP/有HTTP了为什么还要RPC/","date":"09-18","excerpt":"","tags":[]},{"title":"https","text":"加密概念对称加密：使用相同的密钥进行加密解密，快，但密钥管理困难 非对称加密：使用公钥进行加密，使用私钥进行解密，安全性好，但是加解密比较慢 HTTPS使用 对称加密和非对称加密的结合体 通信建立前使用非对称加密交换会话密钥，即**证书验证阶段**。后续就不在使用非对称加密 在通信过程中全程使用对称加密的 会话加密 的方式加密明文数据 HTTP和HTTPS区别HTTP是超文本传输协议，明文传输，安全性比较低 HTTPS 则解决HTTP不安全的缺陷，在TCP和HTTP之间加入了SSL&#x2F;TLS安全协议，使得报文能加密传输 HTTP连接建立相对简单，三次握手后便可以进行HTTP报文的传输。而HTTPS则还需要进行SSL&#x2F;TLS的握手过程。才可以进行加密报文的传输 两者的端口不一样，HTTP的默认端口是80，而HTTPS是443 HTTPS协议是需要向CA申请数字证书的，来保证服务器的身份是可信的，同时获取服务器公钥 CA证书验证过程服务器将它的公钥等原始信息打包起来，用hash算法生成一个信息摘要，然后CA对这个信息摘要进行私钥加密，生成数字签名。 数字签名 &#x3D; 私钥加密（ hash(公钥) ） 原始信息和数字签名一起打包进来，生成数字证书，然后由CA颁发给服务器 以上是服务端申请证书的流程，以下是客户端如何拿到证书 客户端请求服务端后，会拿到证书，然后通过证书的公钥解密数字签名，得到第一份信息摘要，然后通过hash算法对原始内容进行运算，得到第二份信息摘要，通过比较两份信息摘要，就可以知道这个数字证书可不可靠（因为是用公钥解密），且有没有被更改（因为更改的话，hash后的值就会变化） 证书内容： 过程： 数据传输过程随机数加解密这个过程就是 非对称的 随机数就相当于密钥了，服务端和客户端都会存一份，且不会在网络中传输，也就不会被网络劫持拿到 代码模拟HTTPS如何优化协议优化：","path":"2025/09/18/计网/HTTP/https/","date":"09-18","excerpt":"","tags":[]},{"title":"注入方式","text":"","path":"2025/09/17/Spring/注入方式/","date":"09-17","excerpt":"","tags":[]},{"title":"Spring组件","text":"spring4.x的组件图，5.x的变化在图中标注出来了 Spring 的核心容器是其他模块建立的基础，由 Beans 模块、Core 核心模块、Context 上下文模块和 SpEL 表达式语言模块组成，没有这些核心容器，也不可能有 AOP、Web 等上层的功能。具体介绍如下。 Beans模块：提供了框架的基础模块，包括控制反转以及依赖注入 Core 核心模块：封装了Spring框架的底层部分，包括资源访问，类型装换等工具 Context：建立在 Core 和 Beans 模块的基础之上，集成 Beans 模块功能并添加资源绑定、数据验证、国际化、Java EE 支持、容器生命周期、事件传播等。ApplicationContext 接口是上下文模块的焦点 SpEl：提供了强大的表达式语言支持，支持访问和修改属性值，方法调用，支持访问及修改数组、容器和索引器，命名变量，支持算数和逻辑运算，支持从 Spring 容器获取 Bean，它也支持列表投影、选择和一般的列表聚合等。 SPEL日志的用例：如何优雅地记录操作日志？ Data Access&#x2F;Integration： 数据访问／集成层包括 JDBC、ORM、OXM、JMS 和 Transactions 模块，具体介绍如下。 JDBC 模块：提供了一个 JDBC 的样例模板，使用这些模板能消除传统冗长的 JDBC 编码还有必须的事务控制，而且能享受到 Spring 管理事务的好处。 ORM 模块：提供与流行的“对象-关系”映射框架无缝集成的 API，包括 JPA、JDO、Hibernate 和 MyBatis 等。而且还可以使用 Spring 事务管理，无需额外控制事务。 OXM 模块：提供了一个支持 Object &#x2F;XML 映射的抽象层实现，如 JAXB、Castor、XMLBeans、JiBX 和 XStream。将 Java 对象映射成 XML 数据，或者将XML 数据映射成 Java 对象。 JMS 模块：指 Java 消息服务，提供一套 “消息生产者、消息消费者”模板用于更加简单的使用 JMS，JMS 用于用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。 Transactions 事务模块：支持编程和声明式事务管理。 Web： Spring 的 Web 层包括 Web、Servlet、WebSocket 和 Webflux 组件，具体介绍如下。 Web 模块：提供了基本的 Web 开发集成特性，例如多文件上传功能、使用的 Servlet 监听器的 IOC 容器初始化以及 Web 应用上下文。 Servlet 模块：提供了一个 Spring MVC Web 框架实现。Spring MVC 框架提供了基于注解的请求资源注入、更简单的数据绑定、数据验证等及一套非常易用的 JSP 标签，完全无缝与 Spring 其他技术协作。 WebSocket 模块：提供了简单的接口，用户只要实现响应的接口就可以快速的搭建 WebSocket Server，从而实现双向通讯。 Webflux 模块： Spring WebFlux 是 Spring Framework 5.x中引入的新的响应式web框架。与Spring MVC不同，它不需要Servlet API，是完全异步且非阻塞的，并且通过Reactor项目实现了Reactive Streams规范。Spring WebFlux 用于创建基于事件循环执行模型的完全异步且非阻塞的应用程序。 此外Spring4.x中还有Portlet 模块，在Spring 5.x中已经移除 AOP、Aspects、Instrumentation和Messaging： AOP 模块：提供了面向切面编程实现，提供比如日志记录、权限控制、性能统计等通用功能和业务逻辑分离的技术，并且能动态的把这些功能添加到需要的代码中，这样各司其职，降低业务逻辑和通用功能的耦合。 Aspects 模块：提供与 AspectJ 的集成，是一个功能强大且成熟的面向切面编程（AOP）框架。 Instrumentation 模块：提供了类工具的支持和类加载器的实现，可以在特定的应用服务器中使用。 messaging 模块：Spring 4.0 以后新增了消息（Spring-messaging）模块，该模块提供了对消息传递体系结构和协议的支持。 jcl 模块： Spring 5.x中新增了日志框架集成的模块。 Test： Test 模块：Spring 支持 Junit 和 TestNG 测试框架，而且还额外提供了一些基于 Spring 的测试功能，比如在测试 Web 框架时，模拟 Http 请求的功能。","path":"2025/09/17/Spring/Spring组件/","date":"09-17","excerpt":"","tags":[]},{"title":"Spring中的设计模式","text":"工厂模式，eg：ioc容器，BeanFactory 单例模式，eg：ioc容器 适配器，eg：Springmvc那一套，HandlerAdpter用适配器去适配不同的Controller 责任链，eg：过滤器那里 代理设计模式，eg：Spring AOP功能的实现 观察者，eg：Spring的事件发布模式 装饰者模式，eg： 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 说白了就是把那几个不同的数据库包装起来 模版方法，eg：Spring中的RedisTemplate，jdbcTemplate等以Template方法结尾的类，都用到了模版方法","path":"2025/09/17/Spring/Spring中的设计模式/","date":"09-17","excerpt":"","tags":[]},{"title":"Bean的实例化","text":"构造器： 通过构造方法创建Bean（@Compoent就是这种方式） 静态工厂： 一个静态方法返回Bean，声明这个静态方法，例如@Bean或xml配置文件，工厂需要@Configuration 工厂方法： 工厂继承FactoryBean&lt;&gt;接口，指定泛型，即需要创建的Bean，声明这个工厂 实例工厂： 和静态工厂类似，方法不需要是静态的（@Bean就是这种方式） 12345678910111213141516171819202122232425262728293031323334@Configurationpublic class AppConfig &#123; // 1. 构造器方式 @Bean public UserService userServiceByConstructor() &#123; return new UserService(); &#125; // 2. 静态工厂方式 @Bean public UserService userServiceByStaticFactory() &#123; return UserFactory.createStaticUserService(); &#125; // 3. 实例工厂方式 @Bean public UserFactory userFactory() &#123; return new UserFactory(); &#125; @Bean public UserService userServiceByInstanceFactory(UserFactory userFactory) &#123; return userFactory.createInstanceUserService(); &#125; // 4. FactoryBean 方式 @Bean public UserServiceFactoryBean userServiceByFactoryBean() &#123; return new UserServiceFactoryBean(); &#125;&#125;","path":"2025/09/17/Spring/Bean的实例化/","date":"09-17","excerpt":"","tags":[]},{"title":"Bean的生命周期","text":"实例化Bean（通过BeanDefination反射调用无参构造方法创建实例，如果没有，则需要在构造方法上添加@Autowird） 给bean的属性set赋值 检查Bean是否实现了Aware相关接口，实现的话就执行方法Aware接口：空接口，有子类接口，子类接口有方法，方法作用见名知意： BeanNameAware：void setBeanName(String name); BeanFactoryAware：void setBeanFactory(BeanFactory beanFactory) throws BeansException; ApplicationContextAware： void setApplicationContext(ApplicationContext applicationContext); BeanClassLoaderAware：void setBeanClassLoader(ClassLoader classLoader); 执行BeanPostProcessor（Bean后处理器）的before方法，此时返回的Bean可以被偷梁换柱 “偷梁换柱” &#x3D; 在 postProcessBeforeInitialization 里用一个新对象替换原 Bean 主要用途： AOP 代理（Spring 里所有基于代理的增强其实就是这么干的） 装饰模式增强 Bean 做一些动态替换&#x2F;包装 检查Bean是否实现了InitializingBean接口，如果实现了，那就执行里面的afterPropertiesSet（）方法 初始化Bean， —- 配置文件中的init-method方法或者注解的@Bean(initMethod&#x3D;”init”) （两者其一） 执行BeanProcessor的after方法，此时返回的Bean可以被偷梁换柱，AOP此时在这杯发现 使用Bean 销毁Bean，检查Bean是否实现了DisposableBean接口，实现的话执行里面的destroy方法 销毁Bean，配置文件中的destroy-method方法或者方法注解上的@Bean(destroyMethod &#x3D; “destroyMethod”)（二者其一，看使用配置文件还是注解） 注意点： 销毁Bean是在容器关闭前进行的销毁容器关闭 &#x3D; Spring 应用停止&#x2F;销毁时，Spring 容器会结束 Bean 的管理。 如果出现了@PostContruct和@PreDestroy（两个JDK注解，则会分别穿插在第四步和第八步之后） 大致就是分为五个阶段 实例化：步骤一 依赖注入：步骤二 初始化：步骤三到七 使用：步骤八 销毁：步骤九到十 为什么初始化要有那么多步骤，每个步骤干了什么事？ 灵活性：不同的步骤提供了不同的挂钩点，允许开发者在不同阶段进行介入 扩展性：通过实现不同的Aware和PostProcessor接口，开发者可以扩展Bean的功能，增强与容器的交互能力 分离关注点：每个步骤专注于特定的任务，使得初始化过程更加清晰和可维护。 安全：确保Bean在被使用前经过充分的验证和准备 BeanNameAware.setBeanName() 作用：将Bean的名称传递给Bean实例。 用途：在Bean中需要知道自身名称时使用，方便在运行时进行标识或日志记录。 BeanFactoryAware.setBeanFactory() 作用：将当前BeanFactory实例传递给Bean。 用途：允许Bean访问其创建工厂，从而可以调用工厂的其他Bean或获取配置信息。 ApplicationContextAware.setApplicationContext() 作用：将当前的ApplicationContext实例传递给Bean。 用途：使Bean可以与Spring的应用上下文进行交互，获取上下文中的资源或其他Bean。 BeanPostProcessor.postProcessBeforeInitialization() 作用：在Bean初始化之前执行自定义逻辑。 用途：允许在Bean的依赖注入完成后但初始化方法调用前，对Bean进行额外处理，如修改属性或包装Bean实例。 InitializingBean.afterPropertiesSet() 作用：在Bean属性设置完成后进行初始化。 用途：提供了一个在所有属性设置完成后执行初始化逻辑的机会，通常用于配置验证或初始化某些资源。 自定义init-method方法 作用：调用用户在配置中指定的初始化方法。 用途：允许开发者通过配置文件指定一个自定义的初始化方法，以执行特定的初始化逻辑。 BeanPostProcessor.postProcessAfterInitialization() 作用：在Bean初始化之后执行自定义逻辑。 用途：允许在Bean完成初始化后进行最终的处理，如代理增强或其他后处理逻辑。","path":"2025/09/17/Spring/Bean的生命周期/","date":"09-17","excerpt":"","tags":[]},{"title":"单例bean模式是单例模式么","text":"这个得看情况，如果你一个Service接口，然后有三个实现类Service1，2，3。那么这时候这个Service类型的Bean就不是单例了，但对于Service1就是单例的。 如果说单例Bean是单例模式，则它的范围是名字范围，而不是类型范围，就是同个名字下的Bean就是单例的，如果是同个类型下就不是了。","path":"2025/09/17/Spring/单例bean模式是单例模式么/","date":"09-17","excerpt":"","tags":[]},{"title":"Bean是安全的么","text":"Bean安不安全这个取决于其状态以及作用域 我们这里以常用的两种作用域single以及prototype做介绍。几乎所有的应用场景都是默认的single，所以我们 重点关注single就好 像prototype这种就是每次getBean时拿的都是一个新的Bean，那么像这种就是就不存在竞争问题，即是安全 而single作用域下，ioc容器拥有唯一的Bean实例。可能存在资源竞争问题，取决于Bean是否有状态。如果这 个Bean是有状态的，那么就存在线程安全的问题，这里的有无状态指的是是否包含可变的成员变量 不过，大部分 Bean 实际都是无状态（没有定义可变的成员变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的。对于有状态单例 Bean 的线程安全问题，常见的有两种解决办法： 1.在 Bean 中尽量避免定义可变的成员变量。 2.在类中定义一个 ThreadLocal 成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。 即使是无状态的bean也不一定线程安全，可能还需要考虑你的方法有没有涉及到其它类的静态成员变量的资源竞争 eg： 12345678910111213@Servicepublic class UserCacheService &#123; private static final Map&lt;Long, String&gt; userCache = new HashMap&lt;&gt;(); public void put(Long id, String name) &#123; userCache.put(id, name); // HashMap 非线程安全 &#125; public String get(Long id) &#123; return userCache.get(id); &#125;&#125; map线程不安全的，用cmap就好了","path":"2025/09/17/Spring/Bean是安全的么/","date":"09-17","excerpt":"","tags":[]},{"title":"Bean的作用域","text":"singleton : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。 **prototype **: 每次获取都会创建一个新的 bean 实例。也就是说，连续 getBean() 两次，得到的是不同的 Bean 实例。 **request **（仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。 **session **（仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。 application&#x2F;global-session （仅 Web 应用可用）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。 **websocket **（仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。 如何配置： xml方式： 注解方式： @Scope(value &#x3D; ConfigurableBeanFactory.SCOPE_PROTOTYPE)","path":"2025/09/17/Spring/Bean的作用域/","date":"09-17","excerpt":"","tags":[]},{"title":"BeanFactory和FactoryBean","text":"BeanFactory是Spring ioc容器的一个接口，用来获取以及管理Bean的依赖注入和生命周期 FactoryBean是一个接口，用来定义一个工厂Bean，它可以产生某种类型的对象。如果一个Bean实现了FactoryBean，你获取的时候不是直接返回Bean实例，而是返回FactoryBean中getObejct返回的对象，通常用于创建很复杂的对象 eg：复杂的对象：jedis客户端 12345678910111213141516171819202122232425262728293031import org.springframework.beans.factory.FactoryBean;import org.springframework.stereotype.Component;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;@Component(&quot;redisClient&quot;)public class RedisClientFactoryBean implements FactoryBean&lt;JedisPool&gt; &#123; // 模拟配置，可以改成 @Value 注入 application.properties 里的值 private String host = &quot;localhost&quot;; private int port = 6379; @Override public JedisPool getObject() throws Exception &#123; System.out.println(&quot;初始化 Redis 连接池...&quot;); JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(10); return new JedisPool(config, host, port); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return JedisPool.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125;&#125; 使用： 123456789101112131415161718192021222324import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;@Servicepublic class RedisService &#123; @Autowired private JedisPool jedisPool; // 注意：注入的就是 getObject() 返回的 JedisPool public String get(String key) &#123; try (Jedis jedis = jedisPool.getResource()) &#123; return jedis.get(key); &#125; &#125; public void set(String key, String value) &#123; try (Jedis jedis = jedisPool.getResource()) &#123; jedis.set(key, value); &#125; &#125;&#125;","path":"2025/09/17/Spring/BeanFactory和FactoryBean/","date":"09-17","excerpt":"","tags":[]},{"title":"@Autowired和@Resource","text":"@Autowired属于Spring内部注解，默认根据你类型注入，也就是默认优先根据接口的类型去匹配并注入bean 当一个接口存在多个实现类的话，byType这种就无法正确地注入对象了，因为Spring会同时找到多个对象， 然而他并不知道注入哪个（会抛错） 这时候可以通过@qualifer(“xx”)去标明注入哪个类（实现类的小驼峰命名），或者通过根据变量名自动根据 名字匹配。推荐用前者，可读性更强 @Resource是JDK提供的，默认注入类型为byName。如果无法通过name注入名称，那就会变成byType 它两个属性，一个type，一个name。声明哪个用哪个，如果都声明，那就是type+name @Autowired可在构造方法，方法，参数，字段上使用 @Resource只能在方法和字段上使用 @Autowired是Spring官方的注解，@Resource是JDK的注解，更像是一个标准或者约定，所有的IOC容器都 支持这个注解","path":"2025/09/17/Spring/@Autowired和@Resource/","date":"09-17","excerpt":"","tags":[]},{"title":"套路","text":"前缀和滑动窗口分为不定长（最小，最大），定长窗口 时间复杂度都是ON 排列，组合，子集背诵排列： 组合： 子集： 时间复杂度“区分 O(n) 和 O(n²) 主要看指针是否会反复从头开始。像冒泡排序那样，每次外层循环都让内层从 0 跑到 n，就是 O(n²)。但滑动窗口里，l 和 r 都是单调递增的，每个字符只会进窗口和出窗口一次，总次数是线性的，所以是 O(n)。” 🚩 常见时间复杂度 &amp; 如何看出来1. O(1) 常数时间 特征：执行步骤跟输入规模无关。 例子： 12int x = arr[5]; // 随机访问数组map.put(&quot;a&quot;, 1); // HashMap 插入 技巧：只要操作次数固定，不随 n 增长，就是 O(1)。 2. O(log n) 对数时间 特征：每次操作把问题规模缩小一半。 例子： 12345// 二分查找while (low &lt;= high) &#123; mid = (low + high) / 2; ...&#125; 技巧：遇到 “二分 &#x2F; 分治” → log n。 3. O(n) 线性时间 特征：每个元素只处理有限次（常数次）。 例子： 123for (int i = 0; i &lt; n; i++) &#123; ...&#125; 或滑动窗口：左右指针各走一遍数组。 技巧：数一数元素最多被访问几次，如果 ≤ 常数次 → O(n)。 4. O(n log n) 特征：线性扫描 + 对数拆分。 典型：排序算法（快排、归并、堆排）。 快排：O(n) 分区 + O(log n) 递归深度 → O(n log n)。 堆排序：每次调整堆 O(log n)，n 次 → O(n log n)。 技巧：看到 “排序”、“分治+合并”，大概率是 O(n log n)。 5. O(n²) 特征：双重循环，内层循环和外层循环完全独立。 例子： 12345for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; ... &#125;&#125; 技巧：如果每次外层循环都让内层跑一遍 n → O(n²)。 6. O(2^n) 指数级 特征：每一步有两个分支，递归深度为 n。 例子：子集枚举、回溯搜索。 12345void dfs(int i) &#123; if (i == n) return; dfs(i+1); // 选 dfs(i+1); // 不选&#125; → 共 2^n 种可能。 技巧：遇到 “子集 &#x2F; 全排列 &#x2F; 括号生成” → 可能是指数复杂度。 7. O(n!) 阶乘级 特征：枚举全排列。 例子：旅行商问题，生成 n 个数的全排列。 技巧：看到 “全排列” → n!。","path":"2025/09/17/Codetop刷题/套路/","date":"09-17","excerpt":"","tags":[]},{"title":"数组","text":"最大子数组和[🔥350]题目：就是给你一个大数组，然返回和最大的小数组 思路： 前缀和 然后线性更新res&#x3D; curPreSum - minPreSum，然后更新minPreSum 注意： res的初始化 以及前缀和数组的初始值是0 1234567891011121314151617181920212223class Solution &#123; public int maxSubArray(int[] nums) &#123; if(nums.length == 1) return nums[0]; int []preSum = getPreSum(nums); //找最大的和，那么就找最小前缀和 不断更新 //System.out.println(Arrays.toString(preSum)); int minPreSum=0; int res=Integer.MIN_VALUE;; for(int i=1;i&lt;=nums.length;i++)&#123; res = Math.max(res,preSum[i]-minPreSum); minPreSum = Math.min(preSum[i],minPreSum); &#125; return res; &#125; public int[] getPreSum(int []nums)&#123; int []res =new int[nums.length+1]; res[0]=0; for(int i=1;i&lt;=nums.length;i++)&#123; res[i]=nums[i-1]+res[i-1]; &#125; return res; &#125;&#125; 搜索旋转排序数组[🔥285]题目：从一个部分有序的数组中以logN的时间复杂度找数 思路： 有序中找东西就应该想到用二分查找，部分有序也是如此 部分有序就对此进行拆分嘛，分类讨论，左有序，还是右序 然后在各自的有序区域内进行搜索 https://chatgpt.com/s/t_68c997c4d3948191a4497c009540388e 123456789101112131415161718192021222324252627282930313233class Solution &#123; public int search(int[] nums, int target) &#123; int l = 0; int r = nums.length - 1; while (l &lt;= r) &#123; int mid = l + (r - l) / 2; if (nums[mid] == target) &#123; return mid; &#125; //如果 nums[mid] &gt;= nums[l]，说明左半边有序,否则右半边有序 //例如 [4,5,6,7,0,1,2]，如果 mid 在前半段，那 [l...mid] 一定是升序。 //第一个if就起到寻找 有序区间的作用 if (nums[mid] &gt;= nums[l]) &#123; //判断是否在这个左的单调区间内 // l.......mid if (target &gt;= nums[l] &amp;&amp; target &lt;= nums[mid]) &#123; r = mid - 1; &#125; else l = mid + 1; &#125; else &#123; //判断是否在这个右的单调区间内 //// mid.......r if (target &lt;= nums[r] &amp;&amp; target &gt;= nums[mid]) &#123; l = mid + 1; &#125; else r = mid - 1; &#125; &#125; return -1; &#125;&#125; 扩展： 这道题要注意：如果面试官问你再旋转一次怎么做，做法还是一样的，无论旋转几次，最多只有2段递增序列 难度加强版：https://leetcode.cn/problems/search-rotate-array-lcci/description/ 字节一面对这一题做了改造，如果target存在返回target，如果target不存在，返回 &gt; target的最小值 维护一个&gt;target的最小值 if (nums[mid] &gt; target) { &#x2F;&#x2F; nums[mid] 是一个候选答案 if (ans &#x3D;&#x3D; null || nums[mid] &lt; ans) { ans &#x3D; nums[mid]; } } 合并两个有序数组[🔥267]题目：两个有序数组，然后合并成一个 思路： 三指针+从后向前遍历，p1，p2，p3 优先级队列 排序 123456789101112131415161718192021222324252627282930class Solution &#123; public void merge(int[] nums1, int m, int[] nums2, int n) &#123; int p1=m-1; int p2=n-1; int p3=m+n-1; // 1 2 3 6 , 3 4 5 while(p1&gt;=0&amp;&amp;p2&gt;=0)&#123; if(nums1[p1]&gt;=nums2[p2])&#123; nums1[p3]=nums1[p1]; p1--; &#125; else &#123; nums1[p3]=nums2[p2]; p2--; &#125; p3--; &#125; while(p2&gt;=0)&#123; nums1[p3]=nums2[p2]; p3--; p2--; &#125; while(p1&gt;=0)&#123; nums1[p3]=nums1[p1]; p3--; p1--; &#125; &#125;&#125; 买卖股票的最佳时机[🔥257]题目：实现最低买入，最高卖出 思路：贪心，肯定是得选最低价的天买入，维护一个最小值即可。 123456789101112class Solution &#123; public int maxProfit(int[] prices) &#123; int res=0; //肯定是得选最低价的天买入 int minPrice =Integer.MAX_VALUE; for(int i=0;i&lt;prices.length;i++)&#123; res=Math.max(res,prices[i]-minPrice); minPrice=Math.min(minPrice,prices[i]); &#125; return res; &#125;&#125; https://leetcode-cn.com/circle/article/qiAgHn/，这篇文章讲的很通俗易懂，把几种情形都包括了 螺旋矩阵[238]题目：顺时针螺旋顺序遍历二维数组 思路： 维护四个变量，然后模拟四个方向，通过 i 指针for循环遍历 注意边界问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.util.*;class Solution &#123; public List&lt;Integer&gt; spiralOrder(int[][] matrix) &#123; int m = matrix.length; // 行数 int n = matrix[0].length; // 列数 // 定义四个边界 int up = 0, down = m - 1; int left = 0, right = n - 1; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); // 循环条件：还没有遍历完整个矩阵 while (left &lt;= right &amp;&amp; up &lt;= down) &#123; // 1. 从左到右，遍历上边界 for (int i = left; i &lt;= right &amp;&amp; res.size() &lt; m * n; i++) &#123; res.add(matrix[up][i]); &#125; // 2. 从上到下，遍历右边界（注意不包含 corner） for (int i = up + 1; i &lt;= down - 1 &amp;&amp; res.size() &lt; m * n; i++) &#123; res.add(matrix[i][right]); &#125; // 3. 从右到左，遍历下边界 for (int i = right; i &gt;= left &amp;&amp; res.size() &lt; m * n; i--) &#123; res.add(matrix[down][i]); &#125; // 4. 从下到上，遍历左边界（注意不包含 corner） for (int i = down - 1; i &gt;= up + 1 &amp;&amp; res.size() &lt; m * n; i--) &#123; res.add(matrix[i][left]); &#125; // 缩小边界，进入下一圈 left++; right--; up++; down--; &#125; return res; &#125;&#125; 合并区间[206]题目：把多个区间，如果重叠的，就合并成多个 思路： 左端点进行排序 初始化List&lt;int[]&gt; tempList 然后再比较Cur区间左断点是否小于前一个区间的右断点，是的话就更新tempList里的前一个区间的右断点，不是就加入tempList 1234567891011121314151617181920212223242526class Solution &#123; public int[][] merge(int[][] intervals) &#123; //排序 //把情况进行一个合并 //[2,5] // [4,6] Arrays.sort(intervals,(iv1,iv2)-&gt;(iv1[0]-iv2[0])); List&lt;int []&gt; temp=new ArrayList&lt;&gt;(); for(int []interval:intervals)&#123; int size=temp.size(); //存在交集 //执行合并逻辑 //[ ] // [ ] if(size&gt;0&amp;&amp;interval[0]&lt;=temp.get(size-1)[1])&#123; temp.get(size-1)[1]=Math.max(interval[1],temp.get(size-1)[1]); &#125; //无法合并就加入 else temp.add(interval); &#125; return temp.toArray(new int[temp.size()][2]); &#125;&#125; 接雨水[183]给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。 题目：找凹进去最多的区域 思路： 什么决定了雨水最多能装多少，即最高左边界，最高右边界 OK，明白以上两点，我们就可以通过双指针来遍历，找出最高左边界，以及右边界 但实际雨水能装多少，还得决定于这段区间内的空格有多少，如何更新求出空格个数呢？ 最高边界-当前位置高度即 可以装水的空格 最高边界是哪个边界？短板效应，即能装多少水取决于最短的最高边界 维护一个res，res+&#x3D;当前位置装水空格 1234567891011121314151617class Solution &#123; public int trap(int[] height) &#123; int leftMax=0; int rightMax=0; int r=height.length-1; int l=0; int res=0; while(l&lt;r)&#123; leftMax=Math.max(leftMax,height[l]); rightMax=Math.max(rightMax,height[r]); //哪边小先计算哪边，因为木桶效应，装水取决于短的那边 int water= leftMax&lt;rightMax? leftMax-height[l++]:rightMax-height[r--]; res+=water; &#125; return res; &#125;&#125; 寻找两个正序数组的中位数[156]看不懂，先摆着 1234567891011121314151617181920212223242526272829303132class Solution &#123; public double findMedianSortedArrays(int[] A, int[] B) &#123; int m = A.length, n = B.length; // 保证在短数组上二分 if (m &gt; n) return findMedianSortedArrays(B, A); int left = 0, right = m; int halfLen = (m + n + 1) / 2; while (left &lt;= right) &#123; int i = (left + right) / 2; // A 的划分位置 int j = halfLen - i; // B 的划分位置 int A_left = (i == 0) ? Integer.MIN_VALUE : A[i-1]; int A_right = (i == m) ? Integer.MAX_VALUE : A[i]; int B_left = (j == 0) ? Integer.MIN_VALUE : B[j-1]; int B_right = (j == n) ? Integer.MAX_VALUE : B[j]; if (A_left &lt;= B_right &amp;&amp; B_left &lt;= A_right) &#123; // 找到正确划分 int maxLeft = Math.max(A_left, B_left); if ((m + n) % 2 == 1) return maxLeft; int minRight = Math.min(A_right, B_right); return (maxLeft + minRight) / 2.0; &#125; else if (A_left &gt; B_right) right = i - 1; // i 太大 else left = i + 1; // i 太小 &#125; return 0.0; &#125;&#125; 下一个排列[132]题目：给你一个数组，该数组构成一个数字，找到比该数字大的最小值，且该最小值里数必须是数组里面的 arr &#x3D; 例如，arr = [1,2,3] 的下一个排列是 [1,3,2] 。 必须原地修改，只允许使用额外常数空间。 开背吧 思路： 纯纯找规律 从右到左 找到递增的边界。eg：[1,2,4,3,1] 那边边界就是2，我们mark为x 然后还是从右到左找到 x 右边最小大于x的数 y。eg：[1,2,4,3,1] y为3 然后交换x和y的位置。eg：[1,2,4,3,1] —&gt; [1,3,4,2,1] reverse(原x位置，n-1)，如果第二步找不到x即x&#x3D;-1，然后就直接跳这一步。eg：[1,2,4,3,1] —&gt; [1,3,1,2,4] 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123; public void nextPermutation(int[] nums) &#123; int n = nums.length; // 第一步：从右向左找到第一个小于右侧相邻数字的数 nums[i] int i = n - 2; while (i &gt;= 0 &amp;&amp; nums[i] &gt;= nums[i + 1]) &#123; i--; &#125; // 如果找到了，进入第二步；否则跳过第二步，反转整个数组 if (i &gt;= 0) &#123; // 第二步：从右向左找到 nums[i] 右边最小的大于 nums[i] 的数 nums[j] int j = n - 1; while (nums[j] &lt;= nums[i]) &#123; j--; &#125; // 交换 nums[i] 和 nums[j] swap(nums, i, j); &#125; // 第三步：反转 [i+1, n-1]（如果上面跳过第二步，此时 i = -1） reverse(nums, i + 1, n - 1); &#125; private void swap(int[] nums, int i, int j) &#123; int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; &#125; private void reverse(int[] nums, int left, int right) &#123; while (left &lt; right) &#123; swap(nums, left++, right--); &#125; &#125;&#125;作者：灵茶山艾府链接：https://leetcode.cn/problems/next-permutation/solutions/3621022/jiao-ni-cong-ling-kai-shi-si-kao-zhe-ti-9qfrq/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 上一个排列解法只需要改变两点：1.大于号换成小于号2.排降序 缺失的第一个正数[108]题目：目标数据[1,2,3,4,5,6……] ，让你找出缺失的第一个正数 思路： 先把有的整理一遍，寻找i这个位置上对的人 nums[i] !&#x3D; nums[nums[i] - 1] 然后for循环找出来 12345678910111213141516171819202122232425class Solution &#123; public int firstMissingPositive(int[] nums) &#123; //先把元素交换到正确的位置上 for (int i = 0; i &lt; nums.length; i++) &#123; //while循环在干什么？ 在寻找i这个位置上对的人！！！！ //即 i 上应该坐着 i+1 即 nums[i] == nums[nums[i]-1】 =&gt; i = nums[i] - 1 while (nums[i] &gt; 0 &amp;&amp; nums[i] &lt;= nums.length &amp;&amp; nums[i] != nums[nums[i] - 1]) &#123; int temp = nums[nums[i] - 1]; nums[nums[i] - 1] = nums[i]; nums[i] = temp; &#125; &#125; //System.out.println(Arrays.toString(nums)); for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] != i + 1) &#123; return i + 1; &#125; &#125; return nums.length + 1; &#125;&#125; 从前序与中序遍历序列构造二叉树[🔥105]思路： &#x2F;&#x2F;1.从前序遍历里确定根节点&#x2F;&#x2F;2.然后确立根节点在中序遍历的位置 index，然后从中序遍历数组中得出 左子树的长度&#x2F;&#x2F;3.切分中序数组，切出来左子树，右子树 eg：[9,3,15,20,7] -&gt; [9] [15,20,7] [0,leftSize) leftSize [leftSize-1,n)&#x2F;&#x2F; 4.切分前序数组，切出来左子树，右子树 eg：[3,9,20,15,7] -&gt; [1,1+leftSize) [1+leftSize,n)&#x2F;&#x2F;5.递归,求出left,right&#x2F;&#x2F;6. return TreeNode (preOrder[0],left,right) PS：md是真的晕递归啊啊，为什么学了两年还是晕。。。。你理解递归不要陷入细节，先明白方法返回的是什么！！！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; public TreeNode buildTree(int[] preorder, int[] inorder) &#123; //[3,9,20,15,7] //[9,3,15,20,7] //1.从前序遍历里确定根节点 //2.然后确立根节点在中序遍历的位置 index //3.切分中序数组，切出来左子树，右子树 eg：[9,3,15,20,7] -&gt; [9] [15,20,7] [0,leftSize) leftSize [leftSize-1,n) // 4.切分前序数组，切出来左子树，右子树 eg：[3,9,20,15,7] -&gt; [1,1+leftSize) [1+leftSize,n) //5.递归,求出left,right //6. return TreeNode (preOrder[0],left,right) int n = preorder.length; if (n == 0) &#123; return null; &#125; // int leftSize = getLeftSize(inorder, preorder[0]); int[] pre1 = Arrays.copyOfRange(preorder, 1, 1 + leftSize); int[] pre2 = Arrays.copyOfRange(preorder, 1 + leftSize, n); //[0 leftSize-1] [leftSize+1 n] int[] in1 = Arrays.copyOfRange(inorder, 0, leftSize); int[] in2 = Arrays.copyOfRange(inorder, 1 + leftSize, n); TreeNode left = buildTree(pre1, in1); TreeNode right = buildTree(pre2, in2); return new TreeNode(preorder[0], left, right); &#125; public int getLeftSize(int[] order, int x) &#123; for (int i = 0;; i++) &#123; if (order[i] == x) &#123; return i; &#125; &#125; &#125;&#125; 子集[99]思路： 回溯三部曲 做的时候脑子要有回溯树 12345678910 [] (startIndex=0) / | \\ [1] [2] [3] (分别选择 1,2,3) / \\ / \\ \\[1,2] [1,3] [2,3] ··· ··· (继续往右走) /[1,2,3] (完整路径) 123456789101112131415161718192021222324252627class Solution &#123; List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123; if (nums.length == 0) &#123; return res; &#125; dfs(nums, 0); return res; &#125; //startIndex 的作用是控制 // startIndex 的本质是： // 限制递归的选择范围（只能往后，不回头）。 // 保证子集不重复（避免 [2,1] 这种情况）。 public void dfs(int[] nums, int startIndex) &#123; res.add(new ArrayList&lt;&gt;(path)); for (int i = startIndex; i &lt; nums.length; i++) &#123; path.add(nums[i]); dfs(nums, i + 1); path.remove(path.size() - 1); &#125; &#125;&#125; 时间复杂度 O（N*N） 在排序数组中查找元素的第一个和最后一个位置[93]思路： 二分找左右边界 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Solution &#123; public int[] searchRange(int[] nums, int target) &#123; //二分查找 int leftBorder=leftBorder(nums,target); int rightBorder=rightBorder(nums,target); if(leftBorder==-1&amp;&amp;rightBorder==-1)&#123; return new int[]&#123;leftBorder,rightBorder&#125;; &#125; else return new int[]&#123;leftBorder+1,rightBorder-1&#125;; &#125; public int leftBorder(int []nums,int target)&#123; int left=0; int right=nums.length-1;//左闭右闭 int leftBorder=-1; while(left&lt;=right)&#123; int mid=left+(right-left)/2; if(nums[mid]==target)&#123; right=mid-1; leftBorder=right; &#125; else if(nums[mid]&lt;target)&#123; left=mid+1; &#125; else if(nums[mid]&gt;target)&#123; right=mid-1; &#125; &#125; return leftBorder; &#125; public int rightBorder(int []nums,int target)&#123; int left=0; int right=nums.length-1;//左闭右闭 int rightBorder=-1; while(left&lt;=right)&#123; int mid=left+(right-left)/2; if(nums[mid]==target)&#123; left=mid+1; rightBorder=left; &#125; else if(nums[mid]&lt;target)&#123; left=mid+1; &#125; else if(nums[mid]&gt;target)&#123; right=mid-1; &#125; &#125; return rightBorder; &#125;&#125; 组合总和[86]题目：给一个数组，然后给一个target，让你求和等于target的 数组里的数字组合，每个数字可重复取 思路： 回溯 重复取怎么处理呢 dfs(candidates,target,i);不是i+1， i就表示可以重复取。然后用sum&gt;target来控制 超过就return 1234567891011121314151617181920212223class Solution &#123; List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); int sum =0;//用来记录cur和 public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; dfs(candidates,target,0); return res; &#125; public void dfs(int []candidates,int target,int startIndex)&#123; if(sum == target)&#123; res.add(new ArrayList&lt;&gt;(path)); return ; &#125; for(int i=startIndex;i&lt;candidates.length;i++)&#123; if(sum &gt; target) break; sum += candidates[i]; path.add(candidates[i]); //这里的i表示 每个数可以重复选取 dfs(candidates,target,i); sum -= path.remove(path.size()-1); &#125; &#125;&#125; 要考虑去重吗？ 最小路径和[86]题目 思路： 多条路径求最小和的，可以考虑dfs算法，但很遗憾，时间复杂度2的m+n 次方，超时了 动态规划。理清数组元素含义，以及当前状态是怎么由前面的状态推导过来的 dfs： 12345678910111213141516171819202122232425class Solution &#123; int res = Integer.MAX_VALUE; int sum = 0; int n, m; int[][] dir = &#123;&#123;0,1&#125;,&#123;1,0&#125;&#125;; // 只需要右和下 public int minPathSum(int[][] grid) &#123; n = grid.length; m = grid[0].length; dfs(grid, 0, 0, 0); return res; &#125; public void dfs(int[][] grid, int x, int y, int currentSum) &#123; if(x &gt;= n || y &gt;= m) return; // 越界 currentSum += grid[x][y]; if(x == n-1 &amp;&amp; y == m-1) &#123; res = Math.min(res, currentSum); return; &#125; dfs(grid, x+1, y, currentSum); // 下 dfs(grid, x, y+1, currentSum); // 右 &#125;&#125; 动态规划 美团一面，写完要求在源码基础上生成路径？ 123456789101112131415161718192021222324252627282930313233343536373839public int minPathSum(int[][] grid) &#123; int n = grid.length; int m = grid[0].length; int[][] dp = new int[n][m]; // dp[i][j] = 到 (i,j) 的最小路径和 String[][] path = new String[n][m]; // path[i][j] = 到 (i,j) 的路径字符串 dp[0][0] = grid[0][0]; path[0][0] = &quot;(0,0)&quot;; // 初始化第一列 for (int i = 1; i &lt; n; i++) &#123; dp[i][0] = dp[i-1][0] + grid[i][0]; path[i][0] = path[i-1][0] + &quot; -&gt; (&quot; + i + &quot;,&quot; + 0 + &quot;)&quot;; &#125; // 初始化第一行 for (int j = 1; j &lt; m; j++) &#123; dp[0][j] = dp[0][j-1] + grid[0][j]; path[0][j] = path[0][j-1] + &quot; -&gt; (&quot; + 0 + &quot;,&quot; + j + &quot;)&quot;; &#125; // 填表 for (int i = 1; i &lt; n; i++) &#123; for (int j = 1; j &lt; m; j++) &#123; //下走 还是 左走 if (dp[i-1][j] &lt; dp[i][j-1]) &#123; dp[i][j] = dp[i-1][j] + grid[i][j]; path[i][j] = path[i-1][j] + &quot; -&gt; (&quot; + i + &quot;,&quot; + j + &quot;)&quot;; &#125; else &#123; dp[i][j] = dp[i][j-1] + grid[i][j]; path[i][j] = path[i][j-1] + &quot; -&gt; (&quot; + i + &quot;,&quot; + j + &quot;)&quot;; &#125; &#125; &#125; System.out.println(&quot;Path: &quot; + path[n-1][m-1]); return dp[n-1][m-1]; &#125; 最长连续序列[82]题目：从一没排好序的数组里找出 最长的连续序列 如 1,2,3,4 思路： hashset，for x 然后以x为开头搜连续段，后续for 时候如果遇到连续段里的就 continue 。即哈希set，每次搜索一个数搜完一个连续段，后面在遇到连续段中的直接跳过。 123456789101112131415161718192021222324252627class Solution &#123; public int longestConsecutive(int[] nums) &#123; Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); //去重 for (int i : nums) &#123; set.add(i); &#125; // int res = 0; for (int x : set) &#123; //已经找过的 就不要再找了 if (set.contains(x - 1)) continue; //寻找以x为开头的连续序列 //x x+1 x+1+1 .... int cnt = 1; int nextX = x + 1; while (set.contains(nextX)) &#123; nextX++; cnt++; &#125; res = Math.max(res, cnt); &#125; return res; &#125;&#125; 时间复杂度：O N，因为每个元素只被访问了一次 旋转图像[]思路： 先交换行（上下倒转），然后转置（ 转置操作：matrix[i][j] ↔ matrix[j][i]） 1234567891011121314151617181920class Solution &#123; public void rotate(int[][] matrix) &#123; int n = matrix.length - 1; int m = matrix[0].length - 1; //先交换行 上下倒置 第一行 和 第n 行 第二行 和 第 n-1行 for (int i = 0; i &lt;= n/2; i++) &#123; int[] temp = matrix[i]; matrix[i] = matrix[n - i]; matrix[n - i] = temp; &#125; //倒置 [i][j] 和 [j][i] 交换 对角想交换 for (int i = 0; i &lt;= n; i++) &#123; for (int j = i + 1; j &lt;= m; j++) &#123; int temp = matrix[i][j]; matrix[i][j] = matrix[j][i]; matrix[j][i] = temp; &#125; &#125; &#125;&#125; 转置： 岛屿的最大面积[80]思路： 就是dfs，模版题，没啥好说的，需要注意一下这种情况因为是四面八方都可以走，那就得记录走过的位置或者说 for循环入口其实导向是同一块岛屿 1234567891011121314151617181920212223242526272829303132333435class Solution &#123; int area = 0; int res = 0; public int maxAreaOfIsland(int[][] grid) &#123; //bfs or dfs //dfs for (int i = 0; i &lt; grid.length; i++) &#123; for (int j = 0; j &lt; grid[0].length; j++) &#123; area = 0; dfs(grid, i, j); res = Math.max(res, area); &#125; &#125; return res; &#125; public void dfs(int[][] grid, int x, int y) &#123; if (x &lt; 0 || y &lt; 0 || x &gt;= grid.length || y &gt;= grid[0].length) &#123; return; &#125; if (grid[x][y] != 1) &#123; return; &#125; if (grid[x][y] == 1) area++; grid[x][y] = -1; dfs(grid, x + 1, y); dfs(grid, x, y + 1); dfs(grid, x, y - 1); dfs(grid, x - 1, y); &#125;&#125; 寻找峰值[76]题目：找出山峰，返回山峰的索引 思路：二分查找，分情况讨论 123456789101112// [-无穷 ...3 4 .... -无穷]// 那么4的右侧一定有山峰// mid = indexof(3)if (nums[mid] &lt; nums[mid + 1]) &#123; l = mid + 1;&#125;// [-无穷 ...4 3 .... -无穷]// mid = indexof(3)// 那么4的左侧一定有山峰else &#123; r = mid - 1;&#125; 图解：162. 寻找峰值 - 力扣（LeetCode） 1234567891011121314151617181920212223242526272829303132class Solution &#123; public int findPeakElement(int[] nums) &#123; if (nums.length == 1) return 0; //两端 if (nums[nums.length - 1] &gt; nums[nums.length - 2]) &#123; return nums.length - 1; &#125; if (nums[0] &gt; nums[1]) &#123; return 0; &#125; //二分法 int l = 0; int r = nums.length - 1; while (l &lt;= r) &#123; int mid = (r + l) / 2; // [-无穷 ...3 4 .... -无穷] // 那么4的右侧一定有山峰 // mid = indexof(3) if (nums[mid] &lt; nums[mid + 1]) &#123; l = mid + 1; &#125; // [-无穷 ...4 3 .... -无穷] // mid = indexof(3) // 那么4的左侧一定有山峰 else &#123; r = mid - 1; &#125; &#125; return l; &#125;&#125; 乘积最大子数组[70]多数元素[67]思路： map 空间复杂度O（1）的解法：摩尔投票 长度最小的子数组题目：长度最小的和为k的子数组 思路： 移动零[60] 思路： 双指针，i0，i 记录0元素的位置i0，i。如果nums[i]为非0元素，就与其交换，然后i0++ 123456789101112131415161718192021222324class Solution &#123; public void moveZeroes(int[] nums) &#123; //双指针 int i0 = 0;// i0表示指向 for (; i0 &lt; nums.length; i0++) &#123; if (nums[i0] == 0) &#123; break; &#125; &#125; //[1,2,0,5,6,0,1] // for (int i = i0 + 1; i &lt; nums.length; i++) &#123; // 非0 元素与0元素交换 if (nums[i] != 0) &#123; // i0 i交换 int temp = nums[i]; nums[i] = nums[i0]; nums[i0] = temp; // 交换过了 i0++ i0++; &#125; &#125; &#125;&#125; 寻找旋转排序数组中的最小值[56]题目：在部分有序数组中找到最小值 思路： 看到log N的算法，就得想到二分 根据mid和nums.length元素比较 得出最小值是在右边还是在左边 [3,4,5,1,2]：最小值在右边 [1 2 3 4 5]：最小值在左边 1234567891011121314151617181920class Solution &#123; public int findMin(int[] nums) &#123; // int l = 0; int r = nums.length - 1; while (l &lt;= r) &#123; int mid = l + (r - l) / 2; // [3,4,5,1,2] 5 &gt; 2 最小值在右边 // 为什么不能和nums[0] 比较? 因为无法区分 [1 2 3 4 5] [3,4,5,1,2] 这两种情况 if (nums[mid] &gt; nums[nums.length - 1]) &#123; l = mid +1; &#125; else &#123; //[1 2 3 4 5] 最小值在右边 r = mid -1; &#125; &#125; return nums[l]; &#125;&#125; 先升序再降序的数组，找到最大值参考寻找峰值 单词搜索[54]思路： dfs+回溯 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123; int offset = -1; boolean[][] visited; public boolean exist(char[][] board, String word) &#123; visited = new boolean[board.length][board[0].length]; for (int i = 0; i &lt; board.length; i++) &#123; for (int j = 0; j &lt; board[0].length; j++) &#123; if (dfs(board, i, j, word, 0)) &#123; return true; &#125; &#125; &#125; return false; &#125; public boolean dfs(char[][] board, int x, int y, String word, int offset) &#123; if (x &lt; 0 || y &lt; 0 || x &gt;= board.length || y &gt;= board[0].length) &#123; return false; &#125; if (visited[x][y]) return false; if (board[x][y] != word.charAt(offset)) &#123; return false; &#125; if (offset == word.length() - 1) return true; visited[x][y] = true; boolean found = dfs(board, x, y + 1, word, offset + 1) || dfs(board, x + 1, y, word, offset + 1) || dfs(board, x, y - 1, word, offset + 1) || dfs(board, x - 1, y, word, offset + 1); //回溯 visited[x][y] = false; return found; &#125;&#125; 分隔链表[20]思路： 双指针，sml，big if cur &lt; x 加入sml，else 加入big 12345678910111213141516171819202122232425262728293031323334/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode() &#123;&#125; * ListNode(int val) &#123; this.val = val; &#125; * ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125; * &#125; */class Solution &#123; public ListNode partition(ListNode head, int x) &#123; ListNode smlDummy = new ListNode(); ListNode bigDummy = new ListNode(); ListNode smlCur = smlDummy; ListNode bigCur = bigDummy; ListNode cur = head; while(cur!=null)&#123; if(cur.val &lt; x)&#123; smlCur.next = cur; smlCur = smlCur.next; &#125; else &#123; bigCur.next = cur; bigCur = bigCur.next; &#125; cur = cur.next; &#125; smlCur.next = bigDummy.next; //重点 bigCur.next = null; return smlDummy.next; &#125;&#125; 搜索二维矩阵 II[80]思路：旋转45度 123456789101112131415161718192021class Solution &#123; public boolean searchMatrix(int[][] matrix, int target) &#123; //逆旋转旋转45 int i = matrix.length - 1; int j = 0; while(i &gt;= 0 &amp;&amp; j &lt; matrix[0].length)&#123; if(matrix[i][j] &gt; target)&#123; //向左变小 i--; &#125; else if(matrix[i][j] &lt; target)&#123; //向右变大 j++; &#125; else return true; &#125; return false; &#125;&#125; 乘积最大子数组[71]思路： 暴力，两层for循环 是不可以搞前缀积的！！！ 12345678910111213class Solution &#123; public int maxProduct(int[] nums) &#123; int res = Integer.MIN_VALUE; for(int i = 0; i &lt; nums.length; i++)&#123; int sub = 1; for(int j = i; j &lt; nums.length; j++)&#123; sub = sub * nums[j]; res = Math.max(res, sub); &#125; &#125; return res; &#125;&#125; 动态规划 维护当前最大值和当前最小值 解释：当前最大值和当前最小值是指什么？ 变量 更严谨的定义 curMax 以 nums[i] 结尾的所有子数组里「乘积最大的值」，如果当前是 0，则为 0 curMin 以 nums[i] 结尾的所有子数组里「乘积最小的值」，如果当前是 0，则为 0 因为当遇到负数时，要乘上负数时，当前最大值会变成当前最小值，当前最小值会变成当前最大值 如果一直遇到整数，那么不断curMax * curNum[] 就好了 如果遇到了 0，这时候就会自动断开了，curMax &#x3D; 0, curMin &#x3D; 0（即重开了） 12345678910111213141516171819202122232425262728293031class Solution &#123; public int maxProduct(int[] nums) &#123; int res = Integer.MIN_VALUE; //当前最大值，最小值 int curMax = 1; int curMin = 1; for (int i = 0; i &lt; nums.length; i++) &#123; //如果为负数，就会触发 最大值变成最小值 最小值变成最大值 // 1 2 -5 curMax = 2 curMin = 1 // curMax = 1 curMin = 2 // curMax = -5 curMin = -10 if (nums[i] &lt; 0) &#123; int temp = curMax; curMax = curMin; curMin = temp; &#125; curMax = Math.max(curMax * nums[i], nums[i]); curMin = Math.min(curMin * nums[i], nums[i]); if(nums[i] == 0)&#123; System.out.println(&quot;---0-&quot;); System.out.println(curMax); System.out.println(curMin); System.out.println(&quot;---0-&quot;); &#125; System.out.println(curMax); System.out.println(curMin); res = Math.max(curMax, res); &#125; return res; &#125;&#125; 字节腾讯，还要输出这个数组 维护bestStart bestEnd，然后如果nums[i] &gt; curMax 就会开始重新计数了 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123; public int maxProduct(int[] nums) &#123; int res = Integer.MIN_VALUE; //当前最大值，最小值 int curMax = 1; int curMin = 1; //结果集的起始 int start = 0, bestStart = 0, bestEnd = 0; for (int i = 0; i &lt; nums.length; i++) &#123; //如果为负数，就会触发 最大值变成最小值 最小值变成最大值 // 1 2 -5 curMax = 2 curMin = 1 // curMax = 1 curMin = 2 // curMax = -5 curMin = -10 if (nums[i] &lt; 0) &#123; int temp = curMax; curMax = curMin; curMin = temp; &#125; if (curMax * nums[i] &lt; nums[i]) &#123; curMax = nums[i]; start = i; &#125; else curMax = curMax * nums[i]; curMin = Math.min(curMin * nums[i], nums[i]); if (res &lt; curMax) &#123; res = curMax; bestStart = start; bestEnd = i; &#125; &#125; System.out.println(Arrays.toString(Arrays.copyOfRange(nums, bestStart, bestEnd + 1))); return res; &#125;&#125; 跳跃游戏[57]思路：两种做法 1234567891011121314class Solution &#123; public boolean canJump(int[] nums) &#123; //i 是 人的位置，k 是路（即人能最远到达的地方），路就决定了 人能到达的位置 if(nums.length &lt;= 1) return true; int k = 0; for(int i = 0; i &lt;= k; i++)&#123; k = Math.max(k, nums[i] + i); if(k &gt;= nums.length - 1)&#123; return true; &#125; &#125; return false; &#125;&#125; 1234567891011121314151617class Solution &#123; public boolean canJump(int[] nums) &#123; // if(nums.length &lt;= 1)&#123; return true; &#125; // 2 3 1 1 4 // k表示 当前能跳到的最远位置 int k = 0; for(int i = 0; i &lt; nums.length; i++)&#123; if(i &gt; k) return false; k = Math.max(k, i + nums[i]); System.out.println(&quot;当前下标：&quot; + i + &quot;最远位置：&quot; + k); &#125; return true; &#125;&#125; 跳跃游戏 II[47]两种做法： 动态规划 12345678910111213141516171819202122232425262728class Solution &#123; public int jump(int[] nums) &#123; if(nums.length &lt;= 1) return nums.length - 1; //表示 走到i的所需的最小跳跃数 int n = nums.length; int []dp = new int[n]; Arrays.fill(dp, Integer.MAX_VALUE); dp[0] = 0; dp[1] = 1; for(int i = 0; i &lt; nums.length; i++)&#123; //状态方程 int k = i + nums[i]; if( k &gt; nums.length - 1)&#123; k = nums.length - 1; &#125; dp[k] = Math.min(dp[k], dp[i] + 1); for(int j = i + 1; j &lt; k + 1; j++)&#123; dp[j] = Math.min(dp[k], dp[j]); &#125; //Arrays.fill(dp,, dp[k]); System.out.println(Arrays.toString(dp)); &#125; //System.out.println(Arrays.toString(dp)); return dp[n - 1]; &#125;&#125; 时间复杂度 &#x3D; O(n²)，空间复杂度 &#x3D; O(n) 贪心 123456789101112131415161718192021class Solution &#123; public int jump(int[] nums) &#123; int steps = 0; // 总跳跃次数 int end = 0; // 当前这一步能跳到的最远边界 int farthest = 0; // 下一步能跳到的最远位置 // 注意：最后一个位置不需要再跳，所以循环到 n-2 for (int i = 0; i &lt; nums.length - 1; i++) &#123; // 更新下一步的最远可达位置 farthest = Math.max(farthest, i + nums[i]); // 如果到达当前步的边界，就必须跳一次 if (i == end) &#123; steps++; end = farthest; // 更新下一跳的边界 &#125; &#125; return steps; &#125;&#125; 盛最多水的容器[51]思路： 双指针 贪心思路: 木桶容量由短板决定, 移动长板的话, 水面高度不可能再上升, 而宽度变小了, 所以只有通过移动短板, 才有可能使水位上升. 123456789101112131415161718class Solution &#123; public int maxArea(int[] height) &#123; //双指针 int l = 0; int r = height.length - 1; int res = Integer.MIN_VALUE; while(l &lt;= r)&#123; int h = Math.min(height[l], height[r]); res = Math.max(res, h * (r - l)); //把矮的给淘汰掉，因为要装，那么短的那表一定得尽可能长 if(height[l] &gt; height[r])&#123; r--; &#125; else l++; &#125; return res;&#125;&#125; 最短无序连续子数组[10]思路： 最简单的做法，即先排序，然后比对，从左，从右，找第一个不同的元素，然后len &#x3D; right - left + 1 123456789101112131415161718192021class Solution &#123; public int findUnsortedSubarray(int[] nums) &#123; int[] newNums = Arrays.copyOfRange(nums, 0, nums.length); Arrays.sort(newNums); int l = 0; int r = -1; for(int i = 0;i &lt; newNums.length; i++)&#123; if(newNums[i] != nums[i])&#123; l = i; break; &#125; &#125; for(int i = newNums.length - 1;i &gt;= 0; i--)&#123; if(newNums[i] != nums[i])&#123; r = i; break; &#125; &#125; return r - l + 1 &gt; 0? r - l + 1: 0; &#125;&#125; 计数排序 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123; public int findUnsortedSubarray(int[] nums) &#123; int[] newNums = Arrays.copyOfRange(nums, 0, nums.length); sort(newNums); //System.out.println(Arrays.toString(newNums)); int l = 0; int r = -1; for(int i = 0;i &lt; newNums.length; i++)&#123; if(newNums[i] != nums[i])&#123; l = i; break; &#125; &#125; for(int i = newNums.length - 1;i &gt;= 0; i--)&#123; if(newNums[i] != nums[i])&#123; r = i; break; &#125; &#125; return r - l + 1 &gt; 0? r - l + 1: 0; &#125; public void sort(int []nums)&#123; int MAX = 100000; int[] counter = new int[MAX * 2 + 4]; int min = Integer.MAX_VALUE; int max = Integer.MIN_VALUE; for(int i: nums)&#123; min = Math.min(i, min); max = Math.max(i, max); counter[i + MAX]++; &#125; int idx = 0; for(int i = min; i &lt;= max; i++)&#123; int count = counter[i + MAX]; while(count &gt; 0)&#123; nums[idx] = i; count--; idx++; &#125; &#125; &#125;&#125; 任务调度器[5]思路： 贪心：很容易想到就是 先安排出现次数最多的任务，然后让这个任务之间的间隔刚好为N 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123; public int leastInterval(char[] tasks, int n) &#123; //贪心：很容易想到就是 先安排出现次数最多的任务，然后让这个任务之间的间隔刚好为N Map&lt;Character,Integer&gt; counter = new HashMap(); for(char c: tasks)&#123; counter.put(c, counter.getOrDefault(c, 0) + 1); &#125; int max = 0; char cMax = &#x27;*&#x27;; for(char c: counter.keySet())&#123; if(counter.get(c) &gt; max) &#123; cMax = c; max = counter.get(c); &#125; &#125; int bucketCnt = max; int cntOflastBucket = 0; for(char c: counter.keySet())&#123; if(counter.get(c) == max) cntOflastBucket++; &#125; //第一种情况：槽够用 //eg：A：4 B：4 C：1 D: 1 n = 2 //A B C //A B D //A B * //A B //则 完成时间不能等于 长度 //第二种情况：槽不够用 //eg：A：4 B：4 C：4 D: 2 n = 2 //A B C D //A B C D //A B C //A B C //则 完成时间等于 长度 return Math.max((bucketCnt - 1) * (n + 1) + cntOflastBucket, tasks.length); &#125;&#125; 找到所有数组中消失的数字[4]同缺失的第一个正数 思路： 交换到正确的位置上 [1,2,3] –&gt; nums[i] &#x3D;&#x3D; nums[nums[i] - 1]，即nums[0] &#x3D;&#x3D; nums[1 - 1]。为什么不能写成 i&#x3D;nums[i] - 1? 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; public List&lt;Integer&gt; findDisappearedNumbers(int[] nums) &#123; for(int i = 0; i &lt; nums.length; i++)&#123; System.out.println(i); System.out.println(nums[i] +&quot;::::::::::::&quot; + nums[nums[i] - 1]); while(nums[i] &lt;= nums.length &amp;&amp; nums[i] != nums[nums[i] - 1])&#123; System.out.println(Arrays.toString(nums)); System.out.println(i + &quot;:::&quot;+ (nums[i] -1)); swap(nums, i, nums[i] - 1); &#125; &#125; //System.out.println(Arrays.toString(nums)); List&lt;Integer&gt; res = new ArrayList(); // 1 2 3 for(int i = 0; i &lt; nums.length; i++)&#123; if(nums[i] != i + 1) res.add(i + 1); &#125; return res; &#125; public void swap(int []nums, int i,int j)&#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125;&#125;//eg：[2,2,1] nums[i] == nums[nums[i] - 1] 表示当前数字是否在正确位置上，每次就会正确交换一次，这样子每个数字只会被遍历一次// 0// 2::::::::::::2// 1// 2::::::::::::2// 2// 1::::::::::::2// [2, 2, 1]// 2:::0 根据身高重建队列 先排序，先按p[0] 降序 and p[1] 升序。 :::info楼主的解释很棒！但是这里稍微有点没有解释清楚，“按照第二个元素正向排序，我们希望 k 大的尽量在后面，减少插入操作的次数。”不止是为了减少插入次数，也是为了保证正确性。举个例子，在身高一样，k不一样的时候，譬如[5,2]和[5,3], 对于最后排完的数组，[5,2]必然在[5,3]的前面。所以如果遍历的时候[5,3]在前面，等它先插入完，这个时候它前面会有3个大于等于它的数组对，遍历到[5,2]的时候，它必然又会插入[5,3]前面（因为它会插入链表索引为2的地方），这个时候[5,3]前面就会有4个大于等于它的数组对了，这样就会出错。 ::: 然后巧用 add（index，n）实现插队 1234567891011121314151617181920212223class Solution &#123; public int[][] reconstructQueue(int[][] people) &#123; //先排序再插队 //排序 Arrays.sort(people, (a, b) -&gt; &#123; return a[0] == b[0] ? a[1] - b[1] : b[0] - a[0]; &#125; ); List&lt;int[]&gt; res = new ArrayList(); for(int []p: people) &#123; System.out.println(Arrays.toString(p)); //插队 res.add(p[1], p); &#125; System.out.println(&quot;////////////&quot;); for(int []p: res) &#123; System.out.println(Arrays.toString(p)); &#125; return res.toArray(new int[people.length][2]); &#125;&#125; 除自身以外数组的乘积[]思路 前缀积，后缀积 Map&lt;Integer,Integer&gt; front：k：当前元素index。v：包含当前元素的区间积，元素之前的积即map.getIOrDefault(i - 1, 1) * curNum 12345678910111213141516171819202122232425262728import java.util.*;class Solution &#123; public int[] productExceptSelf(int[] nums) &#123; int[] ans = new int[nums.length]; Map&lt;Integer, Integer&gt; front = new HashMap&lt;&gt;(); Map&lt;Integer, Integer&gt; back = new HashMap&lt;&gt;(); // 前缀积 for (int i = 0; i &lt; nums.length; i++) &#123; front.put(i, front.getOrDefault(i - 1, 1) * nums[i]); &#125; // 后缀积 for (int i = nums.length - 1; i &gt;= 0; i--) &#123; back.put(i, back.getOrDefault(i + 1, 1) * nums[i]); &#125; // 最终结果 for (int i = 0; i &lt; nums.length; i++) &#123; int left = front.getOrDefault(i - 1, 1); int right = back.getOrDefault(i + 1, 1); ans[i] = left * right; &#125; return ans; &#125;&#125; 会议室2[24]1","path":"2025/09/17/Codetop刷题/数组/","date":"09-17","excerpt":"","tags":[]},{"title":"重试策略：区分偶发性超时和频繁超时的重试策略","text":"这是一个非常高级的案例。借助这个案例，你可以达成三个效果： 证明自己很擅长搞服务治理 证明自己懂得解决重试风暴的问题 证明自己能够设计非常复杂的方案 这个案例就是借助滑动窗口算法来统计一段时间内的超时请求比率，如果超过了比率，那么就认为此时超时不是一个偶发性的问题，不应该继续重试。而后，为了支撑高并发的场景，滑动窗口算法可以借助 ring buffer 来实现，用一个比特来表达请求是否超时。同时可以用原子操作来进一步提高性能，因此你在这个案例下能够聊的话题非常多： 滑动窗口算法 Ring Buffer 算法 位操作：统计 1 的个数 原子操作 我愿称之为，你拿出去装一次逼，就可以证明你在算法设计上还是有点东西的。 在微服务超时控制和重试策略里面，经常会引用这个案例。代码在 interview-cases&#x2F;case31_40&#x2F;case32 at main · meoying&#x2F;interview-cases (github.com) 普通版普通版本就是使用一个普通的滑动窗口算法，关键点是： 在窗口里面，记录了每个请求的时间戳，以及这个请求是否超时； 每个请求在收到了超时响应之后，统计这个窗口内部的超时请求数量； 如果超时请求数量超过阈值了，那么就认为不应该重试了； 如果超时请求数量没有超过阈值，那么就认为可以重试； 进阶版在高并发的情况下，滑动窗口算法的开销是难以忍受的。举个例子来说，即便将窗口限制在 1s，高并发的时候 1s 也有几万个请求，这几万个请求会占据你很多内存。而且在判定要不要重试的时候还要遍历，这也是一个极大的问题。 所以在进阶版里面，需要做优化： 使用 ring buffer 来实现滑动窗口，进一步使用一个比特来标记请求是否超时； 每个请求超时之后，判定要不要执行重试，就要统计这个 ring buffer 里面为 1 的比特数量； 如果超时请求数量超过阈值了，那么就认为不应该重试； 如果超时请求数量没有超过阈值，那么就认为可以重试； 为了进一步提高性能，这里可以使用原子操作； 举个例子来说，假设我们现在用 128 个比特来记录请求的超时信息，也就是说窗口大小是 128 个请求（不再是以时间来作为窗口大小了）。而后第一个请求过来标记下标 0 的比特，第二个请求标记下标 1 的比特…当都标记满了，就再次从头开始。 要注意，在我们的实现里面使用了大量的原子操作，所以你同样可以用这个案例来证明你很擅长并发编程。如果你觉得代码奇怪，请不要惊讶，它确实是对的，只是说违背一般的并发编程的模式而已，但是它确实是并发安全的，并且性能很好。 适用场景和话术它可以用在这些场景： 介绍你的提高可用性的方案，你可以将重试作为作为提高系统可用性的一环，而后介绍你这个规避了重试风暴的重试策略； 在面试中讨论到了超时问题 在面试中讨论到了重试问题，你可以主动提及重试风暴的问题，以及你解决了这个问题，也就是这个案例； 而在介绍的时候，你要用一种演进的预期来介绍，也就是你不要上来就介绍进阶版，你要先介绍普通版，而后介绍进阶版。从这个演进中能够体现你对系统的思考，以及你是一个精益求精的人。 那么你可以参考这个话术： 在处理大量请求时，我们经常会遇到超时的情况。为了合理控制重试行为，避免所谓的“重试风暴”，我设计了一个基于时间窗口的算法。在这个算法中，我们维护了一个滑动窗口，窗口内记录了每个请求的时间戳以及该请求是否超时。每当一个请求超时后，我们会统计窗口内超时的请求数量。如果超时请求的数量超过了设定的阈值，我们就认为当前系统压力较大，不适合进行重试；否则，我们认为可以安全地进行重试。 然而，随着并发量的增加，普通版的滑动窗口算法暴露出了一些问题。特别是在高并发场景下，窗口内需要维护的请求数量可能非常大，这不仅占用了大量内存，而且在判定是否需要重试时还需要遍历整个窗口，这大大增加了算法的时间复杂度。 为了解决这个问题，我们进一步设计了进阶版的算法。在这个版本中，我们引入了ring buffer 来优化滑动窗口的实现。具体来说，我们不再以时间为窗口大小，而是使用固定数量的比特位来记录请求的超时信息。每个比特位对应一个请求，用1表示超时，用0表示未超时。当所有比特位都被标记后，我们从头开始再次标记。 这种设计极大地降低了内存占用，因为无论并发量多高，我们只需要固定数量的比特位来记录请求的超时状态。同时，在判定是否需要重试时，我们只需要统计ring buffer中为1的比特数量，这大大简化了算法的实现并提高了效率。 模拟面试题你的 ring buffer 设置得多大？ 你可以随便说，并不需要很多。比如说你可以这么回答： 默认情况下是 128 字节，也就是 128 * 8 比特，1024 个比特。相当于每次都是只统计 1024 个请求中超时的比例","path":"2025/09/16/场景题/重试策略：区分偶发性超时和频繁超时的重试策略/","date":"09-16","excerpt":"","tags":[]},{"title":"Redis 数据结构：榜单问题之 zset 拆分解决方案","text":"内容 这个案例本质上也是一个榜单案例，它和另外一个榜单案例比起来：Redis 数据结构：榜单问题之本地缓存 + zset + 定时任务方案 本案例强调的是 zset 存储大量的数据，实时性更好； zset 拆分是 Redis 大key 拆分解决思路的一个具体体现，从技术含量上来说要更高一些； 本案例要求 Redis 最好是一个 Cluster； 代码在这里：interview-cases&#x2F;case21_30&#x2F;case21 at main · meoying&#x2F;interview-cases (github.com) 实现思路整个实现思路很简单，假设我们分 key 之后的 key 形式是 my_biz:%d，假设我们只要榜单前 100： 使用 N 个 zset 来存储所有的榜单数据。在我们的代码的例子里面默认是使用 10 个 key； 根据业务主键除以分 key 的数量，得到 key 的后缀。例如说 id 为 3，那么它的数据在 my_biz:3 这个 key 对应的 zset 上； 定时任务每 1 分钟会从这 N 个 key 里面各取前 100，而后借助归并排序计算全局的前 100。用比喻来说，就好比有 10 个班，我每个班取前 100 名，而后排序再取前 100 名，这 100 名就是全级排名； 定时任务会把这 top100 的数据同步到各个节点的本地缓存中 查询前 100 会直接命中本地缓存。 如图： 这里有一些细节要注意： 在更新的时候要注意顺序问题。举个例子来说，如果针对同一个数据，一个要更新热度为 100，一个要更新热度为 101，你要小心并发问题。最好就是在 ZADD 的命令里面再加上一个 GT 选项； zset 并不是真的要存储全部的数据，你可以只存储一部分，这个要业务来判定。比如说业务上说的是计算七天内的榜单数据，例如说只有七天内的文章才可以上榜，那么你的 zset 里面就只需要维护七天内的数据； 分 key 有很多种分发。在代码例子中用的是哈希来分 key，但是实际上你可以用日期来分。比如说每天一个 key，这样在只需要七天数据参与排行的情况下，可以等 key 自然过期。例如说设置 key 的过期时间是七天，那么七天之后这个 key 就不在了，你也不需要访问了； 从理论上来说，这 10 个 key 应该在经过 CRC16 计算和槽映射之后，应该均匀分散在 Redis Cluster 不同集群上； 当新的业务节点上线的时候，再次计算一下全局前 100，而后这个新节点才能对外提供服务； 从性能角度来说，最主要的就是直接命中了本地缓存。 从高可用的角度来说，即便整个 Redis 集群全崩了，也可以靠着本地缓存撑住。 适用场景通常来说，你在简历里写擅长设计高性能，高可用的缓存方案或者设计过高性能高可用的榜单方案， 就可以用这个案例作为证据。遇到这些问题你就可以用这个案例来回答： 你的项目有什么难点？ 你做过什么令人印象深刻的事情？ 你觉得你做得最好的点是什么？ 如果面试官问到了有关缓存、Redis、Redis zset 这些问题，你也可以使用这个案例 你有设计过缓存方案吗？这个方案总的来说还是很强的 你用过 zset 吗？ 而榜单问题本身就是一个面试热点，所以这个问题也能显著帮到你，换句话来说，只要面试官问你怎么解决排行榜之类的问题，你就可以用这个案例。 可以参考以下话术来使用这个案例，这个案例是站在一个演进的角度来阐述的： 我设计过一个解决大数据、高可用、高性能的榜单方案。一开始我们业务的数据量不是很大，所以直接用了最简单的 Redis zset 来计算榜单。 后面随着业务的发展，计算这个榜单的数据越来越多，并发量越来越高。这个时候，一个 zset 里面要放几百万个数据，存储这个 zset 的 Redis 并发极高，压力极大。并且 zset 中元素数量太多，导致更新的时候越来越慢。 发现这个问题之后，我就综合业务实际情况，设计了一个新的榜单解决方案 —— 拆分 key 的方案。 首先，我根据数据量，将原本单一的 key 拆分成了 10 个key，比如说 my_biz:0, my_biz:1 这种。 其次，key 的后缀是业务 ID 除以 10 的余数，在更新热度可以只更新对应的 key。 第三，启动一个定时任务，这个定时任务会定期从所有的 key 里面各取前 100 名，而后用归并排序计算出来全局的前 100 名。 第四，定时任务还会把计算的结果同步到所有的节点的本地缓存上。 最终业务查询榜单的时候，就直接命中本地缓存，性能极好。 模拟面试题为什么你这里定时任务间隔是 1 分钟？ 这其实是一个经验值，主要是根据产品要求来确定的。如果产品说这个榜单三分钟刷新一次，那么设置为 3 分钟都可以。如果要是产品说实时查询，就不能用定时任务了，只能直接查询 zset。在这种情况下，需要考虑扩大 Redis 集群，不然撑不住高并发。","path":"2025/09/16/场景题/Redis 数据结构：榜单问题之 zset 拆分解决方案/","date":"09-16","excerpt":"","tags":[]},{"title":"Redis 数据结构：榜单问题之本地缓存 + zset + 定时任务方案","text":"这个案例实际上还是相当高端的。但是这个高端不是说技术难度很高，而是说思路很清晰，属于花小钱办大事的典型解决方案。 一方面，你可以把这个当做你的项目难点；另外一方面来说，你也可以在谈及 Redis zset 的时候引用这个案例。当然了，如果要是面试官问你做过啥有挑战性的事情，也可以用这个回答。 总的来说，这个案例用在初中级岗位面试中，效果非常强，能帮你建立极大的竞争优势。你在复习的时候要多琢磨这个案例之中的细节。 内容 这个案例对应的是大数据、高性能、高并发榜单的解决方案。 代码在这里：interview-cases&#x2F;case21_30&#x2F;case21 at main · meoying&#x2F;interview-cases (github.com) 实现思路整个实现的要点： 定时任务计算全局的1000名，假设每个小时计算一次。那么即便有突发热点，那么最多一个小时就能看出来； 将1000名定时写入到 Redis，用 zset 实时维护。写入的时候删除原有的key然后将1000名写入。这一步是为了尽可能保证榜单数据准确。 再起一个定时任务，每一分钟将redis中的前100名（也就是1000中的前100，有可能不是全局的前100）同步到所有节点的本地缓存上，这一步是为了访问效率 从本地读取榜单数据 整个过程如下图： 这里稍微解释一下这个案例的思路： 首先定时任务取前 1000 条，是基于这么一个假设：即这一小时内，top 100 绝大概率就是从这 1000 中选出来。如果你觉得 1000 这个太少，那么可以扩展到 10000。如果你打算进一步扩展到前 10w，那么就要考虑 Redis 分 key 了，不然会有大 key 问题。 那么会不会有例外呢？肯定会有的，比如说某个排名 1200 的热度激增，导致瞬间闯进去前 100，那么在下一次计算前 1000 的时候，它没有机会被发现。但是我们并不在意这点不精确。而且，这种不精准可以通过调低定时任务的间隔来改善。例如说改为每 10 分钟执行一次，就几乎不太可能能耐 其次则是 Redis 的 zset 主要就是为了能够尽可能精准维护这 top 100的。当然，这一步是可以去掉的，也就是只依赖定时任务每隔一段时间利用数据库的数据直接计算出来前 100。 这里还有一些细节要注意： 在使用 zset ZADD 命令的时候，必须要带上 XX。这样可以保证 zset 不会增加额外的元素 在更新的时候要注意顺序问题。举个例子来说，如果针对同一个数据，一个要更新热度为 100，一个要更新热度为 101，你要小心并发问题。最好就是在 ZADD 的命令里面再加上一个 GT 选项； 如果更新热度本身也是一个高并发，那么可以在更新接口之前插入一个 Kafka 操作，也就是将更新操作丢进去 Kafka 中，消费者从里面取出来再慢慢更新热度。而且消费者可以进一步叠加批量消费这种手段来优化更新性能； . 适用场景通常来说，你在简历里写擅长设计高性能，高可用的缓存方案或者设计过高性能高可用的榜单方案， 就可以用这个案例作为证据。遇到这些问题你就可以用这个案例来回答： 你的项目有什么难点？ 你做过什么令人印象深刻的事情？ 你觉得你做得最好的点是什么？ 如果面试官问到了有关缓存、Redis、Redis zset 这些问题，你也可以使用这个案例 你有设计过缓存方案吗？这个方案总的来说还是很强的 你用过 zset 吗？ 而榜单问题本身就是一个面试热点，所以这个问题也能显著帮到你，换句话来说，只要面试官问你怎么解决排行榜之类的问题，你就可以用这个案例。 可以参考以下话术来使用这个案例，这个案例是站在一个演进的角度来阐述的： 我设计过一个解决大数据、高可用、高性能的榜单方案。一开始我们业务的数据量不是很大，所以直接用了最简单的 Redis zset 来计算榜单。 后面随着业务的发展，计算这个榜单的数据越来越多，并发量越来越高，并且还引入了分库分表。这个时候，一个 zset 里面要放几百万个数据，存储这个 zset 的 Redis 并发极高，压力极大。并且 zset 中元素数量太多，导致更新的时候越来越慢。 发现这个问题之后，我就综合业务实际情况，设计了一个新的榜单解决方案。 首先每个小时计算一下全局前1000名数据写入到 Redis 中，用 zset 保存好。这 1000 个是覆盖式更新，也就是原本的 1000 会被删除，而后假如新的 1000 元素。 其次，如果收到新的更新请求，就使用 ZADD XX 来更新数据，并且确保 zset 内始终只有 1000 个元素。 最后，我再使用定时任务，每分钟计算一次 top100，同步到各个节点的本地缓存上。本地缓存本身是永不过期的，这样即便整个机制崩坏，但是还可以从本地缓存中读取到榜单数据，最多就是本地缓存中的榜单数据迟迟没有更新而已。 当然，两个定时任务的间隔都是可以调整的，前 1000 名这个也是可以调整的，可以根据业务需要来调整。 在这种改造之下，先是解决了 zset 引发的大 key 问题和热点问题，其次是大幅度提高了榜单查询的性能。当然缺点就是榜单的实时性下降了，但是这都是可以接受的。 模拟面试题你提到要将前 100 同步到所有节点的本地缓存上，怎么做？ 你可以参考这个问题：怎么同时更新所有节点上的本地缓存？ 我在这里用的方案是定时刷新。也就是每个整分钟（例如说 00:01:00, 00:02:00）每个节点都会查询 Redis，获得最新的 top100 的数据。因为几乎是同时查询 top100，所以大家获得的 top 100 数据都是一样的。 为什么你从数据库中只计算前 1000，而不是 2000 或者 3000？ 这实际上就是一个经验值。也就是说根据我的观察，我发现在一段时间内，前 100 名大概率出自前 1000 名，很少有例外，所以选 1000 就够了。当然选 2000,3000 其实问题也不大。 严格来说，只要使用 Redis zset 的时候没有大 key 问题，那么这个数字是可以尽可能大的。但是从业务上来说犯不着，因为排名靠后的那些数据，很难说短时间就变到前 100 了。 为什么你从数据库中取前 1000 是间隔一小时？间隔 30 分钟行不行？ 1 小时也是一个经验值。从理论上来说，只要间隔时间大于计算前 1000 的时间就可以了。 而间隔一小时可以保证不会频繁计算，也可以保证榜单的实时性处在一种比较好的状态。","path":"2025/09/16/场景题/Redis 数据结构：榜单问题之本地缓存 + zset + 定时任务方案/","date":"09-16","excerpt":"","tags":[]},{"title":"吃透netty","text":"大纲 整体架构模块三个模块 core protosupport transport 1. Core 核心层Core 核心层是 Netty 最精华的内容，它提供了底层网络通信的通用抽象和实现，包括可扩展的事件模型、通用的通信 API、支持零拷贝的 ByteBuf 等。 2. Protocol Support 协议支持层协议支持层基本上覆盖了主流协议的编解码实现，如 HTTP、SSL、Protobuf、压缩、大文件传输、WebSocket、文本、二进制等主流协议，此外 Netty 还支持自定义应用层协议。Netty 丰富的协议支持降低了用户的开发成本，基于 Netty 我们可以快速开发 HTTP、WebSocket 等服务。 3. Transport Service 传输服务层传输服务层提供了网络传输能力的定义和实现方法。它支持 Socket、HTTP 隧道、虚拟机管道等传输方式。Netty 对 TCP、UDP 等数据传输做了抽象和封装，用户可以更聚焦在业务逻辑实现上，而不必关系底层数据传输的细节。 逻辑结构 网络通信层主要负责网络事件的监听，当网络数据读取到内核缓冲区后，会触发各种网络事件，会被注册到事件调度层进 行处理 网络通信层的核心组件包含BootStrap、ServerBootStrap、Channel三个组件。 - **&lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;BootStrap &amp;ServerBootStrap 引导 如下图所示，Netty 中的引导器共分为两种类型：一个为用于客户端引导的 Bootstrap，另一个为用于服务端引导的 ServerBootStrap**，它们都继承自抽象类 AbstractBootstrap。ServerBootStrap用于服务器启动时绑定本地端口，会绑定两个eventloopgroup，一个boss，一个worker。而BootStrap主要是用与服务器进行通信，只有一个eventloopgroup - channelChannel 的字面意思是“通道”，它是网络通信的载体，说白了就是操作内核缓冲区或者说我们可以使用channel的API来操作底层Socket channel还有不同的状态，这些不同的状态就对应的不同的回调事件 事件调度层事件调度层的职责是通过 Reactor 线程模型对各类事件进行聚合处理，通过 Selector 主循环线程集成多种事件（ I&#x2F;O 事件、信号事件、定时事件等），实际的业务处理逻辑是交由服务编排层中相关的 Handler 完成。 事件调度层的核心组件包括 EventLoopGroup、EventLoop。 这group其实就是线程池来着，eventloop就是线程 - eventloopgroup和eventloop和channel的关系 特别地说一下，channel被建立后，就会分配一个eventloop与其绑定，且可不是绑死的，可多次松绑or绑定 一个 Channel 在它的生命周期里，只能绑定到一个 EventLoop。 一个 EventLoop 可以同时绑定多个 Channel，并处理它们的 I&#x2F;O 事件 然后eventloop通过操作系统的epoll监听多个channel的事件，事件复杂度接近 O (1) ·类关系 EventLoopGroup 是 Netty 的核心处理引擎，那么 EventLoopGroup 和之前课程所提到的 Reactor 线程模型到底是什么关系呢？其实 EventLoopGroup 是 Netty Reactor 线程模型的具体实现方式，Netty 通过创建不同的 EventLoopGroup 参数配置，就可以支持 Reactor 的三种线程模型： 1. **&lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;单线程模型&lt;/font&gt;**&lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;：EventLoopGroup 只包含一个 EventLoop，Boss 和 Worker 使用同一个EventLoopGroup；&lt;/font&gt; 2. **&lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;多线程模型&lt;/font&gt;**&lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;：EventLoopGroup 包含多个 EventLoop，Boss 和 Worker 使用同一个EventLoopGroup；&lt;/font&gt; 3. **&lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;主从多线程模型&lt;/font&gt;**&lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;：EventLoopGroup 包含多个 EventLoop，Boss 是主 Reactor，Worker 是从 Reactor，它们分别使用不同的 EventLoopGroup，主 Reactor 负责新的网络连接 Channel 创建，然后把 Channel 注册到从 Reactor。&lt;/font&gt; 服务编排层服务编排层的职责是负责组装各类服务，它是 Netty 的核心处理链，用以实现网络事件的动态编排和有序传播。服务编排层的核心组件包括 ChannelPipeline、ChannelHandler、ChannelHandlerContext。 - **ChannelPipeline** ChannelPipeline 是 Netty 的核心编排组件，**负责组装各种 ChannelHandler。**其实就是把channelHandler给串联起来，本质是一个双向链表。当网络事件来的时候，就会依次调用channelPipeline里的Handler对其进行拦截 ChannelPipeline 是线程安全的，因为每一个新的 Channel 都会对应绑定一个新的 ChannelPipeline。一个 ChannelPipeline 关联一个 EventLoop，一个 EventLoop 仅会绑定一个线程。 ChannelPipeline 中包含入站 ChannelInboundHandler 和出站 ChannelOutboundHandler 两种处 理器，我们结合客户端和服务端的数据收发流程来理解 Netty 的这两个概念 - **&lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;ChannelHandler &amp; ChannelHandlerContext&lt;/font&gt;** 为啥每个channelHandler都要绑定一个**ChannelHandlerContext？** 有点类似于工人和工具工位的关系 ChannelHandlerContext 用于保存 ChannelHandler 上下文，通过 ChannelHandlerContext 我们可以知道 ChannelPipeline 和 ChannelHandler 的关联关系。ChannelHandlerContext 可以实现 ChannelHandler 之间的交互，ChannelHandlerContext 包含了 ChannelHandler 生命周期的所有事件，如 connect、bind、read、flush、write、close 等。此外，你可以试想这样一个场景，如果每个 ChannelHandler 都有一些通用的逻辑需要实现，没有 ChannelHandlerContext 这层模型抽象，你是不是需要写很多相同的代码呢？ 12345678public class MyHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; System.out.println(&quot;收到消息: &quot; + msg); ctx.fireChannelRead(msg); // 传递给下一个 Handler &#125;&#125; 整体流程 服务端启动要干什么配置线程池 Channel 初始化 端口绑定 1234567891011121314151617181920212223242526272829303132// 检测是否使用Epoll优化性能// 启动Netty服务器@SneakyThrows(InterruptedException.class)@Overridepublic void start() &#123; if (!start.compareAndSet(false, true)) return; // 配置服务器参数，如端口、TCP参数等 serverBootstrap .group(eventLoopGroupBoss, eventLoopGroupWorker) .channel(SystemUtil.useEpoll() ? EpollServerSocketChannel.class : NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) // TCP连接的最大队列长度 .option(ChannelOption.SO_REUSEADDR, true) // 允许端口重用 .option(ChannelOption.SO_KEEPALIVE, true) // 保持连接检测 .childOption(ChannelOption.TCP_NODELAY, true) // 禁用Nagle算法，适用于小数据即时传输 .childOption(ChannelOption.SO_SNDBUF, 65535) // 设置发送缓冲区大小 .childOption(ChannelOption.SO_RCVBUF, 65535) // 设置接收缓冲区大小 .localAddress(new InetSocketAddress(config.getPort())) // 绑定监听端口 .childHandler(new ChannelInitializer&lt;&gt;() &#123; // 定义处理新连接的管道初始化逻辑 @Override protected void initChannel(Channel ch) throws Exception &#123; ch.pipeline().addLast( new HttpServerCodec(), // 处理HTTP请求的编解码器 new HttpObjectAggregator(config.getNetty().getMaxContentLength()), // 聚合HTTP请求 new HttpServerExpectContinueHandler(), // 处理HTTP 100 Continue请求 new NettyHttpServerHandler(nettyProcessor) // 自定义的处理器 ); &#125; &#125;); serverBootstrap.bind().sync(); ResourceLeakDetector.setLevel(ResourceLeakDetector.Level.ADVANCED); log.info(&quot;gateway startup on port &#123;&#125;&quot;, this.config.getPort());&#125; eventloop精髓网络框架的设计离不开 I&#x2F;O 线程模型，线程模型的优劣直接决定了系统的吞吐量、可扩展性、安全性等 三种 Reactor 线程模型单 多 主从 前两种就是建立和业务处理没分开，无法轻松建立大量连接，建立连接会被耗时的业务请求影响到 Netty EventLoop 实现原理在 Netty 中 EventLoop 可以理解为 Reactor 线程模型的事件处理引擎，每个 EventLoop 线程都维护一个 Selector 选择器和任务队列 taskQueue。它主要负责处理 I&#x2F;O 事件、普通任务和定时任务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * EventLoop 主循环 * 不停地轮询 I/O 事件 + 执行任务队列（普通任务/定时任务） */protected void run() &#123; // 死循环，直到 EventLoop 被关闭 for (;;) &#123; try &#123; try &#123; // 根据策略决定如何调用 select()（I/O 多路复用） // selectStrategy 会返回 CONTINUE/BUSY_WAIT/SELECT switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: // CONTINUE 表示继续下一次循环，不阻塞 continue; case SelectStrategy.BUSY_WAIT: case SelectStrategy.SELECT: // 轮询 I/O 事件 // wakenUp.getAndSet(false) 用来标记是否需要立即唤醒 select(wakenUp.getAndSet(false)); // 如果在 select 期间又被要求唤醒，则调用 wakeup() if (wakenUp.get()) &#123; selector.wakeup(); &#125; default: // 其他情况不处理 &#125; &#125; catch (IOException e) &#123; // 如果 select 出现 IO 异常，重建 selector rebuildSelector0(); // 打印/处理异常 handleLoopException(e); // 跳过这次循环，继续下一次 continue; &#125; // 已取消的 SelectionKey 数量清零 cancelledKeys = 0; // 是否需要再次 select 清零 needsToSelectAgain = false; // I/O 与任务执行时间比例（默认 50:50） final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; // ioRatio=100，表示只处理 I/O，再统一处理任务 try &#123; processSelectedKeys(); // 处理就绪的 I/O 事件 &#125; finally &#123; runAllTasks(); // 处理所有任务（普通/定时） &#125; &#125; else &#123; // ioRatio &lt; 100，需要在 I/O 与任务之间分配时间 final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); // 处理就绪的 I/O 事件 &#125; finally &#123; // 计算本轮 I/O 花费的时间 final long ioTime = System.nanoTime() - ioStartTime; // 按 ioRatio 分配执行任务的时间 runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; catch (Throwable t) &#123; // 捕获所有异常，避免循环退出 handleLoopException(t); &#125; try &#123; // 如果正在关闭 if (isShuttingDown()) &#123; // 关闭所有 Channel closeAll(); // 确认是否可以安全关闭 if (confirmShutdown()) &#123; return; // 安全关闭后退出循环 &#125; &#125; &#125; catch (Throwable t) &#123; // 关闭过程出现异常，打印处理 handleLoopException(t); &#125; &#125;&#125; select(…) 👉 负责 I&#x2F;O 事件的监听（类似 Selector.select()）。 processSelectedKeys() 👉 处理就绪的 I&#x2F;O 事件（读&#x2F;写&#x2F;连接）。 runAllTasks() 👉 处理任务队列里的任务（用户提交的 Runnable、定时任务等）。 ioRatio 👉 控制 I&#x2F;O 与任务的时间分配。 isShuttingDown()&#x2F;confirmShutdown() 👉 支持优雅关闭。 事件处理机制对于eventloop来说就是无锁串行化，不同eventloop之间是不会有交集的 **一个 ****Channel** 在注册到某个 EventLoop 之后，它的整个生命周期都只会由这个 EventLoop 负责 结合 Netty 的整体架构，我们一起看下 EventLoop 的事件流转图，以便更好地理解 Netty EventLoop 的设计原理。NioEventLoop 的事件处理机制采用的是无锁串行化的设计思路。 BossEventLoopGroup 和 WorkerEventLoopGroup 包含一个或者多个 NioEventLoop。BossEventLoopGroup 负责监听客户端的 Accept 事件，当事件触发时，将事件注册至 WorkerEventLoopGroup 中的一个 NioEventLoop 上。每新建一个 Channel， 只选择一个 NioEventLoop 与其绑定。所以说 Channel 生命周期的所有事件处理都是线程独立的，不同的 NioEventLoop 线程之间不会发生任何交集。 NioEventLoop 完成数据读取后，会调用绑定的 ChannelPipeline 进行事件传播，ChannelPipeline 也是线程安全的，数据会被传递到 ChannelPipeline 的第一个 ChannelHandler 中。数据处理完成后，将加工完成的数据再传递给下一个 ChannelHandler，整个过程是串行化执行，不会发生线程上下文切换的问题。 NioEventLoop 无锁串行化的设计不仅使系统吞吐量达到最大化，而且降低了用户开发业务逻辑的难度，不需要花太多精力关心线程安全问题。虽然单线程执行避免了线程切换，但是它的缺陷就是不能执行时间过长的 I&#x2F;O 操作，一旦某个 I&#x2F;O 事件发生阻塞，那么后续的所有 I&#x2F;O 事件都无法执行，甚至造成事件积压。在使用 Netty 进行程序开发时，我们一定要对 ChannelHandler 的实现逻辑有充分的风险意识。 NioEventLoop 线程的可靠性至关重要，一旦 NioEventLoop 发生阻塞或者陷入空轮询，就会导致整个系统不可用。在 JDK 中， Epoll 的实现是存在漏洞的，即使 Selector 轮询的事件列表为空，NIO 线程一样可以被唤醒，导致 CPU 100% 占用。这就是臭名昭著的 JDK epoll 空轮询的 Bug。Netty 作为一个高性能、高可靠的网络框架，需要保证 I&#x2F;O 线程的安全性。那么它是如何解决 JDK epoll 空轮询的 Bug 呢？实际上 Netty 并没有从根源上解决该问题，而是巧妙地规避了这个问题。 netty如何规避的 1234567891011121314151617long time = System.nanoTime();if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123; selectCnt = 1;&#125; else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; selector = selectRebuildSelector(selectCnt); selectCnt = 1; break;&#125; Netty 提供了一种检测机制判断线程是否可能陷入空轮询，具体的实现方式如下： 每次执行 Select 操作之前记录当前时间 currentTimeNanos。 time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;&#x3D; currentTimeNanos，如果事件轮询的持续时间大于等于 timeoutMillis，那么说明是正常的，否则表明阻塞时间并未达到预期，可能触发了空轮询的 Bug。 Netty 引入了计数变量 selectCnt。在正常情况下，selectCnt 会重置，否则会对 selectCnt 自增计数。当 selectCnt 达到 SELECTOR_AUTO_REBUILD_THRESHOLD（默认512） 阈值时，会触发重建 Selector 对象。 Netty 采用这种方法巧妙地规避了 JDK Bug。异常的 Selector 中所有的 SelectionKey 会重新注册到新建的 Selector 上，重建完成之后异常的 Selector 就可以废弃了。 背景：Selector 的空轮询 bug 在 JDK 的部分版本里，&lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;Selector.select(timeout)&lt;/font&gt; 存在 bug：即使没有任何事件，它也可能立即返回，没有正常阻塞到超时时间。 结果就是：EventLoop 线程会疯狂地“空转”，CPU 飙升到 100%，但又没干实事。 👉 如果发现 &lt;font style=&quot;color:rgb(59, 67, 81);&quot;&gt;select()&lt;/font&gt;连续过早返回 512 次（怀疑 JDK 的 Selector 空轮询 bug），就会 销毁旧 Selector，重建一个新的，从而避免 EventLoop 陷入死循环空转。 正常情况：无事件会在阻塞一段时间，异常情况：立即返回 任务处理机制 处理普通任务 Netty 高性能内存管理设计认识jemalloc前言netty的内存管理也是参考jemalloc的设计。 内存分配器：jemalloc，temalloc，ptmalloc 他们都有一个目的即：提高内存分配回收的效率，以及尽可能地减少内存碎片 内存碎片： Linux会把物理内存分配为一个个4kb的内存页， 物理内存的分配和回收都是基于 Page 完成的，而页里面产生的碎片成为内部碎片，而页与页之间 叫做外部碎片 内存分配算法三种。动态分配，伙伴分配，slab 动态分配动态分配DMA 会用一个链表来维护空闲内存块，程序申请内存时就从这个链表里面挑选 内存就像一个大仓库&#x2F;超市。 空闲分区（free block） &#x3D; 货架上的空篮子（还没被进程用的内存）。 进程的请求（malloc 申请内存） &#x3D; 顾客来装东西（要一块内存）。 分配策略（first fit &#x2F; next fit &#x2F; best fit） &#x3D; 超市员工怎么选篮子给你。 三种算法 伙伴算法伙伴算法就是把内存分成 2 的幂次方大小的块，按需拆分、按对合并，分配快、回收快，但会浪费一些空间（内部碎片）。 比如你分配17kb的，就得申请32kb的 slab算法Linux 内核使用的就是 Slab 算法 jemalloc架构设计netty的实现基本使用 设计原则Netty 高性能的内存管理也是借鉴 jemalloc 实现的 内存分规格tiny，smaller，normal,huge 当想要申请的内存大小大于huge时，netty是会采用非池化的手段 netty的核心组件可以看做是jemalloc的Java版实现 PoolArena也就是jemalloc的arena， 123456Class PoolArena&#123; smallSubpagePools // 用来存放比基本单位page 8k小的内存块 tinySubpagePools //同上 PoolChunkList &#125; 采用固定数量的多个 Arena 进行内存分配，Arena的数量跟CPU核数有关。当线程申请时，就会给它分配一个Arena，且在这个线程声明周期内，线程只会更这个Arena打交道 Netty 借鉴了 jemalloc 中 Arena 的设计思想，采用固定数量的多个 Arena 进行内存分配，Arena 的默认数量与 CPU 核数有关，通过创建多个 Arena 来缓解资源竞争问题，从而提高内存分配效率。线程在首次申请分配内存时，会通过 round-robin 的方式轮询 Arena 数组，选择一个固定的 Arena，在线程的生命周期内只与该 Arena 打交道，所以每个线程都保存了 Arena 信息，从而提高访问效率。 PoolChunk： PoolArena 的数据结构包含两个 PoolSubpage 数组和六个 PoolChunkList，两个 PoolSubpage 数组分别存放 Tiny 和 Small 类型的内存块，六个 PoolChunkList 分别存储不同利用率的 Chunk，构成一个双向循环链表。 PoolArena 对应实现了 Subpage 和 Chunk 中的内存分配，其 中 PoolSubpage 用于分配小于 8K 的内存，PoolChunkList 用于分配大于 8K 的内存 随着PoolChunk的使用率变化，PoolChunk会在不同的PoolChunkList之间移动 分配流程 内存回收 面试回答首先说下它整体是参考jemalloc –&gt; 说说设计原则（分规格，就是有不同规格的内存块，以及实现了每个线程都有自己的内存） —&gt; 列举下组件（poolArean，chunk，subpage，以及基础的分配单位page）–&gt; 分配流程（先检查请求分配的大小是tiny还是smaller，然后检查PoolThreadCache是否够，如果够就使用自己线程私有内存，然后再进行Arena分配，最终返回一个Bytebuffer给 用户）","path":"2025/09/14/netty/吃透netty/","date":"09-14","excerpt":"","tags":[]},{"title":"VMthread","text":"vm thread 机制概念vmthread是jvm内部的核心守护线程非Java线程，在jvm启动时由thread：create_vm()初始化并启动 作用串行任务执行引擎 安全点控制器 任务调度中心 核心职责监听vm opreation_q队列里的任务请求 触发安全点并执行任务 管理任务生命周期 vm opreation分类 整体逻辑 源码解析取任务任务超时了，也会进入safepoint begin 即Safepoint实现机制 线程本地轮询，改的变量应该是在cpu 1,2,3级缓存 所以说让线程停止下来是可以的 等待所有线程进入安全点是一个cas操作 java thread和vm thread的协同 可数循环问题和VMthread的关联 特别的：jit优化，有个东西叫做内联，它就是如果你调用多个方法比较多次，它会把你的方法直接变成机器码，然后还会把方法给展开 即 12345678910111213141516171819main()&#123; save()&#125;save()&#123; iiiii jjjj jjjj&#125;内联之后：main()&#123; iiiii jjjj jjjj&#125;那么这里的方法返回之前的安全点也会失效哦 Java8 和Java11 vmthread的差异","path":"2025/09/13/JVM/jvm源码/VMthread/","date":"09-13","excerpt":"","tags":[]},{"title":"int可数大循环事故","text":"1234567tomcat线程池for(int i:10000000)&#123; for(int i:10000000)&#123; //xxxx &#125;&#125;//可能才有Safepoint int 循环里是没有Safepoint，也就是它会一直执行下去，在parallel那一章我们都知道vmthread每隔1000ms就会让线程进入Safepoint进行stw，stw得等所有线程都进入Safepoint，才能继续往下执行，也就是你这一个大循环线程就会拖累所有线程，你妈的连jstack都进不去 小米的HBASE出过这么一个事故 解决方案：换成long，因为long会有Safepoint","path":"2025/09/13/JVM/jvm源码/int可数大循环事故/","date":"09-13","excerpt":"","tags":[]},{"title":"parallell内存分配和垃圾回收","text":"内存分配时，会尝试先去线程的私有区域（tlb）分，不够再去堆上分 内存分配垃圾回收器 parallell源码首先，大对象体积超过一定阈值时会直接进入老年代吗？ 这个对于parNew是适用的，通过参数配置阈值。但parallel就一样的，它是从 yong_gen直接分配 年轻代：eden form to 老年代： parallel的内存分配 &#x2F;&#x2F;第一次从年轻代分配，分配成功返回Result，分配失败进行第二次 &#x2F;&#x2F;第二次从年轻代分配，分配成功返回Result，分配失败尝试从老年代分配 &#x2F;&#x2F;第二次从老年代分配，分配成功返回Result &#x2F;&#x2F;if(result &#x3D;&#x3D; null) Vmthread:excute 垃圾回收内存了 &#x2F;&#x2F;Paralllel:invoke() 先尝试yong gc 垃圾回收jvm的vmthread主要职责是什么，和gc及Safepoint的关系是什么vmthread的loop() 123456789101112131415loop()&#123; //死循环，等待其他操作唤醒 while(true)&#123; // wait for vm operation //...... //每隔1000ms就触发 if(VMthread:no_op_safepoint_needed(true))&#123; safepointSyn:begion() //暂停所有线程 safepointSyn:end()//恢复所有线程 &#125; &#125;&#125; begin：该标志位，通知其他线程暂停下来，而且得等所有线程都听下来，才能继续执行begin方法剩余的逻 辑 内存不够了不一定会触发fullgc，而是会先根据你新生代回收是否成功以及老年代的大小来决定的 新生代的垃圾回收逻辑 yong gc不会stw？只要执行 Vm:excute 就会stw","path":"2025/09/13/JVM/jvm源码/parallell内存分配和垃圾回收/","date":"09-13","excerpt":"","tags":[]},{"title":"cms垃圾回收流程","text":"安全点 Safe point： 安全点是 JVM 在字节码执行中预设的“安全停车点”，只有线程到达这些位置才能被安全地暂停，用于 GC 等全局操作，保证程序状态一致性 初次标记–&gt;并发标记—&gt;重新标记","path":"2025/09/13/JVM/jvm源码/cms垃圾回收流程/","date":"09-13","excerpt":"","tags":[]},{"title":"jvm源码","text":"","path":"2025/09/13/JVM/jvm源码/","date":"09-13","excerpt":"","tags":[]},{"title":"模版解释器","text":"","path":"2025/09/13/JVM/模版解释器/","date":"09-13","excerpt":"","tags":[]},{"title":"量、引用、池","text":"字面量： 字面量指由字母、数字等构成的字符串或者数字常量，如1，“abc”，10这些都是字面量 变量： 定义出一个符号，这个符号在某个范围内，就代表一个变化的量。要注意两点：1. 变量必须先定义才可以使用。2. 变量如果先被赋值或者初始化才可以使用。如 int a &#x3D; 1，a就是变量；String s &#x3D; “abc”，s也是变量 常量： final修饰的变量 静态变量： static修饰的变量，只能是类的成员变量，不能定义在方法中 符号引用： 符号引用就是一个类中（当然不仅是类，还包括类的其他部分，比如方法，字段等）引入了其他的类，可是JVM并不知道引入的其他类在哪里，所以就用唯一符号来代替，等到类加载器去解析的时候，就通过符号引用找到那个引用类的地址（如果找不到说明引用类还没加载，那就直接把引用类也加载了），这个地址也就是直接引用。 在编译时，java类并不知道所引用的类的实际地址（只是javac编译，JVM还没运行呢，哪知道地址？），因此只能使用符号引用来代替 符号引用包括以下常量： 被模块导出或者开放的包 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 方法句柄和方法类型 动态调用点和动态常量 直接引用： 直接引用是可以直接指向目标的指针、相对偏移量 或者是一个能间接定位到目标的句柄。直接引用是和虚拟机的布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经被加载入内存中了。 常量池： 每个class文件独有一份，常量池中有字面量(数量值、字符串值)和符号引用(类符号引用、字段符号引用、方法符号引用)，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型 运行时常量池： 当类加载到内存中后，jvm就会将class常量池中的内容存放到运行时常量池中，经过解析（resolve）之后，也就是把符号引用替换为直接引用","path":"2025/09/13/JVM/量、引用、池/","date":"09-13","excerpt":"","tags":[]},{"title":"lambda","text":"字节码中，lambda表达式处会出现个invokedynamic，这个指令在运行时会动态链接到 LambdaMetafactory.metafactory。 字节码会多出个方法，比如在main方法使用了lambda表达式，就会多出个lambda$main$0，里面是lambda要执行的代码 lambda相比于匿名内部类来说更高效，因为它避免了每次使用lambda时都生成一个新类的开销，后面会复用生成的lambda方法 lambda中可以使用到外部的变量，但是不能在表达式中对这些变量进行修改，其原理就是，lambda表达式会被动态生成一个方法，这个方法是私有的、静态的，然后外部参数会被这个方法参数传进来。","path":"2025/09/13/JVM/lambda/","date":"09-13","excerpt":"","tags":[]},{"title":"java API","text":"String substring(i,j) [ i , j ) isLetterOrDigit(char c) 判断是数字还是字符 toLowerCase(char c) 转成小写 int indexOf(String s) 从父字符串index &#x3D; 0开始找s，并返回最早出现的index int indexOf(String s, int t) 从父字符串index &#x3D; t开始找，并返回最早出现的index boolean startWith(String s,int t) 判断父字符串从startIndex开始的子串是否以word开头 Array Array.copyOfRange(int [],i,j) 复制某区间的数组 12345678910111213import java.util.Arrays;public class Test &#123; public static void main(String[] args) &#123; int[] arr = &#123;1, 2, 3, 4, 5&#125;; // 复制下标 1 到 3 的元素（不包含下标3） int[] subArr = Arrays.copyOfRange(arr, 1, 3); System.out.println(Arrays.toString(subArr)); // 输出 [2, 3] &#125;&#125; Collection Collection -&gt; Array：xxx.toArray( int []); eg：temp.toArray(new int[temp.size()][2]); MapStringBuilder1. 追加123sb.append(&quot;world&quot;); // 追加字符串sb.append(123); // 追加数字sb.append(true); // 追加布尔值 2. 插入1sb.insert(0, &quot;Hi &quot;); // 在下标0插入 3. 删除12sb.delete(0, 2); // 删除 [0,2) 区间的字符sb.deleteCharAt(3); // 删除指定位置的字符 4. 替换1sb.replace(0, 2, &quot;Hey&quot;); // 替换 [0,2) 的内容 5. 反转1sb.reverse(); // 反转整个字符串 6. 修改1sb.setCharAt(0, &#x27;H&#x27;); // 修改指定位置的字符 7. 长度 &amp; 容量123sb.length(); // 当前字符长度sb.capacity(); // 底层 char[] 容量sb.ensureCapacity(100); // 确保容量至少为100 8. 获取子串1String sub = sb.substring(0, 5); // [0,5) 的子串 9. 查找12sb.indexOf(&quot;lo&quot;); // 找到子串首次出现的位置sb.lastIndexOf(&quot;o&quot;); // 找到子串最后出现的位置 10. 转为 String1String str = sb.toString(); Integer Integer.parseInt(x,进制) 可指定进制","path":"2025/09/13/Codetop刷题/java API/","date":"09-13","excerpt":"","tags":[]},{"title":"运算","text":"只出现一次的数字[🔥49]思路： 利用异或运算^ 1. a^a =0 2. a^0=a 然后运算满足交换率 即 a^b^a&#x3D;a^a^b 最后就可以得出 b是单身狗 12345678910111213class Solution &#123; public int singleNumber(int[] nums) &#123; int x = 0; System.out.println(12^1); for (int num : nums)&#123; // 1. 遍历 nums 执行异或运算 x ^= num; System.out.println(x); &#125; return x; // 2. 返回出现一次的数字 x &#125;&#125; 变种：字节后端，变成有序数组，需要O(logN)复杂度。 思路：二分查找，如果nums[mid]出现了两次，则左边或右边肯定有一边剩余了奇数个数字，朝奇数个的方向走。 123456789101112131415class Solution &#123; public int singleNonDuplicate(int[] nums) &#123; int l = 0, r = nums.length - 1; while (l &lt; r) &#123; int mid = l + (r - l) / 2; if (nums[mid] == nums[mid ^ 1]) &#123; l = mid + 1; // 单身狗在右边 &#125; else &#123; r = mid; // 单身狗在左边或就是mid &#125; &#125; return nums[l]; &#125;&#125; ![](/images/3617fe7504c0cae01de7b87b4d19720a.png) 寻找重复数[34]1 汉明距离思路： 调用函数 Integer.bitCount(x) 统计x中 为1的个数 12345678910111213class Solution &#123; public int hammingDistance(int x, int y) &#123; //bitCount 用于统计 二进制中 1的数量 // x ^ y特性：x和y相同 则x ^ y为0，x = 0 或者 y = 0 则x ^ y = 非0数 System.out.println(0 ^ 6); // 6 System.out.println(1 ^ 6); // 无规则 // 001 // 110 // 111 = 7 System.out.println(6 ^ 6); // 0 return Integer.bitCount(x ^ y); &#125;&#125;","path":"2025/09/13/Codetop刷题/运算/","date":"09-13","excerpt":"","tags":[]},{"title":"other sql db","text":"Oracle：一个Schema是一个user，一个数据库只有一个，可以高sass玩法，数据库层面就做物理隔离了","path":"2025/09/12/MySQL/other sql db/","date":"09-12","excerpt":"","tags":[]},{"title":"手写并发任务编排工具类","text":"需求并发场景可能存在的需求-每个执行结果的回调CompleteableFuture大家都用过，里面有supply、then、combine、allOf等等方法，都可以用来接收一个任务，最终将多个任务汇总成一个结果。 但有一个问题，你supply一个任务后，这个任务就黑盒了。如果你编排了很多个任务，每一个任务的执行情况，执行到哪一步了，每一步的执行结果情况，我们是不知道的。只能等它最终执行完毕后，最后汇总结果。 一个并行框架，它最好是对每一步的执行都能监控。每一步的执行结果，无论成功与失败，它应该有个回调，才算完整。拥有回调的任务，可以监控任务的执行状况，如果执行失败、超时，可以记录异常信息或者处理个性化的默认值。 CompleteableFuture中也有一些回调方法，例如：thenAccept()，whenComplete()，handle()，exceptionally()等，这些方法也能支持任务的回调，但是前提是任务执行了，才能完成回调。在某些场景中，有些任务单元是可能被SKIP跳过不执行的，不执行的任务也应该有回调。 并发场景可能存在的需求-依赖上游的执行结果作为入参future1.thenCompose(f2,()-&gt;xxx) 下游依赖于上游的结果 并发场景可能存在的需求-全组任务的超时一组任务，虽然内部的各个执行单元的时间不可控，但是可以控制全组的执行时间不超过某个值。通过设置timeOut，来控制全组的执行阈值。 1CompletableFuture.allOf(futures).get(timeout, TimeUnit.MILLISECONDS); 并发场景可能存在的需求-高性能、低线程数复用线程 该框架全程无锁，没有一个加锁的地方。 创建线程量少。如上图④中场景。A会运行在B、C执行更慢的那个单元的线程上，而不会额外创建线程。 总结一个并发框架可能需要具备哪些能力？ 1、提供任何形式的串行、并行执行单元的组合 2、为每个执行单元提供执行成功、失败、超时、异常的回调 3、支持为单个执行单元设置异常、失败后的默认值 4、支持为整个group（多个任意组合的执行单元）设置超时时间。单个执行单元失败，不影响其他单元的回调和最终结果获取。如果自己依赖的任务失败，则自己也失败，并返回默认值。 5、整个group执行完毕或超时后，同步阻塞返回所有执行单元结果集，按添加的顺序返回list。也支持整个group的异步回调不阻塞主线程 6、支持每个group独享线程池，或所有group共享线程池（默认） 异步回调如何实现上面我们总结了多线程的编排场景及实现，以及并发场景的一些潜在需求及实现。 该框架的难点和重点，主要有两点，分别是任务的顺序编排和任务结果的回调。 回调是个很有用的模式，譬如我的主线程执行过程中，要执行一个非常耗时的逻辑。为了不阻塞主线程，自然我们会想到用异步的形式去执行这个耗时逻辑，新建个线程，让这个耗时的逻辑在线程中执行，不阻塞主线程。但问题来了，异步执行没毛病，执行成功、失败后出结果了，该怎么通知主线程？ 4.1、CompletableFuture的回调CompletableFuture提供了许多回调的方法，例如：thenAccept()，whenComplete()，handle()，exceptionally()等。下面列举一些比较常用的回调方法，如下： 12345678//1.计算结果完成，或者异常时执行给定action(当前线程执行)CompletableFuture&lt;T&gt; whenComplete(BiConsumer&lt;? super T, ? super Throwable&gt; action);//2.计算结果完成，或者异常时执行给定action（另起线程执行）CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T, ? super Throwable&gt; action);//3.执行完成时对结果进行处理，还可以处理异常&lt;U&gt; CompletableFuture&lt;U&gt; handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn)//4.异常时，返回指定结果CompletableFuture&lt;T&gt; exceptionally(Function&lt;Throwable, ? extends T&gt; fn) CompleteableFuture提供的回调方法，这些方法也能支持任务的回调，但是前提是任务执行了，才能完成回调。在某些场景中，有些任务单元是可能被SKIP跳过不执行的，不执行的任务也应该有回调。 4.2、Netty future中的回调Netty中的回调是非常多的。netty中的future，可以添加Listener，当异步任务执行完毕后，主动回调一下自己就可以了。 整个netty里面大量充斥着类似的回调，但是如果我们要用，仅仅是针对一个或多个异步任务，希望能有个类似的回调，netty就帮不上忙了。 Netty回调的伪代码：其中doSomething是在异步线程里，而回调是在主线程里的。（回调代码是在主线程，回调任务实际是在异步线程里执行的） 12345678910//主线程main &#123; //doSomething是在异步线程里，回调是在主线程 doSomething().async().addListener(new Listener()&#123; @Override public void complete() throws Exception &#123; //do your job &#125; &#125;);&#125; 4.3、如何自己实现一个简单回调的异步任务首先我们有这么一个需求，有N个耗时任务，可能是IO任务，我们希望他执行时不会阻塞主线程，而期望它执行完毕（成功\\失败）后，来发起一次回调，最好还有超时、异常的回调控制。 我们可以有这样的角色： Bootstrap主线程 worker 任务 listener 监听器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.soyo.simple;/** * @author: lkl * @date: 2025/9/12 22:24 */public class Bootstrap &#123; public static void main(String[] args) &#123; Bootstrap bootstrap = new Bootstrap(); Worker worker = bootstrap.newWorker(); Wrapper wrapper = new Wrapper(); wrapper.setWorker(worker); wrapper.setParam(&quot;hello&quot;); //2.回调方法，输出worker中的内容 bootstrap.doWorker(wrapper).addListener(new Listener() &#123; @Override public void callback(Object result) &#123; System.out.println(Thread.currentThread().getName()); System.out.println(result); &#125; &#125;); //1.主线程不阻塞，打印当前线程 System.out.println(Thread.currentThread().getName()); &#125; private Wrapper doWorker(Wrapper wrapper) &#123; new Thread(() -&gt; &#123; Worker worker = wrapper.getWorker(); String result = worker.action(wrapper.getParam()); wrapper.getListener().callback(result); &#125;).start(); return wrapper; &#125; private Worker newWorker() &#123; return new Worker() &#123; @Override public String action(String obj) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return obj + &quot; callback!&quot;; &#125; &#125;; &#125;&#125; 思考核心线程数为0的线程池作者在issue上推荐一个tomcat只使用一个不定长线程池。 AsyncTool关于多线程并发执行的问题。如果不指定线程池，默认使用不定长线程池。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 注意，newCachedThreadPool() 它的核心线程数是0，最大线程数是Integer.MAX_VALUE。可以说它的线程数是可以无限扩大的线程池。 他使用的队列是没有存储空间的，只要请求过来了，如果没有空闲线程，就会创建一个新的线程。 这种不定长线程池，适合处理执行时间比较短的任务。在高并发下，如果在耗时长的RPC\\IO操作中使用该线程池，势必会造成系统 线程爆炸。 AsyncTool作者在京东使用的场景多数为低耗时（10ms）高并发，瞬间冲击的场景。这种高并发，且任务耗时较少的，适合使用不定长线程池。 但是这种低耗时的场景也不多，对于耗时较长的场景，推荐使用自定义线程池，可以避免那些耗时长的任务长时间占用线程，造成线程 ”爆炸 “，容错率更高。 总结： **newCachedThreadPool**** 特性**：核心线程数 0，最大线程数无限，队列无缓存 → 任务一来没线程就新建线程。 适合短耗时任务：任务执行快，线程能很快释放和复用，高并发时能快速扩容，冲击过去后线程又能被回收，不会长期暴涨。 不适合长耗时任务：线程长时间被占用，新任务只能不断新建线程，最终线程数“爆炸”，导致内存和 CPU 切换压力过大，系统崩溃。 结论：短平快的高并发任务用不定长线程池；耗时任务必须用自定义线程池（限制核心数、最大数和队列），避免线程无限增长。 短耗时 + 高并发场景 → 秒杀下单接口 用户在 11.11 秒杀活动一开始，会有 瞬间几十万请求冲进来。 每个请求要做的事情很简单： 校验库存（内存中或 Redis 中） 扣减库存标记 返回“抢购成功&#x2F;失败”结果 整个处理逻辑可能只需要 5~10ms。 在这种场景下： 请求量短时间非常大 → 需要线程池快速扩容，防止请求被阻塞。 每个任务很快执行完 → 线程会迅速释放，可以被复用，不会造成线程无限积压。 高峰一过，线程池里的线程就会在 60s 内回收 → 节省资源。 👉 所以 newCachedThreadPool 就特别适合这种“短平快、高并发、瞬时冲击”的场景。 而且双11这种平台肯定是希望用户请求在机器不会崩的情况下流量越多越好，因为下单的单数越多，那么平台赚得越多 源码解析","path":"2025/09/12/JUC/手写并发任务编排工具类/","date":"09-12","excerpt":"","tags":[]},{"title":"kafka存储原理","text":"","path":"2025/09/12/kafka/kafka存储原理/","date":"09-12","excerpt":"","tags":[]},{"title":"Redis高可用","text":"两套方案 cluster，sentinel sentinel redis当发现Redis主节点宕机后，多个sentinel之间会选一个裁判出来，通过投票的方式，多数大于小数，由于这个东西，所以机器数都是基数的，不然就脑裂了 然后再进行从新选主,且由裁判执行 不同系统之间的选举leader elects mastersentinel leader负责选举新的leader，这个过程中还可以挑一个最好的 选择规则： 优先选数据最完整的slave，因为主从同步是有时间窗口的 slave slave-prioirty 值最低的优先 多个slave满足条件后，选runid最小的 redis cluster就是分片，就是分库分表那一套 有个slot的概念，内置了16384个槽，且不能改变。一个slot只能在一台机器上，且在主节点上 crc16(key) % 16384（固定值，不能调节了，所以就不用了 ）分配在一个slot上。 resharding Redis cluster的数据量极限，16384个slot，一个slot一个Redis master节点 1000w * 16384 &#x3D; 16384000w条数据 分布式数据库为什么不采用slot","path":"2025/09/12/Redis/Redis高可用/","date":"09-12","excerpt":"","tags":[]},{"title":"与memcached对比，挺有意思的中间件","text":"PS：俄罗斯人造的东西都有个特点就是快，Nginx也是，走一个极致路线 对比Redis，Redis其实不是纯粹的缓存，自称NOSQL DB，因为可以落盘么 而memcached就是纯粹的缓存 特点 协议简单 使用libevent进行事件处理 内置内存 之间不进行通信的分布式 简单协议过于简单了，都没自己的命令行工具，直接上去就是开敲 telnet 本地主机 端口 用人来告诉计算机代码更快 之间不进行通信的分布式方式 存储原理slab allocator，也是池化的思想，不用了还回去，用了再回来 PS：文件真删了，还是能找回来的 原理： 内存结构类似于 快递的蜂巢 画格子 其实就是创建一堆类似不同的数组，内存连续，且内存不会释放，且命令执行多线程，所以才快， 内部碎片虽然解决了外部碎片，但还是会有内部碎片问题 解决方案：就是重启，凌晨重启 题外话Redis往里加数据，得架构师评省一下，比如加一个set，评故下n，因为那东西是单线程，如果你加的集合后面慢慢变过大的话，是会影响其他的 slab内存分配和slub内存分配 命令都是基于set 字符串 get 字符串进行的一个扩展","path":"2025/09/12/Redis/与memcached对比，挺有意思的中间件/","date":"09-12","excerpt":"","tags":[]},{"title":"历史","text":"设计模式是1994年的东西了","path":"2025/09/12/设计模式/历史/","date":"09-12","excerpt":"","tags":[]},{"title":"负载均衡","text":"hash取模 一致性hash目的是为了解决传统hash服务上下限导致的hash全都得全部映射好，只需要部分改变，比如k1推到s1,但s1没了，只会影响k1，而不会影响到其他 以及可以让同一类请求每次都映射到同一节点上，适用于 本地缓存之类的场景，提高缓存命中率 虚拟节点解决的问题：实例节点分布不均 虚拟节点越多，hash上的对象分配更均匀 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.grace.gateway.core.algorithm;import java.util.List;import java.util.SortedMap;import java.util.TreeMap;public class ConsistentHashing &#123; private final int virtualNodeNum; // 哈希环 private final SortedMap&lt;Integer, String&gt; hashCircle = new TreeMap&lt;&gt;(); // 构造函数，初始化一致性哈希环 public ConsistentHashing(List&lt;String&gt; nodes, int virtualNodeNum) &#123; this.virtualNodeNum = virtualNodeNum; for (String node : nodes) &#123; addNode(node); &#125; &#125; public void addNode(String node) &#123; for (int i = 0; i &lt; virtualNodeNum; i++) &#123; String virtualNode = node + &quot;&amp;&amp;VN&quot; + i; hashCircle.put(getHash(virtualNode), node); &#125; &#125; public String getNode(String key) &#123; if (hashCircle.isEmpty()) &#123; return null; &#125; int hash = getHash(key); SortedMap&lt;Integer, String&gt; tailMap = hashCircle.tailMap(hash); Integer nodeHash = tailMap.isEmpty() ? hashCircle.firstKey() : tailMap.firstKey(); return hashCircle.get(nodeHash); &#125; private int getHash(String str) &#123; final int p = 16777619; int hash = (int) 2166136261L; for (int i = 0; i &lt; str.length(); i++) &#123; hash = (hash ^ str.charAt(i)) * p; &#125; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; if (hash &lt; 0) &#123; hash = Math.abs(hash); &#125; return hash; &#125;&#125; 权重随机1234567891011@Overridepublic ServiceInstance selectInstance(GatewayContext context, List&lt;ServiceInstance&gt; instances) &#123; int totalWeight = instances.stream().mapToInt(ServiceInstance::getWeight).sum(); if (totalWeight &lt;= 0) return null; int randomWeight = ThreadLocalRandom.current().nextInt(totalWeight); for (ServiceInstance instance : instances) &#123; randomWeight -= instance.getWeight(); if (randomWeight &lt; 0) return instance; &#125; return null;&#125;","path":"2025/09/12/项目/自研网关/网关弹力设计/负载均衡/","date":"09-12","excerpt":"","tags":[]},{"title":"单调栈","text":"基础单调栈分为单调递增，单调递减 递增栈： 栈内元素从栈底到栈顶递增。 用于寻找 下一个更小元素。 递减栈： 栈内元素从栈底到栈顶递减。 用于寻找 下一个更大元素。 👉 核心模式就是： 1234567for (...) &#123; while (!stack.isEmpty() &amp;&amp; 当前元素和栈顶元素满足某条件) &#123; // 处理逻辑：清算旧账 stack.pop(); &#125; stack.push(当前元素/下标);&#125; 每日温度[🔥59]题目：找出每个元素多少index后会出现比他大的元素 思路： 维护一个单调递减栈，存的是index 123456789101112131415161718class Solution &#123; public int[] dailyTemperatures(int[] temperatures) &#123; //维护一个单调递增栈，用来存放已经遍历过的元素，然后就可以与当前元素进行一个比较 //该题是一个单调递减栈，栈顶 --&gt; 栈低 是递增的 Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); int[] res = new int[temperatures.length]; for (int i = 0; i &lt; temperatures.length; i++) &#123; //队列不为空 然后如果当前元素大于那个已经遍历过的元素，那就去清理旧账 while (!stack.isEmpty() &amp;&amp; temperatures[stack.peek()] &lt; temperatures[i]) &#123; int curIndex = stack.pop(); //求的是间隔 res[curIndex] = i - curIndex; &#125; stack.add(i); &#125; return res; &#125;&#125; 时间复杂度：ON 空间复杂度：ON 84. 柱状图中最大的矩形[28]思路： 本质上还是接雨水，理解两个点： 1. 面积等于高度 * 宽度，所以对于任何一个柱子，都要看看往左右两边伸展的最大宽度是多少，使用单调栈 2. 栈有两个语义，栈[-2] 是栈[-1]的左边界，出栈操作时，表示栈[-1] &gt; 当前元素，这样就为栈顶元素确定了两个边界。 这里解释一下，range 为什么是 range &#x3D; i - leftIndex - 1; i 即右边第一个比 h(mid) 小的柱子位置，而leftindex 即左边第一个比它小的柱子（这个值很容易，根据单调栈特性，我们就可以直接peek()出来） 那么当前mid柱子 可扩展的范围 也就是 最右 - 最左 - 1 这里的 - 1就是要把最右最左给排除掉 12345678910111213141516171819202122232425262728293031class Solution &#123; //以 heights[i]为高的 矩形面积有多大 //heights[i] 为基准 public int largestRectangleArea(int[] heights) &#123; int n = heights.length; int[] newHeights = new int[n+2]; newHeights[0] = 0; newHeights[newHeights.length - 1] = 0; System.arraycopy(heights, 0, newHeights, 1 , n); //System.out.println(Arrays.toString(newHeights)); Stack&lt;Integer&gt; s = new Stack(); s.add(0); int res = 0; for(int i = 0; i &lt; newHeights.length; i++)&#123; while(!s.isEmpty() &amp;&amp; newHeights[i] &lt; newHeights[s.peek()])&#123; int midIndex = s.pop(); if(s.isEmpty())&#123; break; &#125; int leftIndex = s.peek(); //以h(mid)为高度 左右扩展的范围 // leftIndex midIndex .... i int range = i - leftIndex - 1; res = Math.max(res, newHeights[midIndex] * range); &#125; s.add(i); &#125; return res; &#125;&#125; 最大矩形[27]思路： 先做84题，是它的父问题。就是把它切 m(martix.length )个 84题问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123; int res = 0; public int maximalRectangle(char[][] matrix) &#123; int[][] t = new int[matrix.length][matrix[0].length + 2]; for(int i = 0; i &lt; t.length; i++)&#123; t[i][0] = 0; t[i][t[0].length - 1] = 0; &#125; // 转换成 84题那种柱状图 for(int i = 0; i &lt; t.length; i++)&#123; for(int j = 1; j &lt; t[0].length - 1; j++)&#123; if(matrix[i][j - 1] == &#x27;1&#x27;)&#123; t[i][j] = 1; //当前 位置为 1时，才能有高度 if(i &gt; 0) t[i][j] += t[i - 1][j]; &#125; else t[i][j] = 0; &#125; &#125; // for(int [] tt: t)&#123; // System.out.println(Arrays.toString(tt)); // &#125; for(int[] tt: t)&#123; f1(tt); &#125; return res; &#125; public void f1(int []hegihts)&#123; Stack&lt;Integer&gt; s = new Stack(); s.add(0); for(int i = 1; i &lt; hegihts.length; i++)&#123; while(!s.isEmpty() &amp;&amp; hegihts[s.peek()] &gt; hegihts[i])&#123; int midIndex = s.pop(); if(s.isEmpty())&#123; break; &#125; int leftIndex = s.peek(); res = Math.max(res, hegihts[midIndex] * (i - leftIndex - 1)); &#125; s.add(i); &#125; &#125;&#125; 去除重复字母","path":"2025/09/11/Codetop刷题/单调栈/","date":"09-11","excerpt":"","tags":[]},{"title":"动态规划","text":"最长重复子数组[🔥64]12345678910111213141516171819202122232425class Solution &#123; public int findLength(int[] nums1, int[] nums2) &#123; //dp吧 //dp数组表示什么? : 以 i结尾的nums1 以j 结尾的nums2 ，最大的子数组长度 //遍历顺序 //状态方程 //dp数组就表示 // 1 2 3 4 // 1 2 3 5 // 1 2 3 4 6 // 1 2 5 4 int [][]dp = new int[nums1.length+1][nums2.length+1]; int res=0; for(int i=0;i&lt;nums1.length;i++)&#123; for(int j=0;j&lt;nums2.length;j++)&#123; if(nums1[i]==nums2[j])&#123; dp[i+1][j+1]=dp[i][j]+1; res=Math.max(res,dp[i+1][j+1]); &#125; &#125; &#125; return res; &#125;&#125; 买卖股票的最佳时机 II [82]题目： 给你一个整数数组 prices ，其中 prices[i] 表示某支股票第 i 天的价格。 在每一天，你可以决定是否购买和&#x2F;或出售股票。你在任何时候 最多 只能持有 一股 股票。你也可以先购买，然后在 同一天 出售。 返回 你能获得的 最大 利润 思路： 贪心：低价买入，如果第二天高价就卖出，局部最优解 12345678910111213class Solution &#123; public int maxProfit(int[] prices) &#123; int res =0; //上帝视角看 //我们要实现最大利润，那么从股票走势图来看就是 递增的每一段我都要赚，只要第二天涨价我就卖，每一段上升期我都吃 for(int i=1;i&lt;prices.length;i++)&#123; if(prices[i]-prices[i-1]&gt;0)&#123; res+=prices[i]-prices[i-1]; &#125; &#125; return res; &#125;&#125; 动态规划：状态：有股票or没股票，dp数组含义：第i天持有or没持有股票的最大利润，状态推导 12345678910111213141516171819class Solution &#123; public int maxProfit(int[] prices) &#123; //dp : i 这一天可获得的最大利润 // 股票状态：有或者没有 int [][] dp = new int[prices.length][2]; dp[0][0] = -prices[0]; dp[0][1] = 0; for(int i=1;i&lt;prices.length;i++)&#123; //0:有：昨天有今天继续持有 or 昨天没有但今天买入 dp[i][0]=Math.max(dp[i-1][0],dp[i-1][1]-prices[i]); //1:没有：昨天没有今天继续没有 or 昨天有但今天卖出 dp[i][1]=Math.max(dp[i-1][1],dp[i-1][0]+prices[i]); &#125; //因为最后一天手里 不能有股票 才是最大利润（卖掉股票才是真实收益）。 return dp[prices.length-1][1]; &#125;&#125; 不同路径[72] 思路：DP，四部曲 ，数组含义，初始化，状态，推导 123456789101112131415161718192021class Solution &#123; public int uniquePaths(int m, int n) &#123; //dp：表示达到该位置i j最大有多少条路径 int [][] dp = new int[m][n]; //初始化 dp[0][0]=1; for(int i=1;i&lt;m;i++)&#123; dp[i][0]=1; &#125; for(int j=1;j&lt;n;j++)&#123; dp[0][j]=1; &#125; for(int i=1;i&lt;m;i++)&#123; for(int j=1;j&lt;n;j++)&#123; //状态推导，当前位置 = 左 + 上 dp[i][j]=dp[i-1][j]+dp[i][j-1]; &#125; &#125; return dp[m-1][n-1]; &#125;&#125; 编辑距离[183]思路： 背诵 哈哈哈 123456789101112131415161718192021222324252627282930class Solution &#123; public int minDistance(String word1, String word2) &#123; int [][]dp=new int[word1.length()+1][word2.length()+1]; //dp[i][j] 表示 word 中前 i个字符，变换到word2中的 前j个字符，需要的最小次数 // dp[0][0] 表示 空字符串 // for(int i=0;i&lt;=word1.length();i++)&#123; dp[i][0]=i; &#125; for(int j=0;j&lt;=word2.length();j++)&#123; dp[0][j]=j; &#125; for(int i=1;i&lt;=word1.length();i++)&#123; for(int j=1;j&lt;=word2.length();j++)&#123; //eg： // ros i=2 // rs i=1 //特殊情况 word1[i-1]==word[j-1] if(word1.charAt(i-1)==word2.charAt(j-1))&#123; dp[i][j]=dp[i-1][j-1]; &#125; //当前状态 是增，删，改 哪个操作数小？ else dp[i][j]=Math.min(dp[i-1][j-1],Math.min(dp[i-1][j],dp[i][j-1]))+1; &#125; &#125; return dp[word1.length()][word2.length()]; &#125;&#125; 爬楼梯思路： 动态规划，思考dp数组含义，当前状态是怎么由前一个状态推导过来的 &#x2F;&#x2F;两种情况：比如我在三阶梯，我可以从一阶梯一下子两步上来，以及从二阶梯一步上来 123456789101112131415161718class Solution &#123; public int climbStairs(int n) &#123; if(n &lt; 2) return n; int []dp = new int[n+1]; dp[0] = 1; dp[1] = 1; dp[2] = 2; //4 //1:1 //2:2 //3: 2 for(int i = 3;i &lt;= n;i++)&#123; //两种情况：比如我在三阶梯，我可以从一阶梯一下子两步上来，以及从二阶梯一步上来 dp[i] = dp[i-1] + dp[i-2]; &#125; return dp[n]; &#125;&#125; 零钱兑换123456789101112131415161718192021class Solution &#123; public int coinChange(int[] coins, int amount) &#123; //dp数组含义： 构成当前金额的最小硬币数 //dp[i] = dp[ i - cions ] + 1 if(amount &lt;= 0)&#123; return 0; &#125; int []dp = new int[amount+1]; Arrays.fill(dp,Integer.MAX_VALUE); dp[0] = 0; for(int i = 0;i &lt; dp.length;i++)&#123; for(int j = 0;j&lt;coins.length;j++)&#123; if( i - coins[j] &gt;= 0 &amp;&amp; dp[i-coins[j]] != Integer.MAX_VALUE)&#123; dp[i] = Math.min(dp[i-coins[j]] + 1, dp[i]); &#125; &#125; &#125; System.out.println(Arrays.toString(dp)); return dp[amount] == Integer.MAX_VALUE? -1: dp[amount]; &#125;&#125; 最大正方形[81]思路：动态规划 就嗯记，dp思路 相邻三个矩形边长的最小值+1 dp数组含义即 以matrix[i][j] 为右下角为右下角的最大正方形边长 12345678910111213141516171819202122class Solution &#123; public int maximalSquare(char[][] matrix) &#123; int n = matrix.length; int m = matrix[0].length; //dp数组含义 dp[i][j] 表示：以 matrix[i][j] 为右下角的最大正方形边长。 int[][] dp = new int[n][m]; int res = 0; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; if(matrix[i][j] == &#x27;1&#x27;) &#123; if(i == 0|| j == 0)&#123; dp[i][j] = 1; &#125; //min (相邻三个正方形) + 1 else dp[i][j] = Math.min(dp[i - 1][j - 1], Math.min(dp[i][j - 1], dp[i - 1][j])) + 1; res = Math.max(res, dp[i][j]); &#125; &#125; &#125; return res * res; &#125;&#125; 打家劫舍[70]思路： 动规，详情见代码 1234567891011121314151617class Solution &#123; public int rob(int[] nums) &#123; if(nums.length == 1) return nums[0]; int []dp = new int[nums.length]; //dp数组含义 小偷走到当前i index房子时 能偷的最高金额 //初始化 dp[0] = nums[0]; dp[1] = Math.max(nums[0], nums[1]); int res = dp[1]; for(int i = 2;i &lt; nums.length; i++)&#123; //两种情况 偷 or 不偷，且不能相邻偷 dp[i] = Math.max(dp[i - 2] + nums[i], dp[i - 1]); res = Math.max(res, dp[i]); &#125; return res; &#125;&#125; 输出路径 123456789101112131415161718192021222324252627class Solution &#123; public int rob(int[] nums) &#123; if(nums.length == 1) return nums[0]; int []dp = new int[nums.length]; //dp数组含义 小偷走到当前i index房子时 能偷的最高金额 //初始化 dp[0] = nums[0]; dp[1] = Math.max(nums[0], nums[1]); int res = dp[1]; //路径 List&lt;Integer&gt; resList = new ArrayList&lt;&gt;(); //resList.add(); for(int i = 2;i &lt; nums.length; i++)&#123; //偷 or 不偷 if(dp[i - 2] + nums[i] &gt; dp[i - 1])&#123; if(i == 2) resList.add(dp[0]); resList.add(nums[i]); &#125; //两种情况 偷 or 不偷，且不能相邻偷 dp[i] = Math.max(dp[i-2] + nums[i], dp[i - 1]); res = Math.max(res, dp[i]); &#125; System.out.println(resList); return res; &#125;&#125; 单词拆分[64]思路： DP做法：看成背包问题，即s是否可以被物品wordDict装满 那么这时候dp数组的含义：dp[i] 表示0….i 范围的s是否可以被worddict里的单词分隔 这种做法时间复杂度 O（）？不太行哦 时间复杂度：O(n³) n &#x3D; 字符串长度 因为三层操作：外层 i、内层 j、substring 复制 123456789101112131415161718192021class Solution &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; //dp数组含义 以i为结尾的字符串，是否可以被转换 HashSet&lt;String&gt; set = new HashSet(wordDict); boolean[] dp = new boolean[s.length()]; for (int i = 0; i &lt; s.length(); i++) &#123; for (int j = 0; j &lt;= i; j++) &#123; //j...i String sub = s.substring(j, i + 1); // 0...j...i //这里的条件成立为两部分：[0..j-1] [j...i] 可以被分隔 //两者共同使 以i为结尾的字符串，是否可以被转换 if ((j == 0 || dp[j - 1]) &amp;&amp; set.contains(sub)) &#123; dp[i] = true; break; &#125; &#125; &#125; return dp[s.length() - 1]; &#125;&#125; https://chatgpt.com/s/t_68ea8e7831c48191ba35865a1392cdee 分割等和子集[28]思路 可能性问题可以优先想到 DP 必会题，01背包 dp[i][j] 表示[0..i]里若干个元素是否可以构成和为j 12345678910111213141516171819202122232425262728class Solution &#123; public boolean canPartition(int[] nums) &#123; int sum=0; for(int i=0;i&lt;nums.length;i++) sum+=nums[i]; int avg =sum/2; if(sum % 2 == 1) return false; //dp数组含义：nums[0.。i] 是否存在若干个元素的和 等于 j boolean [][]dp = new boolean[nums.length][avg + 1]; //初始化 if(nums[0] &lt;= avg)&#123; dp[0][nums[0]] = true; &#125; for(int i = 1; i &lt; nums.length; i++)&#123; for(int j = 0; j &lt;= avg; j++)&#123; //j为 目标和 if(nums[i] &lt;= j)&#123; //不选 则 [0....i-1]若干个元素和为j //选，则[0....i-1]若干个元素和为j-nums[i] dp[i][j] = dp[i - 1][j] || dp[i - 1][j - nums[i]]; &#125; //nums[i] 本身超过了 j,那肯定是不选的 else dp[i][j] = dp[i - 1][j]; &#125; if(dp[i][avg]) return true; &#125; return dp[nums.length - 1][avg]; &#125;&#125; 压缩： 12345678910111213141516171819class Solution &#123; public boolean canPartition(int[] nums) &#123; int sum=0; for(int i=0;i&lt;nums.length;i++) sum+=nums[i]; int avg =sum/2; if(sum % 2 == 1) return false; //dp数组含义：是否存在若干个元素的和 等于 i boolean []dp = new boolean[avg + 1]; if(nums[0] &lt;= avg) dp[nums[0]] = true; //初始化 for(int i = 1; i &lt; nums.length; i++)&#123; for(int j = avg; j &gt;= 0; j--)&#123; if(nums[i] &lt;= j) dp[j] = dp[j] || dp[j - nums[i]]; &#125; if(dp[avg]) return true; &#125; return dp[avg]; &#125;&#125; 分割成和最相近的两个子集 完全平方数[22]完全背包 12345678910111213141516171819202122232425262728293031class Solution &#123; // 和为 n 的完全平方数的最少数量 // /** dp数组含义 和为 i 的完全平方数的最少数量 */ public int numSquares(int n) &#123; if (n &lt;= 3) return n; int length = n / 2; int[] nums = new int[length]; int count = 1; for (int i = 0; i &lt; nums.length; i++, count++) &#123; nums[i] = count * count; &#125; //System.out.println(Arrays.toString(nums)); int dp[] = new int[n + 1]; dp[0] = 0; for (int i = 1; i &lt; dp.length; i++) dp[i] = Integer.MAX_VALUE; for (int i = 0; i &lt; nums.length; i++) &#123; for (int j = 0; j &lt;= n; j++) &#123; if (j &gt;= nums[i] &amp;&amp; dp[j - nums[i]] != Integer.MAX_VALUE) dp[j] = Math.min(dp[j], dp[j - nums[i]] + 1); &#125; &#125; //System.out.println(Arrays.toString(dp)); return dp[n]; &#125;&#125; 目标和1 打家劫舍 III[]思路 树形DP，树的每个节点存储两种状态（抢or不抢），然后从底递推到 根节点 当前节点抢，则 left不抢 + right不抢 + 1 若当前节点不抢，则左右节点的抢or不抢中取最大，然后相加。 12345678910111213141516171819202122232425262728293031323334/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode() &#123;&#125; * TreeNode(int val) &#123; this.val = val; &#125; * TreeNode(int val, TreeNode left, TreeNode right) &#123; * this.val = val; * this.left = left; * this.right = right; * &#125; * &#125; */class Solution &#123; public int rob(TreeNode root) &#123; int[] res = dfs(root); //最后这里，就是当前节点抢不抢的问题 return Math.max(res[0], res[1]); &#125; public int[] dfs(TreeNode root)&#123; if(root == null)&#123; return new int[]&#123;0,0&#125;; //怎么选都是没有的 &#125; int []left = dfs(root.left); int []right = dfs(root.right); //当前节点抢，则 左右子节点必须为 不抢的 int rob = left[1] + right[1] + root.val; //当前节点不抢，则 从左右子节点取 最大的，然后一起带上来当前节点 int noRob = Math.max(left[0], left[1]) + Math.max(right[0], right[1]); return new int[]&#123;rob, noRob&#125;; &#125; &#125; 买卖股票的最佳时机含冷冻期[4]思路 两个状态：持有or不持有 dp数组含义 第i 持有or不持有股票 的最大利润 状态机DP 123456789101112131415161718192021222324252627282930class Solution &#123; public int maxProfit(int[] prices) &#123; //status: 0 没持有 1 持有 // 有冻结期 无非就是 今天卖出 明天不能买入、 //prices 是指同一只股票的价格啊！！！！！ //dp数组含义：第i天 没持有or持有 的利润 int[][] dp = new int[prices.length][2]; dp[0][0] = 0; dp[0][1] = -prices[0]; for (int i = 1; i &lt; prices.length; i++) &#123; //没持有，可能是 继续没持有，或者 在昨天持有股票的基础上 在今天以今天股票的价格股票给卖了 dp[i][0] = Math.max(dp[i - 1][0], dp[i - 1][1] + prices[i]); //持有：可能是继续持有股票 或者是 前天把股票卖出了，然后以今天以今天股票的价格把股票买入了（为什么只能前天，因为不能昨天卖出，然后第二天买入） //不能同时拥有多只股票，其实只有一直股票 if (i == 1) dp[i][1] = Math.max(dp[i - 1][1], dp[i - 1][0] - prices[i]); else //不能同时参与多笔交易 dp[i][1] = Math.max(dp[i - 1][1], dp[i - 2][0] - prices[i]); &#125; //最后肯定得把股票卖了，即没持有，才能实现利益最大化 return dp[prices.length - 1][0]; &#125;&#125; 比特位计数[2]思路 dp含义：第数为i，二进制后1的个数为 dp[i] 递推公式：当i为偶数，当i为奇数 123456789101112131415161718192021222324252627282930class Solution &#123; public int[] countBits(int n) &#123; //0 -&gt; 0 //1 -&gt; 1 //2 -&gt; 10 //3 -&gt; 11 3/2 == 1 &amp; 1 //4 -&gt; 100 4/2 == 2 //5 -&gt; 101 5/2 == 2 //6 -&gt; 110 //7 -&gt; 111 //8 -&gt; 1000 2的3次方 8/2 == 3 int[] res = new int[n + 1]; if(n &lt; 1) return res; res[0] = 0; res[1] = 1; for(int i = 2; i &lt;= n; i++)&#123; int num = i; if(num % 2 == 0)&#123; res[i] = res[num / 2]; &#125; else &#123; res[i] = res[num / 2] + 1; &#125; &#125; return res; &#125;&#125;","path":"2025/09/11/Codetop刷题/动态规划/","date":"09-11","excerpt":"","tags":[]},{"title":"面试前必看！！！！！！！💪💪💪","text":"SQL题 codetop刷题 实习产出 项目 场景题（开放式数据量级问题） 手写系列 卷叶卷到死。。","path":"2025/09/11/面试前必看！！！！！！！💪💪💪/","date":"09-11","excerpt":"","tags":[]},{"title":"哈希表","text":"无重复字符的最长子串[🔥990][中]题目：就是给一个str，然后让你找到无重复字符的最长子串 思路： 整体就是滑动窗口 map来存储子串的字符状态 r++ ,map不断更新，map.put() while(map.get(xx) &gt; 1){ l++; map.put()去把map里的之前状态消掉 } res不断更新 两数之和[🔥285][易]题目：给你一个数组，一个target。然后让你去从数组中找到能组成target的元素 思路： 数组 先存一遍 cache set 遍历一遍数组，然后 cache.contains(target - curV) 如果为true ，就更新 二叉树的中序遍历非递归题目：用非递归的形式输出二叉树的中序遍历 1 最小覆盖子串[🔥114]题目：给你一个字符串 s 、一个字符串 t 。返回 s 中涵盖 t 所有字符的最小子串。如果 s 中不存在涵盖 t 所有字符的子串，则返回空字符串 &quot;&quot; 。 输入：s &#x3D; “ADOBECODEBANC”, t &#x3D; “ABC”输出：”BANC”解释：最小覆盖子串 “BANC” 包含来自字符串 t 的 ‘A’、’B’ 和 ‘C’。 思路： 整体还是滑动窗口 维护一个map，map为t的映射表（k：字符，v：字符出现个数）。一个cnt，cnt初始化为 t的字符个数，表示还剩多少个字符可构成 t r++直到找到了t的第一个元素，ifxxx&gt;0，cnt–，map[c] – while(cnt&#x3D;&#x3D;0) 开始更新结果，且把最左边的东西弹出去 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Solution &#123; public String minWindow(String s, String t) &#123; // 1. 统计 t 中每个字符的需求 Map&lt;Character, Integer&gt; need = new HashMap&lt;&gt;(); for (char c : t.toCharArray()) &#123; need.put(c, need.getOrDefault(c, 0) + 1); &#125; int cnt = t.length(); // 记录还缺多少个字符才能满足条件 int l = 0, r = 0; // 左右双指针 int minLen = Integer.MAX_VALUE; // 最小子串长度 String res = &quot;&quot;; // 最终结果 // 2. 滑动右指针，不断扩展窗口 for (; r &lt; s.length(); r++) &#123; char cr = s.charAt(r); // 只有当 cr 在需求表 need 中时才处理 if (need.containsKey(cr)) &#123; // 如果还缺这种字符，满足一个需求 → cnt-- // ⚠️ 注意：必须是 need(cr) &gt; 0 才 cnt--， // 否则可能是冗余字符，多减会出错 if (need.get(cr) &gt; 0) cnt--; // 不管需不需要，窗口多了这个字符，都要在 need 中减去 need.put(cr, need.get(cr) - 1); &#125; // 3. 当 cnt == 0 时，说明当前窗口已经满足 t 的需求 while (cnt == 0) &#123; // 更新答案（如果更短就更新） if (r - l + 1 &lt; minLen) &#123; minLen = r - l + 1; res = s.substring(l, r + 1); &#125; // 尝试缩小左边界 l char cl = s.charAt(l); if (need.containsKey(cl)) &#123; // 把这个字符移出窗口，need要加回去 need.put(cl, need.get(cl) + 1); // 如果加回去后 &gt; 0，说明这个字符现在又缺了 // 所以 cnt++，窗口不再满足条件 if (need.get(cl) &gt; 0) cnt++; &#125; l++; // 左指针右移 &#125; &#125; return res; &#125;&#125; 时间复杂度：O N（s.length）+M（t.length） 找到字符串中所有字母异位词[🔥15][中]题目：就是给你一个source,一个target，然后找出source字符串里面的包含target所有字符的字符子串 思路： 整体就是滑动窗口 然后初始化一个 26个字母的数组 [0 1 2 ……. ] 长度&lt;target.length()就跳过 啥时候更新结果：当上面那个数组等于 target的数组模式时就更新 1234567891011121314151617181920212223242526272829class Solution &#123; public List&lt;Integer&gt; findAnagrams(String s, String p) &#123; List&lt;Integer&gt; res = new ArrayList(); int[] target = new int[26]; //异位词： 包含p所有字符的 字符串 int[] cs = new int[26]; for (char c : p.toCharArray()) &#123; target[c - &#x27;a&#x27;]++; &#125; //滑动窗口 int l = 0; int r = 0; for (; r &lt; s.length(); r++) &#123; cs[s.charAt(r) - &#x27;a&#x27;]++; //首先得满足长度才能更新结果么 if (r - l + 1 &lt; p.length()) &#123; continue; &#125; //如果数组全相同就 说明找到了，更新结果 if (Arrays.equals(cs, target)) &#123; res.add(l); &#125; cs[s.charAt(l) - &#x27;a&#x27;]--; l++; &#125; return res; &#125;&#125; 评论评论最热 | 最新puffan2021-06-23滑动窗口O(n) 3暂无回复回复一天到晚只会刷算法的疯狂javaer2023-08-16我直接一个滑动窗口滑滑滑 2暂无回复回复Li2022-08-19华子实习手撕 2暂无回复回复伟2022-02-28滑动窗口算法, 跟字符串排列思路一样 1暂无回复回复Thirt33n2024-07-09字节三面 0暂无回复回复用户OTCHR2023-02-02滑动窗口 0暂无回复回复小号备战校招2022-11-06字节一面，跟567一样 0暂无回复回复 ## [和为K的子数组](https://leetcode.cn/problems/subarray-sum-equals-k)[🔥70] 题目：给你一个数组，然后让你从里面找到和为k的子数组，并统计个数 思路1： 给出前缀和 转化为两数之和 即求 i（前缀和）-k的元素是否存在 思路2： 就是map方式的前缀和 思路3： 动态规划 12345678910111213141516171819202122232425262728293031class Solution &#123; public int subarraySum(int[] nums, int k) &#123; // 1 2 3 // 0 1 3 6 //1,1,1 //0 1 2 3 int []preSum=getPreSum(nums); //转换成两数之和了 //k: integer v:出现个数 Map&lt;Integer,Integer&gt; map=new HashMap&lt;&gt;(); int res=0; for(int i:preSum)&#123; // i为和 k为目标数 //看看是否有 k+xx=i 说明k存在 if(map.containsKey(i-k))&#123; res+=map.get(i-k); &#125; map.put(i,map.getOrDefault(i,0)+1); &#125; return res; &#125; public int []getPreSum(int []nums)&#123; int []preSum=new int[nums.length+1]; preSum[0] = 0; for(int i=1;i&lt;=nums.length;i++)&#123; preSum[i]=preSum[i-1]+nums[i-1]; &#125; return preSum; &#125;&#125; 最长重复子数组[🔥64]题目：给两个整数数组 nums1 和 nums2 ，返回 两个数组中 公共的 、长度最长的子数组的长度 。 思路： 滑动 复制带随机指针的链表[🔥58]题目：拷贝特殊链表节点 思路： 普通链表初始化 初始化两个MAP 一个记录旧链表里 节点与index的关系 一个记录新链表里 index与节点的关系 由于新旧节点 index是一样的 故 旧链表可以通过node.random拿到该random.index 再通过index拿到新链表的node 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/*// Definition for a Node.class Node &#123; int val; Node next; Node random; public Node(int val) &#123; this.val = val; this.next = null; this.random = null; &#125;&#125;*/class Solution &#123; public Node copyRandomList(Node head) &#123; //构造一个新链表、 Node node=head; Node dummyHead = new Node(0); Node cur = dummyHead; //记录旧链表里 节点与index的关系 //记录新链表里 index与节点的关系 //由于新旧节点 index是一样的 //故 旧链表可以通过node.random拿到该random.index //再通过index拿到新链表的node Map&lt;Node,Integer&gt; nodeMap=new HashMap&lt;&gt;(); Map&lt;Integer,Node&gt; indexMap=new HashMap&lt;&gt;(); int index=0; while(node!=null)&#123; nodeMap.put(node,index); node=node.next; index++; &#125; node=head; index=0; while(node!=null)&#123; cur.next=new Node(node.val); cur=cur.next; node=node.next; indexMap.put(index,cur); index++; &#125; //构造Random node=head; cur=dummyHead.next; while(node!=null)&#123; cur.random=indexMap.get(nodeMap.get(node.random)); cur=cur.next; node=node.next; &#125; return dummyHead.next; &#125; &#125; 前 K 个高频元素[35]思路：hashmap统计+优先级队列维护前k个高频元素 无法单单用TreeMap排序，因为 TreeMap 只能按 key 排序，不能用value 优先级队列： PriorityQueue map统计 次数 构造最小堆，且维护数量为k个，大于就驱逐最小的 然后到最后剩下的就是前k个高频元素了 Q：为什么不用最大堆？ A：最大堆，堆顶最大元素，你怎么驱逐堆低元素？ 12345678910111213141516171819202122232425262728class Solution &#123; public int[] topKFrequent(int[] nums, int k) &#123; Map&lt;Integer,Integer&gt; countMap = new HashMap&lt;&gt;(); for (int num : nums) &#123; countMap.put(num, countMap.getOrDefault(num, 0) + 1); &#125; // 小顶堆，堆顶是频率最小的元素 PriorityQueue&lt;Map.Entry&lt;Integer,Integer&gt;&gt; heap = new PriorityQueue&lt;&gt;( (a,b) -&gt; a.getValue() - b.getValue() ); for (Map.Entry&lt;Integer,Integer&gt; entry : countMap.entrySet()) &#123; heap.offer(entry); if (heap.size() &gt; k) &#123; heap.poll(); // 保持堆大小为 k 如果堆的元素里超过k就要驱逐人了 &#125; &#125; int[] res = new int[k]; for (int i = k - 1; i &gt;= 0; i--) &#123; res[i] = heap.poll().getKey(); &#125; return res; &#125;&#125; 两个数组的交集[24]思路：查重就用Set 或者Map！！！！！！！！！！ contains 12345678910111213141516171819202122class Solution &#123; public int[] intersection(int[] nums1, int[] nums2) &#123; HashSet&lt;Integer&gt; set=new HashSet&lt;&gt;(); int length=Math.max(nums1.length,nums2.length); HashSet&lt;Integer&gt; res=new HashSet&lt;&gt;(); for(int n:nums1)&#123; set.add(n); &#125; //查重！！！ for(int n:nums2)&#123; if(set.contains(n))&#123; res.add(n); &#125; &#125; int []ans=new int[res.size()]; int count=0; for(int i:res)&#123; ans[count++]=i; &#125; return ans; &#125;&#125; retainAll的用法：求两个集合的交集，会把非交集的元素remove掉 123456789HashSet&lt;Integer&gt; objects = new HashSet&lt;&gt;();objects.add(1);objects.add(2);objects.add(3);ArrayList&lt;Object&gt; objects1 = new ArrayList&lt;&gt;();objects1.add(1);objects1.add(2);objects1.retainAll(objects);System.out.println(objects1);// 1 2 面试官会先问：两个数组求交集，怎么求？以及说一下时间复杂度（不允许使用编程语言自带的交集功能）。答完之后再问：如果两个数组都是非递减的，又应该怎么求？时间复杂度多少？（本人亲身经历） 三数之和[436]思路： 排序 + 三指针（i [l , r]）+ Set（自动去重） 排序 + 三指针 + 手动去重(剪枝) 1 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) &#123; //三指针 i ... [l r] // i是主指针， l和r是区间指针 Set&lt;List&lt;Integer&gt;&gt; res = new HashSet(); int n = nums.length; //排序 Arrays.sort(nums); for(int i = 0; i &lt; n; i++)&#123; // i ....[l...r] int l = i + 1; int r = n - 1; //剪枝。如果当前 元素为正数，说明没必要往下找了，因为后面都是正数了（因为l和r在i的后面） if(nums[i] &gt; 0) break; while(l &lt; r)&#123; int sum = nums[i] + nums[l] + nums[r]; if(sum == 0)&#123; ArrayList&lt;Integer&gt; path = new ArrayList(); path.add(nums[i]); path.add(nums[l]); path.add(nums[r]); res.add(path); //其实是可以优化的，不用HashSet的话 l++; r--; &#125; //小了, 因为是有序数组（之前排序了）。故移动左指针，增大整体sum else if(sum &lt; 0) l++; //大了，移动右指针，减少整体sum else r--; &#125; &#125; return new ArrayList(res); &#125;&#125; 四数之和[21]二数之和：哈希 三数之和：排序 + 双指针 + 剪枝 四数之和：排序 + 双指针 + 剪枝 思路： 1 O(1) 时间插入、删除和获取随机元素[18]思路：hashMap+数组 Map：k为值，v为index，这样就可以containsKey了，杜绝重复insert 数组就是用来存放元素的 并且维护一个index 12345678910111213141516171819202122class RandomizedSet &#123; static int[] nums = new int[200010]; Random random = new Random(); Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int idx = -1; public boolean insert(int val) &#123; if (map.containsKey(val)) return false; nums[++idx] = val; map.put(val, idx); return true; &#125; public boolean remove(int val) &#123; if (!map.containsKey(val)) return false; int loc = map.remove(val); if (loc != idx) map.put(nums[idx], loc); nums[loc] = nums[idx--]; return true; &#125; public int getRandom() &#123; return nums[random.nextInt(idx + 1)]; &#125;&#125; 前K个高频单词[18]题目： 给定一个单词列表 words 和一个整数 k ，返回前 k 个出现次数最多的单词。 返回的答案应该按单词出现频率由高到低排序。如果不同的单词有相同出现频率， 按字典顺序 排序。 看题啊尼玛的 思路： hashmap统计 最小堆维护前k个高频单词 123456789101112131415161718192021222324252627282930313233class Solution &#123; public List&lt;String&gt; topKFrequent(String[] words, int k) &#123; // 1. 统计词频 Map&lt;String, Integer&gt; freqMap = new HashMap&lt;&gt;(); for (String word : words) &#123; freqMap.put(word, freqMap.getOrDefault(word, 0) + 1); &#125; // 2. 小顶堆维护 Top K PriorityQueue&lt;Map.Entry&lt;String, Integer&gt;&gt; pq = new PriorityQueue&lt;&gt;( (a, b) -&gt; &#123; if (!a.getValue().equals(b.getValue())) &#123; return a.getValue() - b.getValue(); // 频率升序 &#125; else &#123; return b.getKey().compareTo(a.getKey()); // 字典序降序 &#125; &#125; ); for (Map.Entry&lt;String, Integer&gt; entry : freqMap.entrySet()) &#123; pq.offer(entry); if (pq.size() &gt; k) pq.poll(); // 保证堆大小为 K &#125; // 3. 从堆中取出元素，倒序输出 List&lt;String&gt; res = new ArrayList&lt;&gt;(); while (!pq.isEmpty()) &#123; res.add(0, pq.poll().getKey()); &#125; return res; &#125;&#125; 167. 招式拆解 I[17]有效的字母异位词[17]12345678910111213class Solution &#123; public boolean isAnagram(String s, String t) &#123; int [] cntS =new int[26]; int [] cntT =new int[26]; for(char c: s.toCharArray())&#123; cntS[c-&#x27;a&#x27;]++; &#125; for(char c: t.toCharArray())&#123; cntT[c-&#x27;a&#x27;]++; &#125; return Arrays.equals(cntS,cntT); &#125;&#125; 砖墙连续数组","path":"2025/09/11/Codetop刷题/哈希表/","date":"09-11","excerpt":"","tags":[]},{"title":"字符串","text":"最长回文子串思路：见代码 123456789101112131415161718192021222324252627282930class Solution &#123; public String longestPalindrome(String s) &#123; //左边界 int resL=0; //右边界 int resR=0; for(int i=0;i&lt;s.length();i++)&#123; //有两种情况：1为一个中心点 2为两个中心点 for(int j=0;j&lt;=1;j++)&#123; int l=i; int r=i+j; //两边扩张 while(l&gt;=0&amp;&amp;r&lt;s.length()&amp;&amp;s.charAt(l)==s.charAt(r))&#123; l--; r++; &#125; //回到正确的位置 l++; r--; if(r-l&gt;resR-resL)&#123; resL=l; resR=r; &#125; &#125; &#125; return s.substring(resL,resR+1); &#125;&#125; 有效的括号思路： 遇到右括号入栈，遇到左括号则与栈顶比较 1234567891011121314151617181920212223242526272829class Solution &#123; public boolean isValid(String s) &#123; Stack&lt;Character&gt; stack=new Stack&lt;&gt;(); for(char c:s.toCharArray())&#123; if(c==&#x27;[&#x27;||c==&#x27;&#123;&#x27;||c==&#x27;(&#x27;)&#123; stack.add(c); &#125; else if(!stack.isEmpty()&amp;&amp;equals(stack.peek(),c))&#123; stack.pop(); &#125; else return false; &#125; //为什么不直接返回 true //&quot;[&quot; 这种情况就得判Stack是否为空 return stack.isEmpty(); &#125; public boolean equals(char a,char b)&#123; if(a==&#x27;[&#x27;&amp;&amp;b==&#x27;]&#x27;)&#123; return true; &#125; else if(a==&#x27;&#123;&#x27;&amp;&amp;b==&#x27;&#125;&#x27;)&#123; return true; &#125; else if(a==&#x27;(&#x27;&amp;&amp;b==&#x27;)&#x27;)&#123; return true; &#125; return false; &#125;&#125; 字符串相加题目：大数相加 思路： 倒序相加，p1,p2从后面遍历字符串，然后at(p1) 和 at(p2) 进行相加，若p1 or p2 &lt;0 就at(p) &#x3D;0 相加过程：sum &#x3D; at(p1) +at(p2) + pos（上一次运算进的位），然后当前位置的相加后的值 &#x3D; sum%10，下一次进位 sum&#x2F;10 后面如果出现 9+1这边，while结束后 if(pos &gt; 1) append(1) 最后结果倒置 reverse() 123456789101112131415161718192021class Solution &#123; public String addStrings(String num1, String num2) &#123; int p1=num1.length()-1; int p2=num2.length()-1; int pos=0; StringBuilder res=new StringBuilder(); while(p1&gt;=0||p2&gt;=0)&#123; int n1=p1&gt;=0?num1.charAt(p1)-&#x27;0&#x27;:0; int n2=p2&gt;=0?num2.charAt(p2)-&#x27;0&#x27;:0; int sum=n1+n2+pos; res.append(sum%10); pos=(sum)/10; p1--; p2--; &#125; if(pos&gt;0)&#123; res.append(1); &#125; return res.reverse().toString(); &#125;&#125; 大数相减要怎么做？或者说num1 为负数呢 1 复原IP地址思路： 第一步要要思考，当下有几种选择？ 以 “25525511135” 为例，第一步时我们有几种选择？ 选 “2” 作为第一个片段 选 “25” 作为第一个片段 选 “255” 作为第一个片段 然后第二步的时候我们又有几种选择，切第二个片段时，又面临三种选择 这会向下分支，形成一棵树，我们用 DFS 去遍历所有选择，必要时提前回溯。 因为某一步的选择可能是错的，得不到正确的结果，不要往下做了。撤销最后一个选择，回到选择前的状态，去试另一个选择。 回溯的第一个要点：选择，它展开了一颗空间树。 第二步思考，有什么约束 约束条件限制了当前的选项，这道题的约束条件是： 不能有前导0，截取的字符串不能比255大，字符串截取长度为1-3 我们应该利用这些约束条件，对其进行剪枝。 用这些约束进行充分地剪枝，去掉一些选择，避免搜索「不会产生正确答案」的分支。 第三部思考，目标是什么什么时候应该收集结果 定义dfs函数 return的作用是退回上一个选择点！！！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123; List&lt;String&gt; res = new ArrayList&lt;&gt;(); List&lt;String&gt; path = new ArrayList&lt;&gt;(); int n; public List&lt;String&gt; restoreIpAddresses(String s) &#123; n = s.length(); dfs(s, 0); return res; &#125; //我们第一步面临几个选择. // 1.选一个 // 2.选两个 // 3.选三个 public void dfs(String s, int start) &#123; if (start == n &amp;&amp; path.size() == 4) &#123; StringBuilder sb = new StringBuilder(); for (String ss : path) &#123; sb.append(ss); sb.append(&quot;.&quot;); &#125; sb.deleteCharAt(sb.length() - 1); res.add(sb.toString()); return; &#125; //走到底，发现每一个选择都是合理，但整体选择就是错误的了 //纵向剪枝 //如：s：123454 path:[1,2,3,4] if (start &lt; n &amp;&amp; path.size() == 4) &#123; return; &#125; for (int len = 1; len &lt;= 3; len++) &#123; //删除不合法的前导0 // len &gt; 1 才会可能不合法： 01 022 //横向剪辑 if (len != 1 &amp;&amp; s.charAt(start) == &#x27;0&#x27;) &#123; //return的作用是退回上一个选择点！！！ return; &#125; //保证后续s.substring() 合法 if (start + len - 1 &gt;= n) &#123; return; &#125; String t = s.substring(start, start + len); //截取后 大小不能超过255 if (len == 3 &amp;&amp; Integer.parseInt(t) &gt; 255) return; path.add(t); dfs(s, start + len); path.remove(path.size() - 1); &#125; &#125;&#125; 比较版本号思路： 分格String，用split，得到string []s 取两个str数组[] ，mark version 将s里的值装成Integer比较 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123; public int compareVersion(String version1, String version2) &#123; String[] s1 = version1.split(&quot;\\\\.&quot;); String[] s2 = version2.split(&quot;\\\\.&quot;); int length = s1.length &gt; s2.length ? s1.length : s2.length; String[] ss1 = new String[length]; String[] ss2 = new String[length]; for (int i = 0; i &lt; s1.length; i++) &#123; ss1[i] = s1[i]; if (i == s1.length - 1) &#123; i++; while (i &lt; length) &#123; ss1[i] = &quot;0&quot;; i++; &#125; &#125; &#125; for (int i = 0; i &lt; length; i++) &#123; ss2[i] = s2[i]; if (i == s2.length - 1) &#123; i++; while (i &lt; length) &#123; ss2[i] = &quot;0&quot;; i++; &#125; &#125; &#125; System.out.println(Arrays.toString(ss1)); System.out.println(Arrays.toString(ss2)); for (int i = 0; i &lt; length; i++) &#123; if (Integer.parseInt(ss1[i]) &gt; Integer.parseInt(ss2[i])) &#123; return 1; &#125; else if (Integer.parseInt(ss1[i]) &lt; Integer.parseInt(ss2[i])) &#123; return -1; &#125; &#125; return 0; &#125;&#125; 字节2面时候遇到过，不让用已知方法（java里String#split 方法），不让分割成String数组，可以试着自己手写一个双指针的方法 括号生成[137]思路： 先把树图给列举出来，思考选择（加右括号还是左括号），约束，目标 回溯属性，path作为参数来说，return时只带恢复现场。而不是像全局属性一样（如下下），得手动恢复现场 1234567891011121314151617181920212223242526272829303132class Solution &#123; List&lt;String&gt; res = new ArrayList&lt;&gt;(); public List&lt;String&gt; generateParenthesis(int n) &#123; dfs(0, 0, n, &quot;&quot;); return res; &#125; public void dfs(int lcnt, int rcnt, int n, String path) &#123; if (lcnt + rcnt == 2 * n) &#123; res.add(path.toString()); return; &#125; //&quot;) xxxx&quot; 肯定不合法 if (path.length() == 1 &amp;&amp; path.charAt(0) == &#x27;)&#x27;) return; //合法的括号，lcnt的大小肯定是得等于n if (lcnt &lt; n) &#123; // System.out.println(&quot;L&quot;); // System.out.println(path); dfs(lcnt + 1, rcnt, n, path + &quot;(&quot;); &#125; //只有当前位置： lcnt&gt;rcnt,才可以加&quot;)&quot;eg： ((() if (rcnt &lt; lcnt) &#123; // System.out.println(&quot;R&quot;); // System.out.println(path); dfs(lcnt, rcnt + 1, n, path + &quot;)&quot;); &#125; &#125;&#125; 全局属性path 1234567891011121314151617181920212223242526272829class Solution &#123; List&lt;String&gt; res = new ArrayList&lt;&gt;(); StringBuilder sb = new StringBuilder(); public List&lt;String&gt; generateParenthesis(int n) &#123; dfs(0, 0, n); return res; &#125; public void dfs(int lcnt, int rcnt, int n) &#123; if (lcnt + rcnt == 2 * n) &#123; res.add(sb.toString()); return; &#125; //合法的括号，lcnt的大小肯定是得等于n if (lcnt &lt; n) &#123; sb.append(&quot;(&quot;); dfs(lcnt + 1, rcnt, n); sb.deleteCharAt(sb.length()-1); &#125; //只有当前位置： lcnt&gt;rcnt,才可以加&quot;)&quot;eg： ((() if (rcnt &lt; lcnt) &#123; sb.append(&quot;)&quot;); dfs(lcnt, rcnt + 1, n); sb.deleteCharAt(sb.length()-1); &#125; &#125;&#125; 字符串转换整数 (atoi)最长有效括号思路： 找到匹配括号的下标，然后存进一个LIst 接下来就是转换成 寻找最长连续子序列 两种做法：排序后滑动窗口，时间复杂度O（NlogN） hashset，时间复杂度O（N） 1234567891011121314151617181920212223242526272829class Solution &#123; public int longestValidParentheses(String s) &#123; List&lt;Integer&gt; indexList = new ArrayList&lt;&gt;(); Stack&lt;Integer&gt; st = new Stack(); for (int i = 0; i &lt; s.length(); i++) &#123; if (s.charAt(i) == &#x27;(&#x27;) &#123; st.add(i); &#125; if (s.charAt(i) == &#x27;)&#x27; &amp;&amp; st.size() != 0) &#123; int index = st.pop(); indexList.add(i); indexList.add(index); &#125; &#125; Collections.sort(indexList); int res = 0; int l = 0; int r = 1; //找出该数组的最长连续数列的长度 for (; r &lt; indexList.size(); r++) &#123; if (indexList.get(r) != indexList.get(r-1) + 1) &#123; l = r; &#125; res = Math.max(res, r - l + 1); &#125; return res; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123; public int longestValidParentheses(String s) &#123; List&lt;Integer&gt; indexList = new ArrayList&lt;&gt;(); Stack&lt;Integer&gt; st = new Stack(); for (int i = 0; i &lt; s.length(); i++) &#123; if (s.charAt(i) == &#x27;(&#x27;) &#123; st.add(i); &#125; if (s.charAt(i) == &#x27;)&#x27; &amp;&amp; st.size() != 0) &#123; int index = st.pop(); indexList.add(i); indexList.add(index); &#125; &#125; Set&lt;Integer&gt; set = new HashSet&lt;&gt;(indexList); int res = 0; // int l = 0; // int r = 1; //找出该数组的最长连续数列的长度 // for (; r &lt; indexList.size(); r++) &#123; // if (indexList.get(r) != indexList.get(r-1) + 1) &#123; // l = r; // &#125; // res = Math.max(res, r - l + 1); // &#125; // return res; //最长连续子序列 for(int x: set)&#123; if(set.contains(x-1))&#123; continue; &#125; int nextX = x+1; int cnt = 1; while(set.contains(nextX))&#123; nextX++; cnt++; &#125; res = Math.max(res,cnt); &#125; return res; &#125;&#125; 字符串相乘[116]思路： 直接背诵，debug一遍也行 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123; public String multiply(String num1, String num2) &#123; // 特殊情况：有一个数为0，结果直接是0 if (num1.equals(&quot;0&quot;) || num2.equals(&quot;0&quot;)) &#123; return &quot;0&quot;; &#125; // 用数组保存结果，最大长度 = num1长度 + num2长度 int[] res = new int[num1.length() + num2.length()]; // 从后往前模拟竖式相乘 for (int i = num1.length() - 1; i &gt;= 0; i--) &#123; int n1 = num1.charAt(i) - &#x27;0&#x27;; for (int j = num2.length() - 1; j &gt;= 0; j--) &#123; int n2 = num2.charAt(j) - &#x27;0&#x27;; // res[i+j+1] 存放当前位的结果（个位） int sum = res[i + j + 1] + n1 * n2; // 更新个位 res[i + j + 1] = sum % 10; // 更新进位（加到前一位） res[i + j] += sum / 10; &#125; &#125; // 构建字符串结果，去掉最高位可能的0 StringBuilder result = new StringBuilder(); for (int i = 0; i &lt; res.length; i++) &#123; if (i == 0 &amp;&amp; res[i] == 0) continue; // 跳过前导0 result.append(res[i]); &#125; return result.toString(); &#125;&#125; 最小覆盖子串题目： 思路： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123; public String minWindow(String s, String t) &#123; // 1. 构建目标字符表：统计 t 中每个字符需要的数量 Map&lt;Character, Integer&gt; target = new HashMap&lt;&gt;(); int cnt = 0; // 还差多少个字符没有被窗口覆盖 for (char c : t.toCharArray()) &#123; target.put(c, target.getOrDefault(c, 0) + 1); cnt++; // t 每有一个字符，就多需要一个 &#125; // 2. 定义滑动窗口的左右边界 int l = 0; int r = 0; String res = &quot;&quot;; // 记录最终结果 int size = Integer.MAX_VALUE; // 记录最小窗口大小 // 3. 滑动右指针，扩大窗口 for (; r &lt; s.length(); r++) &#123; char cr = s.charAt(r); // 如果右指针的字符不是目标字符，直接跳过 if (!target.containsKey(cr)) &#123; continue; &#125; // 如果 cr 仍是需要的字符，就让 cnt--（缺少的字符数减少） if (target.get(cr) &gt; 0) &#123; cnt--; &#125; // 把该字符的需求数减一（可能出现负数，表示“多出来的”） target.put(cr, target.get(cr) - 1); // 4. 当 cnt == 0 时，说明窗口已经包含了 t 的所有字符 while (cnt == 0) &#123; // 更新结果：若当前窗口更小，则替换 if (size &gt; r - l + 1) &#123; size = r - l + 1; res = s.substring(l, r + 1); &#125; // 5. 收缩左指针，尝试缩小窗口 char lc = s.charAt(l); if (target.containsKey(lc)) &#123; // 把左边的字符“归还”给 target target.put(lc, target.get(lc) + 1); // 如果归还后需求量 &gt; 0，说明窗口不再满足条件 if (target.get(lc) &gt; 0) &#123; cnt++; &#125; &#125; l++; // 左指针右移，缩小窗口 &#125; &#125; return res; &#125;&#125; 反转字符串中的单词思路： 先把所有单词挑出来 然后翻转 String数组 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123; public String reverseWords(String s) &#123; //把所有单词都挑出来 List&lt;String&gt; ss = split(s); //System.out.println(ss); //翻转单词 Collections.reverse(ss); StringBuilder sb = new StringBuilder(); for (String v : ss) &#123; sb.append(v); sb.append(&quot; &quot;); &#125; sb.deleteCharAt(sb.length() - 1); return sb.toString(); &#125; public List&lt;String&gt; split(String s) &#123; int r = 0; List&lt;String&gt; res = new ArrayList&lt;&gt;(); StringBuilder sb = new StringBuilder(); for (; r &lt; s.length(); r++) &#123; if (s.charAt(r) == &#x27; &#x27;) &#123; if (sb.length() &gt; 0) &#123; res.add(sb.toString()); sb = new StringBuilder(); &#125; continue; &#125; else &#123; sb.append(s.charAt(r)); &#125; &#125; //[&quot;the sky is blue&quot;] 这种情况会导致blue没法加进去 //所以最后得做兜底 if (sb.length() &gt; 0) res.add(sb.toString()); return res; &#125;&#125; 最长公共前缀耻辱：快手日常侧开一面竟然脑子坏了 思路： 1. 12345678910111213141516171819202122class Solution &#123; public String longestCommonPrefix(String[] strs) &#123; boolean tag = true; String res = &quot;&quot;; //以第一个str为基准 for (int i = 0; i &lt; strs[0].length(); i++) &#123; String preStr = strs[0].substring(0, i + 1); //遍历剩余的子串 for (int j = 1; j &lt; strs.length; j++) &#123; //是否以preStr为开头 if (!strs[j].startsWith(preStr)) &#123; tag = false; &#125; &#125; //所有都为，更新结果 if (tag) &#123; res = preStr; &#125; &#125; return res; &#125;&#125; 验证IP地址思路： 就是简单模拟 学到的东西：Integer.parseInt(x,进制) 可指定进制 可以学学正则表达式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class Solution &#123; public String validIPAddress(String queryIP) &#123; if (is4Or6(queryIP)) &#123; String[] ip = queryIP.split(&quot;\\\\.&quot;); // String[] ip = queryIP.split(&quot;.&quot;); 错误的, &quot;.&quot; 在正则表达式里是 任意字符的意思 // System.out.println(queryIP); // System.out.println(Arrays.toString(ip)); if(getCnt(&#x27;.&#x27;,queryIP) != 3)&#123; return &quot;Neither&quot;; &#125; if (ip.length != 4) &#123; return &quot;Neither&quot;; &#125; for (String s : ip) &#123; try &#123; if (s.length() &gt; 1 &amp;&amp; s.charAt(0) == &#x27;0&#x27;) &#123; return &quot;Neither&quot;; &#125; if (Integer.parseInt(s,10) &gt; 255) &#123; return &quot;Neither&quot;; &#125; &#125; catch (Exception e) &#123; return &quot;Neither&quot;; &#125; &#125; return &quot;IPv4&quot;; &#125; else &#123; String[] ip = queryIP.split(&quot;:&quot;); if(getCnt(&#x27;:&#x27;,queryIP) != 7)&#123; return &quot;Neither&quot;; &#125; if (ip.length != 8) &#123; return &quot;Neither&quot;; &#125; for (String s : ip) &#123; if (s.length() &gt; 4) &#123; return &quot;Neither&quot;; &#125; try&#123; //转成16进制 Integer.parseInt(s,16); &#125;catch(Exception e)&#123; return &quot;Neither&quot;; &#125; &#125; return &quot;IPv6&quot;; &#125; &#125; public boolean is4Or6(String queryIP) &#123; if (queryIP.contains(&quot;.&quot;)) &#123; return true; &#125; else return false; &#125; public int getCnt(char ch,String str) &#123; int count = 0; for (int i = 0; i &lt; str.length(); i++) &#123; if (str.charAt(i) == ch) &#123; count++; &#125; &#125; return count; &#125;&#125; 基本计算器 II[67]思路： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192class Solution &#123; Map&lt;Character,Integer&gt; calOrderMap = new HashMap()&#123; &#123; put(&#x27;+&#x27;,1); put(&#x27;-&#x27;,1); put(&#x27;/&#x27;,2); put(&#x27;*&#x27;,2); //put(); &#125; &#125;; public int calculate(String s) &#123; //替换掉空格 s = s.replaceAll(&quot; &quot;, &quot;&quot;); Deque&lt;Integer&gt; nums = new ArrayDeque&lt;&gt;(); Deque&lt;Character&gt; ops = new ArrayDeque&lt;&gt;(); //防止出现 -1 + 5 这种情况 nums.addLast(0); System.out.println(s); char[] cs = s.toCharArray(); int n = cs.length; for (int i = 0; i &lt; n; i++) &#123; char c = cs[i]; if (isNumber(c)) &#123; int number = 0; int numIndex = i; while (numIndex &lt; n &amp;&amp; isNumber(cs[numIndex])) &#123; numIndex++; &#125; nums.addLast(Integer.parseInt(s.substring(i, numIndex))); i = numIndex - 1; &#125; //遇到运算符了 else &#123; //防止出现 9 + - 1 //将其装换成 9 + 0 - 1 if (i &gt; 0 &amp;&amp; (cs[i - 1] == &#x27;-&#x27; || cs[i - 1] == &#x27;+&#x27;)) &#123; nums.addLast(0); &#125; //遇到新的运算符，先把stack里能计算的给计算了 eg：9+8-1 while (!ops.isEmpty()) &#123; if (calOrderMap.get(ops.peekLast()) &gt;= calOrderMap.get(c)) &#123; cal(nums, ops); &#125; else &#123; break; &#125; &#125; ops.addLast(c); &#125; &#125; // 举例： // 2+3*4 // 遍历完后，栈里的情况大概是： // nums = [2, 3, 4] // ops = [&#x27;+&#x27;, &#x27;*&#x27;] while (!ops.isEmpty()) cal(nums, ops); return nums.peekLast(); &#125; public boolean isNumber(char c) &#123; return Character.isDigit(c); &#125; public void cal(Deque&lt;Integer&gt; nums, Deque&lt;Character&gt; ops) &#123; if (nums.isEmpty() || nums.size() &lt;= 1) return; if (ops.isEmpty()) return; //注意顺序 int b = nums.pollLast(); int a = nums.pollLast(); char op = ops.pollLast(); int opRes = 0; switch (op) &#123; case &#x27;-&#x27;: opRes = a - b; break; case &#x27;+&#x27;: opRes = a + b; break; case &#x27;/&#x27;: opRes = a / b; break; case &#x27;*&#x27;: opRes = a * b; break; &#125; nums.addLast(opRes); &#125;&#125; 完全版，应对所有情况，即完整的计算器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121class Solution &#123; Map&lt;Character, Integer&gt; opsOrderMap = new HashMap&lt;&gt;() &#123; &#123; put(&#x27;-&#x27;, 1); put(&#x27;+&#x27;, 1); put(&#x27;*&#x27;, 2); put(&#x27;/&#x27;, 2); put(&#x27;%&#x27;, 2); put(&#x27;^&#x27;, 3); &#125; &#125;; public int calculate(String s) &#123; //分为两个Stack //一个存操作，一个存数字 Deque&lt;Character&gt; ops = new ArrayDeque(); Deque&lt;Integer&gt; nums = new ArrayDeque(); //为了防止第一个就是负数 nums.addLast(0); //去掉全部空格 s = s.replaceAll(&quot; &quot;, &quot;&quot;); char[] cs = s.toCharArray(); int n = s.length(); for (int i = 0; i &lt; n; i++) &#123; char c = cs[i]; if (c == &#x27;(&#x27;) &#123; ops.addLast(c); &#125; else if (c == &#x27;)&#x27;) &#123; //计算 ( ) 里的内容了 while (!ops.isEmpty()) &#123; if (ops.peekLast() != &#x27;(&#x27;) &#123; cal(nums, ops); &#125; else &#123; //为 ( 说明() 已经计算好了 弹出即可 ops.pollLast(); break; &#125; &#125; &#125; else &#123; //转换数字 if (isNumber(c)) &#123; // 19 char 转成 Integer int number = 0; int numIndex = i; // while(numIndex &lt; n&amp;&amp;isNumber(cs[numIndex]))&#123; // number = number*10 + (cs[numIndex] - &#x27;0&#x27;); // numIndex++; // &#125; while (numIndex &lt; n &amp;&amp; isNumber(cs[numIndex])) &#123; numIndex++; &#125; nums.addLast(Integer.parseInt(s.substring(i, numIndex))); i = numIndex - 1; &#125; else &#123; // 1 - -2 → 1 - (0-2) // 1 + +2 → 1 + (0+2) // (+-3) → (0+0-3) if (i &gt; 0 &amp;&amp; (cs[i - 1] == &#x27;(&#x27; || cs[i - 1] == &#x27;+&#x27; || cs[i - 1] == &#x27;-&#x27;)) &#123; nums.addLast(0); &#125; // 有一个新操作入栈时，先把能算的给算了 eg： 1+7-9 -：当前新操作 while (!ops.isEmpty() &amp;&amp; ops.peekLast() != &#x27;(&#x27;) &#123; char prev = ops.peekLast(); if (opsOrderMap.get(prev) &gt;= opsOrderMap.get(c)) &#123; cal(nums, ops); &#125; else &#123; //没有就继续遍历 eg: 12+9*1 当前运算符为 * break; &#125; &#125; ops.addLast(c); &#125; &#125; &#125; while (!ops.isEmpty()) &#123; cal(nums, ops); &#125; return nums.peekLast(); &#125; public void cal(Deque&lt;Integer&gt; nums, Deque&lt;Character&gt; ops) &#123; if (nums.isEmpty()) &#123; return; &#125; if (ops.isEmpty()) &#123; return; &#125; int b = nums.pollLast(); int a = nums.pollLast(); char op = ops.pollLast(); int res = 0; switch (op) &#123; case &#x27;+&#x27;: res = a + b; break; case &#x27;-&#x27;: res = a - b; break; case &#x27;*&#x27;: res = a * b; break; case &#x27;/&#x27;: res = a / b; break; case &#x27;^&#x27;: res = a ^ b; break; case &#x27;%&#x27;: res = a % b; break; &#125; nums.addLast(res); &#125; public boolean isNumber(char c) &#123; return Character.isDigit(c); &#125;&#125; 解码方法[42]思路： dfs分隔 但单单dfs，就超时了 得进行记忆化操作 1234567891011121314151617181920212223242526272829303132class Solution &#123; int n; int res = 0; public int numDecodings(String s) &#123; n = s.length(); dfs(0, s); return res; &#125; public void dfs(int startIndex, String s) &#123; if (startIndex == n) &#123; res++; return; &#125; for (int i = 1; i &lt;= 2; i++) &#123; if (startIndex + i &gt; n) &#123; return; &#125; String s1 = s.substring(startIndex, startIndex + i); if (s1.charAt(0) == &#x27;0&#x27; &amp;&amp; s1.length() &gt;= 1) &#123; return; &#125; int num = Integer.parseInt(s1); if (num &gt; 26) &#123; return; &#125; dfs(startIndex + i, s); &#125; &#125;&#125; 记忆化后 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; int n; int res = 0; int[] memo; // 用于记忆化 public int numDecodings(String s) &#123; n = s.length(); memo = new int[n]; Arrays.fill(memo, -1); // -1 表示未计算 dfs(0, s); return res; &#125; public void dfs(int startIndex, String s) &#123; if (startIndex == n) &#123; res++; return; &#125; // 如果当前索引的结果已经计算过，直接累加并返回 if (memo[startIndex] != -1) &#123; res += memo[startIndex]; return; &#125; int beforeRes = res; // 记录进入这个索引前的 res for (int i = 1; i &lt;= 2; i++) &#123; if (startIndex + i &gt; n) return; String s1 = s.substring(startIndex, startIndex + i); if (s1.charAt(0) == &#x27;0&#x27;) return; // 0 开头不合法 int num = Integer.parseInt(s1); if (num &lt; 1 || num &gt; 26) &#123; return; &#125; dfs(startIndex + i, s); &#125; // memo[startIndex] = 当前索引开始的新方案数 memo[startIndex] = res - beforeRes; &#125;&#125; 验证回文串思路： 熟悉几个API的使用 双指针 123456789101112class Solution &#123; public boolean isPalindrome(String s) &#123; int i = 0, j = s.length() - 1; while(i &lt;= j)&#123; while(i &lt; j &amp;&amp; !Character.isLetterOrDigit(s.charAt(i))) i++; while(i &lt; j &amp;&amp; !Character.isLetterOrDigit(s.charAt(j))) j--; if(Character.toLowerCase(s.charAt(i)) != Character.toLowerCase(s.charAt(j))) return false; i++; j--; &#125; return true; &#125;&#125; 正则表达式匹配有效的括号字符串思路： 双栈，存小标 最后判断一下下标是否合法 eg：(* or *( 1234567891011121314151617181920212223242526272829class Solution &#123; public boolean checkValidString(String s) &#123; Stack&lt;Integer&gt; left = new Stack(); Stack&lt;Integer&gt; stars = new Stack(); for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); if (c == &#x27;(&#x27;) &#123; left.add(i); &#125; else if (c == &#x27;*&#x27;) &#123; stars.add(i); &#125; else &#123; if (!left.isEmpty()) &#123; left.pop(); &#125; else if (!stars.isEmpty()) &#123; stars.pop(); &#125; else return false; &#125; &#125; //eg：( * while(!stars.isEmpty() &amp;&amp; !left.isEmpty())&#123; if(stars.pop() &lt; left.pop())&#123; return false; &#125; &#125; return left.isEmpty(); &#125;&#125; 字母异位词分组[12]思路： 字符串字典排序，然后MAP 1234567891011121314151617class Solution &#123; public List&lt;List&lt;String&gt;&gt; groupAnagrams(String[] strs) &#123; HashMap&lt;String,List&lt;String&gt;&gt; slots = new HashMap&lt;&gt;(); for(String s: strs)&#123; char []cs = s.toCharArray(); Arrays.sort(cs); String newS = new String(cs); if( slots.get(newS) == null)&#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(s); slots.put(newS,list); &#125; else slots.get(newS).add(s); &#125; return new ArrayList&lt;&gt;(slots.values()); &#125;&#125; 交错字符串[27]题目： 思路： dfs，困惑：有时候连dfs的函数都想不出来，真的逆天，没想清楚是字符串是怎么匹配的。还是得把回溯树给画出来 回溯时间复杂度为2^k（k为s3的长度），故得进行记忆化，来剪枝 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class Solution &#123; int[][] cache; public boolean isInterleave(String s1, String s2, String s3) &#123; int n1 = s1.length(); int n2 = s2.length(); int n3 = s3.length(); if (n1 + n2 != n3) &#123; return false; &#125; cache = new int[n1][n2]; //查找字符串里是否包含s1 但可断续 return dfs(s1, s2, s3, 0, 0, 0); &#125; public boolean dfs(String s1, String s2, String s3, int i, int j, int k) &#123; if (i == s1.length() &amp;&amp; j == s2.length() &amp;&amp; k == s3.length()) &#123; return true; &#125; if (i + j &gt; s3.length()) &#123; cache[i][j]= -1; return false; &#125; if (i &lt; s1.length() &amp;&amp; j &lt; s2.length()) &#123; if (cache[i][j] == -1) &#123; return false; &#125; if (cache[i][j] == 1) &#123; return true; &#125; &#125; if (i &lt; s1.length()) &#123; if (s1.charAt(i) == s3.charAt(k) &amp;&amp; dfs(s1, s2, s3, i + 1, j, k + 1)) &#123; if (i &lt; s1.length() &amp;&amp; j &lt; s2.length()) cache[i][j] = 1; return true; &#125; &#125; if (j &lt; s2.length()) &#123; if (s2.charAt(j) == s3.charAt(k) &amp;&amp; dfs(s1, s2, s3, i, j + 1, k + 1)) &#123; if (i &lt; s1.length() &amp;&amp; j &lt; s2.length()) cache[i][j] = 1; return true; &#125; &#125; if (i &lt; s1.length() &amp;&amp; j &lt; s2.length()) cache[i][j] = -1; return false; &#125; public boolean canForm(String t, StringBuilder sb) &#123; int i = 0; int j = 0; while (j &lt; t.length() &amp;&amp; i &lt; sb.length()) &#123; if (t.charAt(j) == sb.charAt(i)) &#123; j++; sb.setCharAt(i, &#x27;#&#x27;); &#125; i++; &#125; return j == t.length(); &#125;&#125; 补充题9. 36进制加法思路：就是大数相加的扩展 1 去除重复字母字符串解码[90]思路 类似于 基本计算器，也是双栈 一个栈存数字，一个栈存字符。这里的 [ 就类似于 * 逻辑，遇到字符，遍历直到不是字符，遇到数字也是，遇到] 就 cal运算。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class Solution &#123; public String decodeString(String s) &#123; Stack&lt;Integer&gt; nums = new Stack(); Stack&lt;String&gt; chars = new Stack(); for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); if (Character.isDigit(c)) &#123; int startIndex = i; while (startIndex &lt; s.length() &amp;&amp; Character.isDigit(s.charAt(startIndex))) &#123; startIndex++; &#125; nums.add(Integer.parseInt(s.substring(i, startIndex))); i = startIndex - 1; &#125; else if (c == &#x27;]&#x27;) &#123; cal(nums, chars); &#125; else if (c == &#x27;[&#x27;) &#123; chars.add(c + &quot;&quot;); &#125; else &#123; int startIndex = i; while (startIndex &lt; s.length() &amp;&amp; s.charAt(startIndex) &gt;= &#x27;a&#x27; &amp;&amp; s.charAt(startIndex) &lt;= &#x27;z&#x27;) &#123; startIndex++; &#125; chars.add(s.substring(i, startIndex)); i = startIndex - 1; &#125; &#125; //System.out.println(chars); StringBuilder res = new StringBuilder(); List&lt;String&gt; list = new ArrayList(); while (!chars.isEmpty()) &#123; list.add(chars.pop()); &#125; for (int i = list.size() - 1; i &gt;= 0; i--) &#123; res.append(list.get(i)); &#125; return res.toString(); &#125; public void cal(Stack&lt;Integer&gt; nums, Stack&lt;String&gt; chars) &#123; // 基础检查，如果栈为空则返回 if (nums.isEmpty() || chars.isEmpty()) &#123; return; &#125; // 1. 获取重复因子 int factor = nums.pop(); // 2. 提取需要重复的字符串片段 StringBuilder segment = new StringBuilder(); while (!chars.isEmpty() &amp;&amp; !chars.peek().equals(&quot;[&quot;)) &#123; // 优化点 1: Pop and Prepend (弹出并前置) // 将弹出的片段插入到 StringBuilder 的开头 (index 0) // 这样可以避免额外的 List 存储和二次反转操作 segment.insert(0, chars.pop()); &#125; // 3. 移除开头的左括号 &#x27;[&#x27; if (!chars.isEmpty() &amp;&amp; chars.peek().equals(&quot;[&quot;)) &#123; chars.pop(); &#125; // 4. 重复片段并推回栈中 String segmentStr = segment.toString(); // 优化点 2: 使用 String.repeat() (推荐 Java 11+) String repeatedString = segmentStr.repeat(factor); chars.push(repeatedString); &#125;&#125; 时间复杂度","path":"2025/09/11/Codetop刷题/字符串/","date":"09-11","excerpt":"","tags":[]},{"title":"Codetop刷题","text":"每个标签前三十道 面试前API复习","path":"2025/09/11/Codetop刷题/","date":"09-11","excerpt":"","tags":[]},{"title":"TCP 和 UDP 的端口","text":"TCP和UDP可以同时绑定相同的端口吗？ 可以的，网络层会根据你IP包头的协议号就知道该数据包是TCP还是UDP，就确定发给哪一个模块处理 原因在于：操作系统内核管理 socket 的时候，区分的不是单纯的端口号，而是 (协议, 本地IP, 本地端口, 远 端IP, 远端端口) 这个五元组。 多个TCP服务进程可以绑定同一个端口吗？ 如果多个TCP服务进程绑定的端口 IP地址和端口号相同，那就不行，执行bind()会报错 但如果那个Socket设置了SO_REUSEADDR，只要两个进程bind的IP不相同。那就是可以的 如何解决服务端进程重启时，报错“Address already in use”的问题？ 当我们重启TCP服务进程的时候，意味着服务端发起了关闭连接操作。于是就是会经过四次挥手。而对于 主动关闭方，会在TIME_WAIT状态停留一段时间，这个时间大概是2MSL 当tcp服务进程重启时，服务端会出现TIME_WAIT状态的连接，TIME_WAIT状态的连接仍然没有释放ip+port 故执行bind()会报错，address already in use 要解决这个问题，我们可以对Socket 设置 so_reuseadd 这样即使存在一个和bind ip和port一样的TIME_WAIT状态的连接，那还是可以绑定成功，从而重启成功 客户端的端口可以重复使用吗？ 确定唯一的连接是靠五元组（协议，源IP，源端口，目标IP，目标端口），只要其中一个不一样就表明是不同 的连接 内核是通过四元组信息来定位一个 TCP 连接的 客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？ 针对这个问题，那得看客户端连的是不是都是同一个服务器（ip,port相同） 如果不一样的话，端口是可以复用的。 一样的话，就会被端口的数量限制住 所以，如果客户端都是与不同的服务器建立连接，即使客户端端口资源只有几万个， 客户端发起百万级连接也是没问题的（当然这个过程还会受限于其他资源，比如文件描述符、内存、CPU 等）。 如何解决客户端TIME_WAIT连接过多，导致无法同时和同一个服务器建立连接的问题？ 打开tcp_tw_reuse。你客户端调用connect()时，如果发现已经有链接占用ip和port，会检查原有连接是否是 TIME_WAIT状态，然后检查该链接是否存在超过了1s，如果是的话，那就复用它 不过这种方式比较激进，Linux2.4已经被废弃了","path":"2025/09/10/计网/TCP 和 UDP 的端口/","date":"09-10","excerpt":"","tags":[]},{"title":"服务端没有listen，客户端发起连接建立","text":"服务端只bind了ip和端口，但是没有listen这个socket监听，客户端此时发起建立连接，会怎样？ 服务端会返回RST，即把SYN丢掉 RST 报文是什么？ RST 报文是 TCP 中的一种“暴力”断开连接的方式。它的意思是 Reset，即“复位”。当接收方发送 RST 时，它是在告诉对方：“我无法建立这个连接，请立即终止！” 这和正常的四次挥手断开连接不同，RST 是一种不包含任何确认的、突然的连接终止。 不使用listen，可以建立tcp连接吗 可以的。tcp自连接（同一台机器内的不同进程连），也可以是两个客户端同时发起建立连接的请求（两个独 立的客户端之间，它们同时尝试与对方建立连接）。 这两种情况都不需要listen，但都可以建立连接 半连接和全连接队列都是在服务端listen时内核自动创建的，故客户端是没有这个东西的。 但内核有个全局hash表，用来存放sock的信息 在tcp自连接中，客户端在connec方法中，会将自己的连接信息放入这个全局hash表中 然后将信息发出，消息经过回环地址重新回答tcp传输层时，就会根据IP+端口信息去这个全局hash中取信息 于是握手一来一回，最后成功建立连接 在两个独立的客户端之间，同时尝试与对方建立连接时：","path":"2025/09/10/计网/TCP和UDP/服务端没有listen，客户端发起连接建立/","date":"09-10","excerpt":"","tags":[]},{"title":"没有accept，能建立TCP连接吗","text":"半连接队列：是一个hash表，服务端第一次握手后，会将sock存于这个队列里，队列中的sock都处于SYN_RECV状态 全连接队列：是一个链表，在服务端收到三次握手后，就会将Sock从半连接队列中取出，然后放到全连接队列中 队列中。队列中的sock都处于一个established状态，等待服务端执行accept()后就可以取出了 可以的，建立连接根本就不需要 accept的参与，accept意义在于从全连接队列中取出一条连接 虽然都叫队列，但其实全连接队列（icsk_accept_queue）是个链表（accpet方便取出），而半连接队列（syn_table）是个哈希表（第三次握手来了方便找到是哪个socket）。","path":"2025/09/10/计网/TCP和UDP/没有accept，能建立TCP连接吗/","date":"09-10","excerpt":"","tags":[]},{"title":"用了TCP，数据一定不会丢吗","text":"建立连接时会丢包 如果对方全连接或者半连接满了，会拒绝建立请求的 流量控制时丢包 发送数据过快时，超过流控队列 即 内核里面控制数据流量大小的队列 的长度 网卡丢包 Ringbuffer过小会溢出，丢包 网卡处理不过来会丢包 超出对方内核接受缓冲区大小 两端之间网络传输丢包 对于这些丢包现象，采用tcp想协议栈可以解决吗 tcp保证的可靠性只是说保证发送方能可靠地把数据从已方的传输层发到对方的传输层 至于数据到了接收方的传输层后，能不能到应用层，tcp是不管的 假设我们现在用手机给朋友发送一条消息，走到传输层的tcp缓冲区，然后发出，不管中间有没有丢包 最后通过重传保证发到了对方的缓冲区，此时接受端就会回一个ack，然后发送端收到ack后就会把缓存 区里的这一条消息摘掉。到这里tcp的任务就结束了 tcp的任务是结束了，但聊天软件的任务还没结束 聊天软件还需要把消息从tcp缓冲区里读出来，如果在读的时候手机内存不足，程序直接杀死了 但这时候发送端是不可能回重传的 于是乎，消息就丢了么 这个问题其实在两个用户之间加一层服务器中转即可（PS：但有一说一，服务器也会挂 狗头） 对于发送方，只要定时跟服务端的内容对账一下，就知道哪条消息没发送成功，直接重发就好了。 如果接收方的聊天软件崩溃了，重启后跟服务器稍微通信一下就知道少了哪条数据，同步上来就是了，所以也不存在上面提到的丢包情况。 两端通信的时候也能对账，为什么还要引入第三端服务器？ - 第一，如果是两端通信，你聊天软件里有1000个好友，你就得建立1000个连接。但如果引入服务端，你只需要跟服务器建立1个连接就够了，聊天软件消耗的资源越少，手机就越省电。 - 第二，就是安全问题，如果还是两端通信，随便一个人找你对账一下，你就把聊天记录给同步过去了，这并不合适吧。如果对方别有用心，信息就泄露了。引入第三方服务端就可以很方便的做各种鉴权校验。 - 第三，是软件版本问题。软件装到用户手机之后，软件更不更新就是由用户说了算了。如果还是两端通信，且两端的软件版本跨度太大，很容易产生各种兼容性问题，但引入第三端服务器，就可以强制部分过低版本升级，否则不能使用软件。但对于大部分兼容性问题，给服务端加兼容逻辑就好了，不需要强制用户更新软件。","path":"2025/09/10/计网/TCP和UDP/用了TCP，数据一定不会丢吗/","date":"09-10","excerpt":"","tags":[]},{"title":"下","text":"","path":"2025/09/10/计网/tcp那些事/下/","date":"09-10","excerpt":"","tags":[]},{"title":"上","text":"序言我们都知道，程序的数据一般都打到tcp的segement里，然后打到IP的packet，再到达以太网的frame(帧) 后发送到对端 :::color4 TCP头格式 TCP的状态机 数据传输中的Sequence Number TCP重传机制 超时重传机制 快速重传机制 SACK 方法 Duplicate SACK – 重复收到数据的问题 ::: tcp头格式 你需要注意这么几个事情 tcp是没有IP地址的，那是IP层的事情 tcp需要一个四元组来标明是一个连接（源端口，源IP，目标端口，目标IP）当然还需要一个协议 四个重要的东西1.seq num：包的序号，用来解决乱序问题 2.ack num：用于确认收到，解决不丢包的问题· 3.window 滑动窗口，用于解决流控 4.tcp flag 主要用来操控tcp的状态机的 tcp状态机其实，网络上的传输是没有连接的，包括TCP也是一样的。而TCP所谓的“连接”，其实只不过是在通讯的双方维护一个“连接状态”，让它看上去好像有连接一样。所以，TCP的状态变换是非常重要的。 为什么建链接要3次握手？ syn即synchronize sequance number 同步序号么，后序传输数据都会基于这个序号，那么三次的话你来我往 的话才能知根知低 断链接需要4次挥手？ 你仔细看其实只有两次，因为tcp是全双工通信，两条通道，所以，发送方和接收方都需要Fin和Ack 只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到 CLOSING状态，然后到达TIME_WAIT状态 单工通信（Simplex）：只能单方向传输，比如电视广播，只能电视台发 → 用户收，用户不能回传。 半双工通信（Half Duplex）：可以双向传输，但不能同时，要轮流，比如对讲机，“你说完我再说”。 全双工通信（Full Duplex）：可以双向同时进行，比如电话、现代以太网。 多事 建立连接时超时了。Client发出syn后，Server接受到了，发给SYN-ACK后但这时候Client下线了怎么办？ 那么这个连接就处于一个中间状态，没成功也没失败。收不到Client的ack一段时间后在Linux下，Server默认会采用一个重试措施，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，而第5次后得等32秒才能停止等待，故总共是63s，这个时候tcp才会断开 SYN Flood攻击。基于上述情况，就有人利用这种机制，恶意攻击你，发一个syn后，客户端下线，让你的syn连接的队列耗尽（syn队列就是存放那些半连接状态的连接的）。于是，Linux下给了一个叫tcp_syncookies的参数来应对这个事——当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使你不在SYN队列中）。请注意，请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为，synccookies是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择，第一个是：tcp_synack_retries 可以用他来减少重试次数；第二个是：tcp_max_syn_backlog，可以增大SYN连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。 关于Inital Sequence Number。并不是所有syn 的起始值都是一样的。如果是的话，那就乱套了。那是跟一个假时钟绑定的，每四微妙++，直到2的32次方，然后归0。这样，一个ISN的周期大约是4.55个小时。因为，我们假设我们的TCP Segment在网络上的存活时间不会超过Maximum Segment Lifetime（缩写为MSL – Wikipedia语条），所以，只要MSL的值小于4.55小时，那么，我们就不会重用到ISN，也就不会出错 关于 MSL 和 TIME_WAIT。为什么关闭连接的时候要有Time_wait？而不是直接关闭？这主要是保证对端能接受到我这边发的ack，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL，2）以及有足够的时间让这个连接不会跟后面的连接混在一起（你要知道，有些自做主张的路由器会缓存IP数据包，如果连接被重用了，那么这些延迟收到的包就有可能会跟新连接混在一起） 关于TIME_WAIT数量太多。这在主要体现在有大量短连接请求下（比如http1&#x2F;2）。timewait太多是会占据掉大部分资源的。但你去网上搜相关教程，太多都会去教你去调两参数 tcp_tw_reuse,tcp_tw_recycle。这两个参数默认都是关闭的，两个参数涉及到的机制都比较激进。 关于tcp_tw_reuse，tcp_tw_recycle，tcp_max_tw_buckets（对抗DDoS攻击的）参数 tcp_tw_resuse,tcp_tw_recycle因为这两个参数违反了TCP协议。 在 Linux 4.12 版本后被彻底移除 其实，TIME_WAIT表示的是你主动断连接，所以，这就是所谓的“不作死不会死”。试想，如果让对端断连接，那么这个破问题就是对方的了，呵呵。另外，如果你的服务器是于HTTP服务器，那么设置一个HTTP的KeepAlive有多重要（浏览器会重用一个TCP连接来处理多个HTTP请求），然后让客户端去断链接（你要小心，浏览器可能会非常贪婪，他们不到万不得已不会主动断连接）。 数据传输中的seq num SeqNum的增加是和传输的字节数相关 上图中，三次握手后，来了两个Len:1440的包，而第二个包的SeqNum就成了1441。然后第一个ACK回的是 1441，表示第一个1440收到了。 tcp重传机制tcp要保证包都到达接收方，就得有重传机制 接收端给发送端的Ack确认只会确认最后一个连续的包，即遵循累计确认原则 PS：ack &#x3D; seq + 1 接收端收到了1 2 可以 回ack &#x3D; 3 但接收端收到了1 2 4 这时候就不可以回 ack &#x3D; 5。会再次发送 ack &#x3D; 3 这时候发送端就知道得重传seq &#x3D; 3的包 不这样的话，发送端就会以为之前的包都收到了 1. 累积确认是什么？“接收端给发送端的 Ack 确认只会确认**最后一个连续的包”这句话解释了累积确认的精髓。** *在 TCP 中，接收端发回的 ACK 报文（确认号）不是用来确认单个数据包，而是用来告诉发送端：“我收到了到这个序号为止的所有数据，你下次可以从这个序号开始发了。”* 例子： 发送端发送了数据包 1、2、3、4、5。 接收端收到了 1 和 2。 接收端会发送一个 ACK 报文，其确认号为 3。这表明它成功收到了序号 1 和 2 的数据，并期望收到序号为 3 的数据。 2. “收到了 4（注意此时 3 没收到），此时的 TCP 会怎么办？”这是一个非常好的问题，它展示了 TCP 的乱序处理能力。 接收端行为： 收到数据包 1 和 2 后，它会发送 ACK 3。 接着收到了数据包 4。因为它没有收到 3，所以 4 是一个乱序的数据包。 此时，接收端不能发送 ACK 5（因为 3 没收到，确认不连续），它会**再次发送 ACK 3。** 发送端行为： 发送端一开始发送了 1、2、3、4、5。 它收到了接收端发来的 ACK 3。这表示 1 和 2 已经到达，它可以继续发送更多数据了。 但是，发送端很快又收到了**重复的 ACK 3。当它收到多个（通常是 3 个）重复的 ACK 报文时，它就知道序号为 3 的数据包很可能丢失了。** 这时，TCP 会触发快速重传（Fast Retransmit）机制，立即重新发送数据包 3，而不需要等到超时后才重传。 超时重传机制一种是如果发送方死等不回来 ack &#x3D; 3。那么这时候就会触发超时重传，一旦接收方收到seq3，就会回ack&#x3D;4 那么发送方就知道3和4都收到了 但是这种方式也有比较严重的问题，因为你要死等3,那么4,5的状态其实是不得知的。这时候tcp可能就会悲观 地认为它们都需要重传 对此有两种选择 1.只重传Timeout的包，即 3 2.重传timeout后的所有包，即 3 4 5 两种说好不好，第一种节省带宽，但费时，第二种可能会做无用工，两者都在等Timeout。PS：这个timeout 是tcp动态计算出来的 快速重传机制为了解决timeout的问题，tcp就引入了一种快速重传算法，不以时间驱动，而是以数据驱动 也就是说如果包没有连续到达的话，就ack那个最后有可能丢失的包。如果发送发接受到了三次相同的ack， 就重传这个包。快速重传的好处就是 不用等待超时 比如：如果发送方发出了1，2，3，4，5份数据，第一份先到送了，于是就ack回2，结果2因为某些原因没收到，3到达了，于是还是ack回2，后面的4和5都到了，但是还是ack回2，因为2还是没有收到，于是发送端收到了三个ack&#x3D;2的确认，知道了2还没有到，于是就马上重转2。然后，接收端收到了2，此时因为3，4，5都收到了，于是ack回6。示意图如下： Fast Retransmit只解决了一个问题，就是timeout的问题，它依然面临一个艰难的选择，就是，是重传之前的一个还是重传所有的问题。对于上面的示例来说，是重传#2呢还是重传#2，#3，#4，#5呢？因为发送端并不清楚这连续的3个ack(2)是谁传回来的？也许发送端发了20份数据，是#6，#10，#20传来的呢。这样，发送端很有可能要重传从2到20的这堆数据（这就是某些TCP的实际的实现）。可见，这是一把双刃剑。 还是有弊端，就是发送发不清楚，后两次是谁发的，如果丢的不止一个包呢。 SACK机制还有更好的方式，SACK Selective Acknowledgment 这个需要再tcp头里添加一个字段，用来记录 收到的不连续包块 比如发送端只收到了 1 2 4 5 7 8 10 这样的话，发送端就知道哪些没到，哪些到了，那么这样就可以准确地重传那些没到了 当然这个协议需要两边都支持，在 Linux下，可以通过tcp_sack参数打开这个功能（Linux 2.4后默认打开）。 当这还是有问题，即接收方有权把已经报给发送端SACK里的数据给丢了，比如内存不够用了 所以，发送方也不能完全依赖SACK，还是要依赖ACK，并维护Time-Out，如果后续的ACK没有增长，那么还是要把SACK的东西重传，另外，接收端这边永远不能把SACK的包标记为Ack。 而且维护SACK是会耗发送发资源的，如果一个攻击者发送给发送方很多这种SACK，让发送方重发一堆东西 Duplicate SACK – 重复收到数据的问题其主要使用了SACK来告诉发送方有哪些数据被重复接收了","path":"2025/09/10/计网/tcp那些事/上/","date":"09-10","excerpt":"","tags":[]},{"title":"tcp那些事","text":"","path":"2025/09/10/计网/tcp那些事/","date":"09-10","excerpt":"","tags":[]},{"title":"主从同步","text":"主从 知识准备IO复用： https://zhuanlan.zhihu.com/p/367591714 两种触发 水平触发：这次不处理，下次还是会触发 边缘触发：只触发一次 两种事件 可读事件：内核缓冲区有数据可读 可写事件：内核缓冲区还有空间即 对方tcp窗口还没满。在IO多路复用情况下，两个Socket啥事没干，可写事件是会一直触发的 Redis： 一般地客户端的可读事件会一直注册在那个epoll wait里的，没处理事件会持续触发，避免数据丢失 而写事件，只有在输出缓冲区有数据时注册，完成后立马注销 主从复制命令执行以及架构12345678​主节点设requirepass, 从节点设masterauth passwordslaveof host port #当前节点成为某个节点的从节点slaveof no one #解除复制REPLICAOF #5.0以上对slaveof的替代 主从复制详细过程场景说明 初次建立主从关系，必定是全量同步。（从节点会把本身旧的数据给删了） 全量同步完成后，主从节点进入命令传播阶段，此时主节点会将每个写命令同时发送给所有从节点 如果此时网络闪断导致主从连接断开，之后重新连接时，从节点会发送PSYNC命令携带之前保存的主节点runID 和 复制偏移量 （很像断线重连哦） 主节点检查runID 是否匹配，且复制偏移量是否还在复制积压缓冲区范围内 如果条件满足，主节点只需要发送缺失的那部分命令即可，这就是部分同步 初次主从同步（从）执行slaveof ip host 123456slaveofCommand() -&gt; replicationSetMaster()replicationSetMaster()&#123; //改个状态然后啥都不做 server.repl_state = REDIS_REPL_CONNECT;&#125; (从)下一次事件循环 【建立tcp连接】 12345678910111213141516171819serverCron() -&gt; replicationCron() -&gt; connectWithMaster()replicationCron()&#123; if (server.repl_state == REDIS_REPL_CONNECT) &#123; connectWithMaster() &#125;&#125;connectWithMaster()&#123; anetTcpNonBlockConnect() aeCreateFileEvent(server.el,fd,AE_READABLE|AE_WRITABLE,syncWithMaster,NULL) server.repl_transfer_lastio = server.unixtime; server.repl_transfer_s = fd; // 将状态改为已连接 server.repl_state = REDIS_REPL_CONNECTING;&#125; (从）再下一次事件循环 【发送ping】 1234567891011syncWithMaster()&#123; if (server.repl_state == REDIS_REPL_CONNECTING) &#123; // 手动发送同步 PING ，暂时取消监听写事件 aeDeleteFileEvent(server.el,fd,AE_WRITABLE); // 更新状态 server.repl_state = REDIS_REPL_RECEIVE_PONG; // 同步发送 PING syncWrite(fd,&quot;PING\\r\\n&quot;,6,100); return; &#125;&#125; （主）两个事件，回pong，同步从节点信息给客户端 12readQueryFromClient() -&gt; pingCommand() -&gt; addReply()sendReplyToClient() 5，（从）主服务器写数据 触发可读事件 （ 触发注册了的syncWithMaster） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//2.8之前，Redis从节点断线重连 智能全量重同步syncWithMaster()&#123; // 接收 PONG 命令 if (server.repl_state == REDIS_REPL_RECEIVE_PONG)&#123; // 手动同步接收 PONG ，暂时取消监听读事件 aeDeleteFileEvent(server.el,fd,AE_READABLE); syncReadLine()//读取pong &#125; //auth 认证 sendSynchronousCommand(fd,&quot;AUTH&quot;,server.masterauth,NULL); //REPLCONF命令,获取master监听的端口 sendSynchronousCommand(fd,&quot;REPLCONF&quot;,&quot;listening-port&quot;,port,NULL); // 根据返回的结果决定是执行部分 resync ，还是 full-resync psync_result = slaveTryPartialResynchronization(fd); // 可以执行部分 resync if (psync_result == PSYNC_CONTINUE) &#123; redisLog(REDIS_NOTICE, &quot;MASTER &lt;-&gt; SLAVE sync: Master accepted a Partial Resynchronization.&quot;); // 返回 return; &#125; // 主服务器不支持 PSYNC ，发送 SYNC if (psync_result == PSYNC_NOT_SUPPORTED) &#123; // 向主服务器发送 SYNC 命令 syncWrite(fd,&quot;SYNC\\r\\n&quot;,6,server.repl_syncio_timeout*1000) &#125; //到这里 psync_result == PSYNC_FULLRESYNC 或 PSYNC_NOT_SUPPORTED // 新建临时文件, 用来接收传输过来的rdb文件 snprintf(tmpfile,256,&quot;temp-%d.%ld.rdb&quot;,(int)server.unixtime,(long int)getpid()); //安装读事件处理器（readQueryFromClient变为 readSyncBulkPayload）指针函数的改变 aeCreateFileEvent(server.el,fd, AE_READABLE,readSyncBulkPayload,NULL) // 设置状态 server.repl_state = REDIS_REPL_TRANSFER;&#125;slaveTryPartialResynchronization()&#123; //组装参数 //PSYNC ? -1 完整重同步 //PSYNC runid offset 部分重同步 // 向主服务器发送 PSYNC 命令 (同步请求并等待) reply = sendSynchronousCommand(fd,&quot;PSYNC&quot;,psync_runid,psync_offset,NULL); if(reply == &quot;+FULLRESYNC&quot;)&#123; return PSYNC_FULLRESYNC; &#125; if(reply == &quot;+CONTINUE&quot;)&#123; // 安装 readQueryFromClient 或者 sendReplyToClient return PSYNC_CONTINUE; &#125; return PSYNC_NOT_SUPPORTED;&#125; 6，（主）收到 sync命令，进行准备 两种：全同步装备rdb文件，部分重同步 同步命令 1234567891011121314151617181920212223242526&quot;sync&quot;/&quot;psync&quot; readQueryFromClient() -&gt; syncCommand()void syncCommand(redisClient *c)&#123; // 如果这是一个从服务器，但与主服务器的连接仍未就绪，那么拒绝 SYNC if (server.masterhost &amp;&amp; server.repl_state != REDIS_REPL_CONNECTED) &#123; addReplyError(c,&quot;Can&#x27;t SYNC while not connected with my master&quot;); return; &#125; if(&quot;psync&quot;)&#123; if(masterTryPartialResynchronization())&#123; return; &#125; &#125; if (server.rdb_child_pid != -1) &#123; //正好有可用的rdb文件 &#125; else&#123; //fork子进程进行rdb rdbSaveBackground(); &#125; //设置状态 c-&gt;replstate = REDIS_REPL_WAIT_BGSAVE_END; // 添加到 slave 列表中 listAddNodeTail(server.slaves,c);&#125; rdb执行完后，为从客户端安装写事件 123456serverCron() -&gt; backgroundSaveDoneHandler() -&gt; updateSlavesWaitingBgsave()updateSlavesWaitingBgsave()&#123; //遍历所有slave,如果slave状态为 slave-&gt;replstate == REDIS_REPL_WAIT_BGSAVE_END aeCreateFileEvent(server.el, slave-&gt;fd, AE_WRITABLE, sendBulkToSlave, slave) &#125; 发送rdb 文件 12sendBulkToSlave() //主readSyncBulkPayload() //从 超时和典型问题默认60s从节点不回复，视为超时 REPLCONF ACK：从节点每秒上报偏移量，主节点检测延迟 典型为题： 数据不一致场景： 网络延迟，解决：监控master和slave的offset 从节点执行key * 阻塞，解决：避免在从节点执行慢查询 全量复制风暴： 导致主节点压力大，解决：错峰同步，级联更新","path":"2025/09/10/Redis/源码/主从同步/","date":"09-10","excerpt":"","tags":[]},{"title":"进程分类","text":"僵尸进程 孤儿进程","path":"2025/09/09/操作系统/进程分类/","date":"09-09","excerpt":"","tags":[]},{"title":"IO模型","text":"https://zhuanlan.zhihu.com/p/115912936 https://zhuanlan.zhihu.com/p/439770090 https://blog.csdn.net/u014453898/article/details/109811000 https://cloud.tencent.com/developer/article/2141900 https://zhuanlan.zhihu.com/p/614204046 进行一次IO的时候（非零拷贝），是需要经过两个阶段的，分别是 第一阶段：等待内核把数据准备，即等待数据搞好 第二阶段：把数据拷贝到用户态 从操作系统来看，NIO指的是非阻塞IO，而从Java来看，NIO指的是IO多路复用 阻塞IO应用程序向内核发起IO请求，第一阶段也阻塞，第二阶段也阻塞，直到数据从内核空间拷贝到用户空间 非阻塞IO（NIO）应用 程序向内核发起IO请求，第一阶段不会阻塞，会返回去干别的事情，然后定时轮询，如果某次询问到内核数据准备好了。那么这时候就会直接等待数据从内核态拷贝到用户态 即第一节点不阻塞，第二阶段不阻塞 IO多路复用应用程序向内核发起请求，开始阻塞监听多个请求，如果内核收到数据了，就会主动来告诉应用程序说数据好了，然后应用程序向内核发起数据请求，等待数据从内核态拷贝到应用态。 IO多路复用分为三种 select：底层采用数组，最多监听1024个fd，即1024个数据来源。会将已连接的socket存放到文件描述符集合中。然后for(Socket socket：Sockets){ if(socket.isOk()) {开始处理事件}} 。如果for循环之后没有满足条件的Socket，那么内核将进行休眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的内核进程，即在socket可读写时唤醒，或者在超时后唤醒。当检测有事件产生时，将此Socket标记为可读可写，接着将整个集合拷贝回用户态，应用程序再对其进行遍历找到可读or可写的Socket，然后对其进行处理。处理完数据后继续调用select对其进行监听，而此时又要重新设置一遍集合（读，写，异常事件集合，三个集合） 这里两次遍历，一次用户态，一次内核态。还有两次文件描述符的拷贝，拷贝来 以及拷贝回去 poll 底层采用的是链表，没有连接数的限制，将实际发生的事件与关心的事件分开，但是呢没有解决遍历的问题，处理好数据后重置fd对应的revent即可 epoll，底层采用红黑树，可以准确通知应用程序，不需要像poll和select一样遍历了。调用一次epoll_ctl就好了，它会注册一个fd，一旦这个fd就绪的话，内核会采取回调机制，迅速去激活这个fd，当进程调用epoll_wati时就会得到通知 通过epoll_create创建epoll对象，此时epoll对象的内核结构包含就绪链表和红黑树，就绪队列是用于保存所有读写事件到来的socket。红黑树用于保存所有待检测的socket。 通过 **epoll_ctl **将待检测的socket，加入到红黑树中，并注册一个事件回调函数，当有事件到来的之后，会调用这个回调函数，进而通知到 epoll 对象。 调用 epoll_wait 等待事件的发生，当内核检测到事件发生后，调用该socket注册的回调函数，执行回调函数就能找到socket对应的epoll对象，然后会将事件加入到epoll对象的绪队列中，最后将就绪队列（其实是epoll_wait的时候传给内核态的）返回给应用层。 水平触发LT：有fd就绪时，重复通知直到数据处理完成，默认方式 （Redis采用的方式） 边缘触发ET：有fd就绪时，通知一次，直到下次有新的数据来，才会再次通知 第一阶段阻塞，第二阶段也阻塞，但是相比于阻塞IO就是能同时监听多个Socket，仍然会有阻塞现象，如果某个请求卡壳，会影响其他请求（单个selector的情况下） 信号驱动IO应用程序向内核发送信号，然后就可以去做别的事，内核如果有数据，调用信号通知应用，应用程序收到信号后，向内核请求数据，等待内核将数据拷贝到用户空间完成，返回，处理数据。 第一阶段不阻塞，第二阶段阻塞，相比于NIO，不需要主动去轮询去问，而是由内核主动通知 异步IO（第二和第一都不阻塞）应用程序向内核发送信号，然后就可以去做别的事，内核如果有数据，先将数据拷贝到用户空间，然后调用信号通知应用，应用程序收到信号后，可以直接处理数据！ 相比于信号驱动IO，第二阶段不阻塞了，但现在技术还不是很成熟，支持的AIO的操作系统和框架也不多 传统IO模型一对一（一个连接一个线程&#x2F;进程） 每一个请求到来时，大致都会按照：请求读取-&gt;请求解码-&gt;服务执行-&gt;编码响应-&gt;发送答复 这个流程去处理。 Reactor模型Reactor：负责监听和分配事件，将I&#x2F;O事件分派给对应的Handler。新的事件包含连接建立就绪、读就绪、写就绪等。 Acceptor：处理连接事件 Handler：执行非阻塞读&#x2F;写事件 单reactor单线程 单reactor多线程 主从reactor多线程主：负责创建连接请求 从：负责处理业务请求","path":"2025/09/09/操作系统/IO模型/","date":"09-09","excerpt":"","tags":[]},{"title":"虚拟内存","text":"操作系统为每个进程都分配独属于进程自己的 虚拟内存，人人有份，互不干涉 操作系统会提供一种映射机制，将虚拟内存地址 映射成 硬件上的实际物理内存地址 当程序要访问虚拟内存地址时，由操作系统转成物理内存地址这样就可以防止说你直接使用物理内存地址，导 致多个进程之间物理地址冲突。 于是我们就引申出两个概念 1.程序使用的内存地址叫虚拟内存地址 2.实际硬件里的空间地址叫物理内存地址 操作系统引入了虚拟地址，进程持有的虚拟内存地址会通过cpu里的MMU（内存管理单元）来转化成物理地址，然后进程再通过物理地址来访问内存 PS：其实就相当于引入了一中间层来协调防冲突，类似中介 32位操作系统内核态虚拟内存的前896内存是直接映射到物理内存的前896m区域的，是一对一映射 且这种映射是不会改变的 操作系统提供两种方式来管理虚拟内存和物理内存的关系，内存分段和内存分页 内存分段 :::color4程序是由若干个逻辑分段构成的，比如由代码分段，数据分段，栈段，堆段组成。不同段是有不同的属性的，所以就用分段的形式把这些段分离出来 你可以把内存分段想象成一本书： 书的目录分为 序言、正文、附录（这就是分段）。 每一段（章节）都有一个起始页码（段基址）和页数范围（段长度）。 你要找“正文第 5 页”，其实就是 正文起始页码 + 5。 分段的缺点： 内存碎片的问题 第二个就是内存交换的效率低的问题 内存碎片主要分成外部碎片和内部碎片 分段内存管理可以做到根据段的大小分配合适的内存大小，所以不会出现内部内存碎片 但是由于每个段的内存不一样，有大有小，所以多个段未必能恰好使用到所有的内存空间，会产生多个不连续的物理内存空间，导致新的程序无法转载，所以会出现外部内存碎片的问题 总结就是随着段的申请和释放，会导致你的内存空间东一块西一块，新的程序来的时候需要一整块连续的，无法满足 解决外部内存碎片的方案就是 内存交换 内存交换就是指当你新进程来的时候，会把暂时没有用的内存数据搬到硬盘，腾空间给新进程用，然后等到那些搬到硬盘的数据需要用的时候再搬回来，搬回来的时候不一定得放到原始的位置上，而是会先进行内存紧缩，让内存空间变得连续 这个内存交换空间，在Linux中，就是我们常说的 swap空间，Linux专门在硬盘上划出这么一块空间，来进行内存与硬盘交换 ::: 内存分页 :::color4分页是指把虚拟和物理内存分为一段段固定内存的大小。这样一个大小固定且连续的内存空间我们就称之为页（好像是这样的哦，比如你书本的页，就是连续且大小固定的。但段就不一定了）。在Linux下，每个页的大小为 4kb 页表是存储在内存中的，而MMU就做这么一个工作，将虚拟地址转成物理地址 问题1：当进程访问的虚拟地址在表中查不到会怎么样 这时候系统会产生一个缺页的表现，会从用户态切成内核态，然后进行物理内存的分配，页表的更新。最后在返回用户态，恢复进程的运行 分页可以让我们程序在加载时不需要一次性把程序加载到物理内存，而是可以在处理好物理内存和虚拟内存之间的映射关系后，并不真的把页加载进去，而是在程序运行时，需要用到虚拟页中的指令和数据时，在把它加载到物理内存里去。 在分页机制下，虚拟内存里包含 虚拟页号和业内偏移。虚拟页号作为页表的索引，页表里又包含虚拟页号 和物理页号，这个物理页号和页内偏移量就构成了物理地址 在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。 这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。 那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。 多级页表 我们把这100多个页再分页，将一级页表分为1024个二级页表，每一个二级页表里包含1024个页表项 且如果某个一级页表的页表项没有被用到时就不去创建二级页表，大大节省了内存空间，当然这是建议在内存使用是稀疏的情况下 即一级页表有1024个页表项，每个页表项对应了4MB的内存空间，总共是4GB，如果一个程序只需要用400MB内存空间，只需要4KB（1024 * 4字节）（一级页表） + 100 * 4KB（二级页表） &#x3D; 0.395MB的页表去存储，这比之前的4MB好多了 为什么不分级的页表就做不到内存节约呢？ 我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了（中断了，cpu切到内核态，程序不能运行）。 原因是页表需要覆盖所有的虚拟内存空间，而如果不分级，那么所使用到的内存空间是非常大。那么这时分级的话，只需要1024个页表项（此时页表已经覆盖所有虚拟内存地址了，二级页表需要时再创建） ::: 段页管理 :::color4内存分页和内存分段并不是对立的，我们可以吸取两者的优点 ::: 为什么要使用虚拟内存 虚拟内存可以使得运行时内存超过实际内存的大小，因为程序的运行符合局部性原理，cpu访问内存会有明显的重复性访问，那么就可以把那些暂时没用的内存数据都放到硬盘上 由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相对独立的。进程也没法访问其他页表，这解决了多进程下的地址冲突问题 页表里的页表项了除了物理地址外，还会有写比特位用来标识一些属性，比如控制页表的读写权限，标记该页是否存在。在内存访问方便，操作系统提供了更好的安全性","path":"2025/09/09/操作系统/虚拟内存/","date":"09-09","excerpt":"","tags":[]},{"title":"进程、线程、协程","text":"进程可以理解为一个动态的程序，进程是操作系统进行资源分配的基本单元。 比如电脑上的QQ就是一个进程，微信也是 线程是操作系统进行调度的基本单位，进程占一个虚拟内存空间，而进程内的线程可以共享进程内的虚拟内存 线程的粒度更小，比如微信可以有多个线程，一个负责拉消息，一个负责发消息，一个负责下载文件 协程可以理解为用户态的线程，和线程的区别 内存占用更小，大概有2k，且可以动态扩容。而线程有2m，线程是操作系统管理的实体，包括时间片，cpu，线程栈之类的，它占用的资源就比较大么。而协程不归操作系统管理，因为占用的资源就比较少 上下文切换开销小，无需在用户态和内核态之间切来切去。线程的切换就需要保存和回复想线程上下文，需要耗费一定的时间和资源。而协程的保存就只需要保存栈帧之类的东西，因此成本是要比线程低的 线程是由操作系统调度的，而协程则是由程序员控制，可以在不同任务之间来回切换，不需要等待操作系统调度 线程是面向操作系统的，而协程是面向任务的。线程需要使用操作系统提供的api进行线程之间的通信和同步。而协程则可以使用语言级别的协程库进行协作式多任务 进程是怎么切换的 进程切换的步骤有几个。 第一个步骤是中断处理。也就是说进程切换其实是依赖中断来触发的，而后进入中断处理，开始执行切换的代码。 第二个步骤是保存当前进程的上下文。 第三个步骤是根据进程调度策略，选出下一个进程，这里叫做新进程。 第四个步骤是标记新老进程的状态。 第五个步骤是切换虚拟地址空间。 第六个步骤恢复新进程的上下文空间。 最后则是跳转到新进程的代码，开始执行。 简述中断处理，保存上下文，选择新进程，切换与恢复 引导进程上下文；虚拟地址空间切换； 从进程切换的这些步骤也能看出来，它的性能是比较差。 而作为对比，线程切换虽然看上去步骤也是类似的，但是实际上就要轻量很多。首先，线程切换不涉及虚拟地址空间切换，那么因为虚拟地址空间切换带来的各种缓存失效等问题都没有；其次，线程之间是共享很多资源的，如文件句柄等，这些共享资源在线程切换的时候都不需要处理。 总之，线程切换比进程切换快，主要是因为线程共享地址空间和资源，减少了地址空间切换和资源管理的开销。这在多线程编程中提供了更高的并发性和性能 为什么虚拟内存地址切换这么慢 进程都有自己的虚拟地址空间，因此虚拟地址空间切换一般就意味着进程切换了。 整个切换过程之所以慢，有很多因素。 第一个是触发用户态和内核态切换。一般来说，虚拟地址空间切换，都会涉及到用户态和内核态的切换的，因此虚拟地址空间是被内核管理的； 第二个是要重新加载 TLB。新的虚拟地址空间导致 TLB 缓存失效，所以需要重新加载新的页表项到 TLB 中； 第三个是页表切换，主要是更新 CPU 中页表基址寄存器，指向新的页表； 第四个是有可能触发 IO 操作，因为新的虚拟地址空间的内容可能在交换区上，需要重新加载进来内存中。 这几个步骤叠加就导致了虚拟地址空间切换是一个比较慢的过程。那么相比之下，同一个进程内的线程都是共享虚拟地址空间的，所以就不会触发虚拟地址空间切换，因此线程切换效率高很多。 进程状态 进程一共有 5 种状态，分别是新建、就绪、运行、阻塞和终止。 其中运行状态就是进程正在 CPU 上运行。 就绪则是说进程已处于准备运行的状态，万事俱备，只欠 CPU 了。 而阻塞状态就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等待 I&#x2F;O 完成。即使CPU 空闲，该进程也不能运行。 在这五种状态中有四个比较关键的转换。 第一个是就绪态到运行态，这一般是因为进程被调度了，获得了 CPU 时间片； 第二个是运行态到就绪态，这一般是因为 CPU 时间片耗尽了； 第三个是运行态到阻塞态，这一般是因为进程执行了一些会引起阻塞的操作，最典型的就是 IO 操作； 第四个是阻塞态到就绪态，这一般是因为达成了唤醒条件，例如说 IO 操作完成了； 除了这五种状态以外，还有一种很特殊的状态，也就是所谓的僵尸进程。 当一个进程已经执行完毕并退出时，它本应该被操作系统完全清理掉，但如果没有正确地被清理，它就会变成僵尸进程。例如说在子进程终止后，但其父进程没有正确地调用wait()或waitpid()系统调用来获取子进程的终止状态。这样一来，子进程虽然已经停止运行，但其在进程表中的条目仍然存在。 简单来说，可以认为僵尸进程只会占一条进程表中的条目，但是如果僵尸进程太多了，导致这个进程表满了，那么操作系统就无法继续创建新的进程了。 进程同步 进程之间的同步方式有很多。 第一种是共享内存。也就是多个进程共享同一块内存区域，实现高效的数据交换，但是一般要配合别的同步机制来保护共享内存，避免出现并发问题； 第二种是管道。管道可以认为是一种数据结构，可以在进程之间传递数据，多用于父子进程之间； 第三种是信号量，它可以控制多个进程对共享资源的访问数量，用来实现互斥和同步，允许多个进程按照一定的顺序访问资源； 第四种是信号，用于通知进程某个事件的发生，是一种轻量级的异步通知机制； 第五种是文件锁，即通过锁定文件或文件的某一部分来实现进程间的同步； 那当然，类似锁、原子操作的也可以用来同步。","path":"2025/09/09/操作系统/进程、线程、协程/","date":"09-09","excerpt":"","tags":[]},{"title":"如何做到高可用","text":"公司内部其实你做到三个9就已经很无敌了，99.9%，但你出去面试一定得说99.99% 你怎么算出来四个9的，如果你在公司待了一年，可以说去年计算了一下完全不可用大概有30分钟，可用性高 达 99.99% 为什么半小时就完全不可用，根据公司通报是运维把网络防火墙搞崩 网关节点的负载均衡即解决客户端应该连哪个网关的问题 现实里的做法：DNS够了 面试：配置网关节点HTTP的信息 负载均衡的策略，最小连接数 再均衡 某个网关节点，比如华南节点，因为赛龙舟，然后这个节点上20000请求，且有些请求比较长就占着不走 那这时候就需要再均衡 判定什么时候需要再均衡 谁来发起再均衡 再均衡的过程是怎么样的？ 谁判断？谁发起？ 一个是客户端判定 客户端发起 网关节点判断，网关节点发起 客户端判定，客户端发起基于消息延迟，借助滑动窗口时间来统计延迟，计算平均延迟。 （高并发情况下，使用RingBuffer来实现滑动窗口算法）近期几次消息的延迟，显著高于平均延迟，就说明网关节点高负载 基于错误率，借助滑动窗口，连续错误 + 错误率 &gt; 阈值 客户端怎么再均衡？ 断开连接，选择一个新节点然后连上 如果客户端发现全部节点都高负载？ 后端扩容 websocket降级到普通http 请求 跨区域连接 但其实你只要监控和自动扩容做好，就不会有这种问题的了 网关节点怎么判定?怎么发起判定： 1.自身的连接数 2.吞吐量 3.自身资源，cpu，内存等 怎么再均衡 1.分批迁移：网关节点主动发消息，然后客户端收到就要执行再均衡，换一个节点重连 2.网关节点可以主动发那会一个可用节点列表 如果网关需要抗每秒10万的高并发访问，你应该怎么对网关进行生产优化？生成情况下一定得 集群化的 8c16g，对网关路由转发的请求，每秒抗1000+是不成问题的，1000台zuul网关机器 高配32c64g，每秒抗个小几万没问题的，几台zuul网关机器是没问题的 【限流层限制QPS带来的问题和替代方案】https://www.bilibili.com/video/BV1pVyGYZEob?vd_source&#x3D;cae07b1dce3e6abe67fcf72c43031ede","path":"2025/09/08/项目/自研网关/如何做到高可用/","date":"09-08","excerpt":"","tags":[]},{"title":"kafka有哪些不足，你要怎么优化","text":"本文主要谈谈Kafka用于实时数据通道场景的缺陷，以及如何在架构上进行弥补。 Kafka归属于消息队列类产品，其他竞品还有RabbitMQ、RocketMQ等，总的来说它们都是基于生产者、中介和消费者三种角色，提供高并发、大数据量场景下的消息传递。Kafka诞生自Hadoop生态，与生态中的其他组件具有更好的亲和性，在实时数据场景中往往是首选。随着数据实时应用的需求高涨，Kafka作为构建实时数据通道的核心组件，得到了广泛的应用。 Kafka本身不介入消息内容，需要生产者和消费者事先约定某种通讯契约（包括序列化框架和数据结构两部分）来编码和解码消息内容。这个通讯契约由参与双方系统约定而成，双方是对等关系，一旦发生变化需要双方重新协商。 对于消息队列场景，上述机制完全没问题。但在实时数据场景下，数据往往由生产侧CDC工具以抓取数据库的方式产生，那么通讯契约中的数据结构部分直接采用了生产系统的表结构，即由生产侧系统单方面定义的，对下游具有强制性。而且，当生产系统的表结构变化时，下游也不得不适配全表结构的变化，即使只需要部分字段的数据。可见，实时数据场景下，下游系统完全是从属关系，产生了大量冗余工作量。另外，表结构变更传递到下游系统，并没有自动化机制，容易产生时间延迟和沟通误差等问题。 Kafka作为一个实时数据的汇集点，并不能对上述两个问题进行有效控制，也就是本文所说的缺陷。 关于解决方案，首先是在Kafka上增加元数据管理模块，在实践中我们选择了Schema Registry，由confulent开源的元数据管理工具。整体架构如下图所示 每个topic都有schema，且随着topic中数据结构的变化，schema会产生多个版本，每个版本的schema具有全局唯一id。一条完整的消息就由schema id和data两部分构成，在消费端读取消息时可以根据id找回schema，进而解析消息。 可见，引入SR后系统具备了在Kafka通道中获取上游系统表结构继而解析消息的能力。当表结构发生变化时，CDC工具会自动推送schema给SR。市场上主流的CDC工具，如Oracel Golden Gate（OGG），已经提供了对Schema Registry的适配。 这样，我们解决了schema在上下游之间自动更新同步的问题。 在此基础上，我们又增加了对表结构的裁剪能力，即可以基于不同下游系统的需求对同一个topic进行差异化的读取字段内容。而裁剪后，也就形成了一个上下游对等关系的契约，降低了下游系统的无效耦合，从而消除了冗余工作量。更重要的是，裁剪的过程是零编码的，仅在交互界面上点选操作即可。这个裁剪工具并没有找到开源实现版本，所以我们自己进行了研发，取名为schema manager。 最后，我们基于schema registry和schema manager，开发了自适应的消息解析程序，封装为SDK。这样下游系统只需要按照SDK接口（兼容Kafka原生接口）订阅消息，即可完全屏蔽掉无关的上游变更内容，对上述一套实现机制完全无感。 最后，简单总结下答案，实时数据通道的四个能力： Kafka的消息队列能力 与生产侧打通的schema自动更新和管理能力 面向消费侧需求的schema裁剪能力 自适应schema变更的解析能力 通过这样的实时数据通道，上下游系统恢复到了对等通讯关系，基本清除了下游的冗余工作量。","path":"2025/09/07/kafka/kafka有哪些不足，你要怎么优化/","date":"09-07","excerpt":"","tags":[]},{"title":"AOF 和 RDB","text":"https://app.diagrams.net/#G1ZI0SeLxjvF7EnIbyF7G0HyBjzioMod6b#%7B%22pageId%22%3A%22C5RBs43oDa-KdzZeNtuy%22%7D Redis 3.0 由上图可以看到，Redis从整体来看其实就是一个while死循环 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374while(true)&#123; //阻塞，直到被唤醒 //文件处理器 events = epoll_wait() //处理每一个事件 for(event: events)&#123; //这里的读事件是指 从网卡读 要拿取数据了 //这里的写事件是指 往网卡里写 要发送数据了 if(读事件)&#123; //从socket缓冲区拿出数据 readQueryFormClient() ; // while 循环处理 客户端缓冲区 只要构成一个完整的Redis协议命令 //在这也是pipeline机制实现原理 processInputBuffer(); //容易阻塞点!!! //1、检查命令合法性，参数合法性 //2、客户端是否认证，集群转向ask、moved //3、是否maxMemory，slave节点拒绝写命令 //4、订阅模式命令，发布模式命令 processCommand(); //1、执行命令 ---&gt; 执行结果放到输出缓冲区，然后注册可写事件 // 什么是可写事件：客户端tcp窗口没满，就是可写 //2、慢命令 --&gt; show log //3、propagate Command --&gt; feedAppendOnlyFile 把命令写入AOF缓冲区 // --&gt; rePlicationFeedSlave 把命令发送给从服务器 call() //epoll：水平触发，边缘触发。Redis这里属于水平触发 //epoll的坑 /** 水平模式：多次触发 边缘模式：一次没触发后就不会触发了 */ &#125; else if(写事件)&#123; /** 输出缓冲区： buf静态缓冲区，固定大小 replay动态缓冲区，大响应时用 */ //将输出缓冲区里的数据write回 客户端的socket（就是网卡缓冲区） //如果write出错了，就返回（如果tcp窗口满了） //如果缓冲区写完了，那么就卸载可写事件 sendReplyToClient() &#125; &#125; //时间处理器 severcorn(100ms); //低频处理 //每次循环都会执行，跟epoll_wait() 被唤醒的频率有关 beforeSleep()&#125;severcorn()&#123; watch dog 机制 更新信息 时钟 内存峰值 rss内存 关闭信号 客户端操作（超时，缓冲区） 清理过期件，渐进式hash （易阻塞）重写aof rdb 辅助性aof落盘 客户端异步关闭 主从操作 集群操作 sentinel操作 &#125;beforeSleep()&#123; 过期键清理 副本ack同步 （易阻塞）aof缓冲区落盘 集群维护 故障转移&#125; aof和rdb调用关系123456789101112131415161718192021222324252627// 客户端的命令lastsavesaveCommand -&gt; rdbSave()bgsaveCommand -&gt; rdbSaveBackground() -&gt; rdbSave()bgrewriteaofCommand -&gt; rewriteAppendOnlyFileBackground() fork子进程 -&gt; rewriteAppendOnlyFile() 读取内存数据到临时文件//低频调用serverCron()&#123; //如果 BGSAVE 和 BGREWRITEAOF 都没有在执行，并且有一个 BGREWRITEAOF 在等待 if (server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1 &amp;&amp; server.aof_rewrite_scheduled) &#123; rewriteAppendOnlyFileBackground(); //手动触发才会走到这里来 &#125; if (server.rdb_child_pid != -1 || server.aof_child_pid != -1)&#123; backgroundSaveDoneHandler() // backgroundRewriteDoneHandler() &#125;else&#123; //BGSAVE 和 BGREWRITEAOF 都没有在执行 rdbSaveBackground() // save 60 10000 参数格式,及默认 rewriteAppendOnlyFileBackground() &#125;&#125;//高频调用beforeSleep()&#123; //aof刷盘 flushAppendOnlyFile(0); //server.aof_buf 写到文件&#125; aofaof包含刷盘和重写两大块 aof 流程及刷盘每执行一个redis写命令，会存到aof缓冲区。然后在文件事件结束后，依赖** beforeSleep()** 函数执行写入动作。 写命令 -&gt; aof 缓冲区 -&gt; write数据 -&gt; 刷盘策略 flushAppendOnlyFile() 函数被 beforeSleep() 函数高频调用，每次调用都会调用 write函数（主线程执行），然后根据策略刷盘。 aof_fsync 的含义，每次都会调用write函数，但是刷盘时机可以配置 always 模式，也可能丢失数据，而且高频的调用 aof_fsync 会导致redis吞吐量下降。 PS：为什么高频调用会导致Redis，因为always模式下flush是在主线程，而不是跟everysec一样是异步线程 everysec 模式下，数据丢失风险 不止1秒！若刷盘上次刷盘不及时，或者文件事件执行过长（高并发时，且有阻塞性的大key导致） no 依赖操作系统刷盘 思考：如果设置的刷盘策略为每秒，为什么write数据还是在主线程，而刷盘在异步线程。为什么不把write也放到异步线程呢？ :::color41.write是轻量级的，就是将用户态的数据拷贝到page cache，而flush需要等到IO事件结束，耗时长，更适合异步化 2.write的时候涉及 aof_buf，如果是异步的话，在多线程情况下，就需要引入锁机制 ::: 重写aof流程为什么 手动 自动重写aof时机:::color4此时没有进行rdb和重写aof（判断是否存在子进程） aof当前体积 &gt; 最小重写阈值 配置了自动重写百分比，且现在的体积 较于上次aof体积 增长率 大于 配置的值 ::: aof重写逻辑流程:::color4 fork 一个子进程 ，记录fork子进程时间，关闭字典rehash子进程： 1.关闭网络连接 2.创建临时文件名 tempfile &#x3D; temp-rewriteaof-bg-%d.aof**** ，这里就是相当于在内存里创建了一个字符串 3.创建临时文件temp-rewriteaof-%d.aof 4.遍历所有db,写入键值对以及过期信息 5.temp-rewriteaof-%d aof 原子改名为 temp-rewriteaof-bg-%d.aof 6.unlink temp0-rewriteaof-%d.aof &#x2F;&#x2F;unlink：删除文件名 file1.txt。 将 inode 的链接计数器减 1，变为 1。 7.向父进程发送退出信号 在n个循环后子进程执行完毕，打开temp-rewrite-bg-%d aof 遍历aof重写缓冲区，数据追加到 temp-rewrite-bg-%d.aof 打开appendonl.aof，temp-rewrite-bg-%d.aof 改名为 appendonly.aof 更新Server aof_filename 等于tmpfile的 fd引用，并刷盘 异步关闭旧的aof文件fd ::: 伪代码： if(xxx &#x3D; fork() &#x3D;&#x3D; 0){ } else{ &#x2F;&#x2F;关闭网络连接 } 整个过程中会有三个文件 appendonly.aof temp-rewrite-bg-%d aof temp-rewrite-%d aof Redis异步线程rewriteAppendOnlyFileBackground() -&gt; bioCreateBackgroundJob() redis3.0 使用异步线程的地方： 1，异步刷盘（ fsync） 2，重写aof时，异步关闭文件 版本 关键异步任务 技术实现 演进意义 Redis 3.0 AOF持久化（fsync） bioCreateBackgroundJob创建后台线程 首次引入多线程，解决fsync阻塞主线程问题 Redis 4.0 大Key异步删除、数据库清空（UNLINK&#x2F;FLUSHDB ASYNC） 独立BIO线程池（3个线程：关闭文件、AOF刷盘、惰性删除） 主线程与耗时操作解耦，提升稳定性 Redis 6.0 网络I&#x2F;O读写、协议解析 I&#x2F;O线程组（可配置数量） 网络吞吐提升300%，单节点性能突破20W QPS Redis 7.0 RDB生成、AOF重写、集群任务分发 动态线程池（负载自适应） 优化后台任务并行性，减少尾延迟65% Redis 7.4+ 哈希字段过期、向量数据处理（AI优化） 字段级异步过期线程 rdb流程自动处理的默认配置 save xx xx save xx xx save xx xx 只要满足了以上一个就触发 1，记录开始的时间，fork子进程 子进程： 1，关闭网络fd 2，创建临时文件 temp-%d.rdb 3，遍历16个db的所有数据，写入到临时文件，刷盘并关闭fd 4，把临时文件重命名为dump.rdb 5，向父进程发送信号 2，计算fork所花时间，记录子进程id，关闭自动rehash 3，在n个循环后，收到子进程信号，更新一些信息 4，处理正在等待 BGSAVE 完成的那些 slave cow 和 forkcow内存计算逻辑1个g，fork子进程之后 子进程和父进程同一块物理内存，总内存还是一个g，父进程还会写 1g内存 –&gt; fork 子进程后，因为共享 还是1g内存 –&gt; 父进程修改一遍 全部内存后 父进程持有1g内存 –&gt; 子进程修改一遍 全部内存后 子进程持有1g内存 1 + 1 + 1&#x3D;3? 但好像不是 共享内存都很小了 fork的内存计算问题 fork阻塞问题主进程fork子进程本身也是有延迟的。父进程fork 超过5g内存，会有一定延迟，超过200ms fork性能问题堪忧LostPigxx 很好奇一点，fork对开源redis可以说是阿喀琉斯之踵了，我看antirez在twitter上也说尽可能的利用sharding来规避这个问题。从技术上真的没办法解决fork的影响吗？ 2020-12-24 logoV5 其实解决fork影响是os内核要做的，甚至os内核认为这点影响是理所当然，在它看来未必要做啥优化。而使用者是应该认识到并避免它的。Redis之所以无法避免，还是因为它本身是个缓存，又想做持久化。 2020-12-24","path":"2025/09/07/Redis/源码/AOF 和 RDB/","date":"09-07","excerpt":"","tags":[]},{"title":"点赞","text":"抖音的首页点赞是离线的吗","path":"2025/09/07/场景题/系统设计/点赞/","date":"09-07","excerpt":"","tags":[]},{"title":"系统设计","text":"","path":"2025/09/07/场景题/系统设计/","date":"09-07","excerpt":"","tags":[]},{"title":"源码","text":"1.单线程 2.aof 和 rdb","path":"2025/09/07/Redis/源码/","date":"09-07","excerpt":"","tags":[]},{"title":"虚拟线程","text":"为什么说他轻量级 :::color4因为像原来的platform thread创建时，需要在栈空间上分配1mb的内存，1000个线程就需要1g栈空间 而虚拟线程则不用 ::: 执行原理 :::color4当我们创建并且运行虚拟线程时，jvm后台会帮助我们去创建一个platform thread pool，且pool size&#x3D;Runtime.getAvailableCore 我们可以像创建普通Java对象一样创建虚拟线程，你可以把虚拟对象看做平台线程的普通版的。那他要如何执行呢，它会绑定到平台线程上。且一个平台线程只能绑定一个虚拟线程，当虚拟线程里的任务执行完时就会断开。 ::: 适用场景： :::color4IO阻塞任务！！！！ 为啥？阻塞时，虚拟线程会剥离平台线程，然后会生成堆栈快照。且它阻塞完重新被jvm bind到platform thread时会把原来的platform堆栈删掉，并且把之前剥离时产出的堆栈copy并加载到平台线程的堆栈，从而继续完成 最大的好处就是在IO任务避免浪费了cpu ::: 那如果一个虚拟线程阻塞后发现所有线程都被占用了，那会发生什么？ :::color4就继续等待，就这么简单 ::: 意义 :::color41.内存占用小 2.虚拟线程的开销比较小，因为只有mouting or unmouting。但平台线程的parking就会继续上下文切换，这就涉及到用户-&gt;内核-&gt;用户 ::: :::success在大多数现代 OS（比如 Linux）里，线程调度由内核完成，所以线程上下文切换通常伴随 用户态 ↔ 内核态 的切换。 上下文切换 (Context Switch) 指的是 CPU 从执行一个线程（或进程）切换到另一个线程（或进程）。 切换时需要保存和恢复很多内容，例如： 通用寄存器（eax、rbx…） 程序计数器（下一条要执行的指令地址） 栈指针 内存映射（页表信息，切换进程时才会变） 👉 换句话说，就是 CPU 不能“中途换人跑”，必须先把当前线程的“执行现场”保存好，再加载另一个线程的“执行现场”。 :::","path":"2025/09/06/JUC/虚拟线程/协程/虚拟线程/","date":"09-06","excerpt":"","tags":[]},{"title":"Excutor框架","text":"JDK1.5开始，开始将工作单元和工作机制分离开来，工作单元就是Runnable和Callable这种， 而具体工作由Excutor具体提供 在hotspot vm的线程模型中，用户线程和内核线程是一对一的 Excutor可以分为两个部分，一个是架构一个是其包含的组件 Excutor的结构 1.任务：执行的任务需要实现的接口：Runnable（无返回值）和Callable（有返回值） 2.任务的执行：任务执行的core interface：Excutor接口，以及继承于这个接口的ExcutorService接口。 ExcutorService接口有两个非常重要的实现类，ThreadPoolExcutor和ScheduleThreadPoolExcutor 3.异步计算的结果：包括接口Future和实现接口Future的FutureTask类 Executor框架的成员： - ThreadPoolExecutor - ScheduledThreadPoolExecutor - Future接口 - Runnable接口和Callable接口 Runnable、Callable、Future、RunnableFuture、FutureTask、CompletableFuture： Runnable：只有一个void run()方法，Thread实现了这个接口，所以创建Thread的时候实现这个接口，然后thread.start()就能创建一个线程执行run()，或者往Thread构造方法中传入Runnable的一个实现类。 Callable：有返回值的call()方法 Future：接口，异步获取任务结果 RunnableFuture：接口，其实就相当于异步的Runnable **FutureTask：RunnableFuture的实现类。内部其实内聚了一个Callable，即使你用第二个构造方法传入Runnable，也会包装成Callable！所以其实就相当于异步的Runnable和Callable（适配器模式），里面的run方法就是执行Callable的call()！其线程安全通过CAS保证 ** CompletableFuture：实现了Future接口，提供了许多更为强大的功能，使用：Java CompletableFuture ScheduleThreadPoolExcutor 构造方法和普通线程池一样，或者使用Executors.newScheduledThreadPool(int coreSize) 核心方法： 延迟执行一次：schedule(Runnable command, long delay,TimeUnit unit) 固定频率执行：scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)，首次在initialDelay后执行，之后每隔period时间执行一次。如果任务时间超过周期，会等待上次执行完毕 固定延迟执行：scheduleWithFixedDelay(Runnable command, long initialDelay, long period, TimeUnit unit)，和上面类似，但每次计算是上次任务结束后开始计算延迟","path":"2025/09/06/JUC/Excutor框架/","date":"09-06","excerpt":"","tags":[]},{"title":"为什么kafka 2.8 要抛弃zk","text":"1.运维问题 原生部署zk需要强制部署 zk，这使得kafka运维人员需要同时具备运维zk和kafka的能力 2.为了保证可用性 原生kafka与zk交互是依赖单个broker即Controller，如果旧broker故障了，会选举出一个 新的Controller节点。新的Controller继任成功，会从zk上拉取元数据同步初始化，同时通知其他broker更新 新的ActiveControllerID。且旧broker需要关闭监听、事件处理线程和定时任务。这个过程如果partition特别多， 那么就会导致整个过程非常漫长，且这个过程kafka是无法处理消息的，处于不可用状态 3.分区瓶颈 当分区数增加时，&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Zookeeper&lt;/font&gt;保存的元数据变多，&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Zookeeper&lt;/font&gt;集群压力变大，达到一定级别后，监听延迟增加， 给&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Kafaka&lt;/font&gt;的工作带来了影响。所以，&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Kafka&lt;/font&gt;单集群承载的分区数量是一个瓶颈。而这又恰恰是一些业务场景需要 的。 升级 &lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;KIP-500&lt;/font&gt;用&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Quorum Controller&lt;/font&gt;代替之前的&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Controller&lt;/font&gt;，&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Quorum&lt;/font&gt;中每个&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Controller&lt;/font&gt;节点都会保存所有 元数据，通过&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;KRaft&lt;/font&gt;协议保证副本的一致性。这样即使&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Quorum Controller&lt;/font&gt;节点出故障了，新的&lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;Controlle&lt;/font&gt; &lt;font style=&quot;color:rgb(10, 191, 91);background-color:rgb(243, 245, 249);&quot;&gt;r&lt;/font&gt;迁移也会非常快。 即由单个Controller变成了多个Controller，即由独裁变为了议会制 升级kafka后，官方说轻松支持百万partition","path":"2025/09/06/kafka/为什么kafka 2.8 要抛弃zk/","date":"09-06","excerpt":"","tags":[]},{"title":"Kafka的生产数据的流程 ？ACK应答机制 ？","text":"早期kafka集群是由zk来保证，我们公司也是，后面kafka更新了，不需要zk了 早期版本：Consumer靠zk来保存offset，而producer不与zk打交道 生产数据的流程早期版本： 1. producer需要找到集群，并把那个数据放到某个分区中。而这个leader端口号和分区存在zk中，集群和zk一直处于连接状态，partition的leader端口号回由集群去拿出，然后producer会向集群拿到topic对应的partition以及partition的leader信息 2. &lt;font style=&quot;color:rgb(85, 85, 85);background-color:rgb(253, 253, 253);&quot;&gt;当Producer通过Sender从集群获取到partition和Leader信息，若&lt;/font&gt;**&lt;font style=&quot;color:rgb(85, 85, 85);background-color:rgb(253, 253, 253);&quot;&gt;有指定partition则使用指定的partition&lt;/font&gt;**&lt;font style=&quot;color:rgb(85, 85, 85);background-color:rgb(253, 253, 253);&quot;&gt;，若没有则使用分区算法对key做操作；当没有key则轮询partition；&lt;/font&gt; 3. producer会先把数据存入DQ中，每一个partition一个DQ，就是一种消息聚合的方式，sender会轮询，队列满了或者到达一定的时间周期，就会发送给leader。 Producer给Leader发数据使用批处理，如果没有批处理每次发送都建立连接在进程间做交互，会使效率很低 4. leader将数据写入本地的log日志分段 5. 后续Consumer轮询从broker拉取消息，Kafka的ACK应答机制（producer，三种，0,1,2 ）； 三种ACK模式： 当取值为0，则不关心是否到达，尽最大努力交付，效率高，数据可能丢失； 取值为1（默认），Producer的发送数据，需要等待Leader的应答才能发生下一条，不关心Follower是否接收成功，性能稍慢，数据较安全，但当Leader突然宕机，则当Follower还未同步，数据会丢失； 取值为 -1（all） ，Producer发送数据，需要等待ISR内的所有副本（leader和所有Follower）都完成备份，最安全，性能差；需要等待follower一定时间后拉取数据，也就是这个”一定时间”是其效率的主要影响 ![](/images/a27e7ae381e0c5a8aefe7ee4d84f556c.png) 详细流程sender方法：","path":"2025/09/06/kafka/Kafka的生产数据的流程 ？ACK应答机制 ？/","date":"09-06","excerpt":"","tags":[]},{"title":"kafka写入机制","text":"1.producer会将数据push到broker上，每条消息会被追加到topic下的一个partition里的log文件里的末 尾，保证分区有序性，且会顺序写入磁盘 2.为了不让log文件过大，kafka还采用了分区分段存储，即log体积达到了某个阈值，就会生成新的log文件， 后面来的消息会追加到新的文件里 3.文件结构 一个topic里有多个partition，partition内有多个segement，一个segement包括三个文件index，log， timeIndex partition就是一个文件夹，属于物理概念。命名规则为 topic + 分区号 如 first-1 而segement也是个逻辑概念 index，log文件命名为 segement里第一条消息的offset","path":"2025/09/06/kafka/kafka写入机制/","date":"09-06","excerpt":"","tags":[]},{"title":"Kafka为什么读写效率高（高吞吐） ？","text":"首先kafka是分布式集群，吞吐量大。天生分布式，随便加机器 零拷贝这里的零拷贝是对于应用层而言 我们要将磁盘的数据发送到远端的服务器去，一般的应用做法是 0.调用系统函数read，切换为内核态 1.先将数据从磁盘拷贝到page cache 2.然后切换到**用户态，**将数据拷贝到应用层 3.切换为内核态，调用write,将数据写入page cache 4.最后将page cache 拷贝到网卡 缓冲区 5.切换为用户态，继续程序的运行 这其中需要经过四次拷贝，四次用户内核态切换 而对于sendFile的零拷贝 **数据不需要再拷贝到应用层，而是由内核态全程负责，让数据从磁盘拷贝到内核缓存，然后直接发给NIC ** 网卡缓冲区，且用户态内核态也只需要切换两次 PS：DMA 顺序写磁盘page cache预热写page cache分段日志Leader将文件切分为多个segement，好处就是让 IO更快 Topic→partition→segment index、log以当前segement的第一条消息的offset命名，以便可以快速查找 log里面存的是消息，而index里存的是offset和其对应的 物理偏移 Kafka消息（存储）格式及索引组织方式 - 杭州.Mark - 博客园 双端队列与批处理在producer这边，每一个partition在其producer都会对应着一个DQ 1.producer发送数据时都会往这个DQ里存消息 2.DQ满了或者一定的时间周期到了，producer就会拿出里面的消息，send到broker的Leader里。这即满足了 partition里消息的有序性，还提高了效率性 但消息聚合会降低一定的实时性 而Consumer这边也是一样，先拉取一批数据到本地的DQ里，然后消费 压缩：给的字符串，会被压缩成byte数组，压缩后数据小，传输快","path":"2025/09/06/kafka/Kafka为什么读写效率高（高吞吐） ？/","date":"09-06","excerpt":"","tags":[]},{"title":"kafka副本","text":"提供可靠性支持，每个partition都会其replication。broker会从这些里面选举其Leader和follower。 Leader和follower其实都是副本 producer和Consumer只会和 Leader交互 Leader会将数据同步到follower，如果Leader主动push数据，这时候会让Leader负载过大，故这时候 应该让follower主动定时去pull数据","path":"2025/09/06/kafka/kafka副本/","date":"09-06","excerpt":"","tags":[]},{"title":"架构","text":"Kafka集群的目的是保存消息，Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉去指定Topic的消息，生产者把数据以K、V的方式传给集群； 首先Kafka需要多台机器组成一个Kafka集群才能承载负荷，每一台服务器是一个Broker， 数据有多种进行分类 → 一个Broker中有Topic主题 为了提高负载 → 一个Topic有多个partition分区，一个partition可以放在多个不同的Broker上，而数据放在不同的partition当中（取模的方式），可以让不同的消费者来消费，提高消费速率 为了防止数据丢失 → 每个分区下有多个副本，即Leader和Follower，Leader做io处理，Follower只作备份，多个分区进行“交叉备份”，Follower从Leader中实时同步数据，当Leader挂掉后，Follower会代替Leader。 以【消费者组】为单位进行读取数据，其中一个消费者读取一个partition分区，所以一般partition分区数量&#x3D;消费者组中的Consumer消费者数量，以保证分区内数据有序； Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。 Kafka -&gt; Broker -&gt; Topic -&gt; partition -&gt; Replication(Leader、Follower) -&gt;Consumer 1）Producer ：消息生产者，就是向 kafka broker中的Topic主题发消息的客户端； 2）Consumer ：消息消费者，向 kafka broker中的Topic中 取消息的客户端； 3）Consumer Group （CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。 所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。 4）Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。 一个 broker可以容纳多个topic。 5）Topic ：可以理解为一个队列，生产者和消费者面向的都是一个 topic；topic逻辑上的概念，partition是物理上的概念； 6）Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列；partition中的每条消息都会被分配一个有序的id（offset） 7）Replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失， 且kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。 8）leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 leader。 9）follower：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 follower。 10）Offset：偏移量， kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。 当然the first offset就是00000000000.kafka。","path":"2025/09/06/kafka/架构/","date":"09-06","excerpt":"","tags":[]},{"title":"消息队列的两种模式 ？","text":"点到点 同一条消息只会被一个消费者消费 发布订阅一个消费者可以被多个消费者消费","path":"2025/09/06/kafka/消息队列的两种模式 ？/","date":"09-06","excerpt":"","tags":[]},{"title":"为什么用Kafka （使用消息队列的好处）？","text":"异步解耦，削峰 还有就是风险转移","path":"2025/09/06/kafka/为什么用Kafka （使用消息队列的好处）？/","date":"09-06","excerpt":"","tags":[]},{"title":"kafka消息的可靠性","text":"生产者ACK+记录消息失败重试send（msg,callback） 再callback进行处理失败的消息的持久化，然后开定时任务重试 保证msg到达 broker 本质其实就是记了再发，先记日志再发送 副本同步+落盘机制unclean.leader.election.enable &#x3D; false，保证所有副本同步。 同时broker开启 同步刷盘，直接写入磁盘，而不是写入 page cache 消费者 Consume可靠消费+重试机制开启手动ACK，拉取到本地的消息成功消费后，再提交ACK 设置 enable.auto.commit 为 false kafka broker端，消息被消费后，不会立马被删除，而是定时删除，所以要保证Consumer消费成功手 动ACK 为什么不是直接生产者端到消费者端的可靠性？","path":"2025/09/06/kafka/kafka消息的可靠性/","date":"09-06","excerpt":"","tags":[]},{"title":"Kafka 事务","text":"Kafka 的事务机制，就是让 Producer 往 多个分区 &#x2F; 多个 Topic 写消息时，看起来像一个“数据库事务”： 要么这批写入全部生效（commit） 要么这批写入全部作废（abort） 不会出现“写了一半”的中间状态被 Consumer 看到。 这个事务是对外表现的事务 Producer 事务为了是实现跨会话跨partition的事务，这时候需要引入一个事务协调者，将PID（producer ID）与Transition关联起来。这样重启的时候，就不会重新分配新的PID，而是通过正在进行的TransitionId 获取原来的 PID。 还有就是，事务协调者会将事务状态写入一个 topic里，这样的话即使整个服务重启，事务的状态也会得到保存，从而得到延续 整个流程 1234producer.beginTransaction();producer.send(record_to_order);producer.send(record_to_stock);producer.commitTransaction(); // or abortTransaction() 这时候会先开启事务 如果producer全部写入，事务协调者就会往事务topic里写入一个maker消息 如果producer写一半宕机了，因为我们是会设置事务超时时间，且broker和producer之间会有心跳，如果 broker收不到producer的心跳包了，那么就会写入一个abort消息 Consumer 事务Consumer的事务就比较弱， 无法保证commit的消息被准确地消费","path":"2025/09/06/kafka/Kafka 事务/","date":"09-06","excerpt":"","tags":[]},{"title":"Kafka 幂等性","text":"producer的幂等性是指 消息发送到broker，只会在broker被持久化一次，不丢不重 kafka原生机制只能保证在同一个会话的同一个topic下的同一个partition下保证不重 PS：同一个会话是指 Producer 启动 → 和 Broker 建立连接 → 发送消息 → 关闭（或挂掉）。 如果这时候宕机后重启，是否无法保证新消息与旧消息的唯一性的 原理 :::color4producer会在内存维护一个seqNum，broker端会针对一个producor维护一个 lastSeq 如果msg &gt; seqNumseq，则判断不重 :::","path":"2025/09/06/kafka/Kafka 幂等性/","date":"09-06","excerpt":"","tags":[]},{"title":"概念","text":"agentagent：代理，指代表他人行事的人。前两年，AI工具的功能还局限于问答形式：我抛出一个问题，AI告诉我怎么做，我自己去做。 如今，AI工具的功能已经进化成为：我抛出一个问题，并提出要求，AI代替我去做。 这就切合了agent（代理）这个单词的含义，所以此类 能够代替用户完成任务的工具 就叫做AI agent。 由于这种工具比起早期开发的产品更加智能，于是agent又有了一种称呼：智能体 promatSystem prompt 系统提醒词，比如 假设你是我的女朋友 user prompt 即 query rag是为了解决当上下文太长时， function call使用工具时与ai大模型通信的协议 一般是一个json数组 最终流程 mcp与agent tools 通信的协议 意图识别ai游戏助手架构","path":"2025/09/03/ai 应用相关/概念/","date":"09-03","excerpt":"","tags":[]},{"title":"Kafka 消息数据积压，Kafka 消费能力不足怎么处理？","text":"提高partition数量，同时提高 consumer数量，**两者缺一不可，**如果缺一不可，则 consumer 处理消息不及时导致的，增加拉取消息批数的大小，或者多线程方式消费消息，当然这建立在你消费可以忽略顺序性","path":"2025/09/03/kafka/Kafka 消息数据积压，Kafka 消费能力不足怎么处理？/","date":"09-03","excerpt":"","tags":[]},{"title":"关于kafka的partition","text":"** 同一个时刻**一个 partition 只能分配给一个 consumer ，但consumer可以同时负责多个partition。我们在实 际应用时，应该做到一个consumer尽量一个partition 分区数据量不均衡项目中给kafka的一个topic下划分了四个partition，但实际压测的时候发现数据倾斜严重，有时候数据全在一 个partition上。解决方案即send时 要指定 key，kafka会根据key + 某种算法如hash，去决定消息落在哪个 partition上 PS: 不指定 key,应该是对应的 hash 值，取模到对应的分区上。 spring-integration-kafka：在使用spring-integration-kafka做消费者的时候，发现CPU和内存占用量占用非常的大，后来又发现不管生产者发送了多少数据，Kafka的Topic中一直没有数据，这时候才知道spring-integration-kafka会将Topic中的数据全拉到本地，缓存起来，等待后续的处理。 解决方法： [xml] 123&lt;int:channel id=&quot;inputFromKafka&quot;&gt;&lt;int:queue capacity=&quot;25&quot;/&gt; --这里加个配置，相当于缓存多少数据到本地&lt;/int:channel&gt; 死循环消费（消费者位移提交失败导致数据一直重复消费）kafka客户端在消费时会先拉一批数据到本地来，然后等这批数据消费完成后，会提交offset，然后partition 会被分配给别的从consumer。当时的情况是consumer消费能力不行，无法在规定时间内消费完成，自动提 交了offset，导致这批数据继续被别的消费者消费，从而导致重复消费 解决方案： 1.自动改手动 2.调参","path":"2025/09/03/kafka/关于kafka的partition/","date":"09-03","excerpt":"","tags":[]},{"title":"熔断设计","text":"Relience4j框架熔断功能， 三个状态，关闭 -&gt; 开 -&gt; 半开 百分比熔断策略：支持基于百分比的熔断策略，提供更精细的控制。 三态控制机制： a. 关闭状态：允许所有请求通过。 b. 打开状态：拒绝所有请求，直到熔断时间到期。 c. 半开状态：允许一定量的请求通过，用于评估上游服务是否恢复。 静默数机制：引入静默数概念，防止少量请求触发状态切换。只有当请求数量达到静默数且失败率达到阈值时，才会切换至打开状态。 状态切换流程 关闭到打开：当请求数量达到静默数且失败率超过阈值时，熔断器切换至打开状态。 打开到半开：熔断时间到期后，切换至半开状态。 半开到关闭：在半开状态下，若放行的请求数量达到配置值且上游服务恢复正常，则切换至关闭状态；若失败率仍高或无响应，则切换回打开状态。 错误率是基于 滑动窗口进行统计的 Resilience4j熔断器-使用与源码解析 - 是胖虎捏 - 博客园","path":"2025/09/03/项目/自研网关/网关弹力设计/熔断设计/","date":"09-03","excerpt":"","tags":[]},{"title":"降级","text":"降级的定义就是当资源不足和访问量大发生矛盾时，我们需要丢弃一些东西，来让系统平稳运行 我们降级需要丢弃的东西： 1.降低一致性 2.停止次要功能 3.简化功能 降低一致性我们要明白世界上大多数系统是不需要一般来说，会有两种做法，一种是简化流程的一致性，一种是降低数据的一致性。 简化流程秒杀，将支付这个步骤后置化，即秒杀结束了再通知用户支付 降低数据一致性缓存","path":"2025/09/03/项目/自研网关/网关弹力设计/降级/","date":"09-03","excerpt":"","tags":[]},{"title":"弹力设计篇之“限流设计”","text":"保护系统不会在过载的情况下出问题 限流的策略限流的目的是通过对并发访问进行限速，相关的策略一般是，一旦达到限制的速率，那么就会触发相应 的限流行为 限流之后触发的行为有： 1.拒绝 2.降级 3.特权处理 4.延迟处理 5.弹性伸缩，这里如果流量过大，服务抗不住了，这时候就需要去加机器，需要一个自动化的发布、部署和 服务注册的运维系统 限流的方式计数器最简单粗暴的 队列方式但这种方式process得用 pull的方式，不然队列过长，没满，processor就先挂掉了 queue的配置是一个学问来着 漏斗算法 Leaky Bucket 水溢出了就触发限流，这种算法下 处理请求是非常平滑的 实现一般都是通过一个队列来实现，请求多了，队列开始积压请求，超过长度就拒绝请求。 像tcp的流量控制就是这么来的，当请求过多时，会有一个sync backlog队列来缓冲请求，滑动 窗口其实也是 代码： 1 令牌桶算法 Token Bucket这个算法相当于有个中间人，我们请求要过得去，得去这个中间人拿Token。然后会在一个桶内按照一定的 速率放入一些 token。这种设计可以在流量少时攒钱，流量大时快速处理 如果 Processor 是瓶颈（慢的业务逻辑处理器），算法对总吞吐量影响不大，因为 Processor 才是限 制。 如果 Processor 很快（像 Nginx），算法就决定了请求转发节奏：漏斗稳、令牌桶能爆发。 代码： 1 基于响应时间的动态限流以上算法有个不好的点，就是得去设置一个上限值，这个一般都是我们通过压测得到 虽然我们网关可以做到接口级别的限流，但为每一个api去配置，管理起来其实是很麻烦的 而且，现在的服务都是能自动化伸缩的，不同大小的集群的性能也不一样，所以，在自动化伸缩的情况下，我们要动态地调整限流的阈值，这点太难做到了。 那有没有一种能自动根据系统情况进行限流的算法呢 :::color4这种方式，不再设定一个特定的流控值，而是能够动态地感知系统的压力来自动化地限流 这方面设计的典范是 TCP 协议的拥塞控制的算法。 它的是通过RTT 来探测网络的延时和性能，从而确定滑动窗口的大小，我们完全可以参考它的设计 结合计网中学到tcp的一些知识，当时一开始想到就是 ::: 系统自适应限流 基于错误率，且采样基数要大 限流设计要点限流目的： 向用户承弱SLA，高并发下保证可用性 保护服务不崩 在多租户的模式下，保证重要的租户仍然可用 节约成本，我们不会为了一个不常见的尖峰来把我们的系统扩容到最大的尺寸 网关TODO： 0.手动开关 1.head上加上标识，让后端知道发生了限流，后端可以根据这个标识决定是否做降级 2.对于监控，监控应该立马感知到，运维能持续跟进 3.网关性能必须好 荣耀：APIX单机 -&gt; 分布式限流一步步 优化方案单机限流第一阶段： 只是单机，如果后端网关节点是动态变化的，就不符合需求 第二阶段 我们可以引入一个第三方比如 配置中心ETCD，NACOS，来管理我们的限流总量 性能优化： 开一个特权进程来进行ETCD从拉取网关信息，同时避免APISIX本身的开销 特权进程写入共享内存，进程间共享网关信息数据 第三阶段 APISIX 在荣耀海量业务下的网关实践 | Apache APISIX® – Cloud-Native API Gateway and AI Gateway 分布式限流在应用开源分布式限流方案时，我们遇到了以下关键问题： Redis 性能瓶颈：单 key 限流场景下，当限流规则针对整个路由而非路由特征时，Redis 的 key 会过于单一，导致所有请求集中到同一个 Redis 分片，无法通过横向扩容实现负载均衡。 网络性能消耗：频繁的 Redis 请求导致网关节点 CPU 使用率上升 50%+。 请求时延增加：开源分布式限流方案需先访问 Redis 完成计数，再将请求转发至上游，导致业务请求时延增加 2-3 毫秒。 Click to Preview 优化方案 为解决上述问题，我们设计了以下优化方案： Click to Preview 引入本地计数缓存： a. 本地计数机制：请求到达时，首先在本地计数缓存中扣除一个计数。只要计数未降至 0，请求即被放通。 b. 异步同步机制：本地计数通过异步方式定期与 Redis 同步，统计两次同步期间的请求量，并在 Redis 中扣除相应的计数。同步完成后，Redis 的计数覆盖本地缓存，确保分布式限流的一致性。 误差控制：通过合理的公式计算和参数配置，将误差率控制在 3%-4% 的范围内，确保限流精度满足业务需求。 适用场景 高 QPS 应用：该方案适用于 QPS 较大的应用，能够显著降低 Redis 的性能瓶颈和网络开销。 低 QPS 应用：对于 QPS 较低（如几百 QPS）的应用，现有的分布式限流方案已基本满足需求，无需额外优化。","path":"2025/09/02/项目/自研网关/网关弹力设计/弹力设计篇之“限流设计”/","date":"09-02","excerpt":"","tags":[]},{"title":"“服务的状态”","text":"什么是服务的状态即我们会在业务服务里保存一些本地数据即本地缓存，游戏服务端就是典型的状态服务 ServerLess一直以来，无状态的服务被当成分布式服务设计的最佳实践和铁律。因为无状态的服务对于扩展性和运维实在是太方便了。没有状态的服务，可以随意地增加和减少结点，同样可以随意地搬迁。而且，无状态的服务可以大幅度降低代码的复杂度以及 Bug 数，因为没有状态，所以也没有明显的“副作用”。 有状态的服务 Stateful 题外话游戏有状态服务器如何做到伸缩自如，这不得不提到我实习的youzu公司用到的akka框架了","path":"2025/09/02/项目/自研网关/网关弹力设计/“服务的状态”/","date":"09-02","excerpt":"","tags":[]},{"title":"幂等性设计","text":"幂等性：一次和多次请求某一个资源应该具有同样的副作用 为什么会有幂等性问题？上游重试导致的，下游得做好幂等 幂等分为请求幂等和业务幂等，业务幂等是人为定义的，这种东西没有讨论性 全局IDID由谁来分配是个问题？ 分配中心？那么每一次交易都需要找那个中心系统来。 这样增加了程序的性能开销。还是上游？上游的话就可能出来重复ID，因为它一般是个集群，每台机器都承担相同的功能 还有就是我们需要一些不冲突的算法 UUID，是个字符串，占用空间大，索引的效率非常低，生成的 ID 太过于随机，完全不是人读的，而且 没有递增，如果要按前后顺序排序的话，基本不可能 雪花算法的生成原理，生成的东西是一个 long类型的数 41bit 为毫秒数 5bit为数组中心ID（需用用户配置） 5bit为机器ID（需要用户配置） 12bits 作为毫秒内的序列号。一毫秒可以生成 4096 个序号。 123456789101112131415import cn.hutool.core.lang.Snowflake;import cn.hutool.core.util.IdUtil;public class Test &#123; public static void main(String[] args) &#123; // datacenterId = 1, workerId = 1 Snowflake snowflake = IdUtil.getSnowflake(1, 1); for (int i = 0; i &lt; 10; i++) &#123; long id = snowflake.nextId(); System.out.println(id); &#125; &#125;&#125; 幂等性处理流程一锁二判三通过 or 通过mysql 的 insert，update，但其实归结到底它其实还是 一锁二判三通过，因为update会做上行锁 但我们希望我们有一个标准的方式来做这个事，所以，最好还是用一个 ID。 因为我们的幂等性服务也是分布式的，所以，需要这个存储也是共享的。这样每个服务就变成没有状态 的了。但是，这个存储就成了一个非常关键的依赖，其扩展性和可用性也成了非常关键的指标。 HTTP 的幂等性幂等：get,head,delete,put（创建or更新，URL是一样，故为幂等） 不幂等：post 防止表单提交重复性做法 1.表单提交时提交一个Token，这个Token可以是前端生成好携带过来的，然后做下校验Token是否之前就存 在了。用于防止用户多次点击了表单提交按钮，而导致后端收到了多次请求，却不能分辨是否是重复的 提交。我觉得这应该是产品设计 2.前端按钮做好置灰 3.更稳妥的做法是，后端成功后向前端返回302状态码跳转，把用户的post请求变成get请求，把刚才post的 东西展示出来。如果是web的话，就把刚才的提交页面置为过期，防止回退，这种模式叫做PRG模式","path":"2025/09/02/项目/自研网关/网关弹力设计/幂等性设计/","date":"09-02","excerpt":"","tags":[]},{"title":"写MQ的Consumer时会考虑哪些点?","text":"kafka 手动ack死循环！！！！！","path":"2025/08/31/kafka/写MQ的Consumer时会考虑哪些点/","date":"08-31","excerpt":"","tags":[]},{"title":"异步通讯设计","text":"前面所说的隔离设计通常都需要对系统做解耦设计，而把一个单体系统解耦，不单单是把业务功能拆分出来，正如上面所说，拆分完后还会面对很多的问题。其中一个重要的问题就是这些系统间的通讯。 通讯一般来说分同步和异步两种。同步通讯就像打电话，需要实时响应，而异步通讯就像发邮件，不需要马上回复。各有千秋，我们很难说谁比谁好。但是在面对超高吐吞量的场景下，异步处理就比同步处理有比较大的优势了，这就好像一个人不可能同时接打很多电话，但是他可以同时接收很多的电子邮件一样。 异步不一定是多线程！！！，如akka的信箱，它异步可以把消息重新发到自己的信箱，但还是单线程的 但异步也不是完全的好，时延还是不如同步的 但同步有以下问题的 同步调用需要被调用方的吞吐不低于调用方的吞吐。否则会导致被调用方因为性能不足而拖死调用方。换句话说，整个同步调用链的性能会由最慢的那个服务所决定，发送方会被接收方限制死。 同步调用会导致调用方一直在等待被调用方完成，如果一层接一层地同步调用下去，所有的参与方会有相同的等待时间。这会非常消耗调用方的资源（因为调用方需要保存现场（Context）等待远端返回，所以对于并发比较高的场景来说，这样的等待可能会极度消耗资源）。还是那句话，发送方会被接收方限制死 接受发崩了，发送方也得跟着崩 很难做到一对多，跟打电话一样，注意不是微信电话 狗头 所以，异步比同步好的原因，除了提高调用方的吞吐量，最大的一个好处是其可以让服务间的解耦更为彻底，系统的调用方和被调用方可以按照自己的速率而不是步调一致，从而可以更好地保护系统，让系统更有弹力 异步通信几种方式请求响应式这种模式下，调用方直接请求被调用方，然后被调用方回复—收到，正在处理 一般分为两种模式，一种是调用方去轮询询问干没干哦。还有一种是调用方写个回调方法，然后被 调用方处理好请求后通过这个方法回调，游戏支付领域就是这么干的，支付完成后支付中台会回调 游戏服务端，前端回调的这个http &#x2F; rpc 接口游戏服务端会交给支付中台。 但以上两种还是会有一定耦合的 订阅方式pub&#x2F;sub，各个服务之间依靠事件交互，但接收方还是依赖于发送方 服务肯定是无状态好，运维会方便很多 broker模式即消息中间件 这种模式就做到了发送和接受完全解耦 但你broker要做到三高，高性能，高可靠，高可用 事件驱动架构订阅和broker其实都是事件驱动架构 正如前面所说，事件驱动最好是使用 Broker 方式，服务间通过交换消息来完成交流和整个流程的驱 动。 例如： 好处就是 运维测试很容易，故障不容易扩散，服务治理比较容易，吞吐量互不影响 但任何技术都有它不好的一面 可观察性变差了 :::color4ps：NIO&#x2F;Epoll + Eventloop 本身就是事件驱动的设计 ::: 总结首先为什么要有异步通信 异步通信需要注意哪些地方 好了，我们来总结一下今天分享的主要内容。首先，同步调用有四点问题：影响吞吐量、消耗系统资 源、只能一对一，以及有多米诺骨牌效应。于是，我们想用异步调用来避免该问题。异步调用有三种 方式：请求响应、直接订阅和中间人订阅。最后，我介绍了事件驱动设计的特点和异步通讯设计的重点","path":"2025/08/31/项目/自研网关/网关弹力设计/异步通讯设计/","date":"08-31","excerpt":"","tags":[]},{"title":"隔离","text":"如同船舱隔离 对于系统的分离有两种方式，一种是以服务的种类来做分离，一种是以用户来做分离 以服务做隔离，多种业务从接入到应用到持久化层都做隔离，且做到物理上的隔离，如商品，评,论….。这也是现在微服务的常规做法，但这样有个问题，性能会降低，因为你查询可能涉及到多个服务的调用，在网络中转增多了，这里的性能指的是时延，而不是吞吐量，这种场景下吞吐量其实是会增加。对于这样的问题，一般来说，我们需要小心地设计用户交互，最好不要让用户在一个页面上获得所有的数据。对于目前的手机端上来说，因为手机屏幕尺寸比较小，所以，也不可能在一个屏幕页上展示太多的内容。以及还有跨业务板块请求链路中单点故障导致整条链路走不下去问题，跨板块交换复杂的问题（引入消息中间件，且该中间件可pub&#x2F;sub，持久化）,分布式事务问题（在亚马逊中，使用的是 Plan – Reserve – Commit&#x2F;Cancel 模式） 12345678910用户请求资源 │ Plan ──&gt; 检查可用性 │ Reserve ──&gt; 临时锁定资源 │ ┌───┴──────┐Commit Cancel │ │资源最终占用 资源释放回滚 可见，隔离了的系统在具体的业务场景中还是有很多问题的，是需要我们小心和处理的。对此，我们不 可掉以轻心。根据我的经验，这样的系统通常会引入大量的异步处理模型。 用户隔离，即多租户 三种方式，但没有绝对，一般是这种。服务共享，数据独立，若比较重要的客户就做到完全独立 然而，在虚拟化技术非常成熟的今天，我们完全可以使用“完全独立”（完全隔离）的方案，通过底层 的虚拟化技术（Hypervisor 的技术，如 KVM，或是 Linux Container 的技术，如 Docker）来实现物 理资源的共享和成本的节约。 :::color4ps：docker它是内核空间共享，但用户空间隔离，容器里安装的只是操作系统的一部分即用户空间，内核空间还是宿主机的 :::","path":"2025/08/31/项目/自研网关/网关弹力设计/隔离/","date":"08-31","excerpt":"","tags":[]},{"title":"弹力是什么，为什么需要弹力","text":"提高可用性，降低MTT（故障修复时间）。故障分为有计划，无计划，故障是无法避免，我们只能把处理故障的代码融入架构里面 弹力，简单地说就是能上能下","path":"2025/08/31/项目/自研网关/网关弹力设计/弹力是什么，为什么需要弹力/","date":"08-31","excerpt":"","tags":[]},{"title":"建造者","text":"创建型设计模式，就是造模型 为什么需要创建型模式？ 就是规范设置属性，其实写代码久了自己会有这种意识，不写光学感受不到，初学者一定要先学一遍，用不用先不说，一定要知道，等觉得需要规范了，重新学一遍就通了。没办法如果不是天才，一定会经历shi山代码 另外builder这个词确实很贴合了，盖楼必须一层一层盖，强调了创建对象赋值过程中的有序性","path":"2025/08/31/设计模式/常规/建造者/","date":"08-31","excerpt":"","tags":[]},{"title":"什么是序列化？什么是持久化？","text":"","path":"2025/08/31/JavaSE/什么是序列化？什么是持久化？/","date":"08-31","excerpt":"","tags":[]},{"title":"DMA","text":"DMA解放了CPU 有 DMA 时（现代网络发送） DMA（Direct Memory Access） &#x3D; 让外设（网卡）直接访问内存，不需要 CPU 一直搬数据。 流程是： 用户调用 send() → 数据先拷贝到 内核 socket buffer。 内核告诉网卡：”这段内存的数据你自己去拿”。 网卡用 DMA 控制器，直接从内核缓冲区读取数据到网卡缓冲区。 CPU 空出来干别的活。 👉 CPU 只做控制，不做“苦力”搬运工。 没有 DMA 时（早期方式）如果没有 DMA，CPU 就得亲自当“苦力”： 用户调用 send()，数据进入内核缓冲区。 CPU 一点点把内核缓冲区的数据拷贝到网卡的寄存器&#x2F;缓冲区。 网卡再把数据发出去。 问题： CPU 必须忙着不断“搬运字节”，效率很低。 数据传输过程中 CPU 不能干别的事，性能瓶颈严重。 吞吐量大时，CPU 可能光搬数据就耗光了算力。","path":"2025/08/31/操作系统/DMA/","date":"08-31","excerpt":"","tags":[]},{"title":"零拷贝（zero copy）与Linux内核","text":"如今网络应用已经从cpu密集型转成了I&#x2F;0密集型，你CRUD是没有啥cpu消耗的，唯一瓶颈就是多线程，切来 切去的消耗 CS（客户端服务器），BS（浏览器服务器）。BS就是一种特殊的架构 计算机存储器最低端是与cpu同频的寄存器 容量大，速度快，价格便宜三者无法同时满足 1.第一层寄存器 作用：让 CPU 快速访问和处理数据，避免频繁访问速度较慢的内存，是 CPU 执行指令的核心中转站 2.第二层高速缓存 3.主存 4.磁盘 5.物理内存 6.虚拟内存 没有什么是加一层中间件不能解决，如果有那就再加一层，这是计算机领域几乎真理的话 虚拟内存正是此话的又一个重要实践 操作系统32位操作系统，2的32次方，寻址也就只有4GB啊，那你怎么用上8GB的呢 应用程序是不能直接操作物理内存，都是操作虚拟内存，而虚拟内存有一张映射表，它可能映射到磁盘or内 存，这个就不得而知了 7.MMU（内存管理单元） 作用就是管映射到哪去 如果使用虚拟内存技术的话，cpu则会把这些虚拟内存地址通过地址总线送到内存管理单元MMU，MMU 再将虚拟内存地址转成 物理地址之后再通过内存总线访问物理内存 8.用户态和内核态 Linux安全的一个原因就是区分用户态和内核态，硬件只能内核态来操作，即调操作系统函数委托内核来 帮你干事 在资源和用户做了隔离，你碰不到就是安全的 Linux I&#x2F;O1.IO缓冲区 脏不是说数据有问题，只是说没落盘 刷flush了就不脏dity了。只要不是批量写，都有卡的问题 一般数据丢失，都是没刷盘就断电了 2.传统I&#x2F;O读写模式 Linux的系统模式 read，write 3.zero 拷贝 指cpu不需要先将数据从某个内存复制到另外一个特定区域，这种技术通常用于通过网络传输文件时节省cpu 周期和内存带宽，即不用倒腾数据到用户态了 **3.1 mmap（memory map） ** map就是个映射 用对象，一种是深拷贝（产生新的对象），一种是浅拷贝（用的还是同一个对象） mmap就是一种浅拷贝 这种方式是zero 拷贝较为简单的实现方式，通过调用Linux的系统函数mmap()替换原先的read() 不用拷贝到内存，直接在内核里面倒腾 两步走：先mmap 再 write，但还是4次切换 以上是老版本的Linux 3.2 sendfile() 这里的就做得更到底了，sendfile()就相当于把mmap 和 write合成了一个内核函数，这么做的好处就是少了 两次切换，因为原来是调两函数，调完后还得切回去继续调另外一个 kafka就是用sendfile来实现零拷贝，rocketmq还是用的mmap :::color4零拷贝，零拷贝，其实还得是拷贝的，只是不用拷贝到用户态了，直接在内核态里拷贝，对于用户态是无感知的 ::: 总结零拷贝 约等于 对象浅拷贝，直接返回引用映射","path":"2025/08/31/操作系统/零拷贝（zero copy）与Linux内核/","date":"08-31","excerpt":"","tags":[]},{"title":"如何保证消息不丢","text":"其实就只有一种，重试。我们不能保证100%不丢，还有不可能完全依靠中间件的可靠性。 kafka有哪些丢消息的场景？分别怎么处理 1.发消息可能会丢，失败重试 2.broker落盘可能丢，落盘默认是靠系统机制落盘，消息一开始是写入page cache。想要不丢那就配置 为立马刷盘，但性能就比较差 3.消费丢失，手动ack，一条条确认，但手动ack其实会有死循环，依靠人的功底","path":"2025/08/31/kafka/如何保证消息不丢/","date":"08-31","excerpt":"","tags":[]},{"title":"流程","text":"","path":"2025/08/30/项目/自研网关/面试/流程/","date":"08-30","excerpt":"","tags":[]},{"title":"claude code使用技巧","text":"结合cc router 配置免费api，启动 ccr code 命令行 &#x2F;init","path":"2025/08/30/claude code使用技巧/","date":"08-30","excerpt":"","tags":[]},{"title":"三级缓存","text":"caffeine &#x3D;&#x3D;&#x3D;》 Redis &#x3D;&#x3D;》 mysql 如何提高缓存命中率？ 客户端需要使用一致性hash算法来进行负载均衡，保证同一请求能落到同一结点上 缓存的预加载，比如说发现本地缓存快过期了，就去Redis里拉取数如何发现过期？主动（定时器） or 被动（依靠每次请求的检查）需要商酌还有就是并不是全部加载，而是有选择性地加载，捞取热点数据","path":"2025/08/30/Redis/三级缓存/","date":"08-30","excerpt":"","tags":[]},{"title":"压测","text":"locusthttps://blog.csdn.net/liuyunshengsir/article/details/145907880 压测记录 100 - 10 123456789101112131415162025-08-31 03:55:00.474 WARN io.netty.channel.DefaultChannelPipeline :1152 default-netty-worker-nio-3-57 An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.java.net.SocketException: Connection reset at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:394) at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:426) at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253) at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133) at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:833) 2000 - 200","path":"2025/08/29/项目/自研网关/压测/","date":"08-29","excerpt":"","tags":[]},{"title":"三种限流","text":"滑动窗口漏桶令牌桶","path":"2025/08/27/三种限流/","date":"08-27","excerpt":"","tags":[]},{"title":"原理","text":"ps：broker 其实就是Server consumerpull方式拉取数据，不同于Rabbitmq的push producertopicpartition发送到哪个partition是由producer的partitioner的算法决定的，eg: Round storage internals","path":"2025/08/17/kafka/原理/","date":"08-17","excerpt":"","tags":[]},{"title":"面经","text":"网关整体流程 1.介绍一个项目?(网关) a.有没有做竞品调研? b.异步为什么要比同步好? c.返回的请求和你发出的请求如何对应起来的? d.如果又来新的请求，会怎样? 流量控制如何实现的? f.对比三种限流适用场景? g.对请求的时延要求高，用什么限流? h。网关如果是集群，如果在A网关上被限流，B网关上没被限流，怎么办? :::color4分布式限流 ::: i.每次请求都往Redis写一次?有没有优化的点? :::color4 分层限流（局部 + 全局） 本地缓存限流（Guava RateLimiter &#x2F; TokenBucket）：先在网关节点做一层粗限流，绝大多数请求直接被挡掉，不打到 Redis。 全局限流（Redis&#x2F;集群协调）：只对热点请求或临界流量再走 Redis 做精确限流。👉 好处：减少 Redis 压力，避免所有请求都打到 Redis。 批量请求 Redis（滑动窗口优化） 不是每次请求都 Redis INCR，而是 按时间片&#x2F;批量更新： 节点本地计数（比如 100 次请求）先累计。 达到阈值后再批量写 Redis（或者定时刷新）。👉 这样 Redis 访问量从 QPS 级别 降到 QPS&#x2F;100 级别。 令牌预分发（Token 分片） Redis 维护一个全局桶（比如 10w 个 token&#x2F;min）。 每个网关节点定时从 Redis 拉取一部分 token（比如 A 拉 3w，B 拉 2w）。 请求来了就只消耗本地 token，没 token 才拒绝。👉 好处：请求不需要实时访问 Redis，性能最好。👉 缺点：会有一定“不均衡”，但整体不会超全局限流。 总结： 1.对于令牌桶就是一次拿一批，然后缓存到本机，减少网络传输 2.只对热点请求or 临界流量 做Redis限流 ::: j.怎么能让一个请求永远都访问一个节点? 做这个之前有没有做竞品调研? Netty在哪个阶段?什么作用? 为什么用Netty? 只用Netty的HTTP协议，为什么不用Tomcat这些? Netty如何保持长链接? 哪个框架有用到Netty? 链接如何保活的? 你的网关和大厂可用网关对比缺少什么? 用你的网关有多少性能损耗? 一般网关是什么结构? a.rpc如何做泛化调用? b.设计5qps-500wqps的限流器，如何做? c.令牌桶怎么设置?分布式场景下怎么填充令牌? 字节火山暑期一面挑一个熟悉的项目介绍?(网关) :::info ::: 里面的限流、均衡、重试熔断是你自己做的吗? :::info都是有自己的实现 ::: 滑动窗口怎么实现的 :::info双端队列，存时间戳。 来的时候先剔除当前时间点之前的请求时间戳 存队列，先判断是否满了上限，满了就返回一个429的HTTP状态码 ::: i.颗粒度多大? :::info可配的。 配置是三级，nacos动态，文本静态，代码写死 ::: ii.窗口存在哪里? :::infojvm堆内存 ::: 1.存在内存里，那么如果有多台机器的话，怎么做? :::info如果网关集群，如何对下游，单体架构的网关，无状态的集群，发ping。网关搭建集群 网关的理念是不与第三方产生依赖 ::: 不依赖其它外部依赖是为了解决什么问题?为什么这么想? :::info为了更为纯粹，带来繁重的一个复杂度 ::: 令牌桶如何做的? :::info ::: e.一致性哈希算法?解决了什么问题? :::info hash环 数据结构TreeMap，大于等于它的下一个节点。 我们动态增删实例，它影响的范围是可控的。 如果比较好的话，分布比较均衡，加虚拟节点 ::: f.随机、轮询、一致性哈希，哪个更好些? :::info得看具体的需求 但我们比较少或者实际用得比较多，就是像基于最小连接数，或者说基于cpu，这些下游服务的指标么 ::: 某些请求响应时间长，有些短，混着来的，用哪种负载均衡策略更合适? :::info盲目的，不是提前告知的。 那我觉得就我那三种估计是无法满足了吧，就之前我在dubbo官网看到它们有个最短响应优先 + 加权随机，我觉得那个算法应该比较适合这种场景 ::: h.熔断的流程? :::info其实整个包括像是重试，熔断，降级这一块的功能，其实我就是刚刚说的，我其实是用了reforjava这个框架么。然后我选的是 forjava这个框架，它核心在于这个框架的理念，其实是基于一种修饰者模式的一种包装思想，比如说他可以把一串lambda表达式，然后这个lambda表达式其实就是我们调用后端请求，然后后端请求回来，然后回到我们这个网关之后再进行一些回应的处理，这一块其实是一块代码么。然后其实就是可以把这一代码封装程一个lambda表达式。我们的那个框架就是可以对这个lambda表达式进行封装，最底层包装一层重试，如果里面失败的话就会重试。然后再包装一层我们的一个熔断，如果我们重试多少次之后，我们就等于对后端这个请求进行熔断，然后下一次再进行同一次请求会有一个标识的东西，然后同一次再发起请求的时候，他等于说就不允许你再执行这个lambda表达式了。 然后我引入这个框架的原因，主要是因为它并没有像Redis那种需要我去连，它本质其实是对我们代码的一种封装么，它其实是框架而不是中间层，所以说我引入这个来简化我们的一个开发流程 ::: i.知道Netty的内存池算法吗? :::info做通信，应该怎么去做快速分配，这对性能其实有挺大影响的，因为你高并发请求，来的时候得分配内存么 ::: j.解释下NIO? :::info两种含义，一种是Java，一种是操作系统的，它们可能是两个不一样的概念。然后像Java的NIO这种，它其实指的就是操作系统的IO多路复用这种东西 这个东西其实是依赖于操作系统的底层实现的，它就是说可以实现一个线程监听多个请求，然后它的具体落地也是有多种，像Linux这边就有select，poll，epoll这些。 Redis同样也是应用了 ::: k.读写线程怎么和监听线程分开的? :::infoboss线程，worker线程。 ::: 字节火山暑期二面1.介绍下网关? :::info这个项目就是我简历上的一个网关项目么，然后这个项目的话，其实就是我自己从0到1搭建的一个底层的一个所谓的轮子项目，然后这个项目其实就是我做多了，可能做多了，市面上那些教学项目，或者说那些业务项目，然后我就想着自己去搭建这个项目， 然后在做这个网关项目之前，我就做过一些市面上的网关的调查或者说我给自己网关下一个定义以及理念，为什么我要自己实现一个网关而不是说去学习市面上已有的网关， 然后包括我调查了市面上已有的一些网关然后做了对比之后给我自己的网关下的一个理念， 就是一个轻量级，高吞吐的网关， 还有就是不跟外部服务不产生过多依赖的就是或除了服务发现外， 不跟其他中间件以及其他的一些框架比如spring产生依赖， 还有就是对上游的请求是没有要求，就是说你不需要在HTTP请求头里添加特殊字段，你只要正常的HTTP请求就行了，以及我希望我的网关下游的服务对我的网关是没有感知的， 就是说你下游的服务只要把你这个服务注册到你的注册中心或者说我们的一个服务发现平台上也不需要感知到我的网关，我就可以直接调用到你。这几个就是我在做网关之前给我的网关下的几个定义么。 ::: a.和别人一起做的吗? b.只和服务发现产生依赖?如何做到这点的? :::info 如何做到这点 首先就是一个服务发现平台的选择么，就是现在市面上开源的服务发现组件很多，像etcd，zookeeper，nacos这些。然后我之所以选择nacos主要是因为nacos既是注册中心也是配置中心，还有就是社区活跃度也是很高的，后续开发中如果遇到一些bug能得到一些反馈之类的。nacos它的动态配置更新功能也是满足我们下游服务配置信息发生变更，网关就能感知到这么个功能的。然后这个就是我们的服务发现平台的选项 然后像是使用的话，网关这一块因为我们没有依赖spring那一套，所以得去引入nacos客户端原始的jar包。然后当时也是参考了官网文档的实例来进行代码编写。下游后端服务那一块，其实就是只需要把自己注册到nacos上面就好了 ::: c.请求如何发送的? :::info这个的话就是需要暴露出我们的网关的一个IP地址，就是以我目前的一个架构来说，就是肯定是直接访问我们的网关因为我网关启动，其实它是以netty的形式启动的么，然后启动之后，它进程就是会被分配一个IP Port。然后这时候我们对他这个IP Port发送我们的HTTP请求，然后这里面我会用netty它自带的一个解码器，因为默认的话，其实是指当时只提供了HTTP的一个实现。 因为目前我们这个网关是一个单体的架构，然后如果扩展成集群的话，可能又是不一样的请求方式了 然后整体的话就是这样子 客户端直连，要按后端接口请求方式，请求 ::: d.为了不和其他服务产生依赖，肯定对依赖做了收口吧，做了哪些处理呢? :::info ::: e.路由是怎么做到的，谓词匹配?灰度怎么做的? :::info这个主要是参考了springcloudgateway它那套的做法，比如配置文件或者说配置中心的一个大json，然后这个这个文件里有一个routes，里面就存着后端服务一个个接口的路由信息。就是请求来的时候我们会把路由配置的URL转成正则表达式进行匹配，如果匹配不到就返回404。如果匹配到多个，我当时是有对这些路由提供一个Order配置，就优先按order最大的返回，如果出现那种比如api&#x2F;service和api&#x2F;**这种就优先走url最长的。 灰度的话我当时设计的时候一开始是想着把它和负载均衡放在一起，但后面想了想感觉这样耦合度有点高了，所以就是说把灰度放在了负载均衡前面，那么就是请求过来的时候，根据灰度策略决定是否走，然后根据负载均衡从后面挑一个节点出来。然后灰度的实现的话我自己默认提供了两种，一种是根据客户的IP，以及根据灰度流量，就是实例集合里有10%的灰度实例，那就有10%的概率会走灰度 ::: f.信号量隔离和线程池隔离是什么?两者的顺序? :::info信号量隔离就是说我们可以对我们的后端服务进行一个信号的隔离，就是它要请求到我们的后端，就得去拿到我们的信息，拿到了才能往后走，如果拿不到就相当于被限流了，其实是说为了保护后端服务端的一种措施 而线程池隔离其实是说对于我们的后端服务，它其实前面是有一个线程池的，然后请求过来的时候会丢给线程池进行处理，然后这个时候就是能保证每个请求它是分开来的。 顺序的话自己是有默认的，但这是可配置的，就交给用户去配置 ::: g.有限流后为什么还要隔离? :::info我觉得隔离的重点在于那个资源的隔离，就是你某一个点执行不会拖垮到整个服务 ::: h.有限流后，什么情况下还需要信号量隔离? :::info可能那种那种sass平台 ::: 蚂蚁暑期一面12.网关是你公司实习的项目还是自己做的项目? :::info自己做的 ::: 13.网关最难的点? :::info我觉得是有这个想法吧，就是说，有的人可能只是感觉跟网上的一些学习业务项目可能就满足了。然后可能说我最开始这个东西好像很高端或者说能不能行，其实他，你会发信啊感觉好像也没有那么难的样子，我觉得有这个想法才是最难的 ，然后真正实际开发过程中，它其实是属于另外一种层次的难，那种难度的话，它其实是你可以通过去网络上寻找方案或者求助来解决，但是想法上的改变我觉得是比较难以去改变的 ::: 14:网关最需要关注的点? :::info它的高可用或者高性能，就架构层面，网关不崩，性能比较好，大概是这样子 ::: 15.如何保证网关高可用、高性能? :::info在做这个网关之前，我其实就给自己的网关下了几个定义或者说下了几个目标，然后在整个开发过程中，我都遵循了这个目标首先的话，它其实就是说给自己的一个目标就是我要实现高性能的一个网关所以说在技术选择这一块，我使用的是netty和aysnchttpClient的网关，实现了一个全异步链接的请求，这两个框架就在Java网络编程这一块就是属于很出名的，第一梯队的那种，而且开源社区也是比较活跃。 然后测试下来，就我自己在我自己电脑上起了这helloworld的一个springboot服务，然后通过我们的网关去转发请求打到这个服务。测下来吞吐量也是在2w左右，还有就是我还用了springGateway进行一个对比，它的话就是大概才1w出头 对于高可用方面，其实我之前想的就是要不要让我这个网关去支持一个集群，然后导致说提高它的一个高可用指标，后面我想了一次，我就暂时把这个想法搁置了。因为我觉得我们如果网关要搞集群来实现它的高可用的话，它其实是要实现网关之间互相通信，然后我在客户端那边他其实要做一个网关元数据的存储或者负载均衡，它就是说要对客户端做一些改造。然后我之前，给我网关下的要求或者说定义的话，其实是我希望我对上游服务没有要求，对下游服务没有依赖这样子。 然后我也实际的功能实现中也做了其他方面的高可用，当后端出了问题后，我网关会对它进行一些熔断，就是从后端下游这个层次来提高我们这个高可用的架构。 ::: 16.后端服务响应时间太长，但没挂，如何处理的? :::info这个的话就是我这个项目里用的那个HttpClient里有个参数，可以设置超过多久响应时间就失败了。然后我其实在网关的弹性架构层面用了那个resencefjava这个框架，然后我的重试，熔断，降级这些策略都是基于这个框架去做的，里面也是有些参数可以我们去配置的。然后假设重试了3次还是超时，我们还是会对它进行熔断，过了多少秒之后，会再次尝试是否真挂了，如果成功那就取消熔断，失败了那就继续熔断 ::: 17.如果请求在网关挤压，会怎么办? :::info额我觉得就是另外一个请求，就是如何做限流，进行一些限流的规则，比如用滑动窗口，就让它的请求就是平滑化。 ::: 18.网关如果要集群化，如何做? :::info我觉得有两个方案吧，一种就是引入一些分布式协议之类的，然后实现各个网关之间的通信，这个可能改造起来就比较复杂，就如果是那种抛离出来，就像是mysql或者Redis那种集群部署方案。 然后就是在客户端层面做负载均衡，类似与那个memcache那种架构，客户端会从注册中心拿到网关的元数据，然后在客户端那一层面做网关的负载均衡，来实现高可用，这个的话我觉得就得给客户端一个SDK，但这种客户端就得感知到网关了 两种方案就各有缺点吧 ::: 客户端不做改造，有没有可以实现的方案? :::info我觉得得再引入一层来做吧 像是比如说用DNS来做，把我们的网关节点都搬到DNS上面，然后配个域名，然后基于DNS这些来搞，然后可用这方面就转移给第三方了， ::: 蚂蚁暑期二面 挑一个项目介绍(网关) :::info那我还是说先讲我自己做的一个项目，就先不讲实习吧。因为我觉得他是我自己去说，从0到1搭建的一个这么一个网关的项目。也是比较偏底层，就轮子项目，不是外面那种额外卖之类的业务项目。而是我自己去开发打底层的一个项目。然后的话就是我在首先在技术选项上，我是使用了netty。就是作为我们的一个网关的一个主题的一个处理流程，因为其实说白了，还是跟网络打交道比较大，然后在Java领域的话，netty也算是最出名的框架，开源社区活跃也是非常OK的 然后我在这个网关之前，我给自己下的一个理念，就是我的网关尽量要做到轻量级，就是说除了我的服务发现这个应用后，我不应该跟其他的应用产生依赖，但是服务发现他肯定就是一个必须的一个东西么，就是我往往如果发现下游的这些服务，这是一个要求，然后还有一个要求，我希望对上游的请求是没有依赖的，就上游过来的请求是通用的HTTP请求，不会去请求头里面添加一些特殊的字段。然后我也希望我的网关对下游，它下游对我的网关其实是无感知的。 你只需要正常的去说启动你的这个服务。然后把你注册到我们的一个服务发现平台上，那我就可以直接调用我，我们的网关就可以直接调用这个服务。它其实根本不需要知道我们的网关的。所以说，这是我在做网关之前给自己下的一个要求，然后我在之后的开发过程中也是一直希望能够遵循这些要求，然后他的一个整体流程的话。。。。 ::: 能共享屏幕介绍吗?(开始个人吟唱) :::info….. ::: 后过滤有没有可以应用的点? :::info额我想想，我觉得那种跟内容合规有关的点可以在这里做，比如说我们网关后面对接的是AI大模型这一块，然后可能AI大模型它被用户的prompt去诱导生成一些涉黄的东西，我们就可以在这里做些敏感词检测之类的 得用户自定义 我了解你的意思，嗯嗯嗯明白 ::: 有没有做鉴权?鉴权是不是应该在过滤器前去做? :::info这个我有考虑去做他，但最后又没去做他的原因是因为我觉得鉴权比较难统一的了，可能下游我的支付和用户业务是两套不一样的鉴权，如果由网关来做，感觉就把下游限制死了，就可能说你下游给我返回什么字段之类的，比如说拿到一个用户，他是否属于我们的一个黑名单状态，那可能我需要用到下游的一些信息，这时候我的网关就跟下游产生了一个依赖么，我其实是不太想这么干的。 这个就交给用户去扩展 像加一个JWT，技术是比较容易，就是用工具类去生成一个JWT AES….. ::: 如何做并发?(网关做集群) :::info支持一个集群 ::: 网关如何实现幂等性? :::info我觉得得后端去处理吧，如果网关要实现的，那么他就得存储一些唯一标识来实现幂等，那我觉得它就变成有状态的了，就违背了我希望它是无状态的理念，扩缩容这方面就没那么灵活了。 关于有状态服务的扩缩容，游族实习那块接触到一点，其实游戏这边其实都是有状态的 ::: 有没有了解其它负载均衡策略? :::info就是那些基于业务的策略，像什么基于内存，基于最小连接数这些，就是基于后端机器load的一些指标做负载均衡么，就像dubbo的五种负载均衡类型有了解过。但是我觉得还是需要后端的一个支持，比如说后端上报我当前机器负载的指数，像cpu，内存使用率之类的，或者说Tomcat的连接数。 然后这些指标就是得有一个动态配置中心存储或者说去通知网关 ::: 网关有显著用到线程池的地方吗? :::info主要依赖框架吧，像netty的evenloop group之类的 ::: IO密集型的后端调用，延时很大，有怎样的解决思路? :::info它首先就是说我们的IO密集型太高了，然后我这边CPU没吃满么，我们这边load就没上去。然后这种情况的话，我觉得我们最直观的一个方案就是说加大我们的一个线程数量，就是把我们的入口扩大，让更多的请求进来，但当然这得看你机器的内存配置，线程new太多的话OOM了也不好。 还有就是利用compeletableFuture异步， 其实说白就是IO密集的线程占着茅坑（CPU核心）不拉屎，浪费我们的CPU，且因为线程会被阻塞住，新的请求过来就只能等待，吞吐量就下来了，如果扩大线程数又会被硬件条件给限制住，我觉得这种情况下协程或者说虚拟线程就比较适合了，因为它的话就内存占用很小就相比于线程的4mb，而且线程上下文切换成本约等于0，我们几乎可以无限扩大我们的线程数，直接通过升级JDK 升到21 ::: 项目做了多久? :::info我 9 月 8开始说，前置，调研一些网关，或者说常见的一些工具什么的，我觉得都是提前规划好的。 个人对我们所谓的一个Java领域或者说编程领域的一种感觉吧，就是我觉得我还是挺适合当程序员 的，挺喜欢coding的感觉的。 ::: 小红书日常a.做这个之前有没有做竞品调研? :::info嗯，比如说，Spring Cloud Gateway、Zuul 这些都是常见的网关，像 Nginx 也很常用。我想先说 Zuul，它老版本对异步响应支持不是很好，更偏向同步处理。 至于 Spring Cloud Gateway，我一开始以为它是轻量级的，但实际使用下来，感觉还是挺“重”的。我自己写了一个网关，也在同一个环境下对两个网关做了测试。结果我自己的网关吞吐量差不多 2 万，而 Spring Cloud Gateway 大概只有 1.1 万到 1.2 万左右，具体大概 1.177 万。 所以我觉得，我自己的网关在轻量化和高吞吐上更有优势，而我的目标就是做一个既轻量又高吞吐的网关 ::: b.Netty在哪个阶段?什么作用? :::info主要做服务端接受我们外部的一个请求。最基本的就是处理，然后它其实也是提供了很多工具，像协议转换 Netty 在网关中主要充当服务端的角色。它负责接收客户端发过来的请求，然后把这些请求处理成我们应用可以理解的形式。 具体来说，流程大概是这样的： 接收请求当一个请求到达网关时，Netty 会先接收到这个 TCP 层的数据。 编解码处理由于 TCP 本身是字节流，可能会出现“粘包”“拆包”或者大包问题，我们需要对原始数据进行编解码处理。Netty 提供了很多现成的编码器和解码器，比如 HTTP 编解码器，它可以把原始字节流转换成 HTTP 请求对象，方便我们在应用层进行处理。 自定义业务处理编解码完成后，我们可以在 Netty 的 pipeline 中添加自定义处理器（handler），对请求进行各种业务逻辑处理，比如路由转发、认证、限流等。 响应返回处理完请求后，Netty 会把响应对象再编码回字节流，通过 TCP 发送给客户端。 简单来说，Netty 就是网关和客户端之间的“网络桥梁”和“请求处理引擎”，它帮我们解决了底层网络通信、编解码、异步处理等问题。 ::: c.为什么用Netty? :::info这个主要是我当时给我网关下的定义就说尽可能高性能，因为网关作为我们后端服务的门户，网络通信这一块就是非常重要的么。在Java生态这一块，NIO的网络框架属于no1的就是netty，像可能mino那套虽然跟netty很像，但API易用性其实是没netty高的。 还有就是netty也提供了很多工具 ::: d.只用Netty的HTTP协议，为什么不用Tomcat这些? :::info我觉得，如果从零去写网络处理代码，其实没必要那么复杂。你用 Netty，主要是用它提供的 HTTP 能力 对吧？其实你也可以直接用 HTTP 协议，然后像用 Servlet 或者 RestTemplate 那样处理请求就行。 但 Netty 的优势在于，它底层帮我们处理了很多高性能细节，比如： 多路复用（减少线程开销，提高并发能力） 线程模型（worker 线程、事件循环等） 连接管理、超时控制 这些东西，如果自己去写，从零实现，不仅繁琐，而且容易出错。但 Netty 已经帮我们封装好了，而且参数都是可以灵活配置的：比如你可以调 worker 线程数、连接超时时间等等，非常方便。 实际上，你在 Netty 中只需要启动一个客户端或者服务端实例，它就能直接处理大部分底层细节。你只需要专注于业务逻辑，而不必去管 TCP 粘包、拆包、事件循环等复杂问题。 所以核心就是：Netty 省去了很多重复造轮子的工作，让我们专注于业务，而不是底层网络实现。 ::: e.Netty如何保持长链接? :::info ::: f.哪个框架有用到Netty? :::info像rocketmq，zuul2，什么的。很多主流的中间件网络通信这方面都有用到netty的 框架的话，我记得spring webflux也是有用到netty的 ::: g.链接如何保活的? :::info ::: 12345678910public static void writeBackResponse(GatewayContext context) &#123;FullHttpResponse httpResponse = ResponseHelper.buildHttpResponse(context.getResponse());// 保活 if (!context.isKeepAlive()) &#123; // 短连接 取消 就添加一个 监听器 context.getNettyCtx().writeAndFlush(httpResponse).addListener(ChannelFutureListener.CLOSE);&#125; else &#123; // 长连接 httpResponse.headers().set(HttpHeaderNames.CONNECTION, HttpHeaderValues.KEEP_ALIVE); context.getNettyCtx().writeAndFlush(httpResponse);&#125;&#125; 腾讯二面介绍一个项目?(网关) :::info ::: a.有没有做竞品调研? b.异步为什么要比同步好? :::info ::: c.返回的请求和你发出的请求如何对应起来的? :::info ::: d.如果又来新的请求，会怎样? 流量控制如何实现的? f.对比三种限流适用场景? :::info漏桶算法适合于下游需要平滑流量的场景，就是希望以一种恒定的速率去处理请求 而滑动窗口和令牌桶都适用于应对突发流量，就那种瞬间的流量，突刺流量 滑动窗口，如果是基础的滑动窗口因为是一个比较早的算法，不怎么用了，我觉得它应该适用于那种后端服务在一定时间内只能处理一定的请求 ::: g.对请求的时延要求高，用什么限流? :::info滑动窗口吧。我可以判断滑动窗口的大小来判断是否可以放行，如果请求满的话会直接返回，能有失败的反馈。 而漏桶的话，会先进入进入就绪队列里等待 对于令牌桶，嗯我觉得它应该和都一样，都是拿到令牌放行，拿不到就返回了 ::: h.网关如果是集群，如果在A网关上被限流，B网关上没被限流，怎么办? :::infoRedis ::: i.每次请求都往Redis写一次?有没有优化的点? :::info每次会写，网关会被Redis拖一下，从时间延迟来讲。 可以先把Redis的一批Token 拿到加载到本地 ::: j.怎么能让一个请求永远都访问一个节点? :::info就是我们负载均衡那层不能采用随机，轮询，权重这些。 ::: pdd暑期二面1.挑一个项目介绍(网关) :::info项目介绍 这个项目就是我简历上的一个网关项目么，然后这个项目的话，其实就是我自己从0到1搭建的一个底层的一个所谓的轮子项目，然后这个项目其实就是我做多了，可能做多了，市面上那些教学项目，或者说那些业务项目，然后我就想着自己去搭建这个项目， 然后在做这个网关项目之前，我就做过一些市面上的网关的调查或者说我给自己网关下一个定义以及理念，为什么我要自己实现一个网关而不是说去学习市面上已有的网关， 然后包括我调查了市面上已有的一些网关然后做了对比之后给我自己的网关下的一个理念， 就是一个轻量级，高吞吐的网关， 还有就是不跟外部服务不产生过多依赖的就是或除了服务发现外， 不跟其他中间件以及其他的一些框架比如spring产生依赖， 还有就是对上游的请求是没有要求，就是说你不需要在HTTP请求头里添加特殊字段，你只要正常的HTTP请求就行了，以及我希望我的网关下游的服务对我的网关是没有感知的， 就是说你下游的服务只要把你这个服务注册到你的注册中心或者说我们的一个服务发现平台上也不需要感知到我的网关，我就可以直接调用到你。这几个就是我在做网关之前给我的网关下的几个定义么。 看面试官反应。。。。。 面试官想问技术实现？ 技术实现（参考难点那里）： 首先是技术选型：netty，AsyncHTTPClient，为什么要选择。nacos， spi 过滤器，过滤器节点编排 具体过滤器节点实现 ::: a.做了多久? b.实现用到的框架?有用到spring框架吗? c.对并发流量如何处理的? d.有用到线程池吗? ·对线程池的理解? 淘天金融7.为什么写GraceGateway? a.有参考别人的代码吗? :::info有做些前置准备学下netty之类的，参考还是没有的 ::: b.网关用了哪些设计模式? :::info用的还是挺多的。像是工厂，单例。类似责任链 ::: c.有看过Tomcat源码吗? :::info ::: d.对比限流算法特点? :::info :::","path":"2025/08/17/项目/自研网关/面试/面经/","date":"08-17","excerpt":"","tags":[]},{"title":"旅游","text":"Japan travel target point：1 million ，cur process：4k，i hope me that i can achieve it in college 3 England Travel ： 4 million,i hope i can achieve it in college 4","path":"2025/08/17/旅游/","date":"08-17","excerpt":"","tags":[]},{"title":"kafka为什么这么快","text":"说他快，一般是说能高效地移动大数据，类似于管道，即高高吞吐量 两个点 1.顺序磁盘IO 写的是磁盘，kafka是不会写内存的。 kafka的每个partition其实就是一个文件，而topic其实是一个文件夹的名字，写数据都会写到每个partition的末尾 但这种方式有个缺点，就是没法删数据，kafka的所有数据都会保留下来，每个consumer对于同一个topic都会有一个offset去记录当前consumer读到了哪里 而这个offset是客户端SDK保存的，broker无感知 kafka提供了两种删除策略，一种是根据时间，一种是根据partition文件大小 2.零拷贝技术 常规拷贝 零拷贝，通过send file命令直接告诉cpu直接从os buffer里拷贝数据 3.从消息的角度来说，kafka用的是堆外内存，无GC，消息写入的是page cache 对于Linux来说，然后直接落盘 4.自动预热 怎么预热：从日志回放 用户的请求。 kafka会在预热的时候把队列里的消息加载到page cache里，但也怕启动的时候因为预热而变慢，这都是有参数配置的 5.分布式架构 分布式做得好的话，性能不好就加机器呗，无非就是成本问题 6.应用层面的优化 消息压缩，kafka支持gzip 或者 Snappy格式对消息进行压缩，减少网络传输的压力 批次写入，即聚合发送 假设网络带宽为10MB&#x2F;S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。 为啥要用Java写？ 最开始，应该是考虑多平台，内存安全等因素。当然也可能有跟着hadoop随大流走Java的成分。 但是实际上kfk已经有c++版本了。可以获得更好吞吐。那个应该是叫redpanda. 不过，由于go极大刺激了java社区，java社区正在奋力追赶相关特性。分代zgc,虚拟线程，堆外内存API,SIMD等特性基本都追齐了。下一个jdk lts应该就可以全部发布了。 对于目前兴起的用c go等重写中间件的行为，我建议我们可以进入观望期。再看看java的发展与社区的进度。实际上大量的中间件社区已经全面抛弃java8了，升级是大势所趋。","path":"2025/08/15/kafka/kafka为什么这么快/","date":"08-15","excerpt":"","tags":[]},{"title":"优化Redis","text":"具体可以参考其他优秀组件 aerospike 近几年来分布式缓存的组件层出不穷，但真要论一出来就轰动，性能秒杀Redis的也只有Dragonfly Dragonfly： :::color4是一种针对现代应用程序负荷需求而构建的内存数据库，完全兼容Redis和Memcached的 API，迁移时无需修改任何代码。相比于这些传统的内存数据库，Dragonfly提供了其25倍的吞吐量，高缓存命中率和低尾延迟，并且对于相同大小的工作负载运行资源最多可减少80%。 ::: dragonfly&#x2F;README.zh-CN.md at main · dragonflydb&#x2F;dragonfly 核心理念就是丢掉历史包袱，思考在2022我们会怎么去设计一款缓存数据库 base 1.无共享式架构，也就是每个线程都有自己的内存 2.重新设计hash表，一种高效的hash表：dash table https://github.com/dragonflydb/dragonfly/blob/main/docs/dashtable.md 3.多键并发操作的原子性保证 feature： - &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;针对TTL的高效记录过期功能。&lt;/font&gt; - &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;一种新颖的缓存驱逐算法，具有比其他缓存策略（如LRU和LFU）更高的命中率，同时&lt;/font&gt;**&lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;零内存开销&lt;/font&gt;**&lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;。&lt;/font&gt; - &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;一种新颖的无fork快照算法。&lt;/font&gt;","path":"2025/08/15/Redis/优化Redis/","date":"08-15","excerpt":"","tags":[]},{"title":"手写时间轮","text":"","path":"2025/08/15/手写系列/手写时间轮/","date":"08-15","excerpt":"","tags":[]},{"title":"手写IOC容器","text":"","path":"2025/08/15/手写系列/手写IOC容器/","date":"08-15","excerpt":"","tags":[]},{"title":"手写eventgroup","text":"","path":"2025/08/15/手写系列/手写eventgroup/","date":"08-15","excerpt":"","tags":[]},{"title":"手写线程池","text":"","path":"2025/08/15/手写系列/手写线程池/","date":"08-15","excerpt":"","tags":[]},{"title":"CountDownLatch","text":"同步辅助类，它允许一个或多个线程等待其他线程完成操作后再继续执行 - **核心理念：****计数器 + 阻塞** - **构造器：** CountDownLatch latch &#x3D; new CountDownLatch(int count); count &#x3D; 需要等待的事件数（或线程数） 使用：latch.await() 这时候线程就会park,并进入q，state++。countdown()：try state &#x3D;&#x3D; 0，里面有个 dorelease，就会for node: q, node即Thread，然后LockSuport.unpark() 底层原理： 还是基于AQS，可见AQS的抽象能力和通用性， 核心就是 计数器归零唤醒所有等待线程 常用场景 常用于我们的一些需要聚合数据的业务场景中，比如前端的一个页面需要多个组件的数据进行聚合，那么这时候就可以使用countDownLatch开多个线程 还有模拟高并发场景，同时唤醒多个请求任务，唤醒这个操作是比较轻量级的，虽然底层是for(T thread：q)但几乎能做到同时","path":"2025/08/15/JUC/CountDownLatch/","date":"08-15","excerpt":"","tags":[]},{"title":"信号量","text":"juc下的smphone计数信号量，用于控制同时访问某资源的线程数量，也就是限流 可用来实现限流 用法： Semaphore sp &#x3D; new Semaphore(&#x2F;&#x2F;可同时访问某资源的线程数量) sp.acquire() 就会 permits ++ sp.acquire() 就会 permits ++ 底层其实就是基于AQS实现的，跟ReentrantLock某种方面实现基本一致，只是计数器的实现不太一样","path":"2025/08/15/JUC/信号量/","date":"08-15","excerpt":"","tags":[]},{"title":"怎么背八股","text":"首先要明白一个技术点他是为了什么而诞生的，是用来干什么，怎么用 搞清楚以上三点，OK，开始理解它的实现原理，然后意淫它的业务场景，然后把它往下扩展和延伸到哪 然后背的时候，多反问xx的本质到底是什么，到底是个啥","path":"2025/08/14/and so on/怎么背八股/","date":"08-14","excerpt":"","tags":[]},{"title":"如何保证MQ消息不丢","text":"可能会说什么发不丢，存不丢，收不丢，这其实是片面的 真实场景没人会完全依靠中间件的机制来保证不丢，一般我们都是基于自己记了再发，即记日志然后再发消息 所以说记日志是一件很重要的事情 保证分布式一致性，其实说来说去就是 本地持久化，确认机制和重试机制 容错、分片","path":"2025/08/14/如何保证MQ消息不丢/","date":"08-14","excerpt":"","tags":[]},{"title":"issue模版","text":"好的，我给你一个简洁版英文优化建议 Issue 模板，但每一行我会加中文注释，方便你理解和复用。 1234567891011121314151617markdown复制编辑## Optimization Suggestion &lt;!-- 优化建议标题 --&gt;**Background** &lt;!-- 背景：简述遇到的问题或不便之处 --&gt;&lt;!-- e.g., Current API response time is slow when handling large datasets. --&gt;**Proposed Improvement** &lt;!-- 提议的优化方案：用简短的句子说明你的改进想法 --&gt;&lt;!-- e.g., Use batch processing instead of handling items one by one. --&gt;**Impact** &lt;!-- 影响范围：性能提升、可维护性、用户体验等 --&gt;&lt;!-- e.g., Improves performance and reduces server CPU usage. --&gt;**Additional Context (Optional)** &lt;!-- 额外信息（可选）：性能数据、参考链接、相关代码等 --&gt;&lt;!-- e.g., Related issue: #123, Benchmark shows ~20% improvement. --&gt; 这个模板特点： 短：四个核心字段，维护者能在 10 秒内看懂。 适合优化类 PR：没有多余字段，直接背景→方案→影响。 方便复制：可以直接粘到 GitHub Issue 描述里用。","path":"2025/08/13/开源相关/issue模版/","date":"08-13","excerpt":"","tags":[]},{"title":"给github开源项目提pr","text":"给开源项目提 PR 修 bug 的流程，其实就像“搬进别人家的房子帮忙修水管”，既要修好，还得符合人家的规矩。我给你分成 发现问题 → 修复代码 → 提交 PR → 跟进 四个阶段，顺便补上注意事项。 1️⃣ 发现问题 确认是 bug：先看看是不是自己环境问题、依赖版本问题。 搜索 issue：在项目的 Issues 里查一下有没有人提过同样问题。 有：可以在已有 issue 下留言，表明你也遇到，并且愿意修。 没有：新建一个 issue，简明描述问题、复现步骤、期望结果。 2️⃣ 修复代码 Fork 项目 在 GitHub&#x2F;GitLab 点击 Fork，把仓库复制到你自己的账号下。 Clone 到本地 12345bash复制编辑git clone https://github.com/你的账号/项目名.git 创建分支（不要在 main/master 上直接改） 12345bash复制编辑git checkout -b fix/xxx-bug 本地运行并复现 bug（确保能稳定复现，修的时候才能验证成功）。 修改代码（遵循项目的代码规范，比如缩进、命名、注释格式）。 写单元测试（能防止 bug 再次出现，维护者会很喜欢）。 本地跑测试（mvn test &#x2F; npm test &#x2F; pytest 等，看项目用什么工具）。 3️⃣ 提交 PR 提交修改 1234567bash复制编辑git add .git commit -m &quot;fix: 修复 xxx 导致的 xxx 问题&quot;git push origin fix/xxx-bug - commit 信息一般用英文描述，遵循项目 commit 规范（如 Conventional Commits）。 在 GitHub 发起 Pull Request 选择目标仓库的主分支作为 base，你的分支作为 compare。 在 PR 描述里写清： 问题背景 修复思路 测试结果截图（可选） 关联的 issue（比如 Closes #123 会自动关闭 issue） 注意 CI 检查：很多项目会自动跑代码检查、测试用例，不通过的话你需要再改。 4️⃣ 跟进与维护 维护者可能会 review：他们可能会提修改建议，你要及时回复并修改代码。 PR 合并后：可以在后续 release 中看到自己的贡献。 养成习惯：在你 fork 的项目里定期 git fetch upstream 同步源仓库代码。 💡 小技巧 别急着直接修，先看看项目的 CONTRIBUTING.md（贡献指南）和 CODE_OF_CONDUCT.md（行为规范）。 如果 bug 比较复杂，可以先发 issue 让维护者确认，避免白做。 先修小 bug、文档错别字，熟悉流程后再做大功能，容易建立信任。","path":"2025/08/13/开源相关/给github开源项目提pr/","date":"08-13","excerpt":"","tags":[]},{"title":"caffeine","text":"基本使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 @SneakyThrows public static void main(String[] args) &#123; Cache&lt;String, Integer&gt; cache = Caffeine.newBuilder() .maximumSize(1000) .recordStats()// .expireAfterWrite(5, TimeUnit.SECONDS)// .expireAfterAccess(2, TimeUnit.SECONDS) .expireAfter(new Expiry&lt;String, Integer&gt;() &#123; @Override public long expireAfterCreate(@NonNull String key, @NonNull Integer value, long currentTime) &#123; return currentTime; &#125; @Override public long expireAfterUpdate(@NonNull String key, @NonNull Integer value, long currentTime, @NonNegative long currentDuration) &#123; return currentDuration; &#125; @Override public long expireAfterRead(@NonNull String key, @NonNull Integer value, long currentTime, @NonNegative long currentDuration) &#123; return currentDuration; &#125; &#125;) .removalListener(new RemovalListener&lt;String, Integer&gt;() &#123; @Override public void onRemoval(@Nullable String key, @Nullable Integer value, @NonNull RemovalCause cause) &#123; System.out.println(&quot;移除了key：&quot; + key + &quot; value :&quot; + value + &quot; cause : &quot; + cause); &#125; &#125;) .build(); cache.put(&quot;cliffcw1&quot;, 1); System.out.println(cache.getIfPresent(&quot;cliffcw1&quot;)); //可变过期时间策略有没有提供，如果有，就put， cache.policy().expireVariably().ifPresent(policy -&gt; &#123; policy.put(&quot;cliffcw2&quot;, 2, 13, TimeUnit.SECONDS); policy.put(&quot;cliffcw3&quot;, 2, 10, TimeUnit.SECONDS); &#125;); System.out.println(&quot;cliffcw2:&quot; + cache.getIfPresent(&quot;cliffcw2&quot;)); Thread.sleep(11000); System.out.println(&quot;cliffcw22:&quot; + cache.getIfPresent(&quot;cliffcw2&quot;)); System.out.println(&quot;cliffcw3:&quot; + cache.getIfPresent(&quot;cliffcw3&quot;)); &#125;//删除是惰性删除 缺点用本地需要考虑的点 功能能满足，get，put，过期 不能OOM，内存管理 监控展示（肯定不能是黑盒，无提示性语句） 统计（热key，大key，命中率 ….） caffeine的缺点 功能基本满足，但多个业务场景，多种过期时间，不满足 只有key个数上限（不设置默认是）无法设置使用内存上限 解决： 给不同kv设置不同的过期时间 :::info其实是有的，只是隐藏得比较深 &#x2F;&#x2F; 可变过期时间策略没有提供，如果有，那就put。如果不可变那什么都没有 cache.policy().expireVariably().ifPresent( policy -&gt; { policy.put( xx,xx,xx,xx ) }) ::: 可以给内存设置上限 源码build()BoundedLocalManualCache 和 NoBoundedLocalManualCache 12345678BoundedLocalManualCache(Caffeine&lt;K, V&gt; builder, @Nullable CacheLoader&lt;? super K, V&gt; loader) &#123; cache = LocalCacheFactory.newBoundedLocalCache(builder, loader, /* async */ false);&#125;@Overridepublic BoundedLocalCache&lt;K, V&gt; cache() &#123; return cache;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647build:BoundedLocalCache -&gt; LocalCache -&gt; ConcurrentHashMapfinal class LocalCacheFactory://针对每种配置，caffeine会生成每种配置类，但它们都继承于LocalCache，这样的话就不用在代码中进行if判断，因为if判断哪在cpu底层也是需要耗时的，所以说优化到极致//这是根据配置生成对应配置类的类名，然后根据这个类名去找到对应的配置类//思想：就是用元数据空间换 if分支判断时间//想象有什么特殊的应用场景？？？？static String getClassName(Caffeine&lt;?, ?&gt; builder) &#123; var className = new StringBuilder(LocalCacheFactory.class.getPackageName()).append(&#x27;.&#x27;); if (builder.isStrongKeys()) &#123; className.append(&#x27;S&#x27;); &#125; else &#123; className.append(&#x27;W&#x27;); &#125; if (builder.isStrongValues()) &#123; className.append(&#x27;S&#x27;); &#125; else &#123; className.append(&#x27;I&#x27;); &#125; if (builder.removalListener != null) &#123; className.append(&#x27;L&#x27;); &#125; if (builder.isRecordingStats()) &#123; className.append(&#x27;S&#x27;); &#125; if (builder.evicts()) &#123; className.append(&#x27;M&#x27;); if (builder.isWeighted()) &#123; className.append(&#x27;W&#x27;); &#125; else &#123; className.append(&#x27;S&#x27;); &#125; &#125; if (builder.expiresAfterAccess() || builder.expiresVariable()) &#123; className.append(&#x27;A&#x27;); &#125; if (builder.expiresAfterWrite()) &#123; className.append(&#x27;W&#x27;); &#125; if (builder.refreshAfterWrite()) &#123; className.append(&#x27;R&#x27;); &#125; return className.toString();&#125; put底层其实就是一个data:ConcurrentHashMap put -&gt; data -&gt; writeBuffer.offer(全局有界队列) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178// 方法作用：将键值对放入缓存，如果键已存在则覆盖旧值（除非onlyIfAbsent为true）// 参数说明：// key: 缓存键// value: 缓存值// expiry: 过期策略，用于计算条目的过期时间// onlyIfAbsent: 如果为true，则仅当键不存在时才放入（类似putIfAbsent）// 返回值：如果键已存在且被覆盖，则返回旧值；否则返回null@NullableV put(K key, V value, Expiry&lt;K, V&gt; expiry, boolean onlyIfAbsent) &#123; // 参数校验：确保键和值不为空 requireNonNull(key); requireNonNull(value); // 初始化节点变量，用于在键不存在时创建新节点 Node&lt;K, V&gt; node = null; // 获取当前时间（用于过期时间计算） long now = expirationTicker().read(); // 计算新值的权重（用于基于权重的容量控制） int newWeight = weigher.weigh(key, value); // 创建用于查找的键对象（可能是弱引用或强引用，根据配置） Object lookupKey = nodeFactory.newLookupKey(key); // 通过自旋循环处理并发情况，attempts为重试次数 for (int attempts = 1; ; attempts++) &#123; // 从底层ConcurrentHashMap中获取已存在的节点 Node&lt;K, V&gt; prior = data.get(lookupKey); // ========== 场景1：键不存在（新增缓存条目） ========== if (prior == null) &#123; // 如果尚未创建新节点，则创建它 if (node == null) &#123; // 创建新节点，包含键、值、权重和创建时间 node = nodeFactory.newNode(key, keyReferenceQueue(), value, valueReferenceQueue(), newWeight, now); // 设置节点的可变过期时间（基于创建时间计算） setVariableTime(node, expireAfterCreate(key, value, expiry, now)); &#125; // 尝试将新节点原子性地放入缓存Map prior = data.putIfAbsent(node.getKeyReference(), node); // 如果成功放入（prior为null表示没有其他线程抢先放入） if (prior == null) &#123; // 执行写后操作：将添加任务提交到写缓冲区，异步处理缓存维护 afterWrite(new AddTask(node, newWeight)); return null; // 新增条目，返回null &#125; else if (onlyIfAbsent) &#123; // 如果其他线程抢先放入了该键，且onlyIfAbsent为true，则尝试快速返回现有值 V currentValue = prior.getValue(); if ((currentValue != null) &amp;&amp; !hasExpired(prior, now)) &#123; // 记录访问时间并返回当前值（不覆盖） if (!isComputingAsync(prior)) &#123; tryExpireAfterRead(prior, key, currentValue, expiry(), now); setAccessTime(prior, now); &#125; afterRead(prior, now, /* recordHit */ false); return currentValue; &#125; &#125; &#125; // ========== 场景2：键存在且onlyIfAbsent为true ========== else if (onlyIfAbsent) &#123; // 快速路径：不覆盖现有值，只返回当前值 V currentValue = prior.getValue(); if ((currentValue != null) &amp;&amp; !hasExpired(prior, now)) &#123; if (!isComputingAsync(prior)) &#123; tryExpireAfterRead(prior, key, currentValue, expiry(), now); setAccessTime(prior, now); &#125; afterRead(prior, now, /* recordHit */ false); return currentValue; &#125; &#125; // ========== 处理节点状态异常情况 ========== // 如果之前获取的节点已失效（可能被其他线程移除），则重试 if (!prior.isAlive()) &#123; // 如果重试次数达到一定阈值（如自旋等待后仍无效），则通过计算操作确保节点状态 if ((attempts &amp; MAX_PUT_SPIN_WAIT_ATTEMPTS) != 0) &#123; Thread.onSpinWait(); // 提示CPU进行自旋等待优化 continue; &#125; // 通过computeIfPresent方法处理，确保在节点存活状态下进行操作 data.computeIfPresent(lookupKey, (k, n) -&gt; &#123; requireIsAlive(key, n); return n; &#125;); continue; &#125; // ========== 场景3：键存在且需要更新值 ========== // 以下变量用于记录更新过程中的状态 V oldValue; long varTime; // 新的可变过期时间 int oldWeight; // 旧权重值 boolean expired = false; // 标记旧值是否已过期 boolean mayUpdate = true; // 是否允许更新 boolean exceedsTolerance = false; // 是否超过时间容忍度 // 对现有节点加锁，确保更新操作的原子性 synchronized (prior) &#123; // 再次检查节点是否存活（防止在获取锁期间状态变化） if (!prior.isAlive()) &#123; continue; // 如果节点不再存活，重试 &#125; // 获取旧值和旧权重 oldValue = prior.getValue(); oldWeight = prior.getWeight(); // 根据不同的情况计算新的过期时间 if (oldValue == null) &#123; // 旧值已被垃圾回收，视为新创建 varTime = expireAfterCreate(key, value, expiry, now); notifyEviction(key, null, RemovalCause.COLLECTED); &#125; else if (hasExpired(prior, now)) &#123; // 节点已过期，按新创建处理 expired = true; varTime = expireAfterCreate(key, value, expiry, now); notifyEviction(key, oldValue, RemovalCause.EXPIRED); &#125; else if (onlyIfAbsent) &#123; // 如果onlyIfAbsent为true，则不更新值，只更新访问时间 mayUpdate = false; varTime = expireAfterRead(prior, key, value, expiry, now); &#125; else &#123; // 正常更新，计算更新后的过期时间 varTime = expireAfterUpdate(prior, key, value, expiry, now); &#125; // 如果允许更新值，则执行更新操作 if (mayUpdate) &#123; // 检查是否超过写入容忍度（用于控制更新频率，避免频繁维护） exceedsTolerance = (expiresAfterWrite() &amp;&amp; (now - prior.getWriteTime()) &gt; EXPIRE_WRITE_TOLERANCE) || (expiresVariable() &amp;&amp; Math.abs(varTime - prior.getVariableTime()) &gt; EXPIRE_WRITE_TOLERANCE); // 更新节点的值和权重 prior.setValue(value, valueReferenceQueue()); prior.setWeight(newWeight); setWriteTime(prior, now); discardRefresh(prior.getKeyReference()); // 丢弃可能的刷新任务 &#125; // 设置节点的可变时间（用于过期策略）和访问时间 setVariableTime(prior, varTime); setAccessTime(prior, now); &#125; // ========== 通知相关事件 ========== if (expired) &#123; notifyRemoval(key, oldValue, RemovalCause.EXPIRED); &#125; else if (oldValue == null) &#123; notifyRemoval(key, /* oldValue */ null, RemovalCause.COLLECTED); &#125; else if (mayUpdate) &#123; notifyOnReplace(key, oldValue, value); // 通知值被替换 &#125; // ========== 决定后续维护操作 ========== // 计算权重变化 int weightedDifference = mayUpdate ? (newWeight - oldWeight) : 0; // 根据条件决定执行写后操作还是读后操作 if ((oldValue == null) || (weightedDifference != 0) || expired) &#123; // 需要执行写后维护（如大小调整、驱逐检查等） afterWrite(new UpdateTask(prior, weightedDifference)); &#125; else if (!onlyIfAbsent &amp;&amp; exceedsTolerance) &#123; // 即使值未变，但时间偏差超过容忍度，也需要写后维护 afterWrite(new UpdateTask(prior, weightedDifference)); &#125; else &#123; // 仅记录访问（轻量级操作） if (mayUpdate) &#123; setWriteTime(prior, now); &#125; afterRead(prior, now, /* recordHit */ false); &#125; // 返回旧值（如果过期则返回null） return expired ? null : oldValue; &#125;&#125; data.put(keyRef,node) writeBuffer.offer(task); schedule end &#x2F;&#x2F;写入writeBuffer 1234567891011121314151617181920212223242526272829303132void afterWrite(Runnable task) &#123; //写入然后满了 就会重试 默认140次 for (int i = 0; i &lt; WRITE_BUFFER_RETRIES; i++) &#123; if (writeBuffer.offer(task)) &#123; scheduleAfterWrite(); return; &#125; scheduleDrainBuffers(); Thread.onSpinWait(); &#125; // In scenarios where the writing threads cannot make progress then they attempt to provide // assistance by performing the eviction work directly. This can resolve cases where the // maintenance task is scheduled but not running. That might occur due to all of the executor&#x27;s // threads being busy (perhaps writing into this cache), the write rate greatly exceeds the // consuming rate, priority inversion, or if the executor silently discarded the maintenance // task. Unfortunately this cannot resolve when the eviction is blocked waiting on a long- // running computation due to an eviction listener, the victim is being computed on by a writer, // or the victim residing in the same hash bin as a computing entry. In those cases a warning is // logged to encourage the application to decouple these computations from the map operations. //重试后还是写入不了，就会主动同步调起maintenance：消费Buffer 清理key 淘汰key lock(); try &#123; maintenance(task); &#125; catch (RuntimeException e) &#123; logger.log(Level.ERROR, &quot;Exception thrown when performing the maintenance task&quot;, e); &#125; finally &#123; evictionLock.unlock(); &#125; rescheduleCleanUpIfIncomplete();&#125; maintenance 1234567891011121314151617181920212223242526@GuardedBy(&quot;evictionLock&quot;) void maintenance(@Nullable Runnable task) &#123; setDrainStatusRelease(PROCESSING_TO_IDLE); try &#123; drainReadBuffer(); drainWriteBuffer(); if (task != null) &#123; task.run(); &#125; drainKeyReferences(); drainValueReferences(); expireEntries(); evictEntries(); climb(); &#125; finally &#123; if ((drainStatusOpaque() != PROCESSING_TO_IDLE) || !casDrainStatus(PROCESSING_TO_IDLE, IDLE)) &#123; setDrainStatusOpaque(REQUIRED); &#125; &#125; &#125; 若：writeBuffer满了，offer return false。异步任务处理不过来，循环完成后，会主动同步调其maintance（这时候put就会被阻塞，其实是同步的，也是一种保护措施，因为写太多，会OOM，阻塞也会去减慢写的速度）：就会去消费Buffer，节点过期，节点淘汰。如果非常爆炸性的put的画，性能就不是很好了 读多写少用的才是本地缓存 getget -&gt; data -&gt; readBuffer.offer(每个线程一个队列，减少了竞争) 异步任务会被包装成PerformCleanUpTask它其实是一个Runnable，然后丢到线程池去执行 1234567891011121314151617181920212223242526@GuardedBy(&quot;evictionLock&quot;) void maintenance(@Nullable Runnable task) &#123; setDrainStatusRelease(PROCESSING_TO_IDLE); try &#123; drainReadBuffer(); drainWriteBuffer(); if (task != null) &#123; task.run(); &#125; drainKeyReferences(); drainValueReferences(); expireEntries(); evictEntries(); climb(); &#125; finally &#123; if ((drainStatusOpaque() != PROCESSING_TO_IDLE) || !casDrainStatus(PROCESSING_TO_IDLE, IDLE)) &#123; setDrainStatusOpaque(REQUIRED); &#125; &#125; &#125; 内存管理，（淘汰策略：key上限），W-TinyLFU像内存管理，我肯定是有内存的数据才能进行管理，而像这些数据我肯定是不能在put or get 的主线程去做的，有些内存组件其实就是这么去做的，所以性能才差 writeBuffer和readBuffer的作用：就是把统计操作和读写操作分离了（一定情况下），两者不会相互影响 内存模型： 过期策略 全局统一key一个过期时间 12345678910111213141516171819202122232425262728293031323334void expireAfterWriteEntries(long now) &#123; if (!expiresAfterWrite()) &#123; return; &#125; long duration = expiresAfterWriteNanos();//全局过期时间 如 10秒 for (;;) &#123; Node&lt;K, V&gt; node = writeOrderDeque().peekFirst(); if ((node == null) || ((now - node.getWriteTime()) &lt; duration) //判断是否过期 || !evictEntry(node, RemovalCause.EXPIRED, now)) &#123; //去淘汰 break; &#125; &#125;&#125;//...//判断是否过期if (expiresAfterWrite()) &#123; expired |= ((now - n.getWriteTime()) &gt;= expiresAfterWriteNanos());&#125;//...//已过期makeDead(n);//已过期removed[0] = true;return null;//把date 给 put(key， null)；//..//移除写顺序队列，好等下一次循环再次peekFirst进行过期检查writeOrderDeque().remove(node);//..//发出移除key通知，可自定义监听器notifyRemoval(key, value[0], actualCause[0]); 每个key单独一个过期时间 使用的是时间轮算法，时间轮算法过期 12345void expireVariableEntries(long now) &#123; if (expiresVariable()) &#123; timerWheel().advance(now); &#125;&#125; 时间轮：本质其实就是 数组 + 链表 定时器tick从时间轮里取任务时，整体时间复杂度可以为O(1); 包括put也是 而像Linux的双层时间轮，在次基础上还优化了。采用了双层时间轮，支持高延迟，其设计思想类似于分针和秒针 【层1：秒轮（快速轮）】slot0 slot1 slot2 … slot59 【层2：分轮（慢速轮）】slot0 slot1 … slot59 Tick 推进时： 秒轮每走一格 秒轮走满一圈 → 分轮前进一步，并将该分轮槽内的任务下沉到秒轮对应槽 淘汰策略：W-TinyLFU 思想大体就是我觉得就很像jvm的那种分代思想。像这个W-TinyLFU算法，它的话就是把内存总的分成了两端，一个main cache，一个是windows Cache，而main cache里又分为probation(LRU)（试用期） 和 protected(LRU)（受保护的）。（W-TinyLRU 通常包含 两个主要组件：windowCache和mainCache） 工作流程： 当前一个新的item进来时，会先进入我们的windowCache。这里的windowCache比较小，且内存管理就直接使用传统LRU了。 若有item从我们的windowCache淘汰出来的话，会尝试进入mainCache 能否进入看TinyCache对该item的计数是否 大于 主缓存中频率最低的候选淘汰对象 的 频率计数。可以就进入并，不可以就out mainCache整体采用的也是LRU（但是） 整体流程呈现一种 先接纳后淘汰的流程 MainCache里的状态流转 W-TinyLFU解决了LRU和LFU什么问题？ LRU：突发流量污染问题 LFU：老资历不腾空给 新数据 12345678910111213141516171819202122232425262728293031323334353637383940//淘汰节点evictEntries();//..//先window 再mainint candidates = evictFromWindow();evictFromMain(candidates);//evictFromWindowNode&lt;K, V&gt; node = accessOrderWindowDeque().peek();//设100个size//1个给window 99个给main区while (windowWeightedSize() &gt; windowMaximum()) &#123; //.. accessOrderWindowDeque().remove(node); accessOrderProbationDeque().add(node);//..&#125;//evictFromMain//probation区的第一个Node&lt;K, V&gt; victim = accessOrderProbationDeque().peekFirst();//probation区的末尾个，也就是刚才从window移过来的Node&lt;K, V&gt; candidate = accessOrderProbationDeque().peekLast();//key个数有没有超过上限while (weightedSize() &gt; maximum()) &#123; //........ //对比频率 //W - TinyLFU的精髓 //计数 admit(candidateKey, victimKey)；//frequencySketch() 很好的思想，特殊的位计数法， //.. evictEntry(evict, RemovalCause.SIZE, 0L); &#125; //自动调节各区域大小climb(); W-TinyLFU 的精髓是 位计数法 如何一个高性能的本地缓存组件，caffeine在拼多多高并发业务场景下性能还是不行 改进缺点 给不同key设置不同的过期时间，API不够好 1234567public void put(K key, V value, Duration timeout) &#123; if(timeout == null) cache.put(k, v); else cache.policy() .expireVariably() .ifPresent(policy -&gt; policy.put(key, value, timeout));&#125; 2. 对比guava 架构","path":"2025/08/13/caffeine/","date":"08-13","excerpt":"","tags":[]},{"title":"思考","text":"整个链路高速队列基于提问者的这个问题，歪师傅也想起了两个类似的场景。 一个是我参与开发过的一个对客发送短信的消息系统，简化一下整个流程大概是这样的： 上面这个图片会出现什么问题呢？ 就是消息堆积。 当某个业务系统调用短信发送接口，批量发送消息的时候，比如发送营销活动时，大量的消息就在队列里面堆着，慢慢消费。 其实堆积也没有关系，毕竟营销活动的实时性要求不是那么高，不要求立马发送到客户手机上去。 但是，如果在消息堆积起来之后，突然有用户申请了验证码短信呢？ 需要把前面堆积的消费完成后，才会发送验证码短信，这个已经来不及了，甚至验证码已经过期很久了你才发过去。 客户肯定会骂娘，因为获取不到验证码，他就不能进行后续业务。 如果大量客户因为收不到验证码不能进行后续业务，引起群体性的客诉，甚至用户恐慌，这个对于企业来说是一个非常严重的事件。 怎么办呢？ 解决方案非常简单，再搞一个“高速”队列出来： 验证码消息直接扔到“高速”队列中去，这个队列专门用来处理验证码、动账通知这一类时效性要求极高的消息，从业务场景上分析，也不会出现消息堆积。 不是特别复杂的方案，大道至简，问题得到了解决。 类比到前面说的“快慢”线程池，其实是一样的思想，都是从资源上进行隔离。 只不过我说的这个场景更加简单，不需要去收集信息进行动态判断。业务流程上天然的就能区分出来，哪些消息实时性比较高，应该走“高速”队列；哪些消息慢慢 发没关系，可以应该走“常规”队列。 而这个所谓的“高速”和“常规”，只是开发人员给一个普通队列赋予的一个属性而已，站在 MQ 的角度，这两个队列没有任何区别。","path":"2025/08/13/项目/消息推送平台/思考/","date":"08-13","excerpt":"","tags":[]},{"title":"switch时间复杂度","text":"","path":"2025/08/13/JavaSE/switch时间复杂度/","date":"08-13","excerpt":"","tags":[]},{"title":"Dubbo五种负载均衡","text":"最短响应时间策略： 遍历服务提供者，计算每个服务的预计等待时间：(成功总耗时/成功请求数) * 活跃数。 选择时间最短的服务，若多个则按权重选择，权重相同则随机。 加权轮询算法Dubbo的加权轮询算法经历了三个主要阶段，其演进目标是在保证按权重分配请求的前提下，兼顾性能和请求分布的平滑性。 Dubbo 2.6.4 版本及之前：存在严重性能问题的朴素实现。 第一次优化：修复了性能问题，时间复杂度降至O(1)，但请求分布不平滑。 最终方案（平滑加权轮询）：在保证O(1)时间复杂度的基础上，实现了平滑的请求分布，避免了某个节点短时间内压力激增。 该算法的灵感来源于Nginx的平滑加权轮询算法。其核心思想是，通过动态调整一个“当前权重”值，让请求能够更均匀地分散到各个节点上，而不是连续地分配给高权重节点。 对于每一次请求，选择过程如下： 遍历并更新：遍历所有Invoker，将每个Invoker的 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;current&lt;/font&gt;值加上其固定的 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;weight&lt;/font&gt;。 选择最大者：从步骤1更新后的 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;current&lt;/font&gt;值中，选出最大的一个。该值对应的Invoker即为本次选中的节点。 调整选中者权重：将选中节点的 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;current&lt;/font&gt;值减去总权重 &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;total&lt;/font&gt;。 返回结果：返回选中的Invoker。 关键点：第3步“减去总权重”是保证算法能够循环往复、实现平滑的核心。 1234567891011121314151617181920212223242526272829303132333435363738// 非完整代码，仅为说明算法逻辑protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; // 1. 获取第一个Invoker和它的固定权重 Invoker&lt;T&gt; initInvoker = invokers.get(0); int weight = getWeight(initInvoker, invocation); // 2. 初始化所有Invoker的当前权重和总权重 // `weightArray` 是一个数组，保存了每个Invoker的【固定权重】和【当前权重】 // 这里是为了找到最大的固定权重和总权重 int totalWeight = weight; int maxWeight = weight; for (int i = 1; i &lt; length; i++) &#123; weight = getWeight(invokers.get(i), invocation); maxWeight = Math.max(maxWeight, weight); totalWeight += weight; &#125; // 3. 核心算法循环 // 如果最大权重大于0，且所有Invoker的当前权重不全都相等，进入状态机逻辑 if (maxWeight &gt; 0 &amp;&amp; !sameWeight) &#123; // 状态机模式，循环直到选出一个Invoker for (int i = 0; i &lt; length; i++) &#123; // 当前索引的Invoker，将其【当前权重】增加【固定权重】 int current = weightArray[i].current += weightArray[i].weight; // 如果当前值大于已知最大值，更新最大值和选中的Invoker if (current &gt; maxCurrent) &#123; maxCurrent = current; selectedInvoker = invokers.get(i); &#125; &#125; // 选中后，将【选中Invoker】的【当前权重】减去【总权重】 // 这是实现平滑的关键步骤！ weightArray[selectedIndex].current -= totalWeight; return selectedInvoker; &#125; // 4. 如果所有权重相同，则退化为普通轮询 return invokers.get(sequence++ % length);&#125; Dubbo的加权轮询负载均衡算法通过三次演进，最终采用了平滑加权轮询算法。该算法通过引入动态的“当前权重”（&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;current&lt;/font&gt;），并在每次选中后减去“总权重”（&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;total&lt;/font&gt;），巧妙地实现了： 严格按权重分配：在多次请求后，各节点被选中的次数比严格等于其权重比。 请求分布平滑：高权重节点的请求被分散开，避免了瞬时压力过大。 高性能：时间复杂度为O(n)，其中n是服务节点数，通常很小，可视为常量级。 总结 原理： 最短响应时间策略：选择平均响应时间最短的服务，结合权重和活跃数计算预计等待时间。 最小活跃数策略：选择活跃请求数最少的服务，需配合&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;ActiveLimitFilter&lt;/font&gt;使用，否则退化为加权随机。 一致性哈希策略：通过哈希环和虚拟节点分布请求，减少节点变动时的数据迁移。 加权轮询策略：请求按权重比例轮流分配，平滑加权算法避免请求集中。 加权随机策略：根据权重设置随机概率，权重越大的服务被选中的概率越高。 作用：优化资源利用、提升响应速度、保证高可用性。 应用场景： 最短响应时间：适用于对延迟敏感的场景，如实时计算。 最小活跃数：适合处理时间差异大的服务，如慢查询优化。 一致性哈希：需要会话保持或顺序处理的场景，如缓存分片。 加权轮询&#x2F;随机：服务器性能不均时，按权重分配负载。","path":"2025/08/12/Dubbo五种负载均衡/","date":"08-12","excerpt":"","tags":[]},{"title":"IP分片、TCP分段","text":"分片分段的意义 MSS和MTU IP分片了，TCP为什么还要分段？ tcp分段后是为了在传输层保证协议的可靠性，因此给每个段打上标识符，可以实现失败重传和流量控制 的操作 不分段的话，如果这时候某个IP分片丢失了，那么整个IP报文的分片将重传。因为接受方收不到完整数据 就不会回复ack，tcp这边收不到ack，就会触发重传机制，同时因为不知道是哪个分片丢了，所以会将整 个IP报文的分片重传 :::color4如果TCP把这份数据，分段为N个小于等于MSS长度的数据包，到了IP层后加上IP头和TCP头，还是小于MTU，那么IP层也不会再进行分包。此时在传输路上发生了丢包，那么TCP重传的时候也只是重传那一小部分的MSS段。效率会比TCP不分段时更高。 ::: 即分段的意义就是为了提高重传的效率 同为传输层协议的UDP，就不会进行一个分段，重传时就直接重传一整段 TCP分段了，IP为啥还要分片呢？ 一般来说，在发送端，tcp分段后，IP就不会继续分片了。但在传输链路过程中，mtu是会变化的，IP分 片就起到一个兜底的作用","path":"2025/08/10/计网/IP/IP分片、TCP分段/","date":"08-10","excerpt":"","tags":[]},{"title":"为什么要划分网络号和主机号","text":"主机号和网络号是什么？ 网络号用来标识处于哪个网络，而主机号则用于标识处于哪台设备 eg： :::color1192.168.10.25 &#x3D; 11000000.10101000.00001010.00011001 根据子网掩码的 1 位数： - **前 24 位**：网络号 - **后 8 位**：主机号 网络号：11000000.10101000.00001010 &#x3D; 192.168.10 主机号：00011001 &#x3D; 25 ::: 所以为什么？ 如果不区分的话，那么IP地址将不够用，因为那就意味着每台设备就是一个全新的网络。而且划分后可以区分一个个子网，方便子网内的计算机通信","path":"2025/08/09/计网/IP/为什么要划分网络号和主机号/","date":"08-09","excerpt":"","tags":[]},{"title":"URI，URL，URN","text":"","path":"2025/08/09/计网/URI，URL，URN/","date":"08-09","excerpt":"","tags":[]},{"title":"MemorySafeLinkedBlockingQueue","text":"https://mp.weixin.qq.com/s/BTVDPHVWjBiq9mj3mvT_Vw","path":"2025/07/31/JUC/MemorySafeLinkedBlockingQueue/","date":"07-31","excerpt":"","tags":[]},{"title":"jdk bug 合集","text":"刺激，线程池的一个BUG直接把CPU干到100%了。","path":"2025/07/31/场景题/why总/jdk bug 合集/","date":"07-31","excerpt":"","tags":[]},{"title":"LWP","text":"轻量级进程，即用户线程的运行载体，等价于内核线程","path":"2025/07/30/操作系统/LWP/","date":"07-30","excerpt":"","tags":[]},{"title":"Java如何绑定线程到指定CPU上执行?","text":"java线程模型主流虚拟机如hotspot线程模型基本都是1:1，即一个用户线程对应着一个系统线程 一个 Java 线程是直接映射为一个操作系统原生线程的，中间没有额外的间接结构。HotSpot 虚拟机也不干涉线程的调度，这事全权交给底下的操作系统去做。 顶多就是设置一个线程优先级，操作系统来调度的时候给个建议。 但是何时挂起、唤醒、分配时间片、让那个处理器核心去执行等等这些关于线程生命周期、执行的东西都是操作系统干的。 内核线程和用户线程的关系ps：用户线程是指逻辑线程 LWP：Light Weight Process 轻量级进程 KLT：Kernal-Level Thread 内核线程 UT：User Thread 用户线程 程序一般来说不会直接使用内核线程，而是使用内核线程的一种高级接口，即轻量级进程（LWP），轻 量级进程就是我们通常意义上说的线程。 为什么不直接使用内核线程：https://chatgpt.com/s/t_688a3269bab881919cc8b77012464e77 正因为有了内核线程的支持，每个轻量级进程成了独立的调度单元，即使某个轻量级进程阻塞了，也不会 影响到其他轻量级进程的 但他也有局限性，即他属于内核空间的东西，用户线程的创建，切换，销毁都需要用户态和内核态来回切 换，挺耗时的。其次就是那个内核空间有限，轻量级进程要消耗一定的内核资源（如内核线程的栈空 间），因此一个系统支持轻量级进程的数量是有限的 绑核实践绑定线程是操作系统层面干的，即使Java能干，那也只是套层皮而已 使用某位大佬开发的一个库，本质是封装了Linux的taskset指令来要求os为我们的用户线程判定特定cpu 12345&lt;dependency&gt; &lt;groupId&gt;net.openhft&lt;/groupId&gt; &lt;artifactId&gt;affinity&lt;/artifactId&gt; &lt;version&gt;3.2.3&lt;/version&gt;&lt;/dependency&gt; jna：JNA 是一个让你可以在 Java 中直接调用 C 系统函数 &#x2F; 本地库的工具，不用写 JNI，使用简单灵活， 是 Java 调用底层的一把利器。 好处： 减少上下文切换和缓存失效率 谁在使用？ 可用于netty","path":"2025/07/30/JUC/Java如何绑定线程到指定CPU上执行/","date":"07-30","excerpt":"","tags":[]},{"title":"内存泄漏排查","text":"我的程序跑了60多小时，就是为了让你看一眼JDK的BUG导致的内存泄漏。","path":"2025/07/29/场景题/why总/内存泄漏排查/","date":"07-29","excerpt":"","tags":[]},{"title":"linux ntpd机制","text":"问题：线上由于两台服务器的问题造成一机关读条（进度条）功能客户端和服务端对不齐 原因：test时把Server时间调到了未来，然后调了回来","path":"2025/07/28/操作系统/linux ntpd机制/","date":"07-28","excerpt":"","tags":[]},{"title":"简历写法","text":"项目描述核心职责 &amp; 亮点： ✅ 构建消息处理核心模块，实现消息多级处理流程（去重、夜间屏蔽、限流、通道分发等），并通过责任链模式支持消息类型扩展 ✅ 支持定时&#x2F;周期任务调度，封装 cron 模块，结合 Quartz&#x2F;Apollo 实现消息延迟投递与灰度推送调度策略 ✅ 构建全链路生命周期追踪机制，在发送链路关键节点埋点写入 Kafka，消费并清洗数据后实时写入 Redis、离线写入 Hive，支撑运营精准监控与效果评估 ✅ 使用动态线程池隔离各类消息类型处理通道，支持线程资源动态配置与限流熔断机制，提高系统弹性和容灾能力 ✅ 参与建设 Austin 消息运营平台（austin-admin），包括模板工单审核、素材管理、监控告警等功能，完善平台可视化和运营能力 ✅ 接入 Prometheus + Grafana 实现平台全链路监控体系，并结合自定义报警规则大幅降低推送异常延迟处理时间（MTTR ↓ 75%）","path":"2025/07/27/项目/消息推送平台/简历写法/","date":"07-27","excerpt":"","tags":[]},{"title":"为什么做这个项目","text":"","path":"2025/07/27/项目/消息推送平台/为什么做这个项目/","date":"07-27","excerpt":"","tags":[]},{"title":"项目难点","text":"","path":"2025/07/27/项目/消息推送平台/项目难点/","date":"07-27","excerpt":"","tags":[]},{"title":"消息推送聚合","text":"消息聚合 根据消息数量或者时间 消息压缩消息聚合，虽然消息数量减少了，但消息体增大了，影响了写入IO，需要减少消息体大小 选择在消息分发层进行消息压缩，避免在各接入节点多次重复压缩，浪费性能。上线后提升吞吐量的同时， 也降低的宽带使用成本 使用Brotil压缩算法","path":"2025/07/22/项目/消息推送平台/消息推送聚合/","date":"07-22","excerpt":"","tags":[]},{"title":"netty入门","text":"简单Server和简单Client1 几大组件的关系channel，eventLoopGroup，ByteBuf，Handler，pipline EventLoop事件循环对象，本质就是单线程执行器 事件循环组（EventLoopGroup）,channel一般会调用EventLoopGroup中的register来绑定其中一个channel，后面channel上的io事件都由此EventloopGroup来负责，也保证了io处理时的线程安全 NioEventLoop 底层基于NIO DefaultEventLoop Channel作用 - &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;close() 可以用来关闭 channel&lt;/font&gt; - &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;closeFuture() 用来处理 channel 的关闭&lt;/font&gt; * &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;sync 方法作用是同步等待 channel 关闭&lt;/font&gt; * &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;而 addListener 方法是异步等待 channel 关闭&lt;/font&gt; - &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;pipeline() 方法添加处理器&lt;/font&gt; - &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;write() 方法将数据写入&lt;/font&gt; - &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;writeAndFlush() 方法将数据写入并刷出&lt;/font&gt; 注意 connect，bind 方法是异步的，意味着不等连接建立，方法执行就返回了。因此 channelFuture 对象中不能【立刻】获得到正确的 Channel 对象 两种方法：线程sync()阻塞等待建立好，addListener() 添加回调方法 Future &amp; PromiseHandler &amp; Pipeline多个Handler组成一个pipeline ByteBuf是对字节数据的封装 创建 1234567ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(10);//默认使用 池化基于直接内存的 ByteBuflog(buffer);ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer(10);//基于堆ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer(10); 堆内存和直接内存 堆内存：多一次拷贝，需要从os 本地内存拷贝到Java的堆内存 磁盘-》os os-》Java heap内存 数据需要 两次拷贝，效率较低 直接内存：零拷贝技术，只需要一次拷贝 池化 vs 非池化池化的最大意义在于可以重用 ByteBuf，优点有 没有池化，则每次都得创建新的 ByteBuf 实例，这个操作对直接内存代价昂贵，就算是堆内存，也会增加 GC 压力 有了池化，则可以重用池中 ByteBuf 实例，并且采用了与 jemalloc 类似的内存分配算法提升分配效率 高并发时，池化功能更节约内存，减少内存溢出的可能 组成 writewriteByte,writeInt…. 扩容规则 未超过512，下一个则是超过它的第一个16的整数倍 如果超过521，下一个则是超过它的第一个2的n次方数 readreadByte() markReaderIndex() 标志 resetReaderIndex() 重置 retain &amp; release","path":"2025/07/21/netty/netty入门/","date":"07-21","excerpt":"","tags":[]},{"title":"NIO基础","text":"三大组件channel读写数据的双向通道 selector通过引入一个selector实现一个线程同时监控多个channel 适合连接数特别多，但流量低的场景 bytebuffer使用 往buffer写入数据，channel.read() 从buffer读取数据，buffer.get() 切换写读模式，filp 清空 结构 ByteBuffer 有以下重要属性 * &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;capacity&lt;/font&gt; * &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;position&lt;/font&gt; * &lt;font style=&quot;color:rgb(31, 35, 40);&quot;&gt;limit","path":"2025/07/21/netty/NIO基础/","date":"07-21","excerpt":"","tags":[]},{"title":"正向代理和反向代理","text":"https://cloud.tencent.com/developer/article/1418457 https://blog.csdn.net/weixin_45750572&#x2F;article&#x2F;details&#x2F;126234303 我们实现的是反向代理网关","path":"2025/07/18/项目/自研网关/正向代理和反向代理/","date":"07-18","excerpt":"","tags":[]},{"title":"性能","text":"本地电脑16C16G，起了idea、网关、一个springboot下游服务、nacos，jemter起100个线程发请求 吞吐量在2.0w 同条件下，测试SpringCloud Gateway的吞吐量是1.1w，接近1.2w","path":"2025/07/18/项目/自研网关/性能/","date":"07-18","excerpt":"","tags":[]},{"title":"注册中心和配置中心","text":"列出市面上常见的注册中心与配置中心： Nacos 默认模式：基于 AP 模型，侧重于服务的高可用性，允许数据在短时间内不一致。 可配置模式：Nacos 也支持 CP 模式，可通过配置切换，满足对一致性要求更高的场景。 Zookeeper CP 系统：使用 ZAB（Zookeeper Atomic Broadcast）协议，保证数据的强一致性。 应用场景：适合对数据一致性要求高的场景，如分布式锁、配置管理。 Eureka AP 系统：设计上强调服务的高可用性，即使在部分节点失联的情况下，仍能提供服务注册和发现功能。 一致性处理：允许服务实例的信息在短时间内不一致，依靠心跳和自我保护机制来最终达到一致。 Consul CP 系统：使用 Raft 共识算法，确保数据的强一致性。 应用场景：适用于对一致性有严格要求的服务注册、配置管理等。","path":"2025/07/18/项目/自研网关/注册中心和配置中心/","date":"07-18","excerpt":"","tags":[]},{"title":"弹性措施","text":"列出市面上常见的弹性框架，Sentinel、Hystrix、Resilience4j，最终选择Resilience4j Sentinel： 整体较为庞大，配置相对复杂，与我网关的轻量理念不符 需要引入配置台和控制台，非Spring环境下引入成本大 Hystrix： 已停止维护，不适合用于新项目，Netfix官方推荐Resilience4j Resilience4j： 轻量、模块化、lambda表达式编程、功能全面、使用简单、对环境没有要求，非Spring环境下也能很好继承 项目里的熔断用的是Resilience4j，为什么不选择Hystrix？ :::color4这里可以吹一波 Hystrix熔断的问题： 默认机制是线程池代理，即有请求就有线程代理 hystrix是接口级别 一个接口一个线程池 用虚拟线程就可以解决这个问题 ::: 熔断两种： 1.线程代理熔断 2.信号量，sentinel用的就是信号量，比较简单粗暴。但它只是一个开关，只能进或者不进或者知道进来多少。这时如果有一个请求的线程死循环了，也就只能让别的线程不要进来，但无法结束当前这个死循环的线程。而有了线程代理后就可以干很多事情了，只能说各有各的优缺点。如请求线程执行超过1s，浏览器已经timeout，但服务端的请求线程还没停，这时候最好的情况就是服务端你自个把自己给停了，但问题是你用信号量服务端怎么把自己给停了呢，这就是个问题，而线程代理就可以处理这个问题。还有一点，就是停请求一般停的是查询，写是不敢停的 大厂落地的时候不敢在网关上搞太多东西，因为出bug就gg了，一般不在api网关上熔断，虽然理论上可以 举例： 流量网关：nginx api网关：vintage，api网关其实没啥神秘的，就是路由 rpc：motan 在api网关上做熔断的问题 1.单点故障 2.1个服务200个接口，就一个核心接口流量大。熔断颗粒度得做到接口 3.集群是变化的，得动态判断，比较费劲 熔断：挡流量。扛不住就减少请求呗 降级：是把一部分不重要的业务停了，活干不过来了，就不干不重要的 熔断起作用得看 熔断策略，一般两种，请求数量以及响应时间，请求数量及响应时间，如果是请求数量DDOS就会断，而响应时间得看接口性能 降级就是得有开关的，人来决定 限流","path":"2025/07/18/项目/自研网关/弹性措施/","date":"07-18","excerpt":"","tags":[]},{"title":"限流和信号量隔离","text":"限流更偏向于控制并发的速率，信号量隔离更偏向于控制并发的数量，而且是同一时间的数量。 限流是说，希望能够把控并发的速率，比如希望是平滑的流量。 信号量隔离的话就是同一时间，对资源的访问数量，比如数据库资源，需要做信号量隔离，避免同一时间数据库访问数量过多","path":"2025/07/18/项目/自研网关/限流和信号量隔离/","date":"07-18","excerpt":"","tags":[]},{"title":"限流方式","text":"滑动窗口： 和令牌桶其实非常像，实现方式不同，效率可能更差点，因为需要保证剔除请求时的一个线程安全，需要synchronized 令牌桶： 能应对突发大流量，但是超出阈值后，则会把流量变得平滑 漏桶： 恒定非常平滑的流量，适用场景比如限制数据库每秒的写入次数。不允许大突发流量","path":"2025/07/18/项目/自研网关/限流方式/","date":"07-18","excerpt":"","tags":[]},{"title":"HTTP客户端","text":"列出市面上常见的http客户端：AsyncHttpClient、Apache HttpClient、OkHttp、Spring WebClient 为什么选择AsyncHttpClient？ Apache HttpClient：默认同步为主、异步支持较弱、配置较重 OkHttp：更多应用于Android Spring WebClient：过度依赖Spring框架 AsyncHttpClient：异步非阻塞响应、轻量、对环境无要求，甚至非Spring环境下集成更好","path":"2025/07/18/项目/自研网关/HTTP客户端/","date":"07-18","excerpt":"","tags":[]},{"title":"java函数式编程和lambda表达式","text":"函数的真谛123456789101112interface Promise&#123; boolean is(a,b)&#125;fun getByCondition(Promise pm)&#123; if(pm.is(a,b))&#125;//调用getByCondition( (a,b) -&gt; (xxx) ) logger中的 interface Supplier{ T get(); } 在软件开发中，”interface supplier” 通常指的是 提供特定类型对象或数据的接口。 它可以被理解为一个 提供者，其主要功能是生成或获取某种类型的实例，而不需要调用者关心具体的创建过程。 在Java 8及以后的版本中，java.util.function.Supplier&lt;T&gt;接口就扮演着这样的角色，它代表了一个不接受参数但返回一个值（类型为T）的函数。 函数对象表现形式lambda表达式123// Lambda 表达式Predicate&lt;String&gt; startsWithA = s -&gt; s.startsWith(&quot;A&quot;);System.out.println(startsWithA.test(&quot;Apple&quot;)); // 输出 true 方法引用123// 方法引用Predicate&lt;String&gt; startsWithA_MethodRef = String::startsWith;System.out.println(startsWithA_MethodRef.test(&quot;Banana&quot;, &quot;B&quot;)); // 输出 false 函数对象类型参数个数类型相同，返回值类型相同 -&gt; 函数式接口,只包含一个抽象方法，用@FunctionallInterface 自定义函数12345678//编译期检查，是否只有一个抽象方法@FunctionInterfaceinterface Type&#123; boolean op(int a)&#125;main&#123; Type type= a-&gt; xxx&#125; jdk函数 闭包限制：参数以外的数据必须是final or effictive final 柯里化Optional一条龙Optional用法与争议点 - 扣钉日记 - 博客园 123456public String getCity(User user) throws Exception&#123; return Optional.ofNullable(user) .map(u-&gt; u.getAddress()) .map(a-&gt;a.getCity()) .orElseThrow(()-&gt;new Exception(&quot;取指错误&quot;)); &#125;","path":"2025/07/16/java函数式编程和lambda表达式/","date":"07-16","excerpt":"","tags":[]},{"title":"限流","text":"目录 1、路由转发 2、失败重试 3、熔断降级 4、实现过程 4.1 正常路由转发 4.2 请求重试 4.3 熔断降级 1、路由转发路由转发**** 是网关处理完毕所有过虑逻辑之后的最后一个要执行的操作，它负责将请求最终转发到某一个指定的后端服务，这里参考 Spring Cloud Gateway 的实现方式来模拟一个路由转发过滤器 在 Spring Cloud Gateway 这一先进的微服务网关解决方案中，路由转发过滤器扮演着至关重要的角色，负责对进站的 HTTP 请求进行精细化处理与精准调度。以下详述其核心功能及在微服务体系中的价值： 请求适配与重定向**** ：路由转发过滤器具备强大的请求修饰能力，能够对请求的各组成部分进行灵活调整，包括但不限于请求头、主体内容、查询参数等。这种机制使得网关能够在请求抵达目标服务前对其进行定制化改造，确保其完全符合服务接口规范。此外，过滤器还支持动态重定向请求至其他目标服务，实现复杂路由场景下的精准投递。 安全屏障**** ：作为微服务架构的入口防线，路由转发过滤器承载了关键的安全防护功能。通过集成身份验证与授权机制，过滤器能有效拦截未经授权的访问请求，确保仅授权用户方可触及特定服务资源。这一特性对于构建坚实的服务边界，防止未授权渗透，保障整个微服务生态系统安全至关重要。 智能缓存**** ：为了提升系统性能、缓解服务压力并降低响应延迟，过滤器可集成缓存策略。针对特定请求或响应，过滤器能够识别其是否适合缓存，并在必要时直接从缓存中返回结果，避免对后端服务产生不必要的调用。这种机制在面对高并发、数据复用性强的场景时尤为高效，显著提升了系统的整体响应速度与吞吐能力。 日志审计与监控洞察**** ：路由转发过滤器充当了微服务交互的透明观察者，实时捕获并记录请求与响应的详细信息。这些数据不仅可用于生成详细的访问日志，便于问题排查与合规审计，还能作为关键性能指标输入到监控系统，助力运维人员实时掌握服务状态，快速定位异常，确保微服务集群稳定运行。 流量治理与韧性保障**** ：借助路由转发过滤器，网关得以实施精细的流量控制策略，如限流、熔断、降级等，以防止服务因瞬时流量激增而过载崩溃。通过智能调节进入服务的请求速率，过滤器在保障服务质量的同时，增强了系统的弹性和稳定性，为微服务架构应对各种突发情况提供了有力支撑。 负载均衡与服务发现**** ：路由转发过滤器的核心职能之一在于实现请求到多个后端服务实例的透明转发，并依据预设的负载均衡算法，确保请求在各实例间均匀分布，最大限度利用服务资源，实现系统的水平扩展。同时，过滤器通常与服务注册与发现机制紧密集成，确保网关始终能准确找到并连接到可用的服务实例，实现服务间的无缝通信。 综上所述，Spring Cloud Gateway中的路由转发过滤器凭借其丰富的功能集与高度的可配置性，为微服务架构提供了全方位的请求处理、安全防护、性能优化、监控洞察与流量管理能力，是构建健壮、高效、易运维的微服务生态体系不可或缺的关键组件。 2、失败重试请求重试是指在请求失败之后再次尝试请求，一般情况下重试可以减少请求因为服务GC卡顿、网络丢包、网络阻塞等短暂问题而导致的失败；然而重试会增加请求总数量，不合理的重试策略甚至可能在服务端不稳定时，导致重试流量风暴，从而压垮服务端导致故障。 请求失败一般可以按照层级划分为连接失败和请求失败；而请求一般可分为幂等和非幂等请求。 连接失败：由于TCP握手失败，实际业务请求并未发送至服务端，所以对此类错误是可以安全的重试的，配合超时配置将链接超时设置在毫秒级别，可以有效的避免偶发网络拥塞、网络丢包等网络故障导致的报错，提升整体稳定性。 请求失败：由于网络连接已经完成，实际业务请求可能已经发送至服务端，服务端的业务逻辑可能已经执行过了；比如服务端超时，而实际服务端业务逻辑会继续执行完成。因此对于幂等请求相对安全，但是对于非幂等的请求，重试可能会有较大风险。 在短视频APP例子中，比如获取账户信息的请求就是幂等请求，不会有服务端数据的修改，重试操作是比较安全的；但是对于添加评论的请求，如果请求超时进行重试，就可能导致评论服务最终收到多个添加评论的请求，最终添加多个重复的评论，显然这是不正确的，会最终导致数据异常。 因此重试配置一般可归于以下几类 连接重试**** : 因为连接重试风险低，收益高，一般情况下默认开启。 超时重试**** : 需要判断业务接口是否幂等，如非幂等风险是否可控，来决定是否启用；提供重试退避策略：重试等待固定时长或逐次提升等待时长。 Backup Request**** : 为减少服务的延迟波动。在设置时间内未返回，再次发送请求；例如使用P99作为阈值，来降低长尾问题。 同时为了防止大规模重试导致请求量总量成倍上升，最终压垮服务，重试一般需提供熔断错误率阈值，当请求错误率超过阈值时停止重试。 3、熔断降级服务降级是在服务所发出「实际请求需求」大于下游「稳定&#x2F;可提供QPS」阈值时所使用的一种「服务维稳手段」，保障在部分极端情况下整体系统可以通过牺牲部分能力方式换来一定程度的可用性，而不是超出阈值后导致系统雪崩。 服务降级常见有两种方式，业务根据自身需求进行对应选择： 弃车保帅：按一定丢弃规则，仅丢弃部分请求，保障部分高优&#x2F;核心 请求可以获得稳定服务。 贫富相均：对于所有请求一视同仁，按照相同比例丢弃。 对于基础系统&#x2F;核心业务&#x2F;关键服务，其组件可用性有着极高要求，如果因其承载资源需求过高而整体完全不可用，会导致大面积服务调用链直接断裂，并使故障进一步扩散，引起「系统雪崩」，其造成的巨大损失是我们不能接受的。 在短视频APP的例子中，如下图，假如因为突发事件流量，导致账户服务的流量增加触发了限流；但是对于短视频的场景下，视频播放功能价值显然高于评论功能的价值，在有限的资源情况下，账户服务如果主动将评论服务的流量进行降级，将资源腾挪给视频信息服务，舍弃评论功能，保护视频播放能力显然能获得更高性价比。 服务降级究其根本，即是“断臂求生”。对于实际业务场景而言，降级方式的评估即是对「付出成本」和「实际收获」的评估，可以从以下三个维度去抽象细化： 尽可能少丢弃—— “每一个请求都有价值” 尽可能丢弃价值较低的请求—— “请求与请求的价值是不同的” 尽可能丢弃性价比低的请求—— “吃了两份资源却只能产出一份价值的请求” 4、实现过程4.1 正常路由转发在这里创建两个服务，方便测试负载均衡和路由转发效果 这段代码和之前请求服务模块一样，将服务弄到注册中心 【自研网关系列】请求服务模块和客户端模块实现-CSDN博客 123456789101112131415@RestController@ApiService(serviceId = &quot;backend-http-server&quot;, protocol = ApiProtocol.HTTP, patternPath = &quot;/http-server/**&quot;)@Slf4jpublic class HttpController &#123; @Autowired private ApiProperties apiProperties; @ApiInvoker(path = &quot;/http-server/ping&quot;) @GetMapping(&quot;/http-server/ping&quot;) public String ping() &#123; log.info(&quot;&#123;&#125;&quot;, apiProperties); return &quot;pong1&quot;; &#125;&#125; 配置文件就是端口号和 Nacos 地址 1234567server: port: 8201api: registerAddress: 127.0.0.1:8848 env: dev gray: false 启动三个类 继续 debug 来讲解流程 进入过滤器后，会根据配置中是否有熔断降级的逻辑，不是就正常路由 这里使用 Http 异步操作来提高性能和响应速度： 在传统的同步HTTP请求中，每个请求都需要等待服务器的响应，这会导致线程阻塞，从而降低程序的效率。而在异步HTTP请求中，请求发送后不需要等待服务器的响应，可以立即进行其他操作，当服务器响应到来时，会通过回调函数进行处理。这样可以大大提高程序的并发处理能力，从而提高程序的响应速度。 whenComplete 方法**** : whenComplete**** 是一个非异步的完成方法。 当 CompletableFuture**** 的执行完成或者发生异常时，它提供了一个回调。 这个回调将在 CompletableFuture**** 执行的相同线程中执行。这意味着，如果 CompletableFuture**** 的操作是阻塞的，那么回调也会在同一个阻塞的线程中执行。 在这段代码中，如果 whenComplete**** 为 true**** ，则在 future**** 完成时使用 whenComplete**** 方法。这意味着 complete**** 方法将在 future**** 所在的线程中被调用。 whenCompleteAsync 方法**** : whenCompleteAsync**** 是异步的完成方法。 它也提供了一个在 CompletableFuture**** 执行完成或者发生异常时执行的回调。 与 whenComplete**** 不同，这个回调将在不同的线程中异步执行。通常情况下，它将在默认的 ForkJoinPool**** 中的某个线程上执行，除非提供了自定义的 Executor**** 。 在代码中，如果 whenComplete**** 为 false**** ，则使用 whenCompleteAsync**** 。这意味着 complete**** 方法将在不同的线程中异步执行。 由于 ForkJoinPool中的线程是共用的**** ，ParallelStream中的线程也是用的ForkJoinPool，因此我推荐手动设定这个线程池的大小，否则会出现一些异常哦。 123456789101112131415161718192021222324/** * 默认路由逻辑： * 根据 whenComplete 判断执行回调的线程是否阻塞执行； * whenComplete 当异步操作完成时（无论成功还是失败），会立即执行回调函数； * whenCompleteAsync 当异步操作完成时，会创建一个新的异步任务来执行回调函数。 */private CompletableFuture&lt;Response&gt; route(GatewayContext gatewayContext, Optional&lt;Rule.HystrixConfig&gt; hystrixConfig) &#123; // 异步请求发送 Request request = gatewayContext.getRequest().build(); CompletableFuture&lt;Response&gt; future = AsyncHttpHelper.getInstance().executeRequest(request); boolean whenComplete = ConfigLoader.getConfig().isWhenComplete(); // 异步/非异步模型 if (whenComplete) &#123; future.whenComplete(((response, throwable) -&gt; &#123; complete(request, response, throwable, gatewayContext); &#125;)); &#125; else &#123; future.whenCompleteAsync(((response, throwable) -&gt; &#123; complete(request, response, throwable, gatewayContext); &#125;)); &#125; return future;&#125; 然后就是处理HTTP响应，并根据处理过程中是否存在异常来设置不同的响应内容 123456789101112131415161718192021222324private void handleResponse(Request request, Response response, Throwable throwable, GatewayContext gatewayContext) &#123; String url = request.getUrl(); try &#123; if (Objects.nonNull(throwable)) &#123; if (throwable instanceof TimeoutException) &#123; log.warn(&quot;complete timeout &#123;&#125;&quot;, url); gatewayContext.setThrowable(throwable); gatewayContext.setResponse(GatewayResponse.buildGatewayResponse(ResponseCode.REQUEST_TIMEOUT)); &#125; else if (throwable instanceof IOException) &#123; gatewayContext.setThrowable(new ConnectException(throwable, gatewayContext.getUniqueId(), url, ResponseCode.HTTP_RESPONSE_ERROR)); gatewayContext.setResponse(GatewayResponse.buildGatewayResponse(ResponseCode.HTTP_RESPONSE_ERROR)); &#125; &#125; else &#123; gatewayContext.setResponse(GatewayResponse.buildGatewayResponse(response)); &#125; &#125; catch (Exception e) &#123; gatewayContext.setThrowable(new ResponseException(ResponseCode.INTERNAL_ERROR)); gatewayContext.setResponse(GatewayResponse.buildGatewayResponse(ResponseCode.INTERNAL_ERROR)); log.error(&quot;complete process failed&quot;, e); &#125; finally &#123; gatewayContext.setContextStatus(ContextStatus.Written); ResponseHelper.writeResponse(gatewayContext); &#125;&#125; 最终就是将HTTP响应写回客户端 1234567891011121314151617181920/** * 写回响应 */public static void writeResponse(IContext context) &#123; context.releaseRequest(); if (context.judgeContextStatus(ContextStatus.Written)) &#123; FullHttpResponse response = getHttpResponse(context, (GatewayResponse) context.getResponse()); // 如果不是保持连接的情况，响应后关闭通道 if (!context.isKeepAlive()) &#123; context.getNettyContext().writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); &#125; else &#123; response.headers().set(HttpHeaderNames.CONNECTION, HttpHeaderValues.KEEP_ALIVE); context.getNettyContext().writeAndFlush(response); &#125; context.setContextStatus(ContextStatus.Completed); &#125; else if (context.judgeContextStatus(ContextStatus.Completed)) &#123; context.invokeCompletedCallBacks(); &#125;&#125; 这里顺便展示前面的负载均衡 这里请求的网关核心的端口，但可以访问8201或8202的端口，这就是路由转发的效果 4.2 请求重试就是在处理响应请求之前就执行，然后如果有异常，且小于最大重试次数，就重新执行一遍过滤器 1234567891011121314151617private void complete(Request request, Response response, Throwable throwable, GatewayContext gatewayContext) &#123; // 请求已经处理完毕 释放请求资源 gatewayContext.releaseRequest(); // 获取上下文请求配置规则 Rule rule = gatewayContext.getRules(); // 获取重试次数 int currentRetryTimes = gatewayContext.getCurrentRetryTimes(); int confRetryTimes = rule.getRetryConfig().getTimes(); // 异常重试 if ((throwable instanceof TimeoutException || throwable instanceof IOException) &amp;&amp; currentRetryTimes &lt;= confRetryTimes) &#123; doRetry(gatewayContext, currentRetryTimes); &#125; // 处理响应 handleResponse(request, response, throwable, gatewayContext);&#125; 1234567891011121314/** * 重试策略 */private void doRetry(GatewayContext gatewayContext, int retryTimes) &#123; gatewayContext.setCurrentRetryTimes(retryTimes + 1); log.info(&quot;当前请求重试次数为&#123;&#125;&quot;, gatewayContext.getCurrentRetryTimes()); try &#123; // 重新执行过滤器逻辑 doFilter(gatewayContext); &#125; catch (Exception e) &#123; log.warn(&quot;重试请求失败, requestId=&#123;&#125;&quot;, gatewayContext.getUniqueId(), e); throw new RuntimeException(e); &#125;&#125; 4.3 熔断降级首先在 nacos 配置中心中添加 hystrix 的配置 首先需要获得获取 hystrix 的配置 会判断对比请求路径和注册中心注册的路径参数 判断当前请求是否需要走熔断策略分支 1234567private static Optional&lt;Rule.HystrixConfig&gt; getHystrixConfig(GatewayContext gatewayContext) &#123; Rule rule = gatewayContext.getRules(); Optional&lt;Rule.HystrixConfig&gt; hystrixConfig = rule.getHystrixConfigs().stream() .filter(c -&gt; StringUtils.equals(c.getPath(), gatewayContext.getRequest().getPath())) .findFirst(); return hystrixConfig;&#125; 熔断降级请求策略 命令执行超过配置超时时间 命令执行出现异常或错误 连续失败率达到配置的阈值 1234567891011121314151617181920private void routeWithHystrix(GatewayContext gatewayContext, Optional&lt;Rule.HystrixConfig&gt; hystrixConfig) &#123; String key = gatewayContext.getUniqueId() + &quot;.&quot; + gatewayContext.getRequest().getPath(); RouterHystrixCommand proxyCommand = null; if (commandMap.containsKey(key)) &#123; proxyCommand = commandMap.get(key); if (!hystrixConfig.get().equals(commandMap.get(key))) &#123; log.info(&quot;previous HystrixCommand instance hashCode: &#123;&#125;&quot;, proxyCommand.hashCode()); proxyCommand.updateHystrixCommandProperties(proxyCommand.getCommandKey().name()); proxyCommand = new RouterHystrixCommand(gatewayContext, hystrixConfig); log.info(&quot;after HystrixCommand instance hashCode: &#123;&#125;&quot;, proxyCommand.hashCode()); commandMap.put(key, proxyCommand); &#125; &#125; else &#123; proxyCommand = new RouterHystrixCommand(gatewayContext, hystrixConfig); commandMap.put(key, proxyCommand); &#125; proxyCommand.execute();&#125; 其中 RouterHystrixCommand 是路由转发的内部类，RouterHystrixCommand 类的主要功能是执行实际的路由操作和熔断降级操作，它使用了 Hystrix 来实现这些功能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Hystrix命令集合 */private class RouterHystrixCommand extends HystrixCommand&lt;Object&gt; &#123; private GatewayContext context; private Optional&lt;Rule.HystrixConfig&gt; config; public RouterHystrixCommand(GatewayContext context, Optional&lt;Rule.HystrixConfig&gt; config) &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(context.getUniqueId())) .andCommandKey(HystrixCommandKey.Factory.asKey(context.getRequest().getPath())) .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() // 核心线程数 .withCoreSize(config.get().getCoreThreadSize())) .andCommandPropertiesDefaults(HystrixCommandProperties.Setter() // 线程隔离类型 .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.THREAD) // 命令执行超时 .withExecutionTimeoutInMilliseconds(config.get().getTimeoutInMilliseconds()) // 超时中断 .withExecutionIsolationThreadInterruptOnTimeout(true) .withExecutionTimeoutEnabled(true))); this.config = config; this.context = context; &#125; @Override protected Object run() throws Exception &#123; // 实际路由操作 route(context, config).get(); return null; &#125; /** * 熔断降级操作 */ @Override protected Object getFallback() &#123; // 是否是超时引发的熔断 if (isFailedExecution() || getExecutionException() instanceof HystrixTimeoutException) &#123; // 针对超时的异常处理 context.setResponse(GatewayResponse.buildGatewayResponse(ResponseCode.GATEWAY_FALLBACK_TIMEOUT)); &#125; else &#123; // 其它类型异常熔断处理 context.setResponse(GatewayResponse.buildGatewayResponse(ResponseCode.GATEWAY_FALLBACK_ERROR, config.get().getFallbackResponse())); &#125; context.setContextStatus(ContextStatus.Written); return null; &#125; /** * 动态更新 CommandProperties 配置 * 1.因为 Hystrix 内部使用了缓存，如果仅仅修改 HystrixCommand.Setter 是没有用的； * 2.利用反射获取 HystrixPropertiesFactory 的 commandProperties 字段，并更新 */ protected void updateHystrixCommandProperties(String commandKey) &#123; try &#123; Field field = HystrixPropertiesFactory.class.getDeclaredField(&quot;commandProperties&quot;); field.setAccessible(true); ConcurrentHashMap&lt;String, HystrixCommandProperties&gt; commandProperties = (ConcurrentHashMap&lt;String, HystrixCommandProperties&gt;) field.get(null); log.info(&quot;before update HystrixCommandProperties: &#123;&#125;&quot;, commandProperties.get(commandKey)); commandProperties.remove(commandKey); &#125; catch (NoSuchFieldException | IllegalAccessException e) &#123; log.error(&quot;Remove cache in HystrixCommandFactory failed, commandKey: &#123;&#125;&quot;, commandKey, e); &#125; &#125;&#125; 执行结果","path":"2025/07/15/项目/自研网关/详细/限流/","date":"07-15","excerpt":"","tags":[]},{"title":"过滤器设计","text":"目录 1、什么是过滤器 2、实现过滤器 3、实现流程 1、什么是过滤器在我们的微服务架构中，构建了一个关键组件——网关服务，它作为系统的入口，负责对所有进、出流量进行统一管理和控制。为了实现这一功能，前面文章已成功将其注册至注册中心，并从配置中心获取了相关配置。接下来，我们将深入探讨如何构建网关服务的核心部分—— 过滤器链**** 。 过滤器链，顾名思义，是由一系列有序排列的过滤器构成的执行链条。每个过滤器承载特定的业务逻辑，对经过的请求和响应进行特定处理。当一个过滤器完成其预设的过滤流程后，会遵循链条顺序，将请求传递给下一个过滤器继续执行。通过这种方式，过滤器链实现了对请求与响应的深度定制化处理。 过滤器链中的成员可根据其作用范围分为全局过滤器和局部过滤器两种类型： 全局过滤器**** ：这类过滤器具有广泛的适用性，对所有进入网关的请求均进行处理。它们通常负责执行诸如身份验证、权限校验、日志记录、跨域支持等通用性操作，确保所有请求在到达具体业务服务前符合系统的基本规范和要求。 局部过滤器**** ：Spring Cloud框架已为我们预置了一套局部过滤器，用于应对特定场景下的请求处理。尽管如此，我们依然可以根据实际需求，通过继承并实现相关接口来自定义局部过滤器，以满足特定业务逻辑或优化性能。 过滤器链的运作机制遵循严格的流程： 请求首先被送入链首的过滤器进行处理。 每个过滤器依据自身职责对请求进行检查、修改或增强，然后将处理后的请求传递给链中的下一个过滤器。 这一过程持续进行，直到链尾的路由过滤器接收到请求。路由过滤器的核心职责是根据请求信息和预设的路由规则，准确地将请求转发至相应的后台服务进行实际业务处理。 后台服务完成任务后，将响应返回给路由过滤器。 路由过滤器再将响应沿着过滤器链逆序传递，让每个过滤器有机会对响应进行必要的后期处理。 最终，经过完整过滤器链洗礼的响应被写回客户端。 在过滤器链执行过程中，若遇到任何异常情况，可通过设置专门的异常处理过滤器来捕获并妥善处理这些异常，如返回友好的错误信息、记录异常日志等，确保系统的稳定性和用户体验。 当请求在整个生命周期中均正常流转且后台服务处理完毕后，使用 context.writeAndFlush() 方法将处理结果（即响应数据）高效地写回客户端，标志着一次完整的请求响应流程在过滤器链的保驾护航下圆满结束。 综上所述，过滤器链作为网关服务的核心组件，通过串联各个具有特定功能的过滤器，对进出系统的请求与响应进行全方位、多层次的精细化管理，实现了微服务架构下流量的有效管控与优化。 大概流程图： 2、实现过滤器项目结构图 具体代码在 github 上，不一一展示 Filter：这是一个接口，定义了过滤器需要实现的方法。所有的过滤器都需要实现这个接口，并实现doFilter方法来执行具体的过滤操作。getOrder方法用于获取过滤器的执行顺序。 FilterAspect：这是一个注解，用于标记过滤器的一些属性，如ID、名称和执行顺序。这个注解被应用在实现了Filter接口的类上。 FilterChainFactory：这是一个接口，定义了过滤器链工厂需要实现的方法。过滤器链工厂的主要职责是根据给定的上下文构建过滤器链。 GatewayFilterChain：这是一个类，代表了过滤器链。它包含了一个过滤器列表，并提供了添加过滤器和执行过滤器链的方法。 GatewayFilterChainFactory：这个类的具体实现可能会根据你的应用有所不同，但一般来说，它应该是FilterChainFactory接口的一个实现，负责创建GatewayFilterChain实例。这个类可能会使用单例模式，以确保整个应用只有一个GatewayFilterChainFactory实例。 总的来说，这些类和接口共同工作，以创建和管理过滤器链。过滤器链是由一系列过滤器组成的，这些过滤器按照特定的顺序执行，以对通过网关的请求进行处理。 3、实现流程和之前一样，通过 debug 的方式来讲解过滤器链的实现 首先过滤器工厂具体实现类的无参构造 1234567891011121314151617181920/** * SPI加载本地过滤器实现类对象 * 过滤器存储映射 过滤器id - 过滤器对象 */public GatewayFilterChainFactory() &#123; //加载所有过滤器 ServiceLoader&lt;Filter&gt; serviceLoader = ServiceLoader.load(Filter.class); serviceLoader.stream().forEach(filterProvider -&gt; &#123; Filter filter = filterProvider.get(); FilterAspect annotation = filter.getClass().getAnnotation(FilterAspect.class); log.info(&quot;load filter success:&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;&quot;, filter.getClass(), annotation.id(), annotation.name(), annotation.order()); //添加到过滤集合 String filterId = annotation.id(); if (StringUtils.isEmpty(filterId)) &#123; filterId = filter.getClass().getName(); &#125; processorFilterIdMap.put(filterId, filter); processFilterIdName.put(filterId, annotation.name()); &#125;);&#125; 这里还是和注册和配置中心一样的思路，用 SPI 来加载类，加载实时可用的过滤器，组装为网关过滤器链 然后就将各个过滤器的id，名称，排序弄到 ConcurrentHashMap 中 其中 GatewayFilterChainFactory 类采用的是单例模式 在网关之中，GatewayFilterChainFactory 负责创建和管理过滤器链。由于过滤器链在整个应用中是 共享**** 的，因此没有必要为每个请求创建一个新的 GatewayFilterChainFactory 实例。 使用单例模式可以确保所有的请求都使用同一个GatewayFilterChainFactory实例，这样可以避免重复创建实例，节省内存，并 保证所有请求使用的过滤器链的一致性**** 。 此外，GatewayFilterChainFactory 在初始化时会加载所有的过滤器，这可能是一个 耗时**** 的操作。如果每个请求都创建一个新的 GatewayFilterChainFactory 实例，那么这个耗时的初始化操作就会被重复执行，这会影响应用的性能。 使用单例模式，初始化操作只会执行一次，可以提高应用的性能。 总的来说，这里使用单例模式是为了保证过滤器链的一致性，节省内存，提高性能。 在 NettyCoreProcessor 会获取 GatewayFilterChainFactory 这个单例的 1234/** * 过滤器链工厂 */private FilterChainFactory chainFactory = GatewayFilterChainFactory.getInstance(); 在 process 方法中调用构建过滤器链条这个功能 12345// 创建并填充 GatewayContext 以保存有关传入请求的信息。GatewayContext gatewayContext = RequestHelper.doContext(request, ctx);// 组装过滤器并执行过滤操作chainFactory.buildFilterChain(gatewayContext).doFilter(gatewayContext); 构建过滤器链条利用本地缓存，主要确保对于同一规则ID的请求，可以复用已经构建的过滤器链，而不需要每次都重新构建，从而提高了性能 12345/** * 过滤器链缓存（服务ID ——&gt; 过滤器链） * ruleId —— GatewayFilterChain */private Cache&lt;String, GatewayFilterChain&gt; chainCache = Caffeine.newBuilder().recordStats().expireAfterWrite(10, TimeUnit.SECONDS).build(); 123456789101112131415161718192021/** * 构建过滤器链条 */@Overridepublic GatewayFilterChain buildFilterChain(GatewayContext ctx) throws Exception &#123; // 获取规则ID String ruleId = ctx.getRules().getId(); // 从缓存中获取过滤器链 GatewayFilterChain chain = chainCache.getIfPresent(ruleId); // 如果缓存中没有过滤器链，那么构建一个新的过滤器链 if (chain == null) &#123; chain = doBuildFilterChain(ctx.getRules()); // 将新构建的过滤器链添加到缓存中 chainCache.put(ruleId, chain); &#125; // 返回过滤器链 return chain;&#125; 构建一个新的过滤器链 根据给定的规则构建一个过滤器链，这个过滤器链用于处理 HTTP 请求 为什么每个服务请求最终最后需要添加路由过滤器 在网关中，路由过滤器的作用是将 请求路由（转发）到适当的后端服务**** 。 在过滤器链中，路由过滤器通常是最后一个执行的过滤器，因为它需要在所有其他过滤器（如权限、限流、负载均衡等）成功执行后才进行路由。 这个方法中，路由过滤器被添加到过滤器链的末尾，这是因为在执行所有其他过滤器并对请求进行各种检查和处理后，最后的步骤是将请求路由到适当的后端服务。 如果没有路由过滤器，那么即使请求通过了所有其他过滤器，也无法到达任何后端服务，因此每个服务请求最终都需要添加路由过滤器。 在 NettyCoreProcessor 中还会执行 doFilter() 方法，就是遍历过滤器链，逐个执行过滤 12// 组装过滤器并执行过滤操作chainFactory.buildFilterChain(gatewayContext).doFilter(gatewayContext); 1234567891011121314151617/** * 执行过滤器链 */public GatewayContext doFilter(GatewayContext ctx) &#123; if (filters.isEmpty()) &#123; return ctx; &#125; try &#123; for (Filter filter : filters) &#123; filter.doFilter(ctx); &#125; &#125; catch (Exception e) &#123; log.error(&quot;执行过滤器发生异常: &#123;&#125;&quot;, e.getMessage()); throw new RuntimeException(e); &#125; return ctx;&#125; 大概的过滤器设计就这样，还是需要自己根据代码 debug 一下才能根据清晰，点个 ⭐ ！！！","path":"2025/07/14/项目/自研网关/详细/过滤器设计/","date":"07-14","excerpt":"","tags":[]},{"title":"工具类说明","text":"高性能系统时间工具类高并发场景下System.currentTimeMillis()的性能问题的优化-腾讯云开发者社区-腾讯云 发现一个开源项目优化点，点进来就是你的了 - 捉虫大师 - 博客园 JSON序列化工具类对比JackJSON，GSON，FastJson。性能最好的是JackJson 断言参考dubbo NetMapstruct","path":"2025/07/13/项目/自研网关/工具类说明/","date":"07-13","excerpt":"","tags":[]},{"title":"网关DDD领域模型设计","text":"入门了解【10分钟学会DDD领域模型】 bilibili 设计找名词，就是思考网关整个链路有哪些名词 Config，Request，Response，Filter，FilterChain，Context，Processor（处理逻辑），Rule 找属性 比如Request，Context。Request里要有请求唯一ID，请求url，方式….","path":"2025/07/12/项目/自研网关/网关DDD领域模型设计/","date":"07-12","excerpt":"","tags":[]},{"title":"项目模块","text":"项目模块： BreezeGateway-Core BreezeGateway-Client BreezeGateway-Nebula-Bootstrap BreezeGateway-Register-Center BreezeGateway-Config-Center BreezeGateway-Common BreezeGateway-backend-Dubbo BreezeGateway-backend-Httpserver groupId： io.github.soyorin.gw 123&lt;groupId&gt;io.github.soyorin.gw&lt;/groupId&gt;&lt;artifactId&gt;Breeze-Gateway&lt;/artifactId&gt;&lt;version&gt;0.1.0-SNAPSHOT&lt;/version&gt;","path":"2025/07/12/项目/自研网关/项目模块/","date":"07-12","excerpt":"","tags":[]},{"title":"架构&流程","text":"架构 流程","path":"2025/07/12/项目/自研网关/架构&流程/","date":"07-12","excerpt":"","tags":[]},{"title":"如何提高网关性能","text":"使用缓存map,queue。将一些策略比如负载均衡进行缓存 提高吞吐量除了使用mq，我们还可以使用Disruptor，mcmp队列 适当串行化串行化适合于耗时短的任务 而并行化适合于耗时长，任务之间无依赖关系，比如远程RPC调用 工作线程【拒绝八股，线程池线程数设置不再迷茫】 bilibili readBuffer，writeBuffer优化CPU瓶颈特别是Java 21 以前，没有虚拟线程，即使你开启零拷贝，上下文切换这种东西还是有的，但现代CPU其实上下文切换可以忽略不计的。主要是线程调度 网络带宽相比于cpu，网络带宽更是瓶颈，10w在同一时刻发送，如果你的消息是1kb，那么它就需要100mb的带宽 &#x3D;&gt; 1 gib带宽 去优化你们的 Linux参数，主要是tcp连接有关，文件描述符 消息收发优化收： 这个感觉没啥要优化的 发： 1.压缩2.使用紧凑型协议，比如说用 protobuf &#x3D;&gt; json 这两种东西其实是用 cpu 换 网络带宽 3.聚合发送&#x2F;单个改批量 你怎么单个改批量发 1.基于时间or数量 2.kafka stream 滑动窗口来实现批量发 使用Buffer pool 减少内存使用jvm调优优化心跳心跳之间是占带宽的 两种心跳 原来每隔30s就会发心跳，运用了request as ping 后发消息后下一次心跳时间就会往后延迟 即 1.消息发送-接受就被看做是一次心跳 2.只有超过心跳间隔，也没有收发过消息，才会针对发起心跳 3.websocket频繁收发消息的情况下，几乎不会产生额外的心跳消息（在message里 增加一个 headbeat：true）","path":"2025/07/12/项目/自研网关/如何提高网关性能/","date":"07-12","excerpt":"","tags":[]},{"title":"异步化设计","text":"总结插件过滤使用单异步模式 请求响应使用双异步模式 单异步和双异步模式 单异步模式其实就是指你发送和接受请求的线程是同一个，那么你是没法同时发送和接受的 怎么实现双异步模式呢？ 用不同的线程去发送接收请求 completableFuture演示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package async;import java.util.concurrent.*;/** * @author: lkl * @date: 2025/7/12 17:20 * 说明单异步和双异步模式的区别 */public class CompletableFutureDemo &#123; public static void main(String[] args) &#123; //ExecutorService pool = Executors.newFixedThreadPool(1); ////单异步 //CompletableFuture&lt;Integer&gt; future1 = CompletableFuture.supplyAsync(() -&gt; &#123; // System.out.println(&quot;异步任务线程：&quot; + Thread.currentThread().getName()); // return 10; //&#125;,pool).thenApply(result -&gt; &#123; // System.out.println(&quot;回调线程：&quot; + Thread.currentThread().getName()); // 可能是主线程 // return result * 2; //&#125;); ////双异步 //CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(() -&gt; &#123; // System.out.println(&quot;异步任务线程：&quot; + Thread.currentThread().getName()); // return 10; //&#125;,pool).thenApplyAsync(result -&gt; &#123; // System.out.println(&quot;回调线程：&quot; + Thread.currentThread().getName()); // 一定是异步线程 // return result * 2; //&#125;,pool); //单异步 CompletableFuture&lt;Integer&gt; future3 = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(&quot;异步任务线程：&quot; + Thread.currentThread().getName()); return 10; &#125;).thenApply(result -&gt; &#123; System.out.println(&quot;回调线程：&quot; + Thread.currentThread().getName()); // 可能是主线程 return result * 2; &#125;); //双异步 CompletableFuture&lt;Integer&gt; future4 = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(&quot;异步任务线程：&quot; + Thread.currentThread().getName()); return 10; &#125;).thenApplyAsync(result -&gt; &#123; System.out.println(&quot;回调线程：&quot; + Thread.currentThread().getName()); // 一定是异步线程 return result * 2; &#125;); &#125;&#125; 但其实也不是绝对，如果使用的线程池，线程有限，发送和接收也有可能用的同一个线程 使用线程池的时候记得关闭，不然main线程退出后，会由于还存在用户线程，导致程序卡住 thenApplyAsync和thenApply区别https://segmentfault.com/q/1010000042935593 单异步和双异步的适用场景如果我们的下游服务处理比较快，那么双异步模式就会比较吃亏，因为会频繁地进行上下文切换，这样耗时就 会比单异步的大 Future局限性和CompletableFuture使用Future的局限性 CompletableFuture原理与实践-外卖商家端API的异步化 CompletableFuture使用： 创建异步线程 12runAsyncapplyAsync 获取结果 1234//future.get()//future.jion()","path":"2025/07/12/项目/自研网关/异步化设计/","date":"07-12","excerpt":"","tags":[]},{"title":"网络拓扑结构","text":"规则，插件，路径路径与规则，插件是一对多的关系","path":"2025/07/12/项目/自研网关/网络拓扑结构/","date":"07-12","excerpt":"","tags":[]},{"title":"技术栈","text":"高性能组件：Netty、Disruptor 异步交互：asynchttpclient 缓存：caffeine、guava 序列化：protobuf、json 注册中心：Etcd、Nacos、Zookeeper 配置中心：Nacos","path":"2025/07/12/项目/自研网关/技术栈/","date":"07-12","excerpt":"","tags":[]},{"title":"市面上常见网关","text":"网关大体分为两种：流量和业务网关 SpringCloud Gateway：依赖Spring生态、启动时间较长 Zuul：早期版本是同步阻塞的，而新版本代码复杂，学习成本高，且停止维护了 Nginx：更适合静态资源的请求，比如html、css、图片、音频、视频等","path":"2025/07/12/项目/自研网关/市面上常见网关/","date":"07-12","excerpt":"","tags":[]},{"title":"简历","text":"","path":"2025/07/12/项目/自研网关/简历/","date":"07-12","excerpt":"","tags":[]},{"title":"难点","text":"难点我觉得就是一整个netty的核心处理流程吧，就是我通过netty收到网络请求，然后应该如何通过AsyncHttpClient去调用下游，如何将下游返回结果返回，以及如何在这个过程中实现我们的一些功能，比如说灰度分流，负载均衡，弹性保护，路由转发等 我的解决方案就是这样的，就是先从整体出发，把握全局，然后向内填充细节，比如整体是什么，我经过分析后发现，无非就是从netty这边收到netty的fullhttprequest这个类，返回的是FullHttpResponse，然后asyncHttpClient那边无非就是发送request，然后返回Response。首先，两头的请求和响应是不一样的，我要做的是外层的事就是转换，但转换其实不够啊，我肯定是需要加一些自定义的东西方便我去扩展网关功能。所以我还需要一套自定义的网关的请求和响应，然后充当中介来把netty和asynchttpclient连接起来 这就是最外面的一层框架，然后我需要往里面去缩，去填充内部的细节，这毫无疑问地我的想法其实就是使用过滤器，过滤器的这种流水线思想在网关里是很常用的，包括像Spring cloud gateway，shenyu。还有就是责任链把这些过滤器给串起来 到这里，我的想法就是实现一些默认的过滤器，然后也允许用户自定义过滤器去做功能增强。但是我的网关是没有依赖Spring的。所以我需要通过SPI来发现用户自定义的过滤器，这块我选的是jdk自带的ServiceLoader服务发现机制 然后就是实现自己网关的一套过滤器，我先粗略地列出我能想到的过滤器，比如流控，灰度，负载均衡，路由，弹性。然后就安排我这些过滤器的顺序，经过一番思考，我觉得第一个应该是流控，因为你如果被限流的话，那以下的过滤器就没必要走了，第二个在最开始安排的就是负载均衡，因为我最开始是把负载均衡和灰度放一起的，因为我觉得负载均衡就是如果是灰度就是从灰度里挑一个节点出来，而如果是非灰度那就从非灰度里挑一个出来。但后面又觉得这样负载均衡和灰度的耦合度太高了，然后我就尝试分离这两个东西。灰度被我放到了前面，就是根据灰度策略决定是否走，然后根据负载均衡从后面挑一个节点出来。然后接下里就得考虑那个弹性和路由的，我一开始是把它分离开来的，但经过一番思考，我觉得他们放在一起比较好，因为我觉得那个弹性应该是路由的修饰封装，因为我们这些隔离，重试，熔断，降级这种应该是在路由转发后，根据返回的结果来决定来的，两者放一起更好工作，所以我最终把两个放在了一起，就是读取配置，如果用户没有开启配置，那就正常路由转发请求。然后如果开启的话，那就用弹性功能包装下路由转发功能 然后这其实就是过滤器链的大概设计，接着就是过滤器的具体设计，首先就是过滤器接口的设计，其实就是四个方法，一个就是前过滤器方法，一个就是后过滤器方法，一个order标识顺序，一个mark标识过滤器名字。然后就是过滤器工厂，传入路由配置，读取里面的过滤器配置，构建返回这个服务的过滤器链 首先是第一个过滤器，流控吧，流控的话我这边就是参考市面上一些常用的手段的吧。滑动窗口限流，令牌桶，漏桶。这其实就是三种策略，所以我用接口抽象了他们，然后读取配置决定走哪种。首先滑动窗口其实就是我用一个 dq来存储请求的时间戳，然后请求过来的时候我会先去清理掉窗口之前的请求，然后判断队列长度是否超过上限，如果超过了的话就把请求对应的时间戳放进去队列。其实就是先清理窗口之前的旧请求，然后判断当前窗口是否容纳得下当前请求，如果容纳得下就放行，如果容纳不下就抛异常，返回429状态码。然后就是令牌桶，令牌桶的话就是初始化时开个定时任务，不断地去更新我们的tokens数量，然后我们通过原子方法getAndDecreament获取值是否大于0，如果是够的，那就接着走，如果不够的话，也是抛异常，然后返回429异常。接着就是漏桶的话，就是请求来的时候，先判断你的桶水位是否大于limit，如果没过就先入队列，然后请一个定时任务，以均定的速度放走请求，但是这里放行的请求仍然是交给netty的worker线程去处理的，定时任务只负责从队列里poll请求。 PS： 123456789101112131415private void startLeakTask(EventLoopGroup eventLoopGroup) &#123; // 使用 Netty 的定时任务来按频率漏出请求 eventLoopGroup.scheduleAtFixedRate(() -&gt; &#123; if (!waitingQueue.isEmpty() &amp;&amp; currentWaterLevel.get() &gt; 0) &#123; GatewayContext gatewayContext = waitingQueue.poll(); if (gatewayContext != null) &#123; // 重新提交请求到 Netty 事件循环 gatewayContext.getNettyCtx().executor().execute(() -&gt; &#123; currentWaterLevel.decrementAndGet(); gatewayContext.doFilter(); &#125;); &#125; &#125; &#125;, leakInterval, leakInterval, TimeUnit.MILLISECONDS); &#125; 然后接下来就是灰度。灰度的话首先是实例列表里要有灰度实例，这个在每个实例的配置里可以标记 有的话就根据策略决定当前请求是否走灰度，我这边默认提供了两种策略，一种是根据灰度流量，比如实例链表里有10%的灰度实例，那么就有10%的概率会走灰度。第二种是根据客户端IP，对客户端做hash，对100取模，然后如果小于10%，能保证同一ip的请求都能走到灰度上，更符合灰度的需求。 然后就是负载均衡算法，负载均衡算法默认地话就是5种，轮询，随机，权重，hash，一致性hash。这些都是比较好实现的，就是 查出实例列表，然后从里面挑一个出来，主要是把他们封装成一个个策略，然后通过SPI加载，便于用户自定义扩展。 接下来就是一个路由转发和弹性保护，路由转发这里我其实就是把网关内部请求转成Request，然后通过asyncHttpClient转发到下游，然后设置一些回调，但这里是异步，且我还要对其进行一些重试，熔断，降级，所以我这里就是把发请求这里动作封装成了JDK的suppiler类这个lambda表达式，然后对这个表达式进行修饰包，修饰后再执行这个lambda表达式，这里我就开始考虑修饰顺序，我首先想的顺序是重试、熔断、降级。这其实我觉得是正常逻辑顺序，就是请求失败的话，肯定是先重试几遍，如果重试几次后还失败，那就熔断，最后降级处理。但是我们后面在添加隔离措施时，又感觉这样写死顺序不太好，因为我可能会有这样的需求，就是我的隔离支持信号量隔离和线程池隔离，但也可以同时使用这两个，这个时候两种和的装饰顺序就很重要了，例如先使用线程池隔离，信号量隔离，那就是先获取线程池资源，再获取信号量资源，先使用信号量隔离，再用线程池隔离，就是先获取信号量资源，再获取线程池资源。所以我应该把这个弹性配置的顺序交给用户去配置，但是我提供默认的推荐顺序，所以我具体的装饰顺序是读取配置文件来进行装饰的。 到了这里我的框架就是基本搞好了，然后我就开始思考其他的点，第一个想到的就是鉴权，但是我又仔细思考了一下，我觉得鉴权这个行为是很难做到统一的，就是后端模块我们是说不清的，可能有用户，有订单，有支付等，每个模块可能需要单独的一套鉴权，想把它统一到网关去我觉得能做，但它对上游请求有要求，对下游服务有侵入。但我的网关设计的最初思想就是对上游请求无要求，对下游服务无侵入，主打轻量高吞吐。所以我没在这里做文章，但因为我们的过滤器是SPI加载，所以如果真的要搞鉴权的，用户其实是自定义过滤器去实现的 然后就是我想到的是日志收集以及监控这些，这个其实我也思考过。我觉得如果要引入这些功能，就是需要依托某个框架去的，例如ELK这些，首先，这些类似的日志收集框架太多了，我很难说去选择一个出来提供服务，因为这样的话就代表使用者必须搭建对应的日志框架环境。我觉得就是没必要为了丰富我么的网关功能或者让简历更服务去做一些实际不应该存在的东西，而且我觉得这些东西就是调用API传入数据这些，其实没有啥在技术上有太大的难点。而且我们对我网关的最初设计的想法还有一条就是除了服务发现以外，我不再对其他框架产生依赖，所以我是连Spring那一套框架都没引入的 然后就是跨域问题，我觉得这个其实就是我需要实现那的，这也算网关一个比较经典的问题，解决方法也是比较简单通用的，就是返回的结果的请求头添加一些新，然后如果遇到Optional类型的请求就可以直接诶发那会200状态码，不需要往下走了 然后我又想到了跨域问题，我觉得这个其实是我需要实现的，这也算是网关一个比较经典的问题吧，解决方法也是比较简单通用，就是返回结果的请求头中添加一些信息，然后如果遇到Options类型的请求可以直接返回200状态码，不需要往下走了。 然后这大概就是我感觉我整个项目遇到的问题以及解决方法吧。 项目难点我觉得就是一整个netty核心处理过程，就是我通过netty接收到网络请求，然后应该如何通过AsyncHttpClient去调用下游，如何将下游返回结果返回，以及如何在这个过程中实现我们的一些功能，比如灰度分流、负载均衡、弹性保护、路由转发等 我的解决方法是这样的，就是先从整体出发，把握全局，然后向内填充细节，比如整体是什么，我经过分析后发现其实我要做的无非就是从Netty这边收到netty的FullHttpRequest这个类，返回的是FullHttpResponse，然后AsyncHttpClient那边就是发送Request，返回结果是Response，所以首先，两头的请求和响应是不一样的，我要做的最外层的事就是转换，但转换其实不够呀，我肯定是需要加一些自定义的东西方便我扩展网关功能的，所以我还需要有一套自定义的网关的请求与响应，然后充当中介来去把Netty和AsyncHttpClient连接起来。 这就是最外面的一层框架，然后我需要往里去缩，去填充内部的细节，那毫无疑问地我的想法其实就是使用过滤器，过滤器这种流水线思想在网关是很常见的，包括像在其它地方，例如责任链模式我觉得其实都是一种很通用的思想。 我的想法是，实现一些通用的默认过滤器，然后也允许用户自定义过滤器去做功能增强，但是我的网关是没有依赖Spring那一套框架的，所以我需要通过SPI来发现用户自定义的过滤器，这块我选的是JDK自带的ServiceLoader服务发现机制。 然后就是实现自己的一套网关自带的过滤器，我先粗略列出我能想到的过滤器，例如灰度、负载均衡、路由、弹性、流控。然后我就开始安排这些过滤器的顺序，经过一番思考设计，我第一个过滤器是流控，因为如果你流控这一关都过不了，被限流了那你后面的过滤器其实都不需要走了，第二个过滤器我一开始安排的是负载均衡，因为我最开始是把负载均衡和灰度放到一起去了，我觉得负载均衡就是，如果是灰度的，那就从灰度的实例中选择一个实例节点，如果不是灰度的，那就从非灰度实例节点选出一个节点，但是后面就是感觉这样做感觉灰度和负载均衡两个功能的耦合度太高了，我就尝试分离这两个功能，我把灰度安排在了前面，就是根据灰度策略，决定是否走灰度实例，如果走，后面的负载均衡就会从灰度实例中挑出一个实例节点，如果不走，后面的负载均衡就从非灰度实例中挑出一个节点，再过完灰度和负载均衡后，其实就是要考虑弹性和路由功能了，我最开始的想法其实是把这两个拆开，但是经过一番思考，我觉得弹性和路由两个功能反而放一起更好，弹性应该是对路由转发请求的修饰包装，因为我们的弹性功能，例如隔离、重试、熔断、降级这些，其实都是需要在我们路由转发请求之后，根据请求的结果来决定的，两者放到一起其实更好组合工作，所以我最终反而把这两个放到一起，就是读取配置，如果用户没开启弹性配置，那就正常路由转发请求，如果开启了弹性配置，那就用弹性功能对转发请求进行装饰者包装。 然后这其实就是过滤器链的一套大概的整体设计，然后就是开始实现具体的过滤器链，首先就是过滤器接口的设计，其实就是四个方法，一个前过滤器方法，一个后过滤器方法，一个mark标识过滤器名字，一个order标识过滤器顺序。然后就是过滤器工厂，传入路由配置，读取里面的过滤器配置，构建返回这个服务的过滤器链条。 首先是第一个过滤器，流控吧，流控的话我是参考了市面上常见的流控手段，滑动窗口限流、令牌桶限流、漏桶限流，这其实就是三种策略，所以我是用接口抽象了他们，然后读取配置决定使用哪种限流方式。滑动窗口限流的话其实就是来一次请求，先剔除窗口内之前的旧请求，然后看目前的窗口大小还能不能容得下这次的新请求，如果可以的话就放行，不可以的话就抛异常，返回HTTP状态码429。令牌桶限流的话就是初始化令牌桶时起个定时任务，按照参数隔一段时间就将令牌数新增一些数量，但数量不会溢出最大容量，然后请求来了就先获取令牌，获取的到才方向，获取不到就抛异常，返回429。然后是漏桶限流，漏桶限流也是初始化漏桶时起个定时任务，按照参数隔一段时间去将队列中取出一个请求放行，但是这里放行的请求仍然是交给netty的worker线程去处理的，定时任务只负责取出请求放行，然后请求来的话就看队列是否满了，没满就放请求进队列，满了就返回429。这里就是第一个过滤器流控吧 然后就是第二个灰度，灰度首先是实例列表中有灰度实例，这个在实例元数据信息里面定义是否是灰度实例，有的话就根据策略决定当前流量是否走灰度，我默认提供了两种策略，一个是根据灰度流量，比如实例列表中有10%的灰度，那本请求就有10%的概率是灰度流量，另一种是进一步根据ip来进行划分，对客户端ip做哈希，对100取模，然后如果小于10%，这样能保证同一ip的请求都能走到灰度上，更符合灰度的需求。 然后是负载均衡，负载均衡的话就是提供默认五种模式，轮询、随机、权重、ip哈希、一致性哈希，这些其实都是比较好实现的，就是查出实例列表，然后选择一个出来，主要是把他们封装成一个个策略，然后通过SPI加载，也方便用户做自定义策略。 然后是路由转发和弹性保护，路由转发其实就是把请求转换成AsyncHttpClient的参数，然后发出请求，然后设置一些方法回调，但是这里是异步的，而我是可能需要进行一些重试、熔断、降级措施的，所以我是把发出请求这个动作封装成了JDK的Supplier类这个lambda表达式，然后对这个表达式进行装饰者修饰，修饰完之后再执行这个lambda表达式，这里我就开始考虑修饰顺序了，我首先想的顺序是重试、熔断、降级，我觉得这个其实就是正常的逻辑顺序了，就是请求失败的话肯定先重试几次，如果重试几次后还失败，那就进行熔断，然后降级处理。但是后面我再添加隔离措施的时候，又感觉这样写死顺序不太好，因为我可能有这样的需求，就是我的隔离支持信号量隔离和线程池隔离，但也可以同时使用这两个，这个时候两者的装饰顺序就重要了，例如先使用线程池隔离，再使用信号量隔离，那就是先获取线程池资源，再获取信号量资源，先使用信号量隔离，再用线程池隔离，就是先获取信号量资源，再获取线程池资源，所以我应该把这个弹性配置的顺序交给用户去配置，但是我提供默认的推荐顺序，所以我具体的装饰顺序是读取配置文件来进行装饰的。 到了这里我基本框架其实就弄完了，然后我就开始思考一些其它的点。第一个想到的是鉴权，但是我又仔细思考了下，我觉得鉴权这个行为是很难做到统一的，就是后端模块我们是说不清的，可能有用户，有订单，有支付等等，每个模块可能需要单独有一套鉴权，想把它统一到网关去做我觉得能做，但是他肯定对上游请求有要求，对下游服务有入侵，而我的网关设计的最初思想就是对上游请求无要求，对下游服务无入侵，主打轻量高吞吐。所以我没在网关做默认的鉴权过滤器，但是因为我们的过滤器是SPI加载的，所以如果真要搞鉴权，用户其实是可以自定义过滤器去实现的。 然后我想到的是日志收集、监控这些，这个其实我也思考过，我觉得如果要引入这些功能，是需要依托于某个框架的，例如ELK这些，首先，这些类似的日志收集框架太多了，我很难说去选择一个出来提供服务，因为这样的话就代表使用者必须搭建对应的日志框架环境，我觉得没必要好像为了丰富我们的网关功能或者说让简历更丰富去做一些实际上不应该存在的东西，而且这些东西本身就是调用api传入数据这样子，其实并没有在技术上有太大的难点。而且我对我网关的最初设计的想法中还有一条就是说除了服务发现以外，我不再对其它框架产生依赖，所以我是连Spring的那一套框架都没引入的。 然后我又想到了跨域问题，我觉得这个其实是我需要实现的，这也算是网关一个比较经典的问题吧，解决方法也是比较简单通用，就是返回结果的请求头中添加一些信息，然后如果遇到Options类型的请求可以直接返回200状态码，不需要往下走了。 然后这大概就是我感觉我整个项目遇到的问题以及解决方法吧。 nacos配置变化，push还是pullPUSH 从代码分析可以看出： Nacos监听机制：在NacosConfigCenter中使用了configService.addListener()方法注册监听器，这是典型的push模式 实时回调：当Nacos配置发生变化时，Nacos服务端会主动推送变更通知到客户端，触发receiveConfigInfo()回调方法 被动接收：网关不需要主动轮询或查询配置中心，而是被动接收配置变更通知 这种push方式相比pull方式的优势是： 实时性更好，配置变更能立即推送到网关 减少了不必要的轮询请求，降低了网络和服务器负载 基于事件驱动，只有在配置真正发生变化时才触发更新 所以GraceGateway使用的是push方式来实现配置的动态更新。 配置动态更新配置更新到缓存的具体流程和代码如下： 触发点：当配置中心（如Nacos）的配置发生变化时，会触发NacosConfigCenter中的监听器回调方法receiveConfigInfo() 调用链： receiveConfigInfo()解析新的配置内容 调用RoutesChangeListener.onRoutesChange()方法 在Bootstrap类中实现的监听器会调用DynamicConfigManager.getInstance().updateRoutes(newRoutes, true) 具体实现类：DynamicConfigManager 核心方法：全量更新 1234567891011121314public void updateRoutes(Collection&lt;RouteDefinition&gt; routes, boolean clear) &#123; if (routes == null || routes.isEmpty()) return; if (clear) &#123; routeId2RouteMap.clear(); serviceName2RouteMap.clear(); uri2RouteMap.clear(); &#125; for (RouteDefinition route : routes) &#123; if (route == null) continue; routeId2RouteMap.put(route.getId(), route); serviceName2RouteMap.put(route.getServiceName(), route); uri2RouteMap.put(route.getUri(), route); &#125; &#125; 缓存数据结构： routeId2RouteMap：路由ID到路由定义的映射 serviceName2RouteMap：服务名到路由定义的映射 uri2RouteMap：URI路径到路由定义的映射 这样就完成了从配置中心变更到本地缓存更新的全过程。 如何用户使用配置中心还是本地配置文件通过分析代码，可以得出区分用户使用配置中心还是本地配置文件的方式： 判断依据：通过ConfigCenter对象的enabled属性来区分 - 默认值为false（在ConfigCenterConstant中定义） - 如果用户在配置文件中将其设置为true，则使用配置中心 - 如果保持默认值false，则使用本地配置文件 具体实现： - 在NacosConfigCenter和ZookeeperConfigCenter的init()和subscribeRoutesChange()方法中，都会先检查configCenter .isEnabled()条件 - 只有当配置中心启用时，才会执行配置中心相关的初始化和监听逻辑 配置文件示例： 在gateway.yaml中，用户可以通过以下配置启用配置中心： configCenter: enabled: true type: NACOS address: 127.0.0.1:8848 因此，系统通过检查configCenter.enabled属性来决定是使用配置中心还是本地配置文件。 优雅退出在Runtime.shutdown()里注册一个钩子方法 注册关闭钩子： - 在Bootstrap类中通过Runtime.getRuntime().addShutdownHook()注册了一个关闭钩子线程 - 当JVM接收到关闭信号时，会执行这个钩子线程中的container.shutdown()方法 分层关闭机制： - Container类实现了LifeCycle接口，统一管理所有核心组件的生命周期 - 关闭时按顺序调用： i. nettyProcessor.stop() - 停止Netty处理器 ii. nettyHttpServer.shutdown() - 关闭HTTP服务端 iii. nettyHttpClient.shutdown() - 关闭HTTP客户端 Netty优雅关闭： - NettyHttpServer使用eventLoopGroupBoss.shutdownGracefully()优雅关闭Netty线程组 - NettyHttpClient通过asyncHttpClient.close()关闭异步HTTP客户端 资源释放： - 各组件在shutdown方法中释放占用的资源 - 线程池使用executorService.shutdown()优雅关闭 这种分层、有序的关闭机制确保了网关在退出时能够处理完正在执行的请求，避免数据丢失和连接异常。 SPI机制原理 SPI是Java提供的一种服务发现机制，允许第三方为接口提供实现。核心原理： 约定：在META-INF&#x2F;services&#x2F;目录下创建以接口全限定名为文件名的文件 配置：文件内容为接口实现类的全限定名列表 发现：通过ServiceLoader.load()方法自动加载并实例化实现类 特点： 懒加载的，只有迭代时才会去初始化创建实例对象并且缓存起来，所以它又是动态，即 可以在程序运行时添加或删除实现类，而无需修改代码或重新编译 当然这只针对于多次调用Load 使用时，ServiceLoader.load(xxx接口.Class).返回ServiceLoader，它继承了迭代器 🔑 ServiceLoader 的两个迭代器 已加载服务提供者集合的迭代器（providers iterator） 保存已经实例化过的服务实现类对象。 每次 next() 先从这里取。 延迟查找的迭代器（lazy lookup iterator） 当第一个迭代器取完时，它才会去 META-INF/services/ 文件里查找还没加载过的实现类。 查到一个，就用反射创建实例，放入第一个迭代器的集合，下次就可以直接从集合里拿，不需要再查。 👉 这样就实现了 延迟加载：只在真正需要的时候才去找并实例化实现类，而不是一开始全加载。 1234public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return new ServiceLoader&lt;&gt;(Reflection.getCallerClass(), service, cl); &#125; 使用 Java SPI 时，需要注意以下几点： 接口必须是公共的，且只能包含抽象方法。 实现类必须有一个无参构造函数。 配置文件中指定的类必须是实现了相应接口的非抽象类。 配置文件必须放在 META-INF&#x2F;services 目录下。 配置文件的文件名必须为接口的全限定名。 整个链路 Netty底层处理链路 连接接收：NettyHttpServer通过Boss线程组接收客户端连接 通道初始化：为新连接创建ChannelPipeline，添加以下处理器： - HttpServerCodec：HTTP编解码器 - HttpObjectAggregator：聚合HTTP请求分段 - HttpServerExpectContinueHandler：处理HTTP 100 Continue请求 - NettyHttpServerHandler：自定义请求处理器 请求解码：HttpServerCodec将字节流解码为FullHttpRequest对象 事件传递：NettyHttpServerHandler接收channelRead事件，调用NettyProcessor处理 网关核心处理链路 Disruptor缓冲：DisruptorNettyCoreProcessor将请求放入RingBuffer队列 核心处理：NettyCoreProcessor.process()方法处理请求 上下文构建：ContextHelper.buildGatewayContext()构建GatewayContext 过滤器链构建：FilterChainFactory.buildFilterChain()创建服务特定的过滤器链 过滤器链处理 前置过滤： - CORS过滤器：处理跨域请求 - 流量控制过滤器：限流控制 - 灰度路由过滤器：灰度发布控制 - 负载均衡过滤器：选择服务实例 核心路由：RouteFilter发送请求到下游服务 后置过滤：按相反顺序执行过滤器的后置方法 路由和负载均衡 负载均衡：LoadBalanceFilter从DynamicConfigManager获取服务实例 策略选择：根据配置选择负载均衡策略（轮询、权重等） 实例选择：选定具体的服务实例并设置请求目标主机 请求路由：RouteFilter通过AsyncHttpClient发送HTTP请求 响应返回链路 响应处理：异步获取下游服务响应 响应构建：ResponseHelper.buildHttpResponse()构建Netty响应 连接管理： - 短连接：writeAndFlush().addListener(ChannelFutureListener.CLOSE) - 长连接：设置Keep-Alive头并发送响应 资源释放：Netty自动释放FullHttpRequest引用计数","path":"2025/07/12/项目/自研网关/难点/","date":"07-12","excerpt":"","tags":[]},{"title":"调研","text":"得物的自研API网关 得物自研API网关实践之路 b站的API网关 qq的流量网关 长连接网关技术专题(五)：喜马拉雅自研亿级API网关技术实践_Netty_JackJiang_InfoQ写作社区 GitHub - raining0109&#x2F;LiteGateway: 基于Netty、Nacos实现的自研轻量级网关 https://apisix.apache.org/zh/blog/2025/04/27/apisix-honor-gateway-practice-in-massive-business/","path":"2025/07/12/项目/自研网关/调研/","date":"07-12","excerpt":"","tags":[]},{"title":"spring mongodb converter","text":"通过预实例化+预转换，解决Spring Data MongoDB 在首次加载实体类时的反射初始化锁问题 问题所在： 当你使用spring data mongodb的api操作mongodb时，例如 mongoTemplagte.findbyId() 该方法内部会去调用 MongoPersistentEntity&lt;?&gt; entity &#x3D; mappingContext.getPersistentEntity(entityClass); 而getPersistentEntity这个方法会加写锁去注册 TypeInformation 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495@Nullable @Override public E getPersistentEntity(TypeInformation&lt;?&gt; type) &#123; Assert.notNull(type, &quot;Type must not be null&quot;); try &#123; read.lock(); Optional&lt;E&gt; entity = persistentEntities.get(type); if (entity != null) &#123; return entity.orElse(null); &#125; &#125; finally &#123; read.unlock(); &#125; if (!shouldCreatePersistentEntityFor(type)) &#123; try &#123; write.lock(); persistentEntities.put(type, NONE); &#125; finally &#123; write.unlock(); &#125; return null; &#125; if (strict) &#123; throw new MappingException(&quot;Unknown persistent entity &quot; + type); &#125; return addPersistentEntity(type).orElse(null); &#125;------------------------//addPersistentEntity //--------------------------------- /** * Adds the given &#123;@link TypeInformation&#125; to the &#123;@link MappingContext&#125;. * * @param typeInformation must not be &#123;@literal null&#125;. * @return */ protected Optional&lt;E&gt; addPersistentEntity(TypeInformation&lt;?&gt; typeInformation) &#123; Assert.notNull(typeInformation, &quot;TypeInformation must not be null&quot;); try &#123; read.lock(); Optional&lt;E&gt; persistentEntity = persistentEntities.get(typeInformation); if (persistentEntity != null) &#123; return persistentEntity; &#125; &#125; finally &#123; read.unlock(); &#125; E entity; try &#123; write.lock(); Optional&lt;E&gt; userTypeEntity = persistentEntities.get(typeInformation.getUserTypeInformation()); if (userTypeEntity != null) &#123; persistentEntities.put(typeInformation, userTypeEntity); return userTypeEntity; &#125; entity = doAddPersistentEntity(typeInformation); &#125; catch (BeansException e) &#123; throw new MappingException(e.getMessage(), e); &#125; finally &#123; write.unlock(); &#125; // Inform listeners if (applicationEventPublisher != null) &#123; applicationEventPublisher.publishEvent(new MappingContextEvent&lt;&gt;(this, entity)); &#125; return Optional.of(entity); &#125; 而jdk的写锁就有问题 获取写锁失败的线程会一直阻塞，而不是直接返回 总结： 通过「预实例化 + 预转换」的办法，解决了 Spring Data MongoDB 在首次加载实体类时的反 射初始化锁问题，提升了项目首次数据访问时的并发性能 解决方案： ps：https://blog.csdn.net/dch9210/article/details/116131039","path":"2025/07/07/mongodb/spring mongodb converter/","date":"07-07","excerpt":"","tags":[]},{"title":"为什么要做这个项目","text":"现在大家用的都是业务项目，例如外卖、商城、各种秒杀套壳的业务项目，于是我就想着去做个底层的、自己动手研发的技术项目，经过一番思考，最终选择了网关 自研网关能够根据自己的想法，实现网关的功能，根据自己的想法去从0到1构想一个项目。是一个很好锻炼自己项目设计能力、问题解决能力、编码能力的一个机会 我对我网关的要求： 轻量：网关应该主要是负责解耦客户端和服务端的，是两者之间的桥梁，其职责主要就是转发HTTP请求，同时做一些增强功能，除服务发现之外，不应该与其它东西产生依赖 高性能：使用Netty + 全异步链路进行开发 无入侵：下游服务对网关是无感知的。网关对下游服务没有代码入侵，对上游请求无要求 代码简单：代码做到高可读性，代码轻量，代码尽量压进4000行源码 。。。。。。","path":"2025/07/06/项目/自研网关/为什么要做这个项目/","date":"07-06","excerpt":"","tags":[]},{"title":"注册中心对比","text":"微服务注册中心技术选型：5种主流注册中心，哪个最香？-腾讯云开发者社区-腾讯云 作为注册中心，可用性的要求要高于一致性！ zookeeper在 CAP 模型中，Zookeeper整体遵循一致性（CP）原则，即在任何时候对 Zookeeper 的访问请求能得到一致的数据结果，但是当机器下线或者宕机时，不能保证服务可用性。 那为什么Zookeeper不使用最终一致性（AP）模型呢？因为这个依赖Zookeeper的核心算法是ZAB，所有设计都是为了强一致性。这个对于分布式协调系统，完全没没有毛病，但是你如果将Zookeeper为分布式协调服务所做的一致性保障，用在注册中心，或者说服务发现场景，这个其实就不合适。 zookeeper watch机制的推拉模式：","path":"2025/07/06/项目/分布式定时器/k-job/注册中心对比/","date":"07-06","excerpt":"","tags":[]},{"title":"享元模式","text":"达到复用对象的目的，减少对象的频繁创建 对象池里的对象应该是线程安全的，且无状态的，因为需要给外部频繁调用 案例： 1.Integer cache池 2.线程池 3.对象池 实战 kafka内存池","path":"2025/07/05/设计模式/常规/享元模式/","date":"07-05","excerpt":"","tags":[]},{"title":"入门","text":"worker和server之间的关系在K-Job分布式任务调度框架中，server和worker是两个核心组件，它们之间存在明确的分工和协作关系。 Server和Worker的定义**Server（调度服务器）**是负责任务调度和管理的核心组件。 1 它接收来自Producer的任务创建&#x2F;修改请求，进行任务调度，并将任务分发给Worker执行。 2 **Worker（任务执行器）**是实际执行任务的组件，运行在需要执行任务的应用程序中。 3 Worker通过NameServer发现可用的Server，并接收Server分发的任务进行执行。 4 它们之间的关系1. 注册与发现关系Server和Worker都需要向NameServer注册自己的信息： Server注册：Server启动时向NameServer注册，提供自己的IP地址，使自己可被Worker和Producer发现。 5 Worker订阅：Worker向NameServer订阅，获取可用的Server列表，并建立心跳机制。 6 2. 负载均衡关系NameServer采用”最小调度次数策略”来平衡Server和Worker之间的负载： NameServer记录每个Server的调度次数，将Worker分配给调度次数最少的Server。 7 当Worker数量超过阈值时，系统会自动拆分Worker组并重新分配到不同的Server。 8 3. 任务调度关系Server负责将任务分发给Worker执行： Server从消息队列中获取任务，选择合适的Worker进行任务分发。 9 Worker接收任务后执行，并向Server报告执行状态。 10 4. 心跳监控关系系统通过心跳机制维护Server和Worker的健康状态： Server和Worker都定期向NameServer发送心跳，NameServer通过ClientStatusManager跟踪它们的活跃状态。 11 超时的Server或Worker会被自动清理。 12 NotesServer和Worker的这种设计实现了任务调度的分离：Server专注于调度逻辑和任务管理，Worker专注于任务执行，通过NameServer实现服务发现和负载均衡。这种架构支持动态扩缩容，能够很好地适应大量并发任务的场景。 Wiki pages you might want to explore: Architecture (karatttt&#x2F;k-job) Data Synchronization (karatttt&#x2F;k-job) Client Management (karatttt&#x2F;k-job)","path":"2025/06/27/项目/分布式定时器/k-job/入门/","date":"06-27","excerpt":"","tags":[]},{"title":"grpc入门","text":"底层通信框架","path":"2025/06/27/项目/分布式定时器/k-job/grpc入门/","date":"06-27","excerpt":"","tags":[]},{"title":"Nacos一致性协议:Distro与Raft协议","text":"","path":"2025/06/25/项目/分布式定时器/k-job/Nacos一致性协议!Distro与Raft协议/","date":"06-25","excerpt":"","tags":[]},{"title":"整体架构","text":"各个组件间的交互 https://deepwiki.com/search/serverworker_575a4ef6-9fd0-4ef9-9a90-68ce389aa975","path":"2025/06/25/项目/分布式定时器/k-job/整体架构/","date":"06-25","excerpt":"","tags":[]},{"title":"自研nameServer","text":"为什么要自研，市面上的不能直接拿来用吗？ 你自研的有什么优点吗？你当时是怎么设计的？ heartBeat？","path":"2025/06/25/项目/分布式定时器/k-job/自研nameServer/","date":"06-25","excerpt":"","tags":[]},{"title":"源码","text":"录制：生生的快速会议 日期：2025-06-16 20:44:17 录制文件：https://meeting.tencent.com/crm/2kedrqnY69 访问密码：CL27 转写：转写_生生的快速会议 日期：2025-06-16 21:03:09 转写文件：https://meeting.tencent.com/ctm/2qvEaQQObe 访问密码：8YEB 核心概念：topic，partition，replics（副本） partition物理概念，topic逻辑概念 kafka快是指什么，是指高效传输海量数据的能力 基础：磁盘顺序IO 和 零拷贝 粘性分区 nextPartition 在途请求 request-&gt;response （同时请求） 架构概念总结生产者相关topic 代表就一队列，为了提供一个topic queue的吞吐量，就对一个topic里的数据进行了分区（partition） 生产者和消费者实际上操作的是分区 一台Kafka服务器叫做Broker，Kafka集群就是多台Kafka服务器： 消费着相关多个consumer组成一个group 特性天生分布式","path":"2025/06/16/kafka/源码/","date":"06-16","excerpt":"","tags":[]},{"title":"手撕生产者消费者模型","text":"面试官让我手写一个生产者消费者模式？-腾讯云开发者社区-腾讯云","path":"2025/06/13/手写系列/手撕生产者消费者模型/","date":"06-13","excerpt":"","tags":[]},{"title":"升级","text":"自研分布式任务调度框架项目描述项目描述： 自研分布式任务调度框架，作为企业级任务调度中心，用于管理和控制大规模定时任务的创建、调度和执行。基于gRPC+Netty搭建高性能通信核心，使用自研消息队列实现全异步任务处理。实现高效的任务调度、负载均衡、服务发现以及容错保护等多种功能，确保系统在高并发下的稳定性和可扩展性。 我负责的部分： • 针对服务注册与发现实现自研NameServer，基于Distro协议实现AP一致性，支持动态服务发现和负载均衡 • 针对任务处理构建异步消息队列架构，实现任务创建、参数变更、状态同步等功能的异步处理。 • 实现多种负载均衡策略，如最小调度次数策略、动态分组拆分，支持Worker节点动态上下线和智能分配。 • 实现框架弹性扩展，支持应用级别锁隔离、任务重试机制、多级延时队列、死信队列等容错功能。 • 实现了高精度任务调度，基于时间轮算法实现毫秒级定时任务调度，支持CRON表达式和动态参数调整。 • 基于gRPC+Protobuf设计可扩展通信协议，支持用户自定义任务处理器、调度策略、负载均衡算法等扩展功能 https://deepwiki.com/karatttt/k-job/2-architecture","path":"2025/06/13/项目/分布式定时器/k-job/升级/","date":"06-13","excerpt":"","tags":[]},{"title":"网盘文件秒传机制checksum","text":"快速验证文件是否已存在于服务器上的技术","path":"2025/06/09/场景题/网盘文件秒传机制checksum/","date":"06-09","excerpt":"","tags":[]},{"title":"滚动日志收集方法Flume taildir模式","text":"系统未改动之前是通过 tail -f opt.log来实时滚动地查看日志文件 ps：exec模式是指在收集时通过不断执行 tail -f opt.log模式 但系统经过了一个同事的调优后，发现不生效了 之前的日志都是统一写入一个文件里，但想着随着业务的增长，日志文件体量肯定很大，就想着能不能优化成日滚动的模式 日滚动： 但每天到凌晨时发现就会tail -f opt.log命令会失效 我们是以为只要文件的文件名相同 命令还是可以生效的，没想到tail -f要求的是你的文件描述符相同才会生效 怎么解决 1.使用 tail -F app.log 会检测到文件被替换（即使 inode 改变）并自动重新打开新的 app.log 2.使用Flume taildir 读日志，它会保存文件读出的偏移量","path":"2025/06/09/场景题/滚动日志收集方法Flume taildir模式/","date":"06-09","excerpt":"","tags":[]},{"title":"数据库多数据源怎么配置","text":"最简单的使用框架自配的，如mybatis-plus，mybatis-flex https://baomidou.com/guides/dynamic-datasource/ 如何自己实现？","path":"2025/06/04/场景题/数据库多数据源怎么配置/","date":"06-04","excerpt":"","tags":[]},{"title":"TCP四次挥手","text":"双方都可以主动关闭连接，调用 close() 客户端调用CLOSE主动关闭连接，此时会发送一个TCP首部的FIN标志位被置为1的报文，即FIN报文，之后客户端就会进入FIN_WAIT_1的状态 服务端接受到这个FIN报文后，会回一个ACK，并进入CLOSE_WAIT状态 客户端收到这个ACK后，会进入FIN_WAIT_2的状态 等待服务端处理好数据后（这时候TCP连接处于半连接半关闭状态，但还是可以互传数据），调用那个CLOSE函数，也向客户端发送FIN报文，之后服务端就会进入LAST_ACK 状态 客户端收到服务端的 FIN 报文后，回一个ACK，之后进入TIME_WAIT状态 服务端收到ACK后，进入CLOSE状态，即服务端这时候就已经关闭连接了 客户端等待2MSL秒后就自动进入CLOSE状态 为什么需要四次挥手 客户端发送FIN后，仅仅告诉服务端我不再发送数据了，但接受数据还是可以的 服务端接受到FIN后，会给客户端发一个ACK，而服务端可能还会有数据没发送，则等数据发完后才会给客户端发一个FIN，表示我也要关闭连接了 而客户端需要回复第四次挥手，服务端接受到后才知道对方连接额关闭了，不然服务端都不知道客户端是否接受到了第三次挥手，就无法正常关闭连接 服务端发送ACK后，需要等数据全部传输完再发送FIN，所以需要四次挥手的。但是在没有数据发送 且 开启了TCP延迟确认机制下（默认情况下），服务端的ACK和FIN是可以合并的，也就是只需要三次挥手的 TCP延迟确认机制： 当有 为什么要有TIME_WAIT？ 主动发起关闭请求的一方，才会有TIME_WAIT状态 需要这个状态的原因： - 防止历史中的数据，被后面相同四元组的连接误收，这个时间足以让数据在网络中丢失，再出现的数据包一定是新建立连接产生的 - 保证 被动关闭的一方，能被正确地关闭。等待足够的时间以确保最后的ack能让接收方接受到，从而帮助其正常优雅地关闭，即让客户端尽量把数据发完 为什么TIME_WAIT等待的时间是2MSL？ MSL：最大段生存期 （ MSL） 是指 TCP段在互联网络中可以存在的时间。1981 被定义为 2分钟。 最新的内核已经被优化为3.5s 为什么TCP4次挥手时等待为2MSL？ - Gypsophila N的回答 - 知乎 https://www.zhihu.com/question/67013338/answer/1032098712 这个我觉得一个主要原因就是要保证此次TCP连接的所有报文都能在网络中消失，也就是避免前后两个使用相 同四元组的前一个TCP连接的报文干扰到后一个连接。 假设主动关闭方为A，被动关闭方为B A发送ack后，这个ack最坏情况下MSL后到达B，此时B因为没收到ack，会根据ROT机制重传FIN，那么这个 FIN最坏会在1 MSL后消失。因此从A发送ack后，A就需要等待TimeWait 即 2MSL，来保证A发送的最后一个 ack和B发送的最后一个FIN可以在网络中消息 还有一点我看网上说还有就是保证被动关闭方能够接受到自己FIN的ack，我觉得这点是不对的。 假如现在 A 收到 FIN 之后，为了实现目标 1，即保证 B 能够收到自己的 ACK 报文。那么 A 完美的等待时间不是 2MSL，而应该是从 B 发送第一个 FIN 报文开始计时到它最后一次重传 FIN 报文这段时长加上 MSL。但这个计算方式过于保守，只有在所有的 ACK 报文都丢失的情况下才需要这么长的时间；另外，第一个目标虽然重要，但并不十分关键，因为既然已经到了关闭连接的最后一步，说明在这个 TCP 连接上的所有用户数据已经完成可靠传输，所以要不要完美的关闭这个连接其实已经不是那么关键了。因此，（我猜）RFC 标准的制定者才决定以网络丢包不太严重为前提条件，然后根据第二个目标来计算 TIME_WAIT 状态应该持续的时长。 TIME_WAIT过多会怎样？ 1.占用系统资源，像fd,cpu,内存等等 2.占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，当然我们可以设置 TIME_WAIT过多怎么办？ 处于TIME-WAIT状态的TCP连接过多主要会导致三个问题。 第一个问题是资源占用过多的问题，包括端口号占用，内存占用等。 第二个问题是性能下降，包括系统负担加重，响应时间变长等。 第三个问题是连接问题，包括创建新连接可能失败，连接传输不稳定等。 而解决思路也有很多。 第一种思路是尽可能使用长连接和连接池，避免连接频繁创建和关闭。 第二种思路是调整 TIME_WAIT 的参数。 第三种思路是优化操作系统，例如说增大端口号范围，增大内存或者优化内存使用，以便可以支持更多的 TCP 连接。 但在实际场景中，我们一般都是利用谁主动关闭谁才有TIME_WAIT状态这个特性来避免，不让服务端主动关闭，而是浏览器或者客户端 服务端大量出现TIME_WAIT? 说明服务端主动断开了连接，只有主动关闭方才存在这个状态 一般有以下情况，属于正常的情况 1.HTTP短连接，即一个HTTP为一个TCP连接，不存在复用的情况 2.HTTP长连接超时 3.HTTP长连接的数量达到上限 双方同时断开连接？ 如何判断是主动断开的连接，调用了close()函数","path":"2025/06/03/计网/TCP和UDP/TCP四次挥手/","date":"06-03","excerpt":"","tags":[]},{"title":"TCP三次握手","text":"TCP通过三次握手建立连接，随后的数据通信通过该连接进行： 装逼：一个是讨论三次握手机制意味着 TCP 创建连接非常麻烦，所以需要池化技术；另外一个是讨论为啥恰好是三次握手，而不是两次握手，也不是四次握手 TCP三次握手是指建立一个可靠的TCP连接的过程。它的主要目的是让通信双方（客户端和服务器）确认彼此的接收和发送能力，并协商一些关键参数，确保数据传输的可靠性。 最开始，服务端要启动之后，要监听某个端口。 当客户端准备连接服务端的时候，发送 SYN 报文，并且带上自己的初始化序列号（ISN），而后进入 SYN－SENT 状态。这是第一次握手。 服务端收到 SYN 报文之后，会响应一个 SYN－ACK 报文，并且带上自己的初始化序列号（ISN），而后进入 SYN－RECV 状态。这是第二次握手。 当客户端收到 SYN－ACK 报文之后，发送一个 ACK 报文，客户端进入 ESTABLISHED 状态。当服务端收到了 ACK 报文之后，进入了 ESTABLISHED 状态。这是第三次握手。 完成这三次握手之后，客户端和服务端就可以互相发送数据了。 简述SYN，SYN-ACK，ACK 重点三次握手的状态变迁 引导TCP状态； 池化？ 从这个过程上也可以看到，三次握手这个过程虽然可靠性很强，但是性能很差。一方面三次握手过程增加了连接建立的延迟，尤其是在网络状况不佳的情况下；另外一方面是每次建立连接都需要消耗系统资源（如文件描述符、内存等）。 所以在当下来说，基本上使用 TCP 的时候都会使用池化技术，规避 TCP 连接频繁创建和销毁的 风险。 为什么是三次握手？ 当然，我们也可以从一个更加本质的角度去理解三次握手的过程。对于 TCP 连接来说，初始化的时候有两个关键的点：确认网络是连通，同步初始化序列号，即 ISN。 TCP 是一个全双工通信的协议，这就意味着服务端要确认客户端的 ISN，客户端也要确认服务端的 ISN。因此从设计上来说是四个步骤：客户端发送 SYN 和 ISN，服务端确认，服务端发送 SYN 和 ISN，客户端确认。只不过这逻辑上的第二和第三个步骤，可以合并为一个步骤，也就是服务端在确认的时候，也顺手把自己的 ISN 返回去了。 这是三次握手设计的根源。从这个角度出发，就很容易理解为什么不能是两次握手，因为两次握手只是建立了客户端到服务端的单向通信，而服务端没有收到客户端的 ACK，它并不能确定客户端能否正确处理自己发过去数据，因此服务端到客户端这一个方向上的通信并没有建立。 简述两次握手，客户端到服务端单向通信；三次握手，客户端到服务端双向通信； 重点为什么一定是三次握手； 第三次握手时可以发送数据吗？ 可以，这个就用到了TCP Fast Open机制，即第三次握手的时候可以将数据和ack一起携带过来 当然，这要客户端和服务端都支持 TFO 机制。 排除这种机制之后，也就是如果客户端发送第三次握手，而是直接发送数据，也就是报文里面不带 ACK 标记位。这种情况下，服务端会丢弃报文，并且返回 RST 报文，关闭连接。 TCP 协议是明确要求一定要完成三次握手才能正常通信的。 简述ACK带数据，TFO；霸王硬上弓，直接丢弃； 重点TFO机制；没有完成握手就发送数据，会发生什么； 引导TFO； 为什么不是四次握手？ 因为三次握手已经可以确认双方的发送接收能力正常，双方都知道彼此已经准备好，而且也可以完成对双方初始序号值得确认，也就无需再第四次握手了。 这个问题要从 TCP 的全双工通信角度开始说，全双工通信也就是意味着要做到客户端能把数据发到服务端，服务端也能把数据发到客户端。 因此理论上来说，不考虑什么优化的话，就是四次握手。也就是客户端发到服务端，服务端确认，这是两次。服务端发到客户端，客户端确认，也是两次。 而后就会发现，其中服务端确认和服务端发送到客户端的两次可以合并为一次，节省一次。因此最终的成果就是三次握手就够了。 SYN 洪水攻击 - 建立连接时超时了。Client发出syn后，Server接受到了，发给SYN-ACK后但这时候Client下线了怎么办？ 那么这个连接就处于一个中间状态，没成功也没失败。收不到Client的ack一段时间后在Linux下，Server默认会采用一个重试措施，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，而第5次后得等32秒才能停止等待，故总共是63s，这个时候tcp才会断开 - SYN Flood攻击。基于上述情况，就有人利用这种机制，恶意攻击你，发一个syn后，客户端下线，让你的syn连接的队列耗尽（syn队列就是存放那些半连接状态的连接的）。于是，Linux下给了一个叫**tcp_syncookies**的参数来应对这个事——当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后**服务端可以通过cookie建连接（即使你不在SYN队列中）**。 - 请注意，请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为，synccookies是**妥协版的TCP协议**，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择，第一个是：**tcp_synack_retries** 可以用他来**减少重试次数**；第二个是：**tcp_max_syn_backlog**，可以**增大SYN连接数**；第三个是：**tcp_abort_on_overflow** **处理不过来干脆就直接拒绝连接了**。 SYN 洪泛攻击是一种 DDoS 攻击，攻击者发送大量的 SYN 包，但是并不响应服务端返回来的 SYN- ACK包 这样造成的后果是服务端需要消耗资源维护这些半开连接，并且因为没有收到客户端的 ACK 包，所以会不断重试，进一步加重了资源消耗。 SYN 洪泛攻击抵御起来，有多种手段。 最重要的手段就是 SYN Cookie 技术，也就是服务端在收到SYN包时，不立即分配资源，而是生成一个“cookie”作为初始序列号返回给客户端。客户端在回复ACK包时，必须包含这个“cookie”，服务器验证通过后才分配资源。 还有一些治标不治本的手段，例如说增大 TCP 连接队列大小、调整 TCP&#x2F;IP 协议栈参数、延缓 TCB 分配等。 当然，我个人推荐的是不要自己去搞 DDoS 防范，直接购买成熟的服务性价比最高。 简述SYN Cookie 比较好，其余治标不治本 引导SYN Cookie技术 最后一次握手服务端一直收不到来自客户端的ACK，会怎么样 一句话就能说清楚，服务端会重试，直到重试超出最大次数，给客户端发RST报文后，则会关闭连接。","path":"2025/06/03/计网/TCP和UDP/TCP三次握手/","date":"06-03","excerpt":"","tags":[]},{"title":"ARP协议","text":"局域网中设备之间交换IP和MAC地址关系的协议 局域网的某个设备想知道某个IP地址对应的设备是谁，它就会在局域网里广播一个ARP请求，询问它是谁。然 后目标设备就会把自身的IP地址和MAC地址返回回去，原设备接受到后可以把地址存储到ARP缓存表里，方 便后续使用","path":"2025/06/03/计网/ARP协议/","date":"06-03","excerpt":"","tags":[]},{"title":"wireshake使用","text":"基本使用【网络顶级掠食者 Wireshark抓包从入门到实战】https://www.bilibili.com/video/BV12X6gYUEqA?vd_source&#x3D;cae07b1dce3e6abe67fcf72c43031ede 过滤器： 显示器和捕获过滤器，用来筛选我们想要的信息 显示过滤器，哪里想捕获点哪里 捕获过滤器，数据量大的情况下性能更好 实战wiresake分析TCP三次握手","path":"2025/06/03/计网/wireshake使用/","date":"06-03","excerpt":"","tags":[]},{"title":"UDP访问DNS","text":"客户端发送DNS访问请求 当客户端需要解析域名时，就会构造一个DNS（应用层的协议）请求，并通过UDP协议将其发送到DNS 服务器进行域名解析。一般是本地的DNS缓存或者配置的比如ISP的DNS服务器或者一些公共DNS服务器 比如google的8.8.8.8 查询请求的构造 DNS请求一般包含什么 标识符：请求唯一ID，由客户端发送，服务端响应时返回 标志：标志字段，包括查询，响应 问题计数：表示查询请求中的问题数 问题区域：查询的域名 客户端发送UDP数据包","path":"2025/06/02/计网/UDP访问DNS/","date":"06-02","excerpt":"","tags":[]},{"title":"java Reactor","text":"早期tomcat采用的网络IO模型：一个连接即一个线程 Java NIO：用尽量少的线程管理尽量多的网络连接（原生的NIO是 单线程管理多个连接） Reactor响应式编程 单线程Reactor 多线程Reactor Reactor和Java NIO的关系 1.对NIO进行了扩展，NIO对多线程支持不好，得自己封装","path":"2025/05/30/JUC/java Reactor/","date":"05-30","excerpt":"","tags":[]},{"title":"推特混合架构，平衡利弊的优雅设计","text":"推特两个业务：发布推文和主页时间线 两种方案： 读扩散 不足：读取压力大 写扩散 写要比读的好，因为发推的频率要比主页刷新的频率低很多 不足：有些up的博主粉丝量大。写入的粉丝收件箱的数量很大，写入请求量级巨大 在推特的例子中，粉丝数是一个重要参数，推特采用了两种架构的结合","path":"2025/05/30/场景题/推特混合架构，平衡利弊的优雅设计/","date":"05-30","excerpt":"","tags":[]},{"title":"责任链模式","text":"基于责任链模式实现某跨服活动，依次校验红包、库存、物流等正向触点，基于Spring的Bean发现实现高扩展设计，使用单例模式减少每次执行时的内存开销，线上用户订单留存率提升约4%：","path":"2025/05/27/设计模式/常规/责任链模式/","date":"05-27","excerpt":"","tags":[]},{"title":"协程","text":"外部actor查询时通过launch()协程来优化handler方法，实现一个actor同时处理多条查询请求。因为actor本 身就只能处理一条命令","path":"2025/05/27/实习/游族网络/新的知识/协程/","date":"05-27","excerpt":"","tags":[]},{"title":"如何为Java程序优雅增加功能开关","text":"SPI机制 Spring Boot @ConditionalOnProperty Spring AOP PS：isEnable（） 如何感知到配置文件内容的变化 1.结合配置中心 2.将变量的修改应接口的方式暴露出去 出口网关 API网关配置 自适应配置","path":"2025/05/25/场景题/如何为Java程序优雅增加功能开关/","date":"05-25","excerpt":"","tags":[]},{"title":"日志文件为什么要写在本地？","text":"可以先写本地，再由统一的日志收集程序去读取并写到库里","path":"2025/05/25/场景题/日志文件为什么要写在本地？/","date":"05-25","excerpt":"","tags":[]},{"title":"Spring Validation动态校验规则","text":"利用Spring validation的分组校验功能可以实现 同一个请求对象，同一份校验注解，不同接口，不同的校验逻辑。 User 1234567class User&#123; //groups 指定适用规则 @Null(groups=Groups.Insert.class) @NotNull() private Long ID; private String name;&#125; GROUP 1234interface Groups&#123; interface Insert&#123;&#125; interface Update&#123;&#125;&#125; Controller 12void methodA(@Validated(Groups.Insert.class) String xx) gobal exception handler","path":"2025/05/25/场景题/Spring Validation动态校验规则/","date":"05-25","excerpt":"","tags":[]},{"title":"转转亿级核心表如何优雅扩展字段？","text":"就是那些灵活变化的字段独立出去变成一张表，主表为固定不变的字段 但ext表的数据增长量会比较大，针对这个情况可做分表（按id键分） 查询的话，基于ES进行全文查询，插入DB后同步到es，这个过程可以异步的（mq,flinkCDC监听binlog）等 方式进行处理","path":"2025/05/25/场景题/转转亿级核心表如何优雅扩展字段？/","date":"05-25","excerpt":"","tags":[]},{"title":"转转团队批量插入终极优化技巧","text":"PS： mp的saveBatch原理 rewriteBatchStatements&#x3D;true的作用： 直接在数据库连接后加上参数","path":"2025/05/25/场景题/转转团队批量插入终极优化技巧/","date":"05-25","excerpt":"","tags":[]},{"title":"为什么禁止事务嵌套消息","text":"就是禁止 事务里禁止进行远程调用这种行为 用户下单后会给其补发积分，补发积分是订单模块通过发消息实现的 这里会有个问题，就是权益模块在反查订单时，如果给权益发消息发积分是异步调用就可能会权益系统出现订 单查不到的问题，因为事务的隔离级别的问题（事务没提交，不是同一事务下，是无法查到没提交的事务的） 如果是同步调用的问题，就必查不到的 要怎么解决呢？rpc调用这种事情是不能放在事务内的","path":"2025/05/25/场景题/为什么禁止事务嵌套消息/","date":"05-25","excerpt":"","tags":[]},{"title":"基础","text":"MongoDB是面向文档的NoSQL数据库 存储结构 文档：MongoDB存储的基本单位，存储类型为BSON，json的二进制，文本格式和json差不多 特性 集合（相当于表，但结构无约束的），文档（即 记录） 支持多种索引 支持ACID，4.2还支持分布式事务（早期版本中仅支持单文档事务，但从 4.0 版本开始支持多文档事 务） 支持 mapreduce，通过分治的方式完成复杂的聚合任务 CRUD：直接使用Spring JPA提供的API spring-data-examples&#x2F;mongodb&#x2F;kotlin&#x2F;src&#x2F;test&#x2F;kotlin&#x2F;example&#x2F;springdata&#x2F;mongodb&#x2F;people&#x2F;TemplateTests.kt at main · spring-projects&#x2F;spring-data-examples","path":"2025/05/24/mongodb/基础/","date":"05-24","excerpt":"","tags":[]},{"title":"任务池","text":"","path":"2025/05/24/实习/游族网络/任务池/","date":"05-24","excerpt":"","tags":[]},{"title":"遇到的困难/解决","text":"首先是新入职场的Landing过程： 因为游族属于我的第一段实习，然后刚进去也是什么都不懂，然后虽然有leader，mentor向我介绍了部门的大体情况，但是这也只能让我对部门有大致的了解，然后部门内的各个平台也是让我眼花缭乱的，日志平台如何操作查看日志，监控平台如何监控线上机器情况，拿到执行失败的请求日志traceId如何进行排查，如何远程debug调试代码，代码平台的PR的提交流程规范这些。然后就是各种内部术语啊，比如说业务接口、服务接口、肉机等等术语，然后一开始我对这些都是完全没概念的，这些也确实影响了我的工作效率。 而且进去，框架也是公司自研的，游戏服务端开发","path":"2025/05/24/实习/游族网络/遇到的困难!解决/","date":"05-24","excerpt":"","tags":[]},{"title":"实习感受和收获","text":"实习要写好简历应该思考以下问题 解决了什么问题，为什么要这么做，项目用到的技术栈是什么，框架是什么，是开源还是自研的， 自研的带来了什么收益。你这个产出的技术方案是什么，你做了哪些调研 部门的业务是什么，你们是怎么和上下游进行对接的，你们部门的价值是什么","path":"2025/05/24/实习/游族网络/实习感受和收获/","date":"05-24","excerpt":"","tags":[]},{"title":"部门机器","text":"","path":"2025/05/24/实习/游族网络/部门机器/","date":"05-24","excerpt":"","tags":[]},{"title":"产出","text":"基于责任链模式实现跨服活动奖励结算流程，依次处理输出排行、击杀奖励、VIP加成等结算触点，基 于配置驱动实现高扩展设计，使用Kotlin单例对象减少执行开销， 线上结算流程配置灵活性提升显著 基于kotlin的协程实现worldactor内部并发查询世界数据，优化查询性能 优化战斗服务，增加熔断器功能，防止因战斗节点导致级联失败 策划配置表，xlxs-streamer caffine Spring data mongodb 初始化数据时 锁性能问题 任务活动框架重构 由于线上bug问题，需要对任务活动框架重构。 活动分类拆分装成不同Map，然后异步化改造，支持任务编排","path":"2025/05/24/实习/游族网络/产出/","date":"05-24","excerpt":"","tags":[]},{"title":"akka框架","text":"","path":"2025/05/24/实习/游族网络/新的知识/akka框架/","date":"05-24","excerpt":"","tags":[]},{"title":"任务条设置","text":"","path":"2025/05/24/实习/游族网络/任务条设置/","date":"05-24","excerpt":"","tags":[]},{"title":"游戏服务端架构一些见解","text":"关于MMO游戏服务器的思考 - 沉迷于学习，无法自拔^_^ https://zhuanlan.zhihu.com/p/266573590 https://github.com/mikai233/antares CppGuide&#x2F;articles&#x2F;游戏开发专题&#x2F;4关于游戏服务端架构的整理.md at master · balloonwj&#x2F;CppGuide https://skywind.me/blog/archives/2719 codedump的网络日志 https://github.com/gonglei007/GameDevMind/tree/main?tab=readme-ov-file 腾讯游戏4名技术专家详解：《御龙在天移动版》服务器性能优化 - GameRes游资网 宝藏 https://github.com/landon30/Bulls?tab=readme-ov-file akka游戏框架 https://juejin.cn/post/7458548238276853798 java游戏框架 https://github.com/jwpttcg66/NettyGameServer?tab=readme-ov-file 百万游戏 https://zhuanlan.zhihu.com/p/341855913 https://www.zhihu.com/column/codingart 热更新 设计模式 偷产出方法论 对于一些已经稳定运营有些年头的游戏，活动系统是最好编的，如果资料不是很多，可以参考电商的用户增长 业务。","path":"2025/05/24/实习/游族网络/新的知识/游戏服务端架构一些见解/","date":"05-24","excerpt":"","tags":[]},{"title":"线上jvm内存排查","text":"PlayActor","path":"2025/05/22/实习/游族网络/线上jvm内存排查/","date":"05-22","excerpt":"","tags":[]},{"title":"actor","text":"https://zhuanlan.zhihu.com/p/427806717","path":"2025/05/22/JUC/actor/","date":"05-22","excerpt":"","tags":[]},{"title":"如何实现无锁队列","text":"","path":"2025/05/19/JUC/如何实现无锁队列/","date":"05-19","excerpt":"","tags":[]},{"title":"#和$","text":"","path":"2025/05/19/Mybatis/#和$/","date":"05-19","excerpt":"","tags":[]},{"title":"自定义注解","text":"","path":"2025/05/14/项目/AI学生发展性评价系统/自定义注解/","date":"05-14","excerpt":"","tags":[]},{"title":"窗口函数","text":"12345&lt;窗口函数&gt;(&lt;参数&gt;) OVER ( [PARTITION BY &lt;分区表达式&gt;] [ORDER BY &lt;排序表达式&gt; [ASC | DESC]] [ROWS/Range &lt;窗口范围&gt;] ) partion 空间换时间的思想","path":"2025/05/14/项目/AI学生发展性评价系统/窗口函数/","date":"05-14","excerpt":"","tags":[]},{"title":"Mybatis Cursor","text":"123456789101112131415161718easSeniorAnalresultClazzStuRankMapper.cursorRankStudentsByClazz(clazzIds, ORIGINAL_SCORE_TYPE, resultContext -&gt; &#123; EasSeniorAnalresultClazzStuRank row = resultContext.getResultObject(); buffer.add(row); if (buffer.size() &gt;= BATCH_SIZE) &#123; this.saveBatch(buffer); buffer.clear(); &#125; &#125;);/** * 根据班级ID列表查询班级排名和年级排名 * 流式查询 * @param clazzIds 班级ID列表 * @return 班级排名和年级排名列表 */@Options(resultSetType = ResultSetType.FORWARD_ONLY, fetchSize = 1000)@ResultType(EasSeniorAnalresultClazzStuRank.class)void cursorRankStudentsByClazz(@Param(&quot;clazzIds&quot;) List&lt;Long&gt; clazzIds, @Param(&quot;score_type&quot;) Integer scoreType, ResultHandler&lt;EasSeniorAnalresultClazzStuRank&gt; handler); 和分页查询有什么区别吗","path":"2025/05/14/项目/AI学生发展性评价系统/Mybatis Cursor/","date":"05-14","excerpt":"","tags":[]},{"title":"数据卷","text":"docker volume create 数据卷名称 创建一个数据卷 docker volume inspect 数据卷名称 显示数据卷信息 docker volume ls 查看所有数据卷 docker volume prune 删除未使用的数据卷 docker volume rm 数据卷名称 删除一个或多个指定的数据卷 数据卷默认路径：&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes","path":"2025/05/13/Docker/数据卷/","date":"05-13","excerpt":"","tags":[]},{"title":"镜像","text":"docker ps (-a) 查看（所有）容器状态 docker rm (-f) 容器id （强制）删除容器 docker run 参数 镜像名称 (&#x2F;bin&#x2F;bash) 创建并运行一个容器 –name 容器名称 给容器取个名称 –restart&#x3D;always docker重启时容器自动重启 –privileged&#x3D;true 赋予容器几乎与主机相同的权限 -p 81:80 将宿主机端口81映射到容器端口80 -i 打开容器标准输入，即能输入 -t 分配一个伪终端绑定到容器的标准输入，即会在输入行前显示信息 -d 后台运行容器 -v 数据卷名字:容器内路径 将数据卷与容器内路径挂载 -e 环境变量名&#x3D;值 设置环境变量 –rm 临时容器，退出后自动删除 docker exec 参数 容器名称 bash 进入容器 -i 打开容器标准输入，即能输入 -t 分配一个伪终端绑定到容器的标准输入，即会在输入行前显示信息 -d 后台运行容器（exec一般是进入运行中的容器，所以不使用这个，一般是-it） docker stop 容器名称 停止容器 docker start 容器名称 启动容器 docker restart 容器名称 重启容器 docker rm 容器名称 删除容器 docker inspect 容器名称 查看容器信息 docker update –restart&#x3D;no 容器名称 更新容器信息，如关闭自启动","path":"2025/05/13/Docker/镜像/","date":"05-13","excerpt":"","tags":[]},{"title":"镜像","text":"docker images 查看所有镜像 docker rmi 镜像id 删除指定镜像 docker search 镜像名称 查找镜像 docker pull 镜像名称 拉取镜像","path":"2025/05/13/Docker/镜像_ez0sv8trtpzaql3g/","date":"05-13","excerpt":"","tags":[]},{"title":"安装","text":"进入root用户： su 如果有安装过docker，卸载旧版本： yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装所需软件包： yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 设置源地址： yum-config-manager \\ –add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装Docker： yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin 验证安装成功： docker -v 启动Docker并开机自启： systemctl start docker.service systemctl enable docker.service 配置镜像加速： https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 卸载docker： yum remove docker-ce rm -rf &#x2F;var&#x2F;lib&#x2F;docker","path":"2025/05/13/Docker/安装/","date":"05-13","excerpt":"","tags":[]},{"title":"Docker UnionFS文件系统","text":"你下载的镜像是所有的容器都共享的！ 容器的占用其实是很小的","path":"2025/05/12/Docker/Docker UnionFS文件系统/","date":"05-12","excerpt":"","tags":[]},{"title":"Docker容器中操作系统隔离策略","text":"docker容器共享内核空间，但用户空间隔离 共享内核空间即容器不需要每个都运行一个内核实例。这使得容器壁传统的虚拟机更加轻量级，因为每个 vm都得运行一整个客人操作系统和内核 避免重复开销：共享内核避免了多余的资源消耗，如内存和CPU时间，从而提高了效率 cggroup和namespace来实现资源的隔离操作 前面不是说会共享内核吗，我宿主机装的centos 但容器内进入 os-release文件里发现却是ubantu 难道说容器内都有一个操作系统？？？ 其实不是的，容器里安装的只是操作系统的一部分即用户空间，内核空间还是宿主机的 那为什么不共享宿主机的用户空间？ 容器内的app下载的依赖不会受到宿主机的影响","path":"2025/05/12/Docker/Docker容器中操作系统隔离策略/","date":"05-12","excerpt":"","tags":[]},{"title":"高并发系统发现Redis热点数据五种实现方式","text":"redis-cli的hotkeys参数原理：遍历redis实例中的所有key，然后返回实例中热key信息 但有问题：1.redis的淘汰策略必须为LRU 2.需要全部扫描，性能差 3.信息不够全 Monitor命令统计原理：Monitor可以实时抓取redis服务器接受到的命令，然后用 现成的访问工具（redis -faina）统计出抓取时间段内的访问的hotkeys 问题： 但它是一个守护进程，你要保证它高可用的 高并发时，内存会暴增 只能统计Monitor命令开启期间 抓包Client&#x2F;proxy端收集客户端和代理端 redis内核改造参考得物开源","path":"2025/05/12/Redis/高并发系统发现Redis热点数据五种实现方式/","date":"05-12","excerpt":"","tags":[]},{"title":"微服务架构出口网关的作用","text":"","path":"2025/05/12/场景题/微服务架构出口网关的作用/","date":"05-12","excerpt":"","tags":[]},{"title":"请求处理流程","text":"首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行 处理，作为统一访问点，进行全局的流程控制； DispatcherServlet——&gt;HandlerMapping， HandlerMapping 将会把请求映射为 HandlerExecutionChain 对象（包含一 个Handler 处理器（页面控制器）对象、多个HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新 的映射策略； DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器， 即适配器设计模式的应用，从而很容易支持很多类型的处理器； HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处 理方法，完成功能处理；并返回一个ModelAndView 对象（包含模型数据、逻辑视图名）； ModelAndView 的逻辑视图名——&gt; ViewResolver，ViewResolver 将把逻辑视图名解析为具体的View，通过这种策 略模式，很容易更换其他视图技术； View——&gt;渲染，View 会根据传进来的Model 模型数据进行渲染，此处的Model 实际是一个Map 数据结构，因此 很容易支持其他视图技术； 返回控制权给DispatcherServlet，由DispatcherServlet 返回响应给用户，到此一个流程结束。 PS：什么叫很多类型的处理器 :::color4 Spring MVC 的 HandlerAdapter 就是适配器模式的应用：它让 DispatcherServlet 不需要关心处理器的类型，而是通过不同的适配器去支持 多种风格的处理器（Controller 接口、注解方法、HttpRequestHandler、自定义处理器等）。 :::","path":"2025/05/12/SpringMVC/请求处理流程/","date":"05-12","excerpt":"","tags":[]},{"title":"java and kotlin","text":"","path":"2025/05/12/JavaSE/java and kotlin/","date":"05-12","excerpt":"","tags":[]},{"title":"工作中常用的LInux指令","text":"cat tail 查看结尾 tail -f 实习查看 less 分页","path":"2025/05/12/操作系统/工作中常用的LInux指令/","date":"05-12","excerpt":"","tags":[]},{"title":"分布式事务","text":"分布式事务（三）、柔性事务之 TCC、Saga、本地消息表、事务消息、最大努力通知 - 墨天轮 https://zhuanlan.zhihu.com/p/590834427 本地消息表实现业界常见方案，因为其他框架太重 主要思想就是将分布式事务拆分为本地事务和消息事务两个部分，本地事务在本地数据库提交or回滚，而消息事务则将消息写入消息中间内，以实现消息可靠投递和顺序性 做法 创建一张本地消息表，用于记录要发的消息内容 将业务表操作和消息表创建记录置于同一事务下（不要把发消息行为放进去，不然可能会因为网络延迟，导致生产者误认为是发送失败，造成异常回滚，实际是发送成功了） 消费者端消费成功后，改本地消息状态 某个环节可能出现的错误 消息投递失败，开定时任务，扫表重投 消息消费失败，依靠消息的重投机制，不断重试 回填状态失败，那么相当于业务数据已经一致了，但消息表里的状态是错的。 定时任务继续重投消息，依靠幂等校验，去推进消息状态 查下游系统的状态，如果成功了，则直接推进消息状态即可 优缺点 优点 - 没TCC,stea,2Pc重 - 扩展性好 - 适用范围广 缺点 - 定时任务，扫表性能较开销大 - 实现复杂度相对较高 12345678910111213141516171819202122232425262728293031@AutowiredTransactionTemplate transactionTemplate;public void order(OrderDTO orderDTO)&#123; boolean transactionSuccess = transactionTemplate.execute(new TransactionCallback&lt;Boolean&gt;() &#123; @Override public Boolean doInTransaction(TransactionStatus status) &#123; try &#123; orderServive.createOrder(orderDTO); messageService.createMessage(orderDTO); //以上执行如果未抛异常，则成功，返回true return true; // 表示事务执行成功 &#125; catch (Exception e) &#123; // 如果发生异常，则标记事务为回滚 status.setRollbackOnly(); return false; // 表示事务执行失败 &#125; &#125; &#125;); if (transactionSuccess) &#123; // 事务执行成功，可以执行 mqService.send(orderDTO) mqService.send(orderDTO); messageService.updateSuccess(orderDTO); &#125; else &#123; // 事务执行失败的处理逻辑 // 可以抛出异常或记录日志等 &#125;&#125;","path":"2025/05/12/SpringCloud/分布式事务/","date":"05-12","excerpt":"","tags":[]},{"title":"CAP","text":"","path":"2025/05/12/SpringCloud/CAP/","date":"05-12","excerpt":"","tags":[]},{"title":"RAFT算法","text":"","path":"2025/05/12/SpringCloud/RAFT算法/","date":"05-12","excerpt":"","tags":[]},{"title":"单例模式","text":"","path":"2025/05/12/设计模式/常规/单例模式/","date":"05-12","excerpt":"","tags":[]},{"title":"哨兵","text":"高可用主要来自两方面： 数据主从节点之间会有同步，如果主节点没了，从节点还有数据 有哨兵节点进行监控，选主。主节点崩了，重新选一个，继续向外提供服务 为什么要有哨兵？在Redis的主从架构中，读写是分离的，如果主没了，那就没人来处理写命令了，也没法给同节点同步数据了 这时如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新 的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主 节点」的 IP 地址。 redis 2.8后就推出了一种新模式，即Sentinel，干的事情就是监控主节点是否宕机 以及主节点宕机选主，然后把数据同步给从节点和客户端 有了哨兵后，客户端就可以 和sentinel通信，然后获取主节点信息 哨兵如何工作？哨兵其实是运行在特殊环境下的一个Redis进程，所以它是一个节点，但实际落地哨兵也是有多个的。 主要负责三件事：监控，选主，通知 如何判断主节点是否真故障？哨兵每隔一秒给主从节点发心跳包，主从节点在规定时间内回了那就是正常的。 如果没有哨兵就会将它们标记为「主观下线」。这个「规定的时间」是配置项 down-after-millisecon 参数设定的，单位是毫秒。 下线分主观和客观，主观就是唯心的即实际不一定的，从节点只会被标记为客观 主节点可能会因为请求压力大，导致网络阻塞从而回消息慢了点，不是真下线 然后为了避免这种情况，即增强纠错机制，哨兵也是议会制的，即多个哨兵都认为它宕机了它才宕机 增加容错度 具体是怎么判定主节点为「客观下线」的呢？当有一个哨兵认为主节点下线后，就会通知其他哨兵，根据自身和主节点的网络情况，做出攒成和反对的投 票。 当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为 「客观下线」。 PS：quorum 的值一般设置为哨兵个数的二分之一加 1，例如 3 个哨兵就设置 2。 判断完后就会从从节点里选一个出来作为主节点 哪个哨兵来进行选主呢？哨兵投票投出来的。一般会有候选者。 哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想 当 Leader 的哨兵。 每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能 把票投给自己。 那么在投票过程中，任何一个「候选者」，要满足两个条件： 第一，拿到半数以上的赞成票； 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。 举个例子，假设哨兵节点有 3 个，quorum 设置为 2，那么任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以选举成功了。如果没有满足条件，就需要重新进行选举。 如果某个时间点，刚好有两个哨兵节点判断到主节点为客观下线，那这时不就有两个候选者了？这时该如何决定谁是 Leader 呢？ 简单来说，谁先发现有个节点故障了，谁就是候选者，如果只有一个候选者，一般就是它成为Leader，如果 同时有多个候选者，看其它投票者先给谁投票，谁就是Leader 主从故障转移的过程是怎样的？ 从已下线的主节点下的从节点里挑一个出来 让从节点修改copy目标 将新主节点的ip地址和信息，通过pub&#x2F;sub通知到客户端里去 继续监视已下线的主节点，如果它复活了，那就将它设置为新主节点的从节点 步骤一：挑选过程 先过滤掉网络不健康的从节点，然后三轮考察，一是优先级，二是复制进度，三是ID号 前两个都是谁大谁win，id号是谁小谁win winer出来后，然后向这个「从节点」发送 SLAVEOF no one 命令，将这个「从节点」转换为「主节点」 步骤二：让从节点更改 哨兵向原从节点发送 slaveof 命令 步骤三：通知客户的主节点已更换 经过前面一系列的操作后，哨兵集群终于完成主从切换的工作，那么新主节点的信息要如何通知给客户端 呢？ 这主要通过 Redis 的发布者&#x2F;订阅者机制来实现的。每个哨兵节点提供发布者&#x2F;订阅者机制，客户端可以从哨兵订阅消息。 哨兵提供的消息订阅频道有很多，不同频道包含了主从节点切换过程中的不同关键事件，几个常见的事件如下： 客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。主从切换完成后，哨兵就会向 +switch-master 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了。 通过发布者&#x2F;订阅者机制机制，有了这些事件通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度 步骤四：将旧主节点变为从节点 故障转移操作最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 SLAVEOF 命令，让它成为新主节点的从节点 哨兵集群如何组成？ 在配置哨兵信息的时候，只需要设置这几个参数，主节点名字，主节点的IP地址和端口号以及 qunorum值 不需要填其他哨兵的信息，哨兵节点之间是通过订阅发现机制来互相发现的 在主从集群中，主节点上有一个名为 sentinel：hello的频道，不同哨兵就是通过它来互相发现的， 实现互相通信的 哨兵主节点只要发布信息到到这个频道上，哨兵b,c订阅了这个频道，就可以互相通信了，集群就这样形成了 哨兵如何知道从节点信息？ 主节点知道所有从节点的信息，所以从节点每秒10s就向主节点发INFO请求获取所有从节点的信息","path":"2025/05/10/Redis/Redis高可用/哨兵/","date":"05-10","excerpt":"","tags":[]},{"title":"redis使用最佳实践","text":"1.对于一些更改操作多的数据，可以考虑使用hash存储 2.使用时避免存储过大的数据块 3.线上的一些命令使用 不要用keys,会扫描所有key，导致主线程阻塞 避免使用FLUSHALL，FLUSHDB删除数据库 5.合理设置key的过期时间 4.高并发场景，对于一些热点key要做好监控告警措施 5.根据redis的使用场景，选择其持久化策略","path":"2025/05/10/Redis/redis使用最佳实践/","date":"05-10","excerpt":"","tags":[]},{"title":"Redis中有一批key瞬间过期，为什么其它key的读写效率会降低？","text":"","path":"2025/05/10/Redis/过期key删除策略/Redis中有一批key瞬间过期，为什么其它key的读写效率会降低？/","date":"05-10","excerpt":"","tags":[]},{"title":"消息队列？延迟队列","text":"","path":"2025/05/10/Redis/消息队列？延迟队列/","date":"05-10","excerpt":"","tags":[]},{"title":"迭代器的fail-safe和fail-fast","text":"Fail-safeFail-safe迭代器在迭代过程中如果检测到集合的结构被修改，将抛出ConcurrentModificationException。这 种行为主要是通过迭代器中的一个modcount的计数器实现的，元素增or删都会发生变动。迭代器遍历时都会 检查这个计数器是否与size符合，不符合就抛错 主要集合 HashMap，Set，ArrayList等 优点：快速响应错误，帮助开发者早点知道错误 缺点：多线程环境下，如果不进行外部同步，容易抛错 Fail-fastFail-fast迭代器允许在迭代过程中对集合进行修改，不会抛concurrentModification异常但不会在原集合上修 改，而是在集合的副本上修改，即修改不会影响到迭代过程。这样的话这种机制在多线程环境下更加安全 copyonwrite…. concurrenthashmap….","path":"2025/05/09/JavaSE/迭代器的fail-safe和fail-fast/","date":"05-09","excerpt":"","tags":[]},{"title":"ArrayList和LinkedList","text":"ArrayList底层是个数组 LinkedList双向链表，添加和删除元素比ArrayList性能高一点，get()和set()就要比其低点，只不过这里的比较基于大数据量来说，少数据量其实没啥可以忽略不计","path":"2025/05/09/JavaSE/ArrayList和LinkedList/","date":"05-09","excerpt":"","tags":[]},{"title":"GC常见问题","text":"system.gc()?finalize()?是一个protected方法，我们可以去重写这个逻辑。回收对象时会去调用这个方法，但最多只能调用一次 STW任何垃圾回收器都是会STW的 开发时不要使用system.gc(),会STW！！！ 内存泄漏是什么简单地说，就是本该回收即不会再被使用的内存没被回收，俗话讲就是占着茅坑不拉屎 内存泄漏多了就会发生内存溢出即OOM 什么情况下会发生？ 安全点和安全区域哪些情况新生代会进入老年代？ 新生代gc后survivor区不够存放存活下来的对象，会将对象通过内存担保机制晋升到老年代 大对象直接进入老年代，-XX:PretenureSizeThreshold&#x3D;1048576配置，因为大对象在新生代发生来回复制的话，影响gc性能 长期存活的对象，比如经过了15次gc后还存活的对象，由-XX:MaxTenuringThreshold&#x3D;10配置 但是这个年龄是会动态调整的，每次新生代GC后，JVM都会动态调整这个阈值大小，调整的方式是，从年龄为1的所有对象向上累加，直到内存大小大于-XX:TargetSurvivorRatio（默认50%） 例如总共有100MB新生代大小，阈值就是50MB，累加年龄为1的对象，此时10MB，累加年龄为2的对象，此时25MB，累加年龄为3的对象，此时45MB，累加年龄为4的对象，此时55MB&gt;50MB，那么阈值就被设置成4，下次GC时年龄大于等于4的对象会晋升到老年代 算法源码地址：jdk&#x2F;hotspot&#x2F;src&#x2F;share&#x2F;vm&#x2F;gc_implementation&#x2F;shared&#x2F;ageTable.cpp at jdk8-b120 · openjdk&#x2F;jdk (github.com) 为什么默认是15？因为对象头里有个age字段，占4个bit位，所以最大就是15，初始值设为最大，然后依靠后面动态调整。那这样的话，小于等于15都可以吧，反正有动态调整，为什么选15呢？因为-XX:MaxTenuringThreshold其实是限定了一个动态调整年龄范围的上限，设为15能让动态调整更为灵活 什么时候full gc？ 程序代码中调用System.gc() 当新生代对象需要晋升老年代或大对象直接在老年代开辟内存时，老年代空间不足 空间分配担保失败 元空间或永久代（JDK7以前）空间不足，full gc回收未使用的类（需要这个类没有对象，所以要gc回收）和元数据 执行CMS GC的过程中同时有对象要放入老年代，而此时老年代空间不足(可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足)，便会报 Concurrent Mode Failure 错误，并触发 Full GC。 G1内存回收速度赶不上内存分配的速度，也会导致Full GC 什么是Concurrent Mode FailureCMS收集器在工作时，因为用于线程和垃圾回收在并发标记和并发清除阶段是并行的，此时老年代空间不足（例如浮动垃圾过多，用户创建对象频繁，新生代晋升老年代），就会出现Concurrent Mode Failure 出现Concurrent Mode Failure会怎样 触发Full GC","path":"2025/05/08/JVM/GC常见问题/","date":"05-08","excerpt":"","tags":[]},{"title":"垃圾回收器","text":"如果两个收集器之间存在连线，就说明它们可以搭配使用，图中收集器所处的区域，则表示它是属于新生代收集器抑或是老年代收集器 Parallel 吞吐量优先算法CMS（concurrent mark sweep）垃圾回收器JDK1.5时引入，JDK9被标记弃用，JDK14被移除 可以怎么说吧，它是第一款真正意义上的并发收集器，第一次实现了用户线程和垃圾收集线程一起工作 设计目标就是尽快能地减少STW 工作于老年代 它算法层面采用的是标记清除算法，并且也会stw 整个垃圾回收过程分为四个阶段：初始标记，并发标记，重新标记，并发清除 初始标记（STW）：暂时时间非常短，标记与GC Roots直接关联的对象。 并发标记（最耗时）：从GC Roots开始遍历整个对象图的过程。不会停顿用户线程 重新标记：（STW）：修复并发标记环节，因为用户线程的执行，导致数据的不一致性问题 并发清理（最耗时） 因为最耗时的并发标记和并发清理是并发操作，虽然初始和标记会STW，但整体是低延迟的 由于采用标记清除算法，所以会不可避免地出现内存碎片的问题。且在给新数据分配内存时，也无法采用指针碰撞，只能维护一个空闲的内存地址列表 那问题来了，既然标记清除会产生内存碎片，为啥不把算法换成标记整理呢 因为你整理内存时，原来的用户线程要怎么用？因为你整理时会移动对象，移动对象时是会STW的。 优缺点 优点：并发收集，低延迟 缺点：内存碎片问题，占CPU资源（吞吐量可能会有所降低）， G1垃圾回收器在JDK1.7版本正式启用，是JDK 9以后的默认GC选项 为了在大内存的情况下也有短暂的STW，G1是java 7后引入的一个新的垃圾回收器 相比于其他分代收集器（G1物理不分代，但逻辑分代）的全量回收，G1采用了增量回收，每次只回收垃圾最 多的region，且实现了STW真正意义上的可控，大内存的毫秒级别的STW 并行和并发： 并行：回收期间多个GC线程可同时工作，但用户线程STW 并发：G1拥有跟应用程序交替执行的能力，不会在回收长期阻塞应用程序 不分代收集 物理不分代：将堆分为不同的region 逻辑分代：但不要求相同代之间内存连续的 空间整合 内存回收是以region为基本单位的。region之间为复制算法，但整体可以看成标记整理，可以避免内存碎 片 可预测的停顿时间模型 可以让用户指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不过N毫秒 可简化调优 第一步：开启G1 -XX：+UseG1GC 第二步：设置堆的最大内存 -XMS 第三部：设置最大停顿时间 -XX:MaxGCPauseMillis 分区region 每个区大小相等，根据堆实际大小而定，整体被控制在1MB到32MB之间，在且生命周期相同 H区？？：用来存放大对象，如果对象超过1.5region，就会放到这里 为啥要这个区 有些短期的大对象进入老年代不太好，会触发FullGC Minor GC：复制算法 Mixed GC：标记整理算法 mixed GC过程 1.初始标记（STW）：只是标记一下GCRoot能直达的对象 2.并发标记：并发完成GCRoot引用链，标记可达对象 3.最终标记（STW）：确认垃圾 4.筛选回收（STW）：开辟最多5%堆空间的内存用于标记整理的数据交换 STW200ms最多回收10%的垃圾最多区域，且回收会检查老年代是否低于45% 没达标就重新来一次，最多8次，8次没达标就FULLGC oldGC 如何选择垃圾回收器？","path":"2025/05/08/JVM/垃圾回收器/","date":"05-08","excerpt":"","tags":[]},{"title":"Spring-Retry","text":"入门说在前头Spring封装好的重试工具类，可优雅实现接口重试逻辑 github直达：https://github.com/spring-projects/spring-retry 基本使用 为什么要额外学下这个：公司项目中的持久化框架用到这个注解，当时上手项目的时候比较感兴趣就去 翻了源码 demo1234567891011121314151617@Configuration@EnableRetrypublic class Application &#123;&#125;@Serviceclass Service &#123; @Retryable(retryFor = RemoteAccessException.class) public void service() &#123; // ... do something &#125; @Recover public void recover(RemoteAccessException e) &#123; // ... panic &#125;&#125; @EnableRetry 加在启动类，支持重试功能 @Retryable 加在重试的方法上 @Recover 重试完成后还是不成功的情况下，会执行被这个注解修饰的方法。 源码入手因为是注解，不好定位到源码，我们可以通过日志来分析 org.springframework.retry.support.RetryTemplate#doExecute","path":"2025/05/08/Spring/Spring-Retry/","date":"05-08","excerpt":"","tags":[]},{"title":"垃圾收集算法","text":"分代收集理论，垃圾收集器的理论基础，它建立在两个分代假说之上： 弱分代假说：绝大多数对象都是朝生夕灭的。 强分代假说：熬过越多次垃圾收集过程的对象就越难以消亡。 这两个分代假说共同奠定了多款常用的垃圾收集器的一致的设计原则：收集器应该将Java堆划分出不同的区域，然后将回收对象依据其年龄（年龄即对象熬过垃圾收集过程的次数）分配到不同的区域之中存储。 如果一个区域中大多数对象都是朝生夕灭，难以熬过垃圾收集过程的话，那么把它们集中放在一起，每次回收时只关注如何保留少量存活而不是去标记那些大量将要被回收的对象，就能以较低代价回收到大量的空间； 如果剩下的都是难以消亡的对象，那把它们集中放在一块，虚拟机便可以使用较低的频率来回收这个区域，这就同时兼顾了垃圾收集的时间开销和内存的空间有效利用。 Java堆划分为新生代（Young Generation）和老年代（Old Generation）两个区域。在新生代中，每次垃圾收集时都发现有大批对象死去，而每次回收后存活的少量对象， 将会逐步晋升到老年代中存放 标记-清除算法： 基础算法，后面两个算法基于此算法改进 算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，统一回收所有未被标记的对象。标记过程就是对象是否属于垃圾的判定过程。该算法两个缺点： 执行效率不稳定 内存碎片化 标记-复制算法： 适用于新生代的算法，将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。如果内存中多数对象都是存活的，这种算法将会产生大量的内存间复制的开销，但对于多数对象都是可回收的情况，算法需要复制的就是占少数的存活对象，而且每次都是针对整个半区进行内存回收，分配内存时也就不用考虑有空间碎片的复杂情况，只要移动堆顶指针，按顺序分配即可。算法缺点很明显：少了一半空间 新生代中的对象有98%熬不过第一轮收集。因此并不需要按照1∶1的比例来划分新生代的内存空间。 Appel式回收：把新生代分为一块较大的Eden空间和两块较小的Survivor空间，每次分配内存只使用 Eden 和其中一块Survivor。发生垃圾搜集时，将Eden和Survivor中仍然存活的对象一 次性复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor 空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8∶1，也即每次新生代中可用内存空间为整个新生代容量的90%（Eden的80%加上一个Survivor的10%），只有一个Survivor空间，即10%的新生代是会被“浪费”的。当然，98%的对象可被回收仅仅是 “普通场景”下测得的数据，任何人都没有办法百分百保证每次回收都只有不多于10%的 对象存活，因此Appel式回收还有一个充当罕见情况的“逃生门”的安全设计，当 Survivor 空间不足以容纳一次Minor GC之后存活的对象时，就需要依赖其他内存区域 （实际上大多就是老年代）进行分配担保。 标记-整理算法： 针对老年代对象的存亡特征，1974年Edward Lueders提出了另外一种有针对性的 “标记-整理”（Mark-Compact）算法，其中的标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存 为什么标记-复制适用于新生代，标记-整理适用于老年代？ 新生代需要被清理的对象多，复制只需要复制少量存活对象 老年代存活的对象多，不能使用Eden Survivor那套，不然内存就不够了，当然标记-整理也是一项很负重的操作，但如果不整理，就需要额外使用页表等方式标记哪些空间可用来解决空间碎片化问题，这也会导致额外负担，所以从整个程序的吞吐量考虑，标记-整理是较好的选择 当然老年代也可以先标记-清除，等内存空间碎片化到一定程度时，进行一次标记整理 三色标记法： 可达性分析算法中，标记过程需要stop the world，保证全局获得一致性快照，这个操作可否与用户线程并发？ 先来看三色标记法：把遍历对象图过程中遇到的对象，按照“是否访问过”这个条件标记成以下三种颜色： 白色：表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达，需要被回收 黑色：表示对象已经被垃圾收集器访问过，且所有引用了这个对象的对象都已经扫描过。黑色的对象代表已经扫描过，它是安全存活的，不用被回收，如果有其他对象引用指向了黑色对象，无须重新扫描一遍。黑色对象不可能直接（不经过灰色对象）指向某个白色对象。 灰色：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过。是个中间态，当扫描完成后，不会出现这个颜色，整个图非黑即白 可达性分析算法其实就是从GC Roots出发，将图（对象直接的引用关系图）波浪式地由白色转为黑色，其中灰色是黑白之间的过渡色。 这个标记法在用户线程和收集器并发工作下可能存在问题： 是把原本消亡的对象错误标记为存活，这不是好事，但其实是可以容忍的，只不过产生了一点逃过本次收集的浮动垃圾而已，下次收集清理掉就好。 把原本存活的对象错误标记为已消亡，这就是非常致命的后果了，程序肯定会因此发生错误 当且仅当以下两个条件同时满足时，会产生“对象消失”的问题，即原本应该是黑色的对象被误标为白色，导致回收应该存活的对象： 赋值器插入了一条或多条从黑色对象到白色对象的新引用；即对象A被其它已扫描过的且安全存活的对象链上了 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。即所有引用A且正在被扫描的对象取消了对A的引用 因此，我们要解决并发扫描时的对象消失问题，只需破坏这两个条件的任意一个即可。 当标记与用户线程并发时，可能造成以上问题，为了使标记与用户线程并发，减少STW的时间，就需要解决上述问题，由此分别产生了两种解决方案：增量更新 和 原始快照 增量更新要破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象为根，重新扫描一次。这可以简化理解为，黑色对象一旦新插入了指向白色对象的引用之后，它就变回灰色对象了。即出现了新的引用关系就记录下来，然后重新扫描 原始快照要破坏的是第二个条件，当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再以这些灰色对象为根，重新扫描一次。这也可以简化理解为，无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索。（当B删除了N引用之后，B-&gt;N 的关系仍然被记录，这个动作通过一个写屏障来实现（可以理解为一个aop）。扫描结束之后再以B为根（被记录的灰色对象为根）重新扫描一次，此时的扫描的B-&gt;N的引用已经被重新记录了，即使他实际已经被删除但在这次扫描中它仍然存在。但是这可能导致N在本次垃圾回收时应该被回收，却逃过了这次，不过没关系，下次gc它逃不了） 原始快照相对于增量更新更快，但是可能产生更多的浮动垃圾 JVM—理解G1的SATB和CMS的增量更新 增量更新和原始快照这两种解决方案都有实际应用，譬如，CMS是基于增量更新来做并发标记的，G1、Shenandoah则是用原始快照来实现。 新生代Minor GC流程： 当Eden区满时，触发Minor GC 标记算法找到所有存活下来的对象 检查老年代最大可用的连续空间是否大于新生代所有存活下来的对象的空间，如果大于，则发起 Minor GC。 如果小于，则看 HandlePromotionFailure 有没有设置，如果没有设置，就发起 Full GC。 如果设置了 HandlePromotionFailure，则看老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果小于，就发起 Full GC。 如果大于，发起 Minor GC。Minor GC 后，看 Survivor 空间是否足够存放存活对象，如果不够，就放入老年代，如果够放，就直接存放 Survivor 空间。如果老年代都不够放存活对象，担保失败（Handle Promotion Failure），发起 Full GC。 HandlePromotionFailure（是否允许进行晋升担保） 的作用，当设置为 true 时（默认值），JVM 会尝试继续 Minor GC，即使老年代空间不足以容纳所有需要晋升的对象。JVM 会尝试清理更多的老年代空间或者采用其他措施来应对空间不足的情况。避免因为老年代空间不足而过早触发 Full GC（全堆回收）。Full GC 通常比 Minor GC 更耗时，会导致更长时间的停顿。但该参数在JDK7开始彻底被弃用，相当于该参数变为false，这可能导致Full GC频繁发生，但JVM也开始动态调整新生代、老年代的空间大小配置，尽量减少Full GC的发生，且如果老年代空间不足，会提前执行部分清理或混合GC","path":"2025/05/08/JVM/垃圾收集算法/","date":"05-08","excerpt":"","tags":[]},{"title":"redis消息队列","text":"https://juejin.cn/post/7112825943231561741","path":"2025/05/08/项目/分布式定时器/redis消息队列/","date":"05-08","excerpt":"","tags":[]},{"title":"布隆过滤器原理","text":"","path":"2025/05/07/Redis/数据结构/布隆过滤器原理/","date":"05-07","excerpt":"","tags":[]},{"title":"为什么jdk1.7要把方法区迁移到元空间","text":"方法区里存的是类的结构信息啥的，而它是很难被卸载，因为它对应的堆中的class对象与类加载器有着双向关联的关系，而类加载器会维护一个java集合，里面标明着哪些类是被该类加载器加载的，如果要把该类加载器干掉，其他类也会被干掉，那这是不现实的，也就只存在该类加载为自定义类加载器。所以该类的结构信息是很难被回收的，为了防止堆溢出，所以就把它搬到了本地内存中 。","path":"2025/05/05/JVM/为什么jdk1.7要把方法区迁移到元空间/","date":"05-05","excerpt":"","tags":[]},{"title":"判断对象是否需要被gc","text":"可达性分析算法思想jvm里是通过可达性分析算法分析对象是否可以被回收，从GCRoot出发搜索，哪些无法被搜索到哪些就是要 被回收的对象 什么的对象可以当做GCRoot？ 总的来说，因为jvm中是用栈来保存变量和引用，那么只要这个引用保存了堆里的对象， 且它（引用）不 在堆里，那么它就可以作为一个GCRoot 展开来说有这么几种 1.虚拟机栈中的引用对象 2.类静态属性的引用对象 3.方法区常量引用的对象 4.所有被同步锁即synchronized持有的对象 5.jvm内部的引用，如一些常驻异常对象，如NPE对象，OOM对象 ….. 使用可达性分析的时候，jvm必须处于一个一致性快照的状态，这也是导致GC过程中stop the world的原因之一 对象自救，在可达性分析算法过程中被判定为不可达的对象一定是“非死不可的吗？” 不一定。对象在第一次回收时被判定为不可达，可以通过重写finalize()的逻辑来使对象复活，达到一种自 救的目的。如果不重写那么就会直接死亡了，还有就是这个方法最多只会被jvm调用一次 ps:finalize()是对象被回收时会去调用的一个方法，我们在里面做一些对象自救或者资源释放的工作 三色标记法？？三色标记法就是可达性分析算法的落地实现 https://juejin.cn/post/6979249945551339551 三色标记法是为了解决可达性分析算法的STW过长问题，是基于它进行一个升级。CMS，G1垃圾回收器可达 性分析的过程中都用到了 其实就是说用三种颜色来表示对象在回收过程的不同状态 白色：还没被扫描到的对象 灰色：已经被扫描到的对象但其子引用还没被扫到 黑色：当前对象以及其子引用都被扫描到了 它是怎么执行的？？？ 总体分为三个阶段吧：初始，标记，回收 初始：把对象都标记为白色，然后会从GCRoot出发把直接可达对象标记为灰色，并加入到一个集合里 标记：从集合里拿出灰色对象，把这些对象引用的白色对象标记为灰色，最后再把这个对象本身标记为黑 色。重复这个过程，直到为空了 回收：当灰色集合里的对象空了后，就会进入这个阶段了。那这时候就很清楚了，白色集合里的对象都是 不可达的，而黑色都是可达的 优点 在并发环境下确保垃圾回收的安全性和正确性，同时尽可能减少停顿时间（STW） 如果重新标记后又发生了引用更改呢？ 回收阶段会STW 通过可达性分析算法判定对象是否存活： 通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”，如果某个对象到GC Roots间没有任何引用链相连，或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此对象是不可能再被使用的。 在Java技术体系里面，固定可作为GC Roots的对象包括以下几种： 在虚拟机栈（栈帧中的本地变量表）中引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等 在方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量 在方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用 在本地方法栈中JNI（即通常所说的Native方法）引用的对象 Java 虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象 （比如NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器 所有被同步锁（synchronized关键字）持有的对象 反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。 在JDK 1.2版之后，Java对引用的概念进行了扩充，将引用分为强引用（Strongly Re-ference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）4 种 强引用是最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似“Object obj&#x3D;new Object()”这种引用关系。无论任何情况下，只要强引用关系还存在， 垃圾收集器就永远不会回收掉被引用的对象，即使OOM。 软引用是用来描述一些还有用，但非必须的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK 1.2版之后提供了 SoftReference 类来实现软引用。 弱引用也是用来描述那些非必须对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止。当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK 1.2版之后提供了 WeakReference 类来实现弱引用。 虚引用是最弱的一种引用关系。虚引用和引用队列联合使用，用来追踪对象的回收情况。虚拟机回收对象时，如果发现对象还存在虚引用，会在回收对象后将引用加入到关联的引用队列中。程序可以通过观察引用队列的方式，来感知对象即将被垃圾回收的时机。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。在JDK 1.2版之后提供了PhantomReference类来实现虚引用。 对象自救： 即使在可达性分析算法中判定为不可达的对象，也不是“非死不可”的，这时候它们暂时还处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记，随后进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。假如对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，那么虚拟机将这两种情况都视为“没有必要执行”，没有必要执行则直接回收。 如果这个对象被判定为确有必要执行finalize()方法，那么该对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低调度优先级的 Finalizer 线程去执行它们的 finalize() 方法。 finalize()方法是对象逃脱死亡命运的最后一次机会，稍后收集器将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的要被回收了","path":"2025/05/05/JVM/判断对象是否需要被gc/","date":"05-05","excerpt":"","tags":[]},{"title":"类加载器","text":"两个类来源于同一个 Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等 这里所指的“相等”，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括了使用instanceof关键字做对象所属关系判定等各种情况 如果自定义一个com.example.String会怎样？ 可以自定义，项目中的String的优先级是同包下的String&gt;java.lang包下的String&gt;自定义包下的String，然后如果一个类中用到了两种String，需要指定好，比如main函数的入参String[] args 双亲委派模型： 启动类加载器（Bootstrap Class Loader）：负责加载存放在 \\lib目录，或者被-Xbootclasspath参数所指定的路径中存放的， 而且是Java虚拟机能够识别的（按照文件名识别，如rt.jar、tools.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机的内存中，其实就是JDK库里的 扩展类加载器（Extension Class Loader）：负责加载 \\lib\\ext目录中，或者被java.ext.dirs系统变量所指定的路径中所有的类库（JDK9及以后，被重命名为平台类加载器Platform ClassLoader），可能是一些旧版的加密库等等，现在项目很少用到 应用程序类加载器（Application Class Loader）：负责加载用户类路径（ClassPath）上所有的类库，就是我们写的代码，例如com.example.xxx和第三方jar包 双亲委派模型：除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。不过这里类加载器之间的父子关系一般不是以继承（Inheritance）的关系来实现的，而是通常使用组合 （Composition）关系来复用父加载器的代码。 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时， 子加载器才会尝试自己去完成加载。 为什么使用双亲委派： 因为Java是确定一个唯一的类是根据类的全路径+类加载器确定的，对于同一个包名路径下的类，如果被不同类加载器加载出来，就会产生不同的类，这时程序的行为就不能保证了，例如，自己写一个java.lang.Object，并放在程序的ClassPath中，如果没有双亲委派，程序中就出现两个java.lang.Object类了（自己写的和java官方的，分别由应用程序类加载器和启动类加载器加载），但如果使用了双亲委派，即使一开始是由应用程序类加载器加载，最终也会委托给启动类加载器，启动类加载器根据类的全路径发现自己已经加载过这个类了，就不会再加载这个类，这就保证了核心类库里的类都是唯一且正确的，所以双亲委派模型保证了Java程序的稳定运作 为什么要向上委派，不能向下委派？ 是否能一开始就由启动类加载器加载所有的类，启动类加载器发现不在自己加载范围内的类就交给自己的子类加载器？答案是不行的，因为一个类加载器可以只有一个父类加载器，需要加载类时直接向上委派就行，但如果是向下委派，同时又有多个子类加载器，这时候就不知道要委派给哪个子类加载器的（可能有多个子类加载器的原因是因为可以有自定义类加载器，加载器的组合是多样的，但不管怎样，只可能有一个父类加载器），这就好比一个二叉树，从叶子节点向上走，是有且只有一条唯一的路径的，而且这条路径的终点必然是根节点，而从根节点出发，一直向下走，是不能确定一条唯一路径的，虽然最终能到达某一叶子节点，但具体是哪个叶子节点取决于每次向下走的路线决策。而且向下委派意味着需要修改应用程序类加载器的源码。 破坏双亲委派模型： 自定义加载器的话，需要继承 ClassLoader 。如果我们不想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 loadClass() 方法。 Tomcat采用自定义类加载器破坏了双亲委派，实现了Web应用之间的类的隔离 JDBC接口是jre下的，但实现是第三方供应商提供的，按理来说，一个类及其依赖类由同一个类加载器加载（确保这些类之间的依赖关系正确并保持一致），但这种情况下不会被同一个类加载器加载，这就需要用到线程上下文类加载器解决 线程上下文类加载器：当一个线程启动时，jvm会将应用类加载器赋值给当前线程的线程上下文类加载器，此时父类加载器就可以提高线程上下文类加载器获取到子类加载器，再由子类加载器加载父类找不到的类 什么时候需要自定义类加载器： 想加载非classpath随意路径的类文件 隔离同名类，需要不同应用下的同名类可以不冲突，如tomcat容器","path":"2025/05/05/JVM/类加载器/","date":"05-05","excerpt":"","tags":[]},{"title":"抽象类和接口","text":"抽象类是为了复用代码，如模版方法。而接口主要是为了定义规范 抽象类 1.7以前，抽象类的方法默认权限为protected 1.8开始，抽象类的方法默认为default了 接口 接口的成员变量只能为public static final 1.7接口的方法只能有public abstract 1.8接口的方法可以被default修饰，但得有方法体 1.8接口的方法可以被static修饰，但得有方法体，且不能和default一起使用 1.9接口的方法可以被private修饰，但得有方法体，且同时可以有static，但不能用default","path":"2025/05/05/JavaSE/抽象类和接口/","date":"05-05","excerpt":"","tags":[]},{"title":"你如何理解OOP","text":"","path":"2025/05/05/JavaSE/你如何理解OOP/","date":"05-05","excerpt":"","tags":[]},{"title":"重写与重载","text":"1.同名不同参数名之间的方法之间互相称为重载，而重写是指子类重新构造和父类一摸一样的方法 2.重载是编译期确定下来的要使用哪个方法，而重写是运行时绑定的，即看对象引用指向的具体对象类型 只有返回类型不同，可以被叫做重载吗 不是，编译期会报错的 方法签名是由：方法名称 + 参数类型 + 参数个数组成的一个唯一值，这个唯一值就是方法签名，而 JVM （Java 虚拟机）就是通过这个方法签名来决定调用哪个方法的 如果把返回类型也包含进去，那就不知道调用哪个了","path":"2025/05/05/JavaSE/重写与重载/","date":"05-05","excerpt":"","tags":[]},{"title":"异常","text":"运行时异常： 都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。 运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。 非运行时异常（编译异常）： 是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。如IOException、SQLException等 throw： 如果代码可能会引发某种错误，可以创建一个合适的异常类实例并抛出它，这就是抛出异常。 throws： 在Java中，当前执行的语句必属于某个方法，Java解释器调用main方法执行开始执行程序。若方法中存在检查异常，如果不对其捕获，那必须在方法头中显式声明该异常，以便于告知方法调用者此方法有异常，需要进行处理。 在方法中声明一个异常，方法头中使用关键字throws，后面接上要声明的异常。若声明多个异常，则使用逗号分割。 try-catch底层？ class字节码指令中会有异常表，表示哪一行到哪一行的代码可能有什么异常： from 可能发生异常的起始点 to 可能发生异常的结束点 target 上述from和to之前发生异常后的异常处理者的位置 type 异常处理者处理的异常的类信息 什么时候不走finally？ try或catch中进入了死循环 虚拟机退出 守护线程中可能不会走finally就被回收了 finally的执行顺序 finally正常情况下都会被执行的 如果finally里有return语句，那么它就是整个try-catch-finally结构的返回结果 若没有，就得看try or catch里的return语句了 程序出现了异常会发生什么？ 运行时异常： 被try-catch捕获：JVM会将异常对象交给对应的catch处理，异常不会向上抛出（catch块中没有继续抛），处理完后，线程仍然继续执行代码 在方法声明上被抛出：交给上一级的方法进行处理，直到找到能处理该异常的catch块，但运行时异常一般没必要写方法声明上抛出，因为不写同时也不对其try-catch捕获的话，默认就是向上一级方法抛出 无法被处理：没有相应catch块处理，该异常会被交给线程的异常处理器，如果没设置异常处理器，那就走JVM默认的异常处理器，即线程终止，标准输出打印信息，即使有了异常处理器去处理，在处理器处理完后，抛异常的线程仍然会被终止，所以想让线程抛异常后还能继续执行下去，只能用try-catch捕捉异常 非运行时异常： 在编译时就必须被处理，所以和运行时异常走一样的逻辑 如何设置异常处理器？ 为特定线程设置处理器： 123456789101112131415161718192021Thread thread = new Thread(() -&gt; &#123; // 线程的运行代码 &#125;); thread.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() &#123; @Override public void uncaughtException(Thread t, Throwable e) &#123; // 处理未捕获的异常 System.out.println(&quot;线程 &quot; + t.getName() + &quot; 发生异常: &quot; + e.getMessage()); &#125; &#125;); thread.start(); 为所有线程设置默认处理器： Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() &#123; @Override public void uncaughtException(Thread t, Throwable e) &#123; // 处理未捕获的异常 System.out.println(&quot;线程 &quot; + t.getName() + &quot; 发生异常: &quot; + e.getMessage()); &#125; &#125;); 案例： 异常被捕获，仍然执行代码，抛异常之前的代码都能正常执行： 打印：线程仍然执行，i = 10，b = 9 定义异常处理器处理异常： 打印： ![](/images/e353185520d693ae246972e875b7ab13.png) OutOfMemoryError StackOverflowError NoClassDefFoundError","path":"2025/05/05/JavaSE/异常/","date":"05-05","excerpt":"","tags":[]},{"title":"封装，继承，多态","text":"封装 就是利用一些抽象数据结构把数据和基于数据的操作封装成一个“黑盒子”，用户使用时不需要关注具体实现 直接使用就好了 继承 就是用来表示is-a的关系，比如父类是动物，子类是猫，就是用来表示这种关系。子类有着父类的全部属性和 方法。如果子类新增方法，那就是is-like-a关系 多态 同一方法在不同对象上有不同表现 多态的话我觉得就只在运行时才具有，如重写 即对象引用指向的具体类型只有在运行时才会被确定下来 要想实现多态就得满足以下条件 1.有接口实现or类继承 2.子类重写父类的方法 3.父类的引用指向子类的对象 组合 has-a关系，一个类的成员变量是其他类的对象 组合更适合面向接口开发，而且更加简单和灵活，相对于继承，能用组合就用组合 继承得有明确的is-a关系","path":"2025/05/05/JavaSE/封装，继承，多态/","date":"05-05","excerpt":"","tags":[]},{"title":"ArrayList","text":"如何扩容 1.检查加入新元素后是否会超过数组的容量，如果超过，就进行一次扩容 2.设置新的容量为老容量的1,5 最多不超过2^31-1 （Java 8中ArrayList的容量最大是Integer.MAX_VALUE - 8，即2^31-9。这是由于在Java 8中，ArrayList内部实现进行了一些改进，使用了一些数组复制的技巧来提高性能和内存利用率，而这些技巧需要额外的8个元素的空间来进行优化。） 3.申请一个容量为老容量的1.5倍的新数组，然后把原数组的元素复制上去 ArrayList的序列化","path":"2025/05/05/JavaSE/ArrayList/","date":"05-05","excerpt":"","tags":[]},{"title":"数据库死锁如何解决","text":"数据库死锁是指多个并发事务中，出现了彼此相互等待的情况，导致所有事务卡在那里了，无法继续执行 原因：其实就是长时间无法获取想要的资源且无法放弃获取 如何解决？ 大部分的现在数据管理系统都有自动干预功能，即可以选择多个or一个事务回滚来释放锁 还能手动强制回滚 mysql自己也能解决死锁 1.定期检测死锁机制，检测到死锁后，MySQL会自动选择终止一个or多个事务来释放锁 2.设置事务持有锁的超时时间（InnoDB_lock_wait_timeout）。即如果事务持有锁的时间超过这个阈值 就会对这个事务进行回滚 长事务","path":"2025/05/04/MySQL/线上排查/数据库死锁如何解决/","date":"05-04","excerpt":"","tags":[]},{"title":"IO","text":"IO是什么？ 从计算机结构来讲，I就是Input，o就是output，那么IO描述的就是描述计算机系统与外部设备通信的过程 如输入设备（键盘），输出设备（显示屏）就是外部设备，网卡和硬盘也是外部设备 从应用程序角度来说，IO是指应用程序通过系统调用请求操作系统内核空间执行与“外部设备的交互”的过程 当应用程序发起IO调用后，会经历两个阶段 1.内核等待IO设备准备好数据 2.内核把数据从内核空间拷贝到用户空间 UNIX下的五种IO模型UNIX 系统下， IO 模型一共有 5 种：同步阻塞 I&#x2F;O、同步非阻塞 I&#x2F;O、I&#x2F;O 多路复用、信号驱动 I&#x2F;O 和异步 I&#x2F;O。 jtea&#x2F;linux&#x2F;五种IO模型.md at master · jmilktea&#x2F;jtea Java的三种IO模型阻塞IO应用程序发起IO调用后，会一直阻塞，直到成功拿到数据 连接一多起来，每来一次连接就得开一个线程，费内存。且线程阻塞住，不能去干其他事情 NIO 非阻塞IO同步非阻塞 应用程序轮询 询问内核数据是否就绪，避免了一直阻塞。但不断轮询是很耗CPU资源的 IO多路复用 有个重要角色selector会去监听客户端的channel，然后数据准备好了就主动通知客户端可以来读数据了 实现了一个线程就可以监听多个Client的功能 目前支持IO多路复用的系统调用有三种：select（几乎所有的系统都支持），poll，epoll 异步IO","path":"2025/05/04/Redis/网络模型/IO/","date":"05-04","excerpt":"","tags":[]},{"title":"SQL调优","text":"","path":"2025/05/04/MySQL/QPS ？调优/SQL调优/","date":"05-04","excerpt":"","tags":[]},{"title":"如何设计完美的表结构","text":"","path":"2025/05/04/MySQL/QPS ？调优/如何设计完美的表结构/","date":"05-04","excerpt":"","tags":[]},{"title":"数据库字段加密后怎么做模糊查询？","text":"","path":"2025/05/04/场景题/数据库字段加密后怎么做模糊查询？/","date":"05-04","excerpt":"","tags":[]},{"title":"为什么大厂要把RR改成RC","text":"1.提高并发 2.降低锁的粒度，能有效降低死锁风险","path":"2025/05/04/MySQL/事务/为什么大厂要把RR改成RC/","date":"05-04","excerpt":"","tags":[]},{"title":"为什么RR为默认的事务隔离级别","text":"兼容老版本， “MySQL选择RR作为默认隔离级别，核心考虑是保证主从复制的数据一致性。早期MySQL使用statement格式的binlog，如果采用RC隔离级别，并发事务的执行顺序差异可能导致主从数据不一致。RR级别通过GAP锁机制强制事务串行化，确保binlog回放结果与主库一致。虽然这牺牲了部分并发性能，但对于数据库集群的数据一致性保障是必要的设计权衡。”","path":"2025/05/04/MySQL/事务/为什么RR为默认的事务隔离级别/","date":"05-04","excerpt":"","tags":[]},{"title":"MySQL性能？","text":"TPS： 每秒钟系统处理的事务数量 MySQL5.5版本，普通8核16G的机器，一张100万的常规表，顺序写性能在2000tps，读性能的话，如果索引有效，tps在5000左右","path":"2025/05/04/MySQL/QPS ？调优/MySQL性能？/","date":"05-04","excerpt":"","tags":[]},{"title":"树高计算","text":"假设数据库每个数据记录的大小为400字节（50个bigint类型），而用于索引的键占8字节。三层树高（两层索引页，一层数据页）能放多少数据？ 页的大小为16k（实际会有其它信息占用大概200字节），这里按16k来算，非叶子节点中，一行记录包括索引的键和指向其它页号的指针（InnoDB指针占6字节），所以一行记录是8 + 6 &#x3D; 14字节 每页可以包含的键数 &#x3D; 16384字节 &#x2F; 14字节 &#x3D; 1170 每个数据记录400字节，那么一个数据页16k可以存放16384 &#x2F; 400 &#x3D; 40行数据 那么两层b+树高则有1170个叶子节点（第一层为一个索引页根节点，然后第二层扩展出1170个数据页叶子节点）每个叶子节点能存放40行数据，即1170 * 40 &#x3D; 46800行记录 那么三层b+树高则有1170 * 1170 &#x3D; 1368900 个叶子节点（第一层为一个索引页根节点，然后第二层扩展出1170个索引页叶子节点，然后第三层扩展出1170 * 1170个数据页叶子节点），每个叶子节点能存放40行数据，即 1368900 * 40 &#x3D; 54756000（五千万？！） 我们不是说三层树高是2000w数据吗，现在算怎么三层树高就能存5000w数据？实际上，2000w的那个数据是每行数据记录大小为1k计算得来的，也就是1024个字节，128个bigint，而我们不是每个表都会定义这么多字段，所以还得根据表的具体情况来计算，而且每个页都需要一定空间存放其它信息，每行也需要存放其它的信息，实际的话还需要考虑这些内存占用","path":"2025/05/03/MySQL/树高计算/","date":"05-03","excerpt":"","tags":[]},{"title":"如何提高QPS","text":"QPS：即每秒查询量 硬件优化 1.CPU 2.内存 3.磁盘 SSD 参数设置 1.InnoDB_buffer_pool_size 2.redo log buffer大小 3.连接数 业务层面 1.读写分离 2.数据库分片 3.冷热分离","path":"2025/05/03/MySQL/QPS ？调优/如何提高QPS/","date":"05-03","excerpt":"","tags":[]},{"title":"Spring事务","text":"事务：一组操作的集合 事务是怎么实现的底层基于数据库事务和AOP来实现的。也就是说如果你数据库用的存储引擎不支持事务，那 Spring事务就肯定没有的。（声明式事务才会基于AOP，编程式事务只是基于数据库的事务） 首先它会对使用了@Transitional注解的Bean（怎么判断Bean上是否有的？类、或者父类、或者接口、或 者方法中有这个注解都可以），创建一个代理对象 当调用代理对象的方法时，就会去判断方法上是否加了@Transitional 如果是，那么就用事务管理器创建一个数据库连接 并且把其自动提交置为false，变为手动提交，这是Spring重要的一步，即把事务交给Spring管理 然后就会执行SQL 执行完当前方法后，就直接提交事务 如果有异常，且这个异常是要回滚的异常，就会回滚事务，如果不是就还是直接提交 Spring事务的隔离级别对应的就是数据库的事务隔离级别 Spring事务的传播行为是Spring自己来实现的，也是Spring事务中最复杂的地方 Spring事务的传播是基于数据库连接来做的，一个事务对应着一个数据库connection 隔离级别传播机制声明式@Transitional 无侵入性，但粒度大，只支持方法级别 编程式粒度小，可以避免Spring AOP失效的问题 基于TransitionTemplate 12345678910111213141516171819@Autowiredprivate TransactionTemplate transactionTemplate;public void testTransaction() &#123; transactionTemplate.execute(new TransactionCallbackWithoutResult() &#123; @Override protected void doInTransactionWithoutResult(TransactionStatus transactionStatus) &#123; try &#123; // .... 业务代码 &#125; catch (Exception e)&#123; //回滚 transactionStatus.setRollbackOnly(); &#125; &#125; &#125;);&#125; 基于TransitionManager 12345678910111213@Autowiredprivate PlatformTransactionManager transactionManager;public void testTransaction() &#123; TransactionStatus status = transactionManager.getTransaction(new DefaultTransactionDefinition()); try &#123; // .... 业务代码 transactionManager.commit(status); &#125; catch (Exception e) &#123; transactionManager.rollback(status); &#125;&#125; 事务失效spring 事务失效的 12 种场景_spring 截获duplicatekeyexception 不抛异常-CSDN博客 声明式失效的场景 方法访问权限不为public，因为方法要想被Spring代理，就必须是public 方法被final修饰，被final修饰意味着不能被重写。声明式事务使用了AOP，底层是用到jdk和cglib了动态代 理，都得通过重写重写方法去实现代理 方法内部调用时，没通过代理对象调用方法，而是通过this调用 Bean没被Spring所管理 多线程事务 表不支持事务 事务回滚不了的场景 错误的传播特性 自己捕获了异常，且不抛出 自定义异常 手动抛了别的异常，默认情况下不指定只会抛运行时异常 嵌套事务回滚多了","path":"2025/05/01/Spring/Spring事务/","date":"05-01","excerpt":"","tags":[]},{"title":"InnoDB逻辑储存结构","text":"表空间——段——区——页——行 表空间： 默认情况下InnoDB有一个共享表空间ibdata1，所有数据放入这个表空间，如果开启了innodb_file_per_table（默认ON），每张表都可以放到一个单独的表空间，但只把数据、索引和Insert Buffer Bitmap放入单独表空间，其它数据，如undo信息、插入缓冲索引页、事务信息，二次写缓冲等还是放共享表空间 段： 表空间由各个段组成，数据段、索引段、回滚段等，数据段即B+树叶子节点，索引段即B+树非叶子节点。每个段开始时，先用32个页大小的碎片页存放数据，使用完这些碎片页，再去一个区一个区地申请内存，这保证了小段如undo这样的段可以省空间 区： 区由连续的页组成，一个区固定是1MB，页默认16KB，即一个区有64个连续的页，InnoDB1.0.x引入压缩页，页的大小可以是2K、4K、8K，但不管怎么变，区都是1MB 页： InnoDB磁盘最小的管理单位，默认16KB，InnoDB1.2.x开始可以更改默认大小innodb_page_size为4K、8K、16K，更改后，不得再次修改，除非mysqldump导入导出产生新的库 常见的页类型： 数据页（B-tree Node） undo页（undo Log Page） 系统页（System Page） 索引页（Index Page） 事务数据页（Transaction system Page） 插入缓冲位图页（Insert Buffer Bitmap） 插入缓冲空闲列表页（Insert Buffer Free List） 未压缩的二进制大对象页（Uncompresses BLOB Page） 压缩的二进制大对象页（compressed BLOB Page） 行： 行存储有四种格式，Redundant、Compact、Dynamic和Compressed。MySQL5.1开始默认使用Compact，MySQL5.7开始默认使用Dynamic Compact： 变长字段长度列表 NULL标志位 记录头信息 row_id trx_id roll_ptr 列1数据 列2数据 …… 变长字段长度列表：当数据表有变长字段时才出现，记录本行中各变长字段实际长度，当长度小于255时用1个字节表示，大于255时用2个字节表示，不会用3个字节，因为变长字段有长度限制，最多65535字节 NULL标志位：当数据表存在允许NULL的字段时才出现，本行每个字段是否为null用0或1表示，同时必须是整数个字节大小，即不足8个bit位的高位补0 记录头信息：存储一些信息，固定5个字节，如delete_mask，标识删除位；next_record下条记录的地址；record_type，记录类型，0为普通，1为B+树非叶子节点，2为最小记录，3为最大记录 变长字段长度列表和NULL是逆序存储(方便寻址) row_id：当建表时没指定主键时，选择第一个非空唯一索引当主键，如果没有，添加该列作为主键，6字节大小 trx_id：事务id，这条数据是哪个事务生成的，6字节大小 roll_ptr：上个版本的指针，7字节大小 一个页最多有16KB，16384字节，而varchar(n)最多可以存储65533字节，那么一个页可能都放不了一条记录，这时就会行溢出，溢出的数据会放到“溢出页”中，原页会保留20个字节指向该溢出页的地址。 Compressed和Dynamic行格式和Compact非常相似，主要是行溢出时的处理，这两个不会在原页保存数据，只用20字节指针指向溢出页，数据全在溢出页，而Compressed还会对BLOB、TEXT、VARCHAR这些大长度类型的数据进行zlib算法压缩 varchar类型理论最多可以存放65535个字节，但实际上最多65533个字节： 除了TEXT、BLOBs这种大对象类型，其它所有列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535字节 所以65535字节&gt;&#x3D;变长字段长度列表 + NULL标志位 + 各列长度 当一列只有varchar时，需要占用2字节的变长字段长度列表 + 0或1的NULL标志位（看varchar允不允许为NULL）+ varchar长度 所以最多varchar最多存储65533个字节（当varchar不允许为NULL时） char和varchar？ char存储固定长度字符串，最大长度255字节，当存储长度小于定义的长度时，MySQL在后面补空格（如果本身存储的字符串尾部就有空格，就会丢失空格信息！） varchar存储可变字符串，读取速度相对更慢一点，因为需要先读长度，再读数据 一般使用varchar存储较好，但考虑到极端情况，varchar因为长度可变，可能出现页分裂的情况 如果是身份证号、订单号、国家编码等这些固定长度的，可以用char 如果是产品描述、用户地址、用户名称这种，可以用varchar 数据页结构： 采用链表的结构是让数据页之间不需要是物理上的连续的，而是逻辑上的连续。 数据页中的记录按照「主键」顺序组成单向链表，单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索。 因此，数据页中有一个页目录，起到记录的索引作用，就像我们书那样，针对书中内容的每个章节设立了一个目录，想看某个章节的时候，可以查看目录，快速找到对应的章节的页数，而数据页中的页目录就是为了能快速找到记录。 将所有的记录划分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录； 每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为 n_owned 字段（上图中粉红色字段） 页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），每个槽相当于指针指向了不同组的最后一个记录。 从图可以看到，页目录就是由多个槽组成的，槽相当于分组记录的索引。然后，因为记录是按照「主键值」从小到大排序的，所以我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录，无需从最小记录开始遍历整个页中的记录链表。 第一个分组中的记录只能有 1 条记录； 最后一个分组中的记录条数范围只能在 1-8 条之间； 剩下的分组中记录条数范围只能在 4-8 条之间。 索引： 索引页的行记录是指针，指向一个页，索引页的索引键值就是指向的页的最小索引键值 数据页的行记录就是数据（聚簇索引，如果是二级索引，存放的是主键值） 页合并和页分裂： 页合并： 当一个数据页的使用率低于一定阈值（50%）时，MySQL 就会将该页与相邻的空闲页合并成一个页面。 例如，数据页能存放7条数据，有两个相邻的数据页，一个存储 [1, 2, 3, 4]，另一个是[5, 6]。当删除4时，会检查本页，本页数据只有三条，小于阈值，MySQL 就会将两个页面合并成一个页面，存储的数据变成 [1, 2, 3, 5, 6] 页分裂： 当一个数据页已经满了，而有新的数据要插入到该页时，MySQL 就会进行页分裂操作。 例如，数据页能存放5条数据，假设一个数据页已经存储了 [1, 2, 3, 4, 5]，而有新的数据6要插入到该页中，MySQL 就会将该页拆分为两个页面，一个页面存储 [1, 2, 3]，另一个页面存储 [4, 5, 6]。 页分裂是为了保证插入顺序的同时不大量挪动数据 采用逻辑删除可以减少页合并 采用批量顺序插入可以减少页分裂","path":"2025/04/30/MySQL/引擎/InnoDB/InnoDB逻辑储存结构/","date":"04-30","excerpt":"","tags":[]},{"title":"数据库三范式","text":"简单地说就是 一个字段干一个字段该干的事，一张表干一张表该干的事 第一范式：每个属性不能再拆，例如地址需要拆成省、市、区、街道、小区等等多个字段才满足第一范式，否则如果是长文本的话，不满足第一范式 第二范式：所有信息必须直接和整个主键相关，不能只依赖不分主键（比如只依赖联合索引的部分），比如【（订单号，包裹号），收件人，包裹内容，收件人电话】，这里面（订单号，包裹号）是主键，而收件人和电话其实只依赖订单号，而不依赖包裹号，所以不满足第二范式 第三范式：非主键外的字段互不依赖，比如【订单号，收件人，驿站编号，驿站地址】，这里面驿站地址依赖的其实是驿站编号，而不是直接依赖订单号，所以不满足第三范式 满足范式的好处： 减少数据冗余 增强数据一致性 数据易于维护","path":"2025/04/29/MySQL/数据库三范式/","date":"04-29","excerpt":"","tags":[]},{"title":"BlockingQueue","text":"blockingQueue一Java接口，它代表了Java中线程安全的队列，不仅可以多线程地访问元素，还添加了等待-通知机制， 可以实现在阻塞等待取元素，阻塞等待插入元素 boolean add(E e) ：将元素添加到队列尾部，如果队列满了，则抛出异常 IllegalStateException。 boolean offer(E e)：将元素添加到队列尾部，如果队列满了，则返回 false。 void put(E e)：将元素添加到队列尾部，如果队列满了，则线程将阻塞直到有空间。 offer(E e, long timeout, TimeUnit unit)：将指定的元素插入此队列中，如果队列满了，则等待指定的时间，直到队列可用。 take()：检索并删除此队列的头部，如有必要，则等待直到队列可用； 一般会上锁保证只有一个线程take到头部 poll(long timeout, TimeUnit unit)：检索并删除此队列的头部，如果需要元素变得可用，则等待指定的等待时间。 boolean remove(Object o)：从队列中删除元素，成功返回true，失败返回false E poll()：检索并删除此队列的头部，如果此队列为空，则返回null。 E element()：检索但不删除此队列的头部，如果队列为空时则抛出 NoSuchElementException 异常； peek()：检索但不删除此队列的头部，如果此队列为空，则返回 null. blockingDequeue双端阻塞队列，继承于blockingQueue，可以想使用blockingQueue的API一样使用它 ArrayBlockingQueue数组阻塞队列，有界的，且因为是基于静态数组实现的，一旦初始化，数组大小无法修改，且必须在构造时 初始化。 FIFO：队列操作符合先进先出 ArrayBlockingQueue并不能保证绝对的公平，即先到先得，因为还有线程调度的存在。想要保证绝对的公平 ，可以在构造时置 fair&#x3D;true 并发控制基于ReentrantLock和对应的Condition实现，读和写都得先获取锁。 LinkedBlockingQueue基于链表实现的线程安全的阻塞队列 可实现头部和尾部的高效插入 可在构造时指定最大容量，若没指定，即为Integer.MAX_VALUE，即受限于内存大小，但还是有界的 LinkedBlockingQueue和ArrayBlockingQueue的区别相同点： 都是通过从condition通知机制来实现可阻塞的插入和获取 不同点： 1.一个基于链表，一个基于数组 2.ArrayBlockingQueue读和写都是一把锁，而LinkedBlockingQueue读和写两把锁，锁的粒度更小 PriorityBlockingQueue 具有优先级特性的无界队列，元素在队列里面的排序基于自然的排序，或者我们实现Compare接口来实现自 定义排序，适用于根据优先级来执行任务 SynchronousQueue LinkedTransferQueue DelayQueue延迟队列","path":"2025/04/29/JUC/BlockingQueue/","date":"04-29","excerpt":"","tags":[]},{"title":"AQS","text":"是什么？AbstractQueueSynchronized 抽象队列同步器。是Java并发编程整个体系的基石，是用来构建锁或者同步组件的基础框架。它通过FIFO队列来实现线程获取资源的排队工作，并通过一个int变量来表示锁的获取状态 锁和同步器的关系 锁是面向锁的使用者，你调用就好了 同步器是面向锁的实现者，比如说你开发的时候需要自定义锁，而同步器可以为你提供实现锁的框架，帮你简化了实现，比如你不用去关心同步状态管理，阻塞队列的排队情况等等 AQS的独占模式和共享模式？独占意味着同一时刻只有一个线程可以获取同步状态，是互斥锁的基础 共享意味着多个线程可以同时获取同步状态，如 信号量，ReadWriteLock 同步队列FIFO虚拟双向队列，是CLH队列的变种 想要加锁失败后导致阻塞，阻塞就得排队，那么排队就得有队列 如果资源被占用，那么就得有一定的线程阻塞等待唤醒机制来保证锁的分配。FIFO AQS为什么采用双向链表？1234567//基本结构 class Node&#123; Node pre; Node next; Thread thread; ...... &#125; 双向链表有两个指针，一个指向前驱节点，一个指向后驱节点 需要前驱节点： 能够实现常量级别的前驱节点查找，增删操作比单向链表更加高效和简单。 AQS在设计的时候为了去避免有线程节点因为异常而导致后置的节点无法被正确唤醒的情况，所以线程节点 在入队的时候都会去判断前置节点的状态，如果这时候没有前驱指针的话，那找到前驱节点就得从头开始遍历 了。 Lock接口里有个lockInterrupt方法，该方法就是说允许加入到阻塞队列里的线程节点被外部所中断。当阻塞队列里的线程被中断后，当线程节点并不会被立马删除，而是会被标记为cancelled状态，然后从尾节点找到离cancelled节点最近的正常节点进行唤醒。同样如果没有前置节点的话，得一个个往下遍历，查询性能很低 按照公平锁的设计，只有头结点的下一个节点才有必要去竞争锁。那么这里就涉及一个前置节点的判断，这个 是单向链表无法实现的。 总的来说就是存在需要高效查找前置节点的需求 ps：上面说的线程节点被外部中断后不会立马删除，那啥时候删除呢 为什么上面说要从尾节点向前遍历，不可以头节点向后遍历？这个官网没说这么做的原因，网上也没人提为啥这么干。我当时是觉得这样可以减少对头部节点的竞争。因为在高并发情况下，头结点一定是被频繁访问or修改最大的节点，因为头节点是释放锁or被唤醒的首选位置。从尾结点向前遍历就可以减少在头结点上的竞争。","path":"2025/04/28/JUC/AQS/","date":"04-28","excerpt":"","tags":[]},{"title":"EasyExcel","text":"百万Excel数据导出如何实现查询数据时分页查，写入多个sheet页 看多线程 导出慢的话，改成异步，用户不需要等待，生成完成，用户点击按钮下载即可 百万Excel数据导入如何实现Easy Excel基于事件流，一行一行读 内存占留的记录也不要太多，分批插入数据库 使用 .csv 文件代替 .xlsx：CSV 文件结构简单，解析更快，占内存更小 避免一次上传过大的 Excel（分批上传） 异步上传，先保存到对象存储服务器，消费者根据实际情况拉取进行处理 读多个sheet页？123456789101112131415161718InputStream inputStream = new FileInputStream(&quot;your_excel_file.xlsx&quot;);ExcelReader excelReader = EasyExcel.read(inputStream).build();ReadSheet sheet1 = EasyExcel.readSheet(0) .head(StudentData.class) .registerReadListener(new StudentDataListener()) .build();ReadSheet sheet2 = EasyExcel.readSheet(1) .head(ScoreData.class) .registerReadListener(new ScoreDataListener()) .build();excelReader.read(sheet1, sheet2);excelReader.finish(); 合并单元格 12345678910//定义一个Handler去继承CellWriteHandler 重写里面的afterSheetCreate@Overridepublic void afterSheetCreate()&#123; &#125; EasyExcel.write(&quot;学生信息.xlsx&quot;, StudentData.class) .registerWriteHandler(new MergeSameCellHandler(0)) // 合并“班级”列（第0列） .sheet(&quot;学生表&quot;) .doWrite(list);","path":"2025/04/28/项目/AI学生发展性评价系统/EasyExcel/","date":"04-28","excerpt":"","tags":[]},{"title":"大型订单系统分库分表设计","text":"什么时候应该分库？ 如果你是为了解决并发量太高，数据库连接数不够，CPU，内存，磁盘不够的原因 什么时候时候应该分表？ 只是说单表数据量太大，需要提高查询性能 所以说分表解决的是大数量的问题，而分库解决的是高并发的问题","path":"2025/04/28/场景题/大型订单系统分库分表设计/","date":"04-28","excerpt":"","tags":[]},{"title":"约定大于配置？","text":"","path":"2025/04/27/SpringBoot/约定大于配置？/","date":"04-27","excerpt":"","tags":[]},{"title":"如何优雅停机","text":"","path":"2025/04/27/SpringBoot/如何优雅停机/","date":"04-27","excerpt":"","tags":[]},{"title":"JDK新特性","text":"JDK 8： Lambda表达式 Stream流 日期类 接口的默认方法、静态方法 Optional CompletableFuture JDK 17： instanceof的匹配增强，不需要进行强转了，例如 if (obj instanceof String s) {System.out.println(s.toUpperCase())}; Text Blocks文本块： switch表达式","path":"2025/04/27/JavaSE/JDK新特性/","date":"04-27","excerpt":"","tags":[]},{"title":"多态原理","text":"创建多态对象时使用 invokespecial 字节码，调用对象方法时使用 invokevirtual 字节码 invokevirtual 指令在运行时的解析过程可以分为以下几步： 找到操作数栈顶的元素所指向的对象的实际类型，记作 C。 如果在类型 C 中找到与常量池中的描述符匹配的方法，则进行访问权限校验，如果通过，则返回这个方法的直接引用，查找结束，否则返回 java.lang.IllegalAccessError 异常。 常量池找不到方法，则按照继承关系从下往上依次对 C 的各个父类进行第二步的搜索和验证。 如果始终没有找到合适的方法，则抛出 java.lang.AbstractMethodError 异常。","path":"2025/04/27/JavaSE/多态原理/","date":"04-27","excerpt":"","tags":[]},{"title":"泛型","text":"什么是泛型1.5的时候，出的一种新特性，允许在定义 类、接口或方法 时指定一个“类型参数”，这个参数在使用时再确 定为实际的类型 ** ** 好处就是 编译时就进行类型检查，避免之前运行时Object类型转换错误带来的异常问题 泛型擦除在底层会把泛型擦成 Object 泛型的不可协变性 如何解决泛型的不可协变性","path":"2025/04/27/JavaSE/泛型/","date":"04-27","excerpt":"","tags":[]},{"title":"反射","text":"可以动态地获取类的全部信息和方法 优点： - 灵活性和扩展性 缺点 - 破坏了封装性 - 可读性和可维护性低 - 执行性能低 反射为什么性能差？","path":"2025/04/27/JavaSE/反射/","date":"04-27","excerpt":"","tags":[]},{"title":"动态代理","text":"","path":"2025/04/27/JavaSE/动态代理/","date":"04-27","excerpt":"","tags":[]},{"title":"内存结构","text":"1.7和1.8的区别 程序计数器：线程私有，程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都依赖这个计数器完成。唯一一个不会OOM的 如果线程正在执行一个Java方法， 这个计数器记录的是正在执行的虚拟机字节码指令的地址； 如果线程正在执行一个本地方法，这个计数器的值应为空 虚拟机栈：线程私有，每个方法被执行时，Java虚拟机都会同步创建一个栈帧用于存储局部变量表，操作数栈，动态连接，方法出口等信息。 每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表：存放了编译器可知的各种Java虚拟机基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或者其它与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址），当 Java 源代码文件被编译成 class 文件的时候，局部变量表的最大容量就已经确定了 动态链接：指向运行时常量池中该栈帧所属方法的引用 操作数栈：临时存放操作数以及计算结果，最大深度在编译的时候就确定了 方法返回地址：方法执行完毕后返回的地址 本地方法栈：线程私有，和虚拟机栈作用类似，本地方法栈内部执行的是本地方法，在hotspot里和虚拟机栈合二为一了 Java堆：线程共享，几乎所有的对象都在堆上分配（逃逸分析可能导致对象在栈上分配） 线程分配缓冲区：线程私有，提升对象分配时的效率 方法区：线程共享，存储已经被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。 方法区一直是个概念上的区域，在不同jdk版本有不同实现 jdk6及6之前，方法区是使用永久代实现的，发现放到永久代不太好，决定开始放到本地内存 jdk7把原本放在永久代的字符串常量池、静态变量等移出，此时运行时常量池还是在永久代中 jdk8彻底废弃永久代的概念，将永久代的剩余内容（主要是类型信息）全部移到元空间，使用元空间实现方法区 永久代时，默认大小64MB；元空间时，大小不受JVM限制 运行时常量池：当类被加载时，类中的字面量与符号引用被放入运行时常量池，由符号引用翻译出来的直接引用也存储在运行时常量池 直接内存：并不是Java虚拟机规范中定义的内存区域","path":"2025/04/27/JVM/内存结构/","date":"04-27","excerpt":"","tags":[]},{"title":"类加载","text":"类加载针对对象总所周知，java中数据类型分为 基本数据类型和**引用数据类型，**基本数据类型一开始就被jvm定义好了，故类 加载的类型是针对于 引用数据类型 一个类只能被加载一次吗准确地说应该是一个类只能被同一类加载加载一次 加载过程 loading：简而言之，就是把磁盘里的字节码文件加载到内存，并在堆上生成一个Class对象（类模版对象） Linking(验证)阶段 验证：验证加载的字节码是否合法，合理符合规范 准备：为类的静态变量分配内存，并将其赋为默认值。不包含static final修饰的基本数据类型，final类型 的在编译就分配好内存了，准备阶段就是显性赋值了 解析：把符号引用变成直接引用 ps：java虚拟机并没有规定以上三步一定要按顺序。比如在hotspot vm中，解析操作是在初始化化后 的，因为涉及到内存的分配 初始化阶段：重要工作就是执行类的初始化方法:()方法。简而言之，就是为类的静态变量赋正确的值 1.clinit&lt;&gt;()是由jvm来控制的，我们不能在代码中重写or调用它，本身就是字节码指令 2.它是由类的静态成员变量语句以及static代码块组成的 3.在虚拟机加载一个类之前，会先尝试加载该类的父类，因为父类的clinit&lt;&gt;()方法总是在子类之前被执行 也就是说父静态代码块优先于子类 4.clinit&lt;&gt;()是加锁的，多线程尝试去初始化同一个类的，只能有一个线程去执行初始化，其他线程都得阻 塞 5.clinit&lt;&gt;()采用的是懒加载思想，类or接口只有在被第一次主动使用时才会初始化 类的主动使用和被动使用？ 主动使用： 1. 创建一个实例对象，如new,clone,反序列化 2. 调用类的静态方法，即执行字节码指令invokestatic 3. 当使用类,接口的静态变量（final变量另外说），即执行字节码指令getstatic,putstatic 4. 通过反射API去创建 5. 当初始化一个类时，其父类还没初始化，会先初始化其父类 6. 虚拟机启动时，main方法所在那个类也会先被初始化 7. jdk7中methodHandle第一次使用调用它的invoke时也会初始化其目标类 只有主动使用xx类，类才会被初始化，而被动使用是不会的 被动使用的情况： 1. 只有真正声明静态变量的类才会被初始化，比如子类去调用父类的静态变量，子类并不会被初始化。至于子类有没有验证，准备，则需要通过使用-XX:+TraceClassLoading来追踪类的加载信息 2. 调用类的引用常量该类并不会被初始化 3. 通过数组定义类引用，不会触发此类的初始化 即 MyClass[] arr=new MyClass[6]; 什么时候加载类？ JVM规范并没有强制约束，交给虚拟机具体实现来自由把握","path":"2025/04/27/JVM/类加载/","date":"04-27","excerpt":"","tags":[]},{"title":"高可用","text":"","path":"2025/04/27/RabbitMQ/高可用/","date":"04-27","excerpt":"","tags":[]},{"title":"事务机制","text":"","path":"2025/04/27/RabbitMQ/事务机制/","date":"04-27","excerpt":"","tags":[]},{"title":"4.0x特性？Rabbitmq未来？","text":"","path":"2025/04/27/RabbitMQ/4.0x特性？Rabbitmq未来？/","date":"04-27","excerpt":"","tags":[]},{"title":"虚拟线程/协程","text":"kotlin的协程就是扯淡 go协程池是为了在cpu密集型场景得到复用 Java的虚拟线程就不建议用cpu密集型","path":"2025/04/27/JUC/虚拟线程!协程/","date":"04-27","excerpt":"","tags":[]},{"title":"优先级队列","text":"","path":"2025/04/27/RabbitMQ/优先级队列/","date":"04-27","excerpt":"","tags":[]},{"title":"架构","text":"channel： exchange Queue virtual host","path":"2025/04/27/RabbitMQ/架构/","date":"04-27","excerpt":"","tags":[]},{"title":"死信队列","text":"","path":"2025/04/27/RabbitMQ/死信队列/","date":"04-27","excerpt":"","tags":[]},{"title":"如何保证消息可靠性","text":"","path":"2025/04/27/RabbitMQ/如何保证消息可靠性/","date":"04-27","excerpt":"","tags":[]},{"title":"与其他MQ的对比","text":"","path":"2025/04/27/RabbitMQ/与其他MQ的对比/","date":"04-27","excerpt":"","tags":[]},{"title":"并发并行","text":"","path":"2025/04/27/JUC/并发并行/","date":"04-27","excerpt":"","tags":[]},{"title":"unsafe","text":"unsafe类是Java中一个比较特殊的类，它为Java提供了一种不安全的 直接访问和操作内存和线程和对象 正如它的名字一样，unsafe提供了很多不安全的操作，我们应该尽量不直接使用它，除非真的要操作底层 unsafe类需要通过反射才能获取对象，这样做的是让程序员知道这是一个非常底层的类，如果是能直接new的 话，那使用起来就很轻松了 内存操作： &#x2F;&#x2F;分配新的本地空间public native long allocateMemory(long bytes);&#x2F;&#x2F;重新调整内存空间的大小public native long reallocateMemory(long address, long bytes);&#x2F;&#x2F;将内存设置为指定值public native void setMemory(Object o, long offset, long bytes, byte value);&#x2F;&#x2F;内存拷贝public native void copyMemory(Object srcBase, long srcOffset,Object destBase, long destOffset,long bytes);&#x2F;&#x2F;清除内存public native void freeMemory(long address); 对象操作：&#x2F;&#x2F;在对象的指定偏移地址获取一个对象引用publicnativeObjectgetObject(Objecto,longoffset);&#x2F;&#x2F;在对象指定偏移地址写入一个对象引用publicnativevoidputObject(Objecto,longoffset,Objectx);&#x2F;&#x2F;在对象的指定偏移地址处读取一个int值，支持volatile load语义publicnativeintgetIntVolatile(Objecto,longoffset);&#x2F;&#x2F;在对象指定偏移地址处写入一个int，支持volatile store语义publicnativevoidputIntVolatile(Objecto,longoffset,intx); CAS操作：publicfinalnativebooleancompareAndSwapInt(Objecto,longoffset,intexpected,intx); 线程调度：park、unpark Class操作：&#x2F;&#x2F;获取静态属性的偏移量publicnativelongstaticFieldOffset(Fieldf);&#x2F;&#x2F;获取静态属性的对象指针publicnativeObjectstaticFieldBase(Fieldf);&#x2F;&#x2F;判断类是否需要实例化（用于获取类的静态属性前进行检测）publicnativebooleanshouldBeInitialized(Class&lt;?&gt;c);","path":"2025/04/27/JUC/unsafe/","date":"04-27","excerpt":"","tags":[]},{"title":"原子类","text":"AtomicInteger、AtomicLong、AtomicBoolean（三者基本一致）： public final int get() &#x2F;&#x2F;获取当前的值 public final int getAndSet(int newValue)&#x2F;&#x2F;获取当前的值，并设置新的值 public final int getAndIncrement()&#x2F;&#x2F;获取当前的值，并自增 public final int getAndDecrement() &#x2F;&#x2F;获取当前的值，并自减 public final int getAndAdd(int delta) &#x2F;&#x2F;获取当前的值，并加上预期的值 boolean compareAndSet(int expect, int update) &#x2F;&#x2F;如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update） public final void lazySet(int newValue)&#x2F;&#x2F;最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray（三者基本一致）： public final int get(int i) &#x2F;&#x2F;获取 index&#x3D;i 位置元素的值 public final int getAndSet(int i, int newValue)&#x2F;&#x2F;返回 index&#x3D;i 位置的当前的值，并将其设置为新值：newValue，返回旧值 public final int getAndIncrement(int i)&#x2F;&#x2F;获取 index&#x3D;i 位置元素的值，并让该位置的元素自增 public final int getAndDecrement(int i) &#x2F;&#x2F;获取 index&#x3D;i 位置元素的值，并让该位置的元素自减 public final int getAndAdd(int i, int delta) &#x2F;&#x2F;获取 index&#x3D;i 位置元素的值，并加上预期的值 boolean compareAndSet(int i, int expect, int update) &#x2F;&#x2F;如果输入的数值等于预期值，则以原子方式将 index&#x3D;i 位置的元素值设置为输入值（update） public final void lazySet(int i, int newValue)&#x2F;&#x2F;最终 将index&#x3D;i 位置的元素设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。","path":"2025/04/27/JUC/原子类/","date":"04-27","excerpt":"","tags":[]},{"title":"其他集合类","text":"","path":"2025/04/27/JUC/其他集合类/","date":"04-27","excerpt":"","tags":[]},{"title":"CopyOnWrite","text":"","path":"2025/04/27/JUC/CopyOnWrite/","date":"04-27","excerpt":"","tags":[]},{"title":"ConcurrentHashMap","text":"吊打Java面试官之ConcurrentHashMap（线程安全的哈希表） jdk1.7 concurrentHashMap里存了一个segement数组，然后一个segement元素类似于一个HashTable。当put元素 时，然后根据Hash值定位到某个segement里，然后对segement加一个ReentrantLock就好了，这也保证了 不同segement之间可以并发操作。 无参构造初始化后 concurrencyLevel（最大并发级别，即决定segement数组的容量）默认为16，一旦初始化后不可扩容 2.初始化segement[i]（HashEntry数组）为2，负载因子为0.75，扩容阀值是 2*0.75&#x3D;1.5，即插入第二个值 后才会触发扩容，扩容一次 size*2 3.插入元素时才会初始segement[cur]，其他的都还是null。如果这时候segement[i]扩容到了4，那么其他 segement也会参照segement[cur]进行初始化 4.segementshift 和 segementmask 用来定位元素在哪个segement位置 put流程 1.为输入的key做Hash运算，得到其Hash值 2.通过Hash值，定位到在segement数组的位置 3.获取ReentrantLock 4.再次Hash运算，得到在segement元素内部的位置 5.覆盖or插入HashEntry对象 6.释放ReentrantLock get(无锁) 为输入的key做Hash运算，得到Hash值 根据Hash值定位到segement对象 再进行一次Hash 定位到segement数组里的具体位置 为什么get()不需要上锁，因为Node节点里的val和next都用到了volatile jdk1.8 concurrentHashMap采用了Node数组来存元素，并基于CAS+synchronized来保证线程安全 初始化 懒汉式初始化桶元素（new的时候，Node[]还是null，HashMap也是） 负载因子默认为0.75。它这里有个有趣的点，即使让构造时用户手动指定了负载因子，后续扩容还是会 按0.75来进行扩容（HashMap就不是，会按照用户设置好的负载因子进行扩容） capacity表示你想往里存放的元素个数，但实际它在初始化时会将其变成2的幂，比如你cap&#x3D;18,它会变 成32，这也是跟HashMap一样 get()：无锁，因为Node[]和Node里的next和value都有volatile修饰，保证读取到的都是最新的值 initTable(): CAS保证只有一个线程初始化成功，涉及到volatile 修饰的sizeCtl。如果有线程初始化成功就会把 它设置为-1，下一个线程发现&lt;0时，说明已经有线程进行初始化了。就会进行Thread.yield() 即让出CPU使 用权 put() 1.检查key和value不能为null 2.进入死循环 3.如果是第一次put，则初始化Table，并用cas保证线程安全，然后重新进入死循环 4.如果头节点为null，则通过CAS将当前值设置为头节点，成功就直接break，失败就重新进入死循环 5.如果头节点为ForwardingNode，说明此时当前桶在扩容，则当前线程需要去协助扩容，扩容完成后 重新进入循环 6.到了这里说明要往当前槽位的链表or红黑树里加元素了，此时使用synchronized对头结点进行上锁操作 a.再次判断头节点是否被移动 如果此时是链表，则走链表的更新逻辑 如果是红黑树，就走红黑树的更新逻辑 b.释放锁，判断是否需要树化，然后break 7.执行addCount方法，addCount(1L, binCount); 更新binCount（ 当前桶（bucket）中节点个数 ） 扩容 何时扩容？当前元素个数为 数组大小*0.75 整个扩容操作分为两个部分 1.构建一个nextTable，容量为原来的2倍，且这个构建是单线程的 2.把原来Table里的元素复制到新的Table里，这个主要是遍历复制的过程。然后遍历是指会从后往前遍历 原Table，然后通过tableAt(i)获取i位置的元素 a.若tableAt(i)等于null，则会将其标记为ForwardingNode，这是并发协作的基础 b.若tableAt(i)为Node节点（fh&gt;&#x3D;0），即为链表节点，会将其链表一分为2。然后将其放到 nextTable的i和i+n位置上（n为数组长度） c.若为TreeBin即红黑树节点，则判断是否需要取消树化，将其放到nextTable的i和i+n位置 d.遍历所有元素完成复制，并将nextTable做为新的Table，把sizeCtl赋值为新容量的0.75，至此完 成扩容 ps：sizeCtl是什么？（CTL： Control ） size() counterCells：每个槽位里的桶数量，会在高并发时被初始化出来，且高并发场景下size的部分逻辑就会 走counterCells 为什么HashMap的key和value可以是null？ containsKey(key)：先根据key获取Node，再判断Node是否为null。可以解决key为null的歧义问题 单线程的情况下，不如出现二义性 为什么concurrentHashMap的key和value不可以是null？ 在多线程的情况下，会有二义性。 二义性： get(key)后发现value&#x3D;null，存在两种情况，一种不存在，一种value为null。但此时你要 containsKey(key)时，有线程把key删了，让你误认为key是不存在，而不是只是value为null 如果想要解决它，其实是可以解决的。两个方法 1.get()方法加锁，保证没有人来删，但费性能 2.value直接不能为null，简单暴力，concurrentHashMap就是采用此方法 当你的value不为null时，key为null，完全是可以通过containsKeys来解决二义性的 那为什么concurrentHashMap还要把key设置为null呢？？ ConcurrentHashMap作者 道林认为往Map里塞key为null，显然就是一件奇怪的事。这 也是他HashMap作者的分歧。因为道林他认为key中存在null是存在风险的，而且直接让key不为null可以 在代码层面少去很多判空逻辑 为什么jdk1.8concurrentHashMap要采用synchronized，而不是ReentrantLock ReentrantLock是对象锁吧，占的空间是要比synchronized大的。","path":"2025/04/27/JUC/ConcurrentHashMap/","date":"04-27","excerpt":"","tags":[]},{"title":"线程中断/停止","text":"强制：Thread.stop() 已废除了 优雅：Interrupt()","path":"2025/04/27/JUC/线程中断!停止/","date":"04-27","excerpt":"","tags":[]},{"title":"线程池","text":"手搓一个123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/** * 线程根本不存在复用这一说，在它创建，销毁这个生命周期来看，执行完一个任务后肯定是会销毁的 *//** * 我们需要什么？ * 核心线程 coreThread * 非核心线程 supportThread * 任务队列 workQueue * 拒绝策略 rejectHandle */public class MyThreadPool &#123; public MyThreadPool(BlockingQueue&lt;Runnable&gt; workQueue, int corePoolSize, int maxPoolSize, TimeUnit timeUnit, long timeout, RejectHandle rejectHandle)&#123; this.workQueue = workQueue; this.corePoolSize=corePoolSize; this.maxPoolSize=maxPoolSize; this.timeUnit = timeUnit; this.timeout = timeout; this.rejectHandle = rejectHandle; &#125; //存放任务的队列 private final BlockingQueue&lt;Runnable&gt; workQueue; private final int corePoolSize; private final int maxPoolSize; private final TimeUnit timeUnit; private final long timeout; private final RejectHandle rejectHandle; //TODO: 当前这个execute一系列判断操作不是原子操作，所以存在线程安全问题，加锁，使用原子变量，volatile public void execute(Runnable command)&#123; //如果核心线程数还没满，则创建核心线程去执行 if(coreThreadList.size()&lt;corePoolSize)&#123; //创建线程 Thread thread = new CoreThread(); //添加线程 coreThreadList.add(thread); //开启线程 thread.start(); &#125; //任务进入任务队列 //如果可以在不违反容量限制的情况下立即将指定的元素插入到此队列中，成功时返回 true， //如果当前没有可用空间，则返回 false。当使用容量受限的队列时，此方法通常比 add 更可取， //后者可能仅通过引发异常来无法插入元素。 if(workQueue.offer(command))&#123; return; &#125; //任务队列满了的话，开始创建非核心线程了 //判断线程数是否超过最大线程树 if(coreThreadList.size()+supportThreadList.size()&lt;maxPoolSize)&#123; Thread supportThread = new SupportThread(); supportThreadList.add(supportThread); supportThread.start(); &#125; //阻塞队列还是放不下的话，就要执行拒绝策略了 if (!workQueue.offer(command)) &#123; //执行拒绝策略 rejectHandle.reject(command, this); &#125; &#125; public void executeSafe(Runnable command)&#123; synchronized (command)&#123; //如果核心线程数还没满，则创建核心线程去执行 if(coreThreadList.size()&lt;corePoolSize)&#123; //创建线程 Thread thread = new CoreThread(); //添加线程 coreThreadList.add(thread); //开启线程 thread.start(); &#125; //任务进入任务队列 //如果可以在不违反容量限制的情况下立即将指定的元素插入到此队列中，成功时返回 true， //如果当前没有可用空间，则返回 false。当使用容量受限的队列时，此方法通常比 add 更可取， //后者可能仅通过引发异常来无法插入元素。 if(workQueue.offer(command))&#123; return; &#125; //任务队列满了的话，开始创建非核心线程了 //判断线程数是否超过最大线程树 if(coreThreadList.size()+supportThreadList.size()&lt;maxPoolSize)&#123; Thread supportThread = new SupportThread(); supportThreadList.add(supportThread); supportThread.start(); &#125; //阻塞队列还是放不下的话，就要执行拒绝策略了 if (!workQueue.offer(command))&#123; //执行拒绝策略 rejectHandle.reject(command,this); &#125; &#125; &#125; List&lt;Thread&gt; coreThreadList=new ArrayList&lt;&gt;(); List&lt;Thread&gt; supportThreadList=new ArrayList&lt;&gt;(); //核心线程：会一直执行 class CoreThread extends Thread&#123; @Override public void run() &#123; //死循环,一直存活 while(true)&#123; //阻塞从任务队列里拿任务 try &#123; Runnable task = workQueue.take(); //运行任务 task.run(); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; &#125; //辅助线程，有存活时间 class SupportThread extends Thread&#123; @Override public void run() &#123; //死循环,一直存活 while(true)&#123; //阻塞从任务队列里拿任务 try &#123; // timeout – how long to wait before giving up Runnable task = workQueue.poll(timeout,timeUnit); //如果一直拿不到任务就返回null if (task==null)&#123; break; &#125; //运行任务 task.run(); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; &#125;&#125; 线程池八大参数12345678this.workQueue = workQueue;this.corePoolSize=corePoolSize;this.maxPoolSize=maxPoolSize;this.timeUnit = timeUnit;//非核心线程最大活跃时间this.timeout = timeout;this.rejectHandle = rejectHandle;this.线程工厂 线程池核心流程核心就阻塞队列的三个方法 Object take() 一直阻塞获取队列的元素 Object poll(timeOut,TimeUtil) 在规定时间内阻塞获取任务，如果获取不到就返回 null boolean offer() 往队列里塞任务，如果塞不进去就返回false 塞得进去就返回true 先判断当前线程数大小是否小于corePoolSize，是的话创建核心线程数，不是的话就直接执行2 把任务塞到队列里，看任务是否塞得进去 塞得进去返回，塞不进去判断TreadSize是否&lt; maxSize 是：创建非核心线程 再一次把任务塞进队列里，判断是否能成功，失败就触发拒绝策略 拒绝策略 AbortPolicy****：丢弃任务并抛出 RejectedExecutionException 异常，这是默认的策略。 DiscardOldestPolicy：丢弃队列最前面的任务，执行后面的任务 CallerRunsPolicy：由调用线程处理该任务 DiscardPolicy：也是丢弃任务，但是不抛出异常，相当于静默处理。 线程池参数设置？线程池参数设置 线程池默认有线程吗没有。如果想要先创建好一些线程，来提高性能，我们可以通过预热机制，preStartThread or preStartAllCoreThread来预热线程，然后线程池等着接任务就行了 线程池如何保证线程安全操作的keepAliveTime对核心线程有效吗默认无效，但我们可以开启 allowedCoreThreadTimeOut 来生效 如果线程池里的任务出异常了，我们是否可以捕获这个异常，且这个工作线程会不会被销毁可以捕获，但需要手动捕获。如果不捕获，线程就相当于崩溃了工作线程会被销毁，且后面会重新new一个出 来，这是线程的恢复机制 如何对线程池的内存使用情况进行一个预估线程池的任务如何进行持久化引入MQ，发到MQ，利用MQ消费者的ack机制，防止没执行的任务在线程池所在的机器宕机时发生丢失 线程死循环获取任务，会浪费cpu吗? 如果是忙轮询（busy loop），线程会一直占用 CPU 核，确实会浪费 CPU，哪怕没有任务也会不断执行指令。 如果加了sleep &#x2F; wait &#x2F; condition variable 机制，那么线程会在没有任务时阻塞，让 CPU 去干别的事，这样几乎不浪费 CPU。 所以关键是有没有阻塞机制。比如 BlockingQueue.take() 就会在没任务时阻塞，不会忙等 while(true){ &#x2F;&#x2F;取不到任务就阻塞住 task &#x3D; queue.take(); } take()： public E take() throws InterruptedException { &#x2F;&#x2F;中断锁，即不会死等到拿到锁，期间能响应中断 lock.lockInterruptibly(); try &#123; while (count == 0) &#123; // 队列空 notEmpty.await(); // 等待条件满足 &#125; return dequeue(); &#125; finally &#123; lock.unlock(); &#125; } 不断沉睡唤醒，内核态和用户态不断切换，会不会有开销?会有，但相对 CPU 忙等来说，这个开销小很多。 沉睡：线程会调用系统调用（syscall）让内核把它挂起（从用户态切到内核态）。 唤醒：任务到来时，内核会切回用户态让线程运行。这个切换属于上下文切换，大概是微秒级的开销，除非唤醒特别频繁，否则影响不大。 线程池有什么缺陷?常见缺陷： 资源占用：线程是重量级对象，占内存（线程栈）和内核资源。 线程数固定：线程池满了，新任务要么排队，要么拒绝，容易导致延迟变大。 任务阻塞问题：如果线程执行的任务是阻塞型（特别是 I&#x2F;O 阻塞），会占住线程，导致其他任务排队等待，甚至造成线程池“假死”。 调优复杂：核心线程数、队列长度、拒绝策略等要根据业务特点调，不同场景差异大。 IO密集型任务适合放线程池吗?注意两点： 线程的核心任务就是执行 CPU 指令，因为这是它能对世界产生效果的唯一方式。 IO操作不是 CPU 做的运算，而是 外设&#x2F;设备控制器 做的工作。CPU 只负责发起操作和检查状态，真正的数 据传输是硬件自己完成的。 那么 I&#x2F;O 密集型任务不适合直接放传统线程池，因为线程容易被阻塞占用，导致线程池空转和任务堆积。更适合异 步 I&#x2F;O 或事件驱动模型，让线程资源得到充分利用。 IO密集型任务为什么不适合放线程池? 线程池的线程是稀缺资源，而 I&#x2F;O 阻塞期间，线程只是“等数据”，没用 CPU 干活。 阻塞 I&#x2F;O 会让有限的线程数被浪费掉，新任务只能等它们完成。 解决办法是异步化或加大线程池线程数（但这样会增加上下文切换和内存开销）。 你说IO任务堵住了，为什么会堵住? 阻塞 I&#x2F;O（Blocking I&#x2F;O）调用，比如 read()、accept()、recv()，在数据没到之前，线程会停在这里等。 数据没到可能是因为： 对方（客户端&#x2F;服务器）没发送数据。 网络延迟高。 磁盘读写速度慢（比如从 HDD 读大文件）。 在阻塞期间，这个线程既不释放线程池的线程，也不能去干别的事，导致任务堆积。 关于如何尽快释放宝贵资源，业务最佳实践，dubbo服务端线程模型jdk线程池的一个bug，但官方没修复，把它当成了一个feature，但我认为这其实是一个设计不好的地方netty的eventloopgroup核心线程数为0的场景有哪些?核心线程数和最大线程数一样，会有什么场景?线程池优化利用cpu亲和性优化上下文切换 什么地方用到了，netty 其他类线程池 forkjionpool Tomcat pool eventLoopGroup forkjionpool双端队列头和尾都可以进行添加和删除操作的队列，本质就是stack和queue的结合 工作窃取算法 工作窃取算法是一种动态、负载均衡高效的多线程任务分配机制，空闲线程可主动“窃取”其它线程未完成任务，使系统资源利用率最大化。 举一个例子： 假设有线程A&#x2F;B&#x2F;C，每个线程一开始都有一份任务队列： - &lt;font style=&quot;color:rgb(78, 78, 78);&quot;&gt;线程A：任务A1, A2, A3&lt;/font&gt; - &lt;font style=&quot;color:rgb(78, 78, 78);&quot;&gt;线程B：任务B1, B2&lt;/font&gt; - &lt;font style=&quot;color:rgb(78, 78, 78);&quot;&gt;线程C：任务C1&lt;/font&gt; - &lt;font style=&quot;color:rgb(78, 78, 78);&quot;&gt;线程C完成C1后，将自己任务队列清空。&lt;/font&gt; - &lt;font style=&quot;color:rgb(78, 78, 78);&quot;&gt;它随机选取别的线程（比如线程A），“偷”走A的最后一个任务A3执行。&lt;/font&gt; - &lt;font style=&quot;color:rgb(78, 78, 78);&quot;&gt;这样被称为“工作窃取”。&lt;/font&gt; 线程安全的保证： 执行流程及原理： 什么时候用threadpool，什么时候用forkjoin?","path":"2025/04/27/JUC/线程池/","date":"04-27","excerpt":"","tags":[]},{"title":"ReentrantLock源码","text":"可重入锁 Lock的实现类都是通过 聚合了一个同步队列的子类来 实现线程访问的控制 类基本结构 方法 非公平锁的lock先自旋一次，成功就获取锁，失败再正常获取 tryAcquire调用父类Sync的非公平获取方法 公平锁的lock，与非公平锁的唯一区别就是多了个hasQueuePredecessors()方法判断等待队列是否有有效节点 释放锁的流程，因为是可重入锁，会通过state判断是否为0来决定是否释放锁 ReentrantLock的上锁流程 非公平锁：总的来说就两bu：每个线程都会尝试获取锁，获取锁失败就进入阻塞队列 * &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;一开始会先通过CAS操作判断是否可以把state从0改为1，如果可以，则表示加锁成功，并通过set&lt;/font&gt;&lt;font style=&quot;color:rgb(37, 41, 51);&quot;&gt;ExclusiveThread()将exclusiveThread设置为当前线程&lt;/font&gt;&lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;;&lt;/font&gt; * &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;cas操作不成功，那么就会进入acquire（1）方法 &lt;/font&gt; * &lt;font style=&quot;color:rgb(0, 0, 0);&quot;&gt;然后回进入tryAcquire方法，这时候还是会通过CAS去获取锁，看看getState是否为0，如果 &lt;/font&gt; 公平锁：不管3721，都给我先入队列 * 为什么ReentrantLock，synchronized默认要为非公平锁 提升锁竞争的性能，如果是公平锁的话，往往要比非公平锁多出一个进入队列阻塞等待，然后再被唤醒。这会 涉及到一个内核态的切换，这对性能是有很大影响。而非公平锁的话，当前线程正好处于上一个线程释放锁时 的临界点，也就意味着当前线程不需要切换到内核态，虽然说对等待中的线程不公平，但这大大提高了锁竞争 时的性能","path":"2025/04/27/JUC/ReentrantLock源码/","date":"04-27","excerpt":"","tags":[]},{"title":"强引用、软引用、弱引用、虚引用分别是什么？","text":"强引用JAVA中最常见的一种引用，强引用的对象就算出现了OOM，JVM也不会对他进行回收的。当一个对象被强引用指向时，处于可达状态，即使它永远不会被用到，也不会被JVM的回收机制回收的。 对于普通对象而言，只要他超出了引用范围or手动把引用变量置null，它就可以认为被JVM回收 软引用内存不够时才回收，够时就不回收 适用场景 假如有一个应用需要读取大量的本地图片: 如果每次读取图片都从硬盘读取则会严重影响性能, 如果一次性全部加载到内存中又可能造成内存溢出。 这时候就可以利用软引用的内存不够才回收的特性，采用一个Map把图片路径和图片内容关联起来，可以有效避免OOM Map&lt;String, SoftReference&gt; imageCache &#x3D; new HashMap&lt;String, SoftReference&gt;(); 弱引用WeakReference 不管内存够不够用，只要JVM一触发回收，弱引用指向的对象就会被回收 虚引用必定会被回收，一般配合引用队列使用，可用于监控回收","path":"2025/04/27/JUC/强引用、软引用、弱引用、虚引用分别是什么？/","date":"04-27","excerpt":"","tags":[]},{"title":"JMM","text":"java内存模型 本身只是一个抽象概念，只是一种规范，用来实现线程与主内存之间的关系还有就是屏蔽各个硬件平台和操作 系统的内存访问差异 关键技术点都是围绕多线程的原子性，可见性和有序性展开的 在该模型下，多线程对变量的读写过程 所有的共享变量是存储在物理主内存中的 而每个线程都有自己独立的工作内存，里面保存着该线程使用到的变量的副本 线程对共享变量的读写都得先在工作内存中操作，后写回主内存，不能直接在主内存中读写 happens-before 他就是说在JMM中，如果一个操作执行的结果需要对另外一个操作可见性，那么这两个操作之间 必然存在happens-before关系 有什么用？ 有没有发现，我们没有时刻添加volatile和synchronized来完成程序，这是因为java语言中JMM原则下有一个happenss-before原则限制和规则 依赖这个原则，我们可以通过几条简单的规则一下子解决并发下两个操作之间是否可能存在冲突的有 所有问题","path":"2025/04/27/JUC/JMM/","date":"04-27","excerpt":"","tags":[]},{"title":"Synchronized","text":"是什么Java中的关键字，主要用来加锁 怎么用不管怎么用，最终锁的都是对象 1234567//加到方法上synchronized static f()锁的是类的class对象synchronized void f() 锁的是类的实例对象//代码块synchronized()&#123;&#125; 管程即monitor（管程or监视器），用来实现多个线程对统同一资源的互斥访问 在Java中，每个对象都有Monitor，Monitor伴随Java对象一身 在hotsopt虚拟机中，monitor的实现为ObjectMonitor。ObjectMonitor是基于c++来实现的，它有几个重要属性： 123456789_owner：指向持有 ObjectMonitor 对象的线程_WaitSet：存放处于 wait 状态的线程队列_EntryList：存放处于等待锁 block 状态的线程队列_recursions：锁的重入次数（控制可重入次数的）_count：用来记录该线程获取锁的次数 （辅助判断锁的整体活跃度、竞争情况） 对象头的mark word 和ObjectMonitor的关系？ 如果一个Java对象被线程持有，那么这个Java对象的对象头中的mark word的Lock word就会指向 ObjectMonitor的起始地址 重要级锁在JDK1.6之前，synchronized的实现才会直接调用ObjectMonitor的enter和exit方法，这种锁被称为 重量级锁。主要实现是通过ObjectMonitor的关键属性来实现的，owner，EntryList,waitset,count 当多个线程同时访问同一段同步代码时，会先进入EntryList队列，当其中某个线程获取得到对象的Monitor后 进入owner区域并把Monitor中的_owner变量设置为当前线程，同时把Monitor中的计数器_count+1 即获得对 像锁。而其他线程这时候来获取锁，获取不到就处于变为阻塞状态。 当持有Monitor的线程调用了wait()方法后，那么他就会释放当前的Monitor，并将owner变量置为null， count–，同时该线程进入waitset集合中等待被唤醒。若当前线程执行完毕也将释放monitor并复位变量的值 ，以便其他线程进入获取monitor，这时候会去唤醒EntryList中的其他线程。 monitor依赖于操作系统的mutexLock 为什么说他重？ Java的线程模型默认是一个用户线程对应着操作系统的一个内核线程。那么在synchronized中涉及到大 线程的阻塞和唤醒，这些都是从用户态切换到内核态来实现的，而这个切换操作在早期CPU是很耗时的 偏向锁在JDK1.6引入，在JDK13默认为关闭了，JDK 15 完全禁用，JDK 17彻底移除代码 正确地来说，它并不是一个真正的锁。当第一个线程抢到锁时，会在java锁对象中的对象头的markword里填 入自己的线程名字。下个线程还获取时就会进行一个判断（这个判断操作是很轻的），如果还是同一个的话， 就会直接获取。不是的话，就得进行一个锁升级了 匿名偏向？ 还没有人去持有偏向锁，这时候锁就是匿名的 为什么要有这个锁？ 因为在通过Java开发团队的大量统计，其实在开发中很多代码都是同一个线程在执行 为什么偏向级锁不要设置为一开始就启动，默认是JVM启动后4s才会开启 如果一开始就明确就是多线程环境，那么偏向锁还有什么意义？JVM启动涉及到10多个线程，本身就是 多线程环境 为什么JDK 15要废弃偏向锁？ 早期很多集合都是一把synchronized梭哈，比如vector，HashTable。不可否认，偏向锁能保证这些老集 合在单线程使用的环境下的性能，但后来随着HashMap，ArrayLIst等集合的出现。偏向锁变得不是很 重要了 而且官方还说偏向锁的引入导致代码的复杂度升高了，不好维护 微博禁用偏向锁，性能直接飙升 偏向锁这种东西会让对象迟迟无法被回收，导致对象一直越来越多，STW时间变长 锁撤销轻量级锁它的出现是为了优化重量级锁在竞争少的场景下的开销大的问题 当另外一个线程获取非匿名偏向锁时，偏向锁就会被撤销，锁就会自动升级为轻量级锁 轻量级锁状态时，JVM为锁对象的对象头markword预留了一部分空间，用来存储指向线程栈中Lock record 的指针 当一个线程尝试获取轻量级锁时（即发现对象头里的锁标记位为 00），就在线程虚拟机栈中开辟一快空间， 即Lock record，里面有两个部分 然后尝试通过CAS操作将对象头的mark word更新为指向锁记录的指针 自适应自旋？ 锁膨胀发生在轻量级—&gt; 重量级锁 锁升级 锁升级过程 synchronized 的锁能降级吗？对于HotSpot虚拟机来说，是没办法的。即一旦锁升级为重量级锁后，你的锁状态就会一直维持重量级锁，直到释放。 不过还有一种特殊的“降级”情况，即重量级锁的monitor对象不再被任何线程持有时，被清理和回收的过程。 JDK6对synchronized的优化？自旋锁 JDK1.4引入，JDK1.6默认开启 锁消除 JIT层面的优化，即在使用synchronized的时候，如果JIT经过逃逸分析后发现并无线程安全的问题的话， 就会做锁消除 锁粗化 如果在一个循环里，频繁地获取资源释放资源，这样带来的消耗会很大，锁粗化会扩大锁的范围，把加锁 逻辑放到外面。 ps：锁粗化和“平时我们在开放中要尽可能地减少锁的粒度”矛盾吗？ 不矛盾 锁升级 JDK1.6引入了偏向锁，轻量级锁。当线程竞争不激烈时，可以减少性能开销 Synchronized的缺点无法知道线程是否获取到了锁 锁只有阻塞状态","path":"2025/04/27/JUC/Synchronized/","date":"04-27","excerpt":"","tags":[]},{"title":"ThreadLocal","text":"是什么？线程本地变量，可以实现线程之间的隔离，线程内部共享。我们平时都是在类中作为私有静态变量来使用的，目的是为了让一些状态（用户ID，事务ID）与线程进行关联。 有什么用实现每个线程内都有一份专属的本地变量副本。 实现线程之间隔离，线程内共享 共享这个更重要，有人就要问，线程内共享，难道直接传参就好了吗，但你想想这样不丑陋吗，如果你的方法调用链很长的花，例如Spring的事务机制，我们都知道Spring事务支持嵌套，如果你的事务嵌套10层，那你不是每个方法都要加一个 Connection 参数？那不丑陋死了 API 方法 作用 initialValue() 定义初始值，默认null，可以重写 get() 拿当前线程自己的值，没有就用initialValue() set(value) 给当前线程自己设置一个新值 remove() 删除当前线程自己的值，防内存泄漏 原理ThreadLocal，Thread和ThreadLocalMap的关系 当我们在往ThreadLocal里set值时，其实是往Thread的ThreadLocalMap里set值，key为ThreadLocal实例（弱引用），而value为我们set的值。为什么这就是线程安全的了？原因是ThreadLocalMap是Thread里维护的一个变量，可以说是线程私有的。 ThreadLocal可以认为是 ThreadLocalMap的封装，传递了变量值，而且它本身并不存储值，而是把自己作为一个key，来让线程从ThreadLocalMap获取得到值 123456class ServiceA&#123; private static ThreadLocal&lt;xx&gt; t=new ThreadLocal(); public void methodA()&#123; t.set(&quot;xx&quot;); &#125;&#125; ThreadLocal内存泄漏问题内存泄漏是什么？ ： 不再使用的内存不能被回收 为什么Entry的key要为弱引用，不用如何？ 主要是为了能让ThreadLocal对象能够回收掉。若这个key为强引用，那么会导致key指向的ThreadLocal对象，以及value对象无法被GC。若为弱引用，key所指向的ThreadLocal就可以被回收且Entry指向的对象为null，减少内存泄漏概率 但这单单不够，value为强引用，且引用链依然存在，仍然无法被GC。 其实ThreadLocal内存泄漏的说法只存在于线程池的情况，比如tomcat线程池，它会复用线程，导致你的线程一直存活。没有线程复用的化，线程执行后立马销毁了，那其实啥事都没有了 如何做？ 手动remove，但其实但key为null后，我们再次去get,set也会自动清空 最后重中之重！！！ 是否会内存泄露不是取决于是否remove，而是取决于怎么用。平时使用我们都是将ThreadLocal声明为一个 static对象，那这样的话它的生命周期就会和容器保持一样，那么它就不可能被回收掉，也就是这时候key是 个强引用，我们说的内存泄露主要是说我们无法把value置为null了，而这种情况下是不会出现的，因为key不 为null，我们还是可以通过key拿到我们的value的。那不正常情况，那就是一些傻子会把ThreadLocal当做局 部变量使用，这种情况就会出现随着线程结束，出现key也就是ThreadLocal被回收，因为它是局部变量么。 那么也就是key没了，但value还在，而这个kv（Entry）是存于ThreadLocalMap里的，而ThreadLocalMap是 和线程强相关的，而在tomcat线程里，有些核心线程是一直存在，ThreadLocalMap无法被回收掉。也就导 致了内存泄露 ThreadLocalMap如何解决哈希冲突？开放寻址法（当发生Hash冲突时，则加1向后寻址，直到找到空位置或者被垃圾回收的位置）,不同于HashMap采用的拉链法，也就是说ThreadLocalMap没有采用链表结构存储。而且在此期间还会清理掉key为null的Entry Hash表的默认大小为 10，扩容阈值为 len*2&#x2F;3 也就是10，大于10就扩容，扩容两倍 InheritableThreadLocal可以解决父子线程间ThreadLocal无法共享的问题 它的原理是 子线程是在父线程中通过new Thread()创建的，在Thread构造方法中调用init，在init方法中父线程的数据会传递到子线程 但我们平常开发中异步都是配合线程池来使用的，这种问题还是无法解决 TransmitThreadLocal?在ThreadLocal基础上进行了增强，增加了值拷贝和传递的功能 不同于 InheritableThreadLocal， TTL管它什么新线程&#x2F;线程池，它自己控制拷贝和恢复 新一代ThreadLocal？ScopedValue这东西鉴于ThreadLocal的缺点","path":"2025/04/27/JUC/ThreadLocal/","date":"04-27","excerpt":"","tags":[]},{"title":"线程基础","text":"线程创建的方式 new Thread，重写run方法 实现Runnable接口，重写run方法 实现Callable接口，重写call方法 通过线程池方式创建 底层的来说就一种 即通过thread.start()创建并开启线程 线程状态 new：线程创建了但没start 反复调用线程的start是否可行？线程执行完毕再次start是否可行？都不行，因为start后threadStatus会改变，再次调用start方法会抛IllegalThreadStateException异常 runnable：线程正在执行代码中，也可能正在等待cpu调度 blocked：阻塞等待锁中 waiting：等待状态，有三种可能： Object.wait()：使线程变为等待中，直到其他线程唤醒它 Thread.jion()：等待线程执行完毕，底层其实是Object.wait() LockSupport.park()： timed_waiting：超时等待，时间到了自动觉醒，有以下可能 wait(time) Thread.sleep(time) jion(time) parkNacos(time) terminated：终止状态，表示线程已执行完毕 线程优先级thread.setPriority() 设置线程优先级，分为1-10 默认5。哈哈哈，只是建议，低的不比高的后 多线程带来的问题多线程之间，单个线程执行的流程可能不是原子性的，途中可能会有其他线程影响 多个线程之间，数据的可见性可能不是实时的，可能导致数据对不上 要解决以上问题，就得引入多线程 同步机制，例如加锁。但这又会引入新的问题，如死锁，锁开销，锁饥饿 多线程还会带来线程上下文切换的开销 线程安全如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。 如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。 线程存活isAlive() 可判断线程是否是存活 虚假唤醒java 线程之间是如何通信的Java中线程通信方式七种_java线程间通信的方式-CSDN博客 总的来说，线程之间通信有三种模型，一种是共享内存的形式，一种是消息传递的方式（也叫等待-通知），一种是 管道流。在java中一共有八种，volatile，synchronized，Interrupt，wait，notify，notifyAll，jion，管道通信 实现管道通信，我们可以使用jdk自带的PipedOutputStream和PipedInputStream，或者PipedWriter，PipedReader","path":"2025/04/27/JUC/线程基础/","date":"04-27","excerpt":"","tags":[]},{"title":"volatile","text":"看过八股的都知道volatile可以保证有序性和可见性，但其实他还保证了部分原子性 有序性简单地说就是防止指令重排，保证代码按照程序员的意愿执行 它的实现是通过内存屏障来实现的。硬件层面有Load Barrier读屏障和Store Barrier写屏障 。而jvm层面有 LoadLoad（读读屏障），LoadStore（读写屏障），StoreStore（写写屏障），StoreLoad（读写屏障）。 内存屏障相当于一堵墙，墙两边的指令不能翻墙重排，而墙同侧的可以发生重排 eg：指令1 指令2 | 指令3 指令4 指令2和指令3不可以重排，即强制执行完指令2后才会执行指令3 指令1和指令2可以重排 内存屏障到底是什么？ 本质上就是CPU指令 可见性一个线程修改了volatile变量，这个修改对于其他线程立即可见 因为CPU运算速度要比内存块很多，所以会把主存的值缓存到高速缓存中。而这时线程的高速缓存可能就会 出现和主存不一致的情况。而volatile就可以解决这种情况 当写一个volatile变量时，写操作完成后会多出一条Lock为前缀的汇编指令，这指令在多核处理器下会做两件 事 1.将当前CPU缓存里的值写回主存 2.将其他CPU核的内存置为无效，读取必须去主存读 当读一个volatile变量时，会直接去主存里读 这样就可以保证其变量在多线程下的可见性了 部分原子性关键字: volatile详解 它的原子性体现在赋值层面，在30位的操作系统，cpu只能一次性读写32位的数据，那么对于long类型的，也就只能分为两步，即高32位，低32位。如果在多线程中，一个线程只操作了前部分，而另外一个线程来操作这个变量，这样的话就发生了错误了么。那如果是被volatile修饰就不会发生这个问题。但自增自减就无法保证其原子性，因为这些操作都不是由单条字节码指令组成的 双重检验锁volatile真正的作用？DCL 123456789101112131415161718192021222324252627282930public class TestSingleton implements Serializable &#123; private static TestSingleton INSTANCE; /** * 防止反射多个对象 */ private TestSingleton()&#123; if (INSTANCE!=null) &#123; throw new RuntimeException(&quot;singleton&quot;); &#125;else&#123; INSTANCE=this; &#125; &#125; public static TestSingleton getInstance()&#123; if (INSTANCE==null) &#123; synchronized(TestSingleton.class)&#123; if (INSTANCE==null) &#123; INSTANCE=new TestSingleton(); &#125; &#125; &#125; return INSTANCE; &#125; /** * 防止序列化多个对象 * @return */ private Object readResolve()&#123; return INSTANCE; &#125;&#125; 网上有很多说法说对它是能防止new操作的指令重排序，然后并不是的，new操作分为三步（分配内存，对象初始化，指针指向），而volatile只能保证单个指令的可见性，有序性，原子性，i++这种也是无法保证的。它真正的作用是通过在new操作前加入了store_store屏障，在后加入store_load屏障。保证对INSTANCE的写是要优先于对它的读的，但其new的内部是无法保证有序性的，从而避免了有线程获得还没有初始化的实例","path":"2025/04/27/JUC/volatile/","date":"04-27","excerpt":"","tags":[]},{"title":"String的不可变性","text":"它是怎么实现不可变性的？ 首先String类被final修饰，那就意味着它不能被继承。那么他里面的方法就不能被覆盖的 用final去修饰字符串内容的char，保证其地址不可变 无对外暴露字符串的setter方法，可以在一定程度上保证内容不可变，像substring,concat这种API，其 实是new 了一个String然后返回的。 ps：为什么说 一定程度呢，因为如果你通过反射或者unsafe类还是可以修改的 如果我们要实现一个可变的字符串，我们可以使用StringBuffer和StringBuilder 为什么要为不可变 我觉得是出于安全性的考量，String的用途很广泛。因为你不可变，也就意味着可以避免线程安全的问题 而且不可变的话，Hash值就定下来了，而且Hash值是存储在对象头里的，String不断Hash，不可变就可 以复用Hash值，提高效率（因为你Hashcode你根据字符串内容生成的） Java 9 为何要将 String 的底层实现由 char[] 改成了 byte[] ? byte数组占用内存空间更小吧。java9之前采用char[]，由于java内部使用的编码是UTF16，这就导致即 有些字符可以用1个字节表示，但它还是会占两个字节。 因此java9对他进行了优化 通过byte[]（一个byte 8位）和字段coder来控制字符的存储。如果字符串的编码没超过lan-1的范围 （纯英文）就用lan-1，每个字符就占1个字节（8位）而对于超过的话，那就统一采用UTF6，不管中英文来 进行一个存储，每个字符就两个字节（16位）。 String的长度有限制吗 编译期，受限制；运行期，受int最大长度限制","path":"2025/04/27/JavaSE/String的不可变性/","date":"04-27","excerpt":"","tags":[]},{"title":"redis可以干什么？？？","text":"缓存（建议） 消息队列（不建议） 延迟消息（不建议） 排行榜（建议） 计数器（建议） 分布式ID（可以） 分布式锁（建议） 地理位置应用（建议） 分布式限流（可以） 分布式Session（建议） 布隆过滤器（建议） bitmap状态统计（可以） 共同关注（建议） 推荐关注（可以）","path":"2025/04/27/Redis/网络模型/基础/redis可以干什么？？？/","date":"04-27","excerpt":"","tags":[]},{"title":"big key","text":"客户端超时阻塞 引发网络阻塞 内存占用不均 持久化的影响","path":"2025/04/27/Redis/big key/","date":"04-27","excerpt":"","tags":[]},{"title":"线程模型","text":"执行命令都是单线程的 redis2.6后会启动两个后台线程，负责关闭文件andAOF刷盘 redis4.0后引入了多线程，去执行一些比较缓慢的操作，如删除bigkey redis6.0后引入了多线程网络模型，默认是关闭","path":"2025/04/27/Redis/线程模型/","date":"04-27","excerpt":"","tags":[]},{"title":"Redis的虚拟内存","text":"2.4已经丢弃 它是指redis一开始为了解决物理内存限制的问题，会把一些不常用的数据刷到磁盘里，腾空间给常用的数据 用 但有性能问题，因为多了刷盘时产生的IO","path":"2025/04/27/Redis/Redis的虚拟内存/","date":"04-27","excerpt":"","tags":[]},{"title":"truncate、delete、drop的区别？","text":"DELETE 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作。 TRUNCATE TABLE 则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。 DROP语句将表所占用的空间全释放掉。 在速度上，一般来说，drop&gt; truncate &gt; delete。 如果想删除部分数据用 delete，注意带上 where 子句，回滚段要足够大； 如果想删除表，当然用 drop； 如果想保留表而将所有数据删除，如果和事务无关，用 truncate 即可； 如果和事务有关，或者想触发 trigger，还是用 delete； 如果是整理表内部的碎片，可以用 truncate 跟上 reuse stroage，再重新导入&#x2F;插入数据 整理表内部的碎片 方法 实现原理 操作流程 &#x2F; 示例 优缺点 适用场景 TRUNCATE + INSERT 删除表数据页，重建表结构；InnoDB 会重用原来分配的页 sql -- 备份表 CREATE TABLE t_backup AS SELECT * FROM t; -- 清空表 TRUNCATE TABLE t; -- 重新插入数据 INSERT INTO t SELECT * FROM t_backup; 快速、简单；但会隐式提交事务，删除数据风险大 小表 &#x2F; 可停机维护 OPTIMIZE TABLE InnoDB 创建临时表，将原表数据复制过去 → 连续页存储 → 删除原表 → 重命名临时表 sql OPTIMIZE TABLE t; 无需手动备份，操作简单；大表占用临时空间多 中小表、定期维护 pt-online-schema-change 在线重建表 → 数据复制到新表 → 最后切换表名 bash pt-online-schema-change --alter &quot;ENGINE=InnoDB&quot; D=mydb,t=t --execute 不锁表，在线整理大表；需要额外工具 大表、在线环境","path":"2025/04/27/MySQL/truncate、delete、drop的区别？/","date":"04-27","excerpt":"","tags":[]},{"title":"深分页如何解决","text":"为什么会造成深分页？ 假如有张百万数据的表，你想通过分页的方式来展示这些数据。当用户请求第1w页数据时，假设 pagesize&#x3D;10，那么最终是9万9千，10。数据库必须先扫描前9万9千条数据，才能返回第1w页的数据， 如果你查询返回的字段不在索引中，需要回表很多次，性能明显很低 怎么优化？ 假设：SELECT c1, c2, cn… FROM table WHERE name &#x3D; “Hollis” LIMIT 1000000,10 1.子查询+jion优化 12345678910SELECT c1, c2, cn...FROM tableINNER JOIN ( SELECT id FROM table WHERE name = &quot;Hollis&quot; ORDER BY id LIMIT 1000000, 10) AS subquery ON table.id = subquery.id 这样的话就不需要每条记录都回表 2.子查询+ID过滤 1234567SELECT c1, c2, cn...FROM tableWHERE name = &quot;Hollis&quot; AND id &gt;= (SELECT id FROM table WHERE name = &quot;Hollis&quot; ORDER BY id LIMIT 1000000, 1)ORDER BY idLIMIT 10 缺点就是ID一定得是自增的 3.记录上一个ID，即游标字段 4.如果是基于文本的搜索，使用ES","path":"2025/04/27/MySQL/深分页如何解决/","date":"04-27","excerpt":"","tags":[]},{"title":"HashMap","text":"快速根据 key 找到 value 的“键值对集合” ，查询和插入平均时间复杂度都是o(1) 底层数据结构 1.7为数组+链表 1.8为数组+红黑树&#x2F;链表 为什么要用红黑树，为何不一上来就树化？ 链表太长，会影响查询性能，出现树化意味着被DDoS攻击了，即 被人恶意哈希冲突攻击（构造大量相同 的hashkey），树化可以缓解这种情况。 而平衡二叉树在极端情况下也是有这个问题，相当于链表了，红黑树比二叉树好一点，因为红黑树追求 大致平衡，自平衡效率高。 树化应该是一种偶然现象，链表短的情况下没必要，查询性能很高了，而且链表的占用内存要比树 要少 何时会树化，树化阈值为什么是8？ 数组长度&gt;&#x3D;64 且链表长度&gt;&#x3D;8 就会进行扩容 jdk开发者他们基于大量的实验验证出来的，什么泊松分布，在负载因子为0.75的情况下，链表长度为8 的概率为0.00006，即选择8是让树化的概率最小 红黑树何时退化 - 扩容拆分树时，发现树的元素小于6，也会链表化 - remove树节点时，发现root,root.left,root.rigth,root.left.left为null（移除前检查），也会链表化 索引计算？为什么数组容量要为2的n次幂 idnex&#x3D;hash&amp;(size-1)，相当于hash%size，但前提是size为2的n次幂 这个是为了底层能通过位运算来提高性能，还有一个就是扩容的时候如果index&#x3D;oldCap&amp;(size-1)&#x3D;&#x3D;0， 说明还在原位，如果不是newIndex&#x3D;oldIndex+oldSize。综上所叙，size为2的幂次方的好处挺多的 数组容量可以不为2的n次幂吗 可以的。size为2的n次幂虽然性能比较高，但如果hash全是偶数，运算出来的index就都是偶数，这 就导致hash分布不均 若追求更好的hash分布，可以用质数作为容量，这样还不用二次hash 例如hashTable它的扩容策略就是 oldCap*2+1 hashmap的容量如何设置？ hashCode都有了，为什么还要调用HashMap的hash()方法对hashCode进行二次哈希？为什么用异或？ jdk1.8中是拿着hashcode()的高16位和低16位进行异或 jdk1.7中是拿hashcode()多次移位,异或 用异或是为了扰乱hash，让hash分布更加均匀，只要32位中的一位不同，hash()返回的结果就不同 put方法流程？1.8和1.7的区别 1.HashMap为懒加载，即初始化只会初始化负载因子，而不是初始化容量 2.计算索引（桶下标） 3.判断索引位置是否为null，为null就创建Node节点插入 4.不为null，则判断是链表还是树，创建对应的节点走相应的添加or更新。如果是链表达到了树化的 逻辑，就走树化的逻辑（链表长度&gt;&#x3D;8且数组长度&gt;&#x3D;64） 5.添加后，判断是否需要扩容 1.7和1.8的扩容也是有所不同 1.7扩容时链表节点移动为头插入法，而1.8为尾插法 1.7是大于阈值且插入的桶没空位才会扩容（懒扩容），1.8是大于阈值就会扩容（主动扩容） 1.8扩容时计算Node的索引时，会有优化（位置不变+oldCap）。1.7是重新hash get()方法流程 1.计算hash值 2.定位桶索引 3.通过hash()和equals方法和第一个桶节点比较是否相等，若相等就返回，不相等就进行链表or红黑树的 查询逻辑 加载因子为什么为0.75 在空间和时间查询性能之间能取得较好平衡 大了，链表长度容易长 小了，就经常扩容，影响性能 但其实根据二项分布，0.693是最好的选择，但考虑到size为2的n次幂，故取到了0.75，其实0.695….其 实也可以，只不过从中位数的角度，0.75是最好的 多线程下出现的问题 1.7的时候扩容时为头插入法，就会出现死循环 丢数据 两个线程同时判断一个桶位置可以插入位置，就插入了，然后就造成数据被覆盖了，而不会走解决 hash冲突的逻辑 1.7为什么要采用头插入法 首先HashMap本身就不是为多线程设计的，头插入法在线程安全的情况下完全是合适的，而且实现起来 也很简单 还有就是jdk开发者认为后插入的元素更加热点，放在头节点比较合适 jdk8为什么采用了尾插入法 1.jdk8引入的红黑树，那么可以顺便遍历一下链表的元素，统计个数，判断是否需要树化 2.避免多线程下扩容可能产生的死循环 key能否为null？key对象有什么要求？ HashMap的key可以为null。对象必须实现hashcode()和equals方法，hashcode()是定位，equals是比较 两者是否相等，并且key的内容必须不能被修改 hash冲突解决方法 拉链法：hash冲突时，同一槽位的拉成一条链表，hashmap采用的 开放寻址法：发生hash冲突时，寻找其他位置，这就保证了一个位置只有一个元素 线性探测：hash冲突时，往后找，直到找到第一个为null的位置，ThreadLocalMap采用的 二次探测：跟线性探测类似，只不过往后探测的步长是有规律的，2,4,8,16 二次hash","path":"2025/04/27/JavaSE/HashMap/","date":"04-27","excerpt":"","tags":[]},{"title":"两阶段提交","text":"只有bin log开启的情况下才存在，默认情况下是不存在两阶段提交的 默认情况下的流程 把事务更改的数据记录到redo log中，当事务提交时，进入commit阶段，先把redo log的状态变为 commit。然后根据innodb_flush_log_at_trx_commit有不同的行为 如果宕机了要回滚，就看看redo log状态是否为commit，如果是就数据恢复。如果是prepare，就根据 redo log的完整性，看看是否要回滚或者数据恢复 在开启了redo log和bin log的情况下就需要考虑到两个的一致性了 1.主节点宕机了，redo写了，但bin log没来得及写入，那么主节点重启数据恢复后，数据就会出现主从 不一致 2.主节点宕机，redo没写，但bin log已经写了，那么也会出现主从不一致的情况 两阶段提交就是为了解决redo log和bin log不一致的情况 它其实就是分布式事务协议，保证多个逻辑要么都成功，要么都失败 它把单个事务的提交拆成了两个阶段，一个是 prepare阶段，一个是commit阶段 prepare * 将XID（内部事务XA的ID）写入redo log，并将redo log的事务状态置为prepare。然后将redo log持久化到磁盘（InnoDB_flush_log_trx_id==1） commit * &lt;font style=&quot;color:rgb(44, 62, 80);&quot;&gt;把 XID 写入到 binlog&lt;/font&gt;，并将其持久化到磁盘 （sync==1） * &lt;font style=&quot;color:rgb(44, 62, 80);&quot;&gt;接着调用引擎层的接口，把redo log对应的事务状态置为commit，这时候不需要持久化，只需要进行write就可以了即存到os的page cache。因为只有bin log写入成功，&lt;/font&gt;**&lt;font style=&quot;color:rgb(44, 62, 80);&quot;&gt;那么不管redo log的状态是不是commit&lt;/font&gt;**&lt;font style=&quot;color:rgb(44, 62, 80);&quot;&gt;，都是会认为事务已经是执行成功了的&lt;/font&gt; 出现的异常情况 不管是时刻a or b，此时的redo log的状态都为prepare MySQL重启后，如果发现redo log的状态为prepare，那么就会拿着redo log的XID去bin log里面寻 找，是否存在。如果存在，表示bin log已经写入成功，即事务已经执行成功了，那么就做数据恢复 如果没有，即事务没执行成功，就会做一个事务回滚操作 ps：事务回滚时redo log会怎么变化？事务回滚redo log也会产生相应数据变更记录 所以说两阶段提交是以 bin log写入成功为事务提交成功的标识 两阶段提交有什么缺点吗？ 1.磁盘IO高，会刷两次盘，一次是redo，一次是binlog 2.锁竞争激烈，早期MySQL，事务只有获取锁，才能进入prepare状态，一直到commit状态才会释放 虽然加锁完美解决了一致性的问题，但在高并发的情况下性能不太行 这时候组提交就出现了","path":"2025/04/27/MySQL/日志/两阶段提交/","date":"04-27","excerpt":"","tags":[]},{"title":"bin log 和redo log","text":"两者的不同 适用对象 写入方式 日志格式 用途 为什么有了 binlog， 还要有 redo log？ 历史遗留问题，早期mysql官方只有binlog日志，且不支持掉电数据恢复。而redo log是InnoDB引擎特有 的，是为了解决buffer pool脏页丢失的问题，只依靠bin log是不能实现crash safe 能不能只用redo，不用binlog 可以的，不考虑主从复制or数据备份的话（即从权限上解决删库跑路的问题），而且bin log默认就是关 闭的 为什么binlogcache是线程私有的，而redo log buffer的就是全局共享的呢？ 这是因为一个事务的bin log要求不可以被拆分的，且我们都知道的bin log是用来主从同步的。一个线程 同时只能执行一个事务，基于这个特性，每个线程就得有一个binlogcache。如果不是的话，到时候在从 库执行binlog时，每个事务的命令就会交叉在一起，那这样就会破坏原子性了，这显然是不行的。 而redo log显然就没这个要求","path":"2025/04/27/MySQL/日志/bin log 和redo log/","date":"04-27","excerpt":"","tags":[]},{"title":"组提交","text":"MySQL引入bin log组提交是为了提升两阶段提交过程中，磁盘IO高的问题。它会把多个bin log刷盘合并成一 个刷盘","path":"2025/04/27/MySQL/日志/组提交/","date":"04-27","excerpt":"","tags":[]},{"title":"日志顺序","text":"先写undo log，修改buffer pool的同时，先记录变更数据到redo log中，然后再写bin log。那么这时候事务 已经算提交了，不管脏页有没有被刷到磁盘","path":"2025/04/27/MySQL/日志/日志顺序/","date":"04-27","excerpt":"","tags":[]},{"title":"慢查询log","text":"","path":"2025/04/27/MySQL/日志/慢查询log/","date":"04-27","excerpt":"","tags":[]},{"title":"bin log","text":"用于数据备份和主从复制，默认下是关闭的 bin log有三种格式 statement：记录的是sql原句 row：记录的是哪里变更了xx row和statement混合 怎么刷盘的？ mysql会先给每个线程分配一块binlog cache，且每个binlog cache都有固定大小binlog_cache_size，如 超过了这个大小，就会先暂时存到磁盘。虽然每个线程都有，但最终都还是写到同一个bin log里 什么时候binlog cache里的内容会写到磁盘？","path":"2025/04/27/MySQL/日志/bin log/","date":"04-27","excerpt":"","tags":[]},{"title":"redo log ","text":"记录的是事务的更改数据 即某个页的修改，用于保证事务的持久性，就是如果数据库宕机后，可以用于数据 恢复 采用了WAL（写前日志，先写日志再写数据），将随机写变成顺序写 记录格式为物理日志，即记录的是某某地方发生了xx变化 为什么事务提交后不直接把 Buffer pool 的数据同步到磁盘 首先你如果直接用bufferpool，可能你就修改一个页中的某条数据，然后就把整个页的数据刷到磁盘里去 这显然是不合理的，因为数据库内存和磁盘交换的基本单位是页（16kb），所以你每次刷只能刷一整 页。且这个行为是随机写，效率偏低。而写redo log，一行记录可能就占10多byte，内容少，再加上这 哥顺序写，性能要比直接刷盘要快得多 redo log的三种状态 1.在redo log buffer里 2.在os的page cache里 3.在磁盘里 redo的流程 整体流程就是 1.先看看bufferpool里面有没有数据，没有就去磁盘拉取 2.这时候先把修改的内容记录到redo log buffer里 3.在bufferpool里修改页数据 4.事务提交时，将redo log里的内容追加到redo file里面去 **磁盘表数据的最终变更是靠 Buffer Pool 中的脏页刷盘实现的，不是 redo log 直接修改的；redo log 的 ** 作用是在崩溃后辅助恢复这些变更 ps：Redis的AOF是写后日志，先执行Redis的命令，再写日志。为什么？ 这可能跟AOF记录的内容有关，AOF记录的是执行的Redis命令，先执行可以避免记录一些错误的命 令 那么为什么redo log要为写前日志了呢 redo log buffer刷盘时机参数：&lt;font style=&quot;color:rgb(194, 24, 91);background-color:rgb(255, 244, 244);&quot;&gt;innodb_flush_log_at_trx_commit&lt;/font&gt; 的三种状态 InnoDB_flush_log_at_trx_commit&#x3D;&#x3D;1：每次事务提交时都刷盘，会先把pool里的内容刷到操作系统的文件缓存 系统page cache里去，再刷到磁盘里，这个是默认设置。好处就是能满足ACID的D，因为只有你的redo log落入磁盘才算事务提交成功，但就是效率低 InnoDB_flush_log_at_trx_commit&#x3D;&#x3D;2：先刷到page cache，再由OS后台线程定期 fsync。操作系统宕机就会 丢失这个定期的间隔的数据，但效率要比上一种高一点 innodb_flush_log_at_trx_commit&#x3D;&#x3D;0：不刷到page cache,直接由后台线程定期刷到磁盘 怎么选择？从安全性和性能两个方面出发 redo log写满了怎么办？ 我们都知道redo log是为了解决buffer pool脏页数据丢失的问题（脏页：内存里有，磁盘没有的数据页）； 因为redo log写日志，它是通过循环写的方式，磁盘里有两文件，什么0和1，一开始从0开始写，写完就到1 然后再从头开始写覆盖原先数据，前提是原先数据已经全部落入磁盘。那么写满的意思就是redo log记录的变更都还没持久化到磁盘的数据库表（即write pos追上check point了）。 那么这时候MySQL就会被阻塞，停下来把buffer pool的脏页数据刷到磁盘，并把旧的redo log擦除掉，腾空间出来，mysql才会恢复。（所以说在高并发系统中，适当设置redo log的大小很重要的） 事务还没提交，redo会被持久化到磁盘吗？ 是有可能的。 一般来说有三种情况。 1.你采用的刷盘策略为0和2，因为它们的刷盘策略是由操作系统后台线程来控制，而不是说你执行完commit 后才刷盘，那么就存在这种commit前，redo log就被持久化到磁盘 ps：事务怎么提交？？？ 就是手动命令哦 123begin;commit;//执行到这行，就是提交了 2.采用的刷盘策略为1，也有可能。另一个事务提交时顺便把其他事务在redo log buffer里的redo log也给刷 到磁盘里 3.redo log pool满了，达到我们设置的上限的一半了，就会先把里面的内容刷到page cache，但不会落盘， 还是在磁盘里","path":"2025/04/27/MySQL/日志/redo log /","date":"04-27","excerpt":"","tags":[]},{"title":"undo log","text":"保证原子性，用于事务回滚 实现MVCC 记录的是事务修改前的数据 它的持久化是靠redolog","path":"2025/04/27/MySQL/日志/undo log/","date":"04-27","excerpt":"","tags":[]},{"title":"Redis网络模型","text":"https://zhuanlan.zhihu.com/p/614204046","path":"2025/04/27/Redis/网络模型/Redis网络模型/","date":"04-27","excerpt":"","tags":[]},{"title":"MySQL自增主键用完了会怎么样？怎么解决","text":"自增主键分为两种，一种是显性的，一种是隐性的（row_id）。如果是显性的，那么就会报主键冲突错误， 如果是隐性的，下次申请ID的时候，得到的值会从0开始，然后继续开始自增，但这个时候会覆盖原有相同 row_id的数据 显性的一般是bigint,unsign 这样的话，肯定是自己显性指定主键ID，毕竟这样的话异常我们才能感知到的 真用完了怎么办？ 1.脚本扫描没用到的主键，然后插入，但不推荐，会破坏其原有数据的连续性 2.将表里的久远数据归档（推荐） 3.使用UUID，UUID是128位，几乎不可能用完的，但不推荐，UUID作为主键ID容易造成页分裂，页合并","path":"2025/04/27/MySQL/MySQL自增主键用完了会怎么样？怎么解决/","date":"04-27","excerpt":"","tags":[]},{"title":"count","text":"count(1) count() count(列名) 哪个性能高？ count(1)和count() 表示直接查询符合where条件的行数，而count（列名）表示查询的列名不为 空且符合where条件的行数。count(*)是要比count(1)性能高，因为它是标准语法，MySQL对它进行了 很多优化 count(*)的优化？ 首先声明一点，优化的前提是使用count(*)时不带where和group by - 对于myisam而言，因为它锁的粒度最小只有表锁，所以它不会有并发的行数据修改，故MySQL采用了一个字段进行存储它的行数 - 对于InnoDB而言，MySQL进行count(*) 时会选择一个最小非聚簇索引，因为count时他是不会关心你具体数据的，而非聚簇索引的叶子结点装的是主键ID，比聚簇索引小。所以建索引时，再建一个非聚簇索引也是必要的 count（列名）？ count(1)和count(*)只是扫描索引树，而count（列名）则需要进行全表扫描，如果列名不加索引 大数据量统计下，可以怎么优化count（*） 1.如果对count的精准要求不高，可以通过explain里的row代替 2.用一张表维护count，insert就+1，或者delete就 -1 3.用列式存储数据库，如click house","path":"2025/04/27/MySQL/count/","date":"04-27","excerpt":"","tags":[]},{"title":"索引合并机制","text":"数据库查询优化的一种手段，它就是说多个索引同时检索来提高查询效率，类似于我们开多线程 通过explain，我们可以清晰地看到用到了索引合并的标识 index_merge 并且可以在extra 看到使用了哪种策略 using interset： using union： using sort_union：","path":"2025/04/27/MySQL/索引/索引合并机制/","date":"04-27","excerpt":"","tags":[]},{"title":"索引覆盖","text":"查询的字段被包含在了索引里，不需要回表了，这就是索引覆盖","path":"2025/04/27/MySQL/索引/索引覆盖/","date":"04-27","excerpt":"","tags":[]},{"title":"为什么mysql索引结构要采用b+树","text":"首先我们要明白采用它的目的，一定就是要时间复杂度尽可能地小，支持范围查询。前者无非就是树，跳表，Hash表。而hash索引不支持范围查询 为什么不用Hash？ 不支持范围查询 为什么不用跳表？ 跳表是内存友好型，而b+树是磁盘友好型。b+树一般在磁盘里寻址三次足以，每次都会读取一个数据页，然 后在数据页进行二分查找 而跳表每次读取一个数据页节点都需要跳跃，而链表又是几万个节点，虽然是logn，但寻址次数明显是要比 b+树多，因为b+树的二分查找主要是在数据页中（已经读到内存中了，InnoDB是读到bufferpool，myisam 是读到 page cache），而跳表的二分查找就是在链表中，即磁盘中，而且索引之间的物理距离可能比较长 为什么不用b树？ b树的非叶子节点的v也会存数据，这导致一个页中存储的kv值会减少（因为一个页的大小是固定的），指针 就会表少，要同样保存大量数据，就得去增加树高，导致其性能降低。然后就是叶子节点之间是没有指针相连 的，对范围查询不是很友好，且叶子节点之间是无指针相连的，对范围查询不是很友好 为什么不用二叉树&#x2F;红黑树？ 二叉树层级过高，搜索效率偏低，百万数据约为20层","path":"2025/04/27/MySQL/为什么mysql索引结构要采用b+树/","date":"04-27","excerpt":"","tags":[]},{"title":"索引失效","text":"补： %北%走索引的，但是%北%无法二分查找啊，这下索引就没卵用了，因为只会全扫 – 1.索引也是会全扫描的 – 2.mysql加载16k一页，全扫索引比全扫主键快很多，IO快，列差得很大，快很多，因为你拿数据拿得多啊，二级索引树就拿了ID+列名，你主键拿的是一行，即所有列的数据","path":"2025/04/27/MySQL/索引/索引失效/","date":"04-27","excerpt":"","tags":[]},{"title":"查询优化器","text":"将SQL语句转成物理执行计划，并以最小化查询时间or资源消耗 工作流程 将SQL转成抽象语法树 2.重写查询：简化条件，合并子查询、消除冗余操作 3.根据模型评估执行计划，选择最小成本计划（选哪个索引） 4.将最优计划转换为可执行的指令集","path":"2025/04/27/MySQL/查询优化器/","date":"04-27","excerpt":"","tags":[]},{"title":"最左前缀原则","text":"是什么？ 假如有一个联合索引（A,B,C）,如果你想要命中这个联合索引，where就得包含最左列即A。 且where a b c的顺序不影响索引的命中 为什么得遵循？联合索引的索引树示例结构 （age，name） 那他是怎么构造索引树的呢，首先会根据联合索引中字段的位置来决定谁先排序。如果age不同，会先对 age进行排序，如果age相同，再进行name的排序。 那么就可以很好理解最左匹配原则了：因为索引的底层是b+树，如果是联合索引的话，在构造索引树时， 会先按左边的字段进行排序，左边的key相同时再根据右边的字段排序 MySQL8.0引入的索引跳跃机制索引跳跃机制","path":"2025/04/27/MySQL/索引/最左前缀原则/","date":"04-27","excerpt":"","tags":[]},{"title":"加锁算法？","text":"MySQL不同隔离级别下的加锁情况 | Exploring MySQL&#x2F;mysql-storage-engines&#x2F;innodb&#x2F;1.5.5.InnoDB锁——lock之不同SQL加锁分析.md at master · asdbex1078&#x2F;MySQL 抛开隔离级别谈上锁都是耍流氓！ 读未提交 - 增：插入数据后，给新插入的数据上&lt;font style=&quot;color:#DF2A3F;&quot;&gt;记录锁&lt;/font&gt;，防止其它事务更改这条记录 - 删：需要获取到要删除的记录的&lt;font style=&quot;color:#DF2A3F;&quot;&gt;记录锁&lt;/font&gt;，保证删除的时候其它事务没在使用这些数据，并保证删除后其它事务无法对这些数据进行操作 - 改：给需要更改的数据上&lt;font style=&quot;color:#DF2A3F;&quot;&gt;记录锁 &lt;/font&gt; - 查：任何读都不加锁 读已提交 - 增：插入数据后，给新插入的数据上&lt;font style=&quot;color:#DF2A3F;&quot;&gt;记录锁&lt;/font&gt;，防止其它事务更改这条记录 - 删：需要获取到要删除的记录的&lt;font style=&quot;color:#DF2A3F;&quot;&gt;记录锁&lt;/font&gt;，保证删除的时候其它事务没在使用这些数据，并保证删除后其它事务无法对这些数据进行操作 - 改：给需要更改的数据上&lt;font style=&quot;color:#DF2A3F;&quot;&gt;记录锁 &lt;/font&gt; - 查：快照读不加锁，当前读只加记录锁 可重复读 - 增：使用&lt;font style=&quot;color:#DF2A3F;&quot;&gt;插入意向锁&lt;/font&gt;，进行插入，插入后给插入的数据上&lt;font style=&quot;color:#DF2A3F;&quot;&gt;记录锁&lt;/font&gt;（隐式锁，其实这个记录锁不是这个时候上的） - 删：使用&lt;font style=&quot;color:#DF2A3F;&quot;&gt;临键锁&lt;/font&gt;，防止其它事务在删除的区间内插入数据 - 改：给需要更改的数据上&lt;font style=&quot;color:#DF2A3F;&quot;&gt;临键锁 &lt;/font&gt; - 查：快照读不加锁，当前读：加临键锁和间隙锁，唯一索引则加记录锁 序列化 - 增：使用&lt;font style=&quot;color:#DF2A3F;&quot;&gt;插入意向锁&lt;/font&gt;，进行插入，插入后给插入的数据上&lt;font style=&quot;color:#DF2A3F;&quot;&gt;记录锁&lt;/font&gt;（隐式锁，其实这个记录锁不是这个时候上的） - 删：使用&lt;font style=&quot;color:#DF2A3F;&quot;&gt;临键锁&lt;/font&gt;，防止其它事务在删除的区间内插入数据 - 改：给需要更改的数据上&lt;font style=&quot;color:#DF2A3F;&quot;&gt;临键锁&lt;/font&gt; - 查：普通查询自动变为select … lock in share mode，上&lt;font style=&quot;color:#DF2A3F;&quot;&gt;临键锁，锁间隙&lt;/font&gt;！ 唯一索引加记录锁 细节 锁的对象是索引，而不是记录 二级索引的记录加了排他锁，聚簇索引也会加对应的锁。 如果没有合适的索引，那么MySQL就会扫表来处理，那么表的每一行都会被锁定，从而阻塞其他用户对 表的所有插入 临键锁只存在于可重复读和串行化事务隔离级别下 MVCC只存在于读已提交和可重复读 next-key lock 是前开后闭（(x,y]）区间，而间隙锁是前开后开区间（(x,y)） 临键锁上锁的优化： 临键锁锁的是一个间隙以及一个间隙后面的行记录，锁粒度比较大，在一些情况下会对其进行一定优化 总结起来就是 在加间隙锁or记录锁能避免幻读的情况下，临键锁就会退化成记录or间隙 唯一索引等值查询： 当查询的记录存在时，定位到了在索引树上的位置，那么原先在扫描时加的临键锁就会退化成记录锁 当查询的记录不存在时，在索引树找到比它大的第一条记录时，那么临建锁就会退化成 间隙锁 唯一索引范围查询情况 唯一索引扫描索引树时，会对扫描到的每一个索引加临键锁，如果满足一些条件就有可能发生锁退化 非唯一索引等值查询 非唯一索引范围查询情况 临键锁无法进行退化 非索引扫描情况 每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表**：****从负无穷到正无穷（全表记** 录 + 所有间隙） 以上加锁的机制都是围绕着如何避免幻读来展开的 ps：锁全表的数据（临建锁）时，那这时候往表的最后一行后插入数据会被阻塞吗。会的，锁到正无穷，如果插入头部，负无穷也会被锁住 MySQL只操作同一条记录，也会发生死锁吗？ 会的。mysql锁的是索引，而不是记录。如果是根据二级索引查询（加锁查询orDML），那么它会 先获取二级索引上的锁，然后再去对主键索引上的锁。如果有两线程同时获取锁的顺序不一样了， 那么就会发生死锁 加锁原则：两个原则两个优化一个bug","path":"2025/04/27/MySQL/锁/加锁算法？/","date":"04-27","excerpt":"","tags":[]},{"title":"架构","text":"连接层 服务层 引擎层 文件层 是CP，还是AP的？","path":"2025/04/27/MySQL/架构_gpkxww1hmhwreqcl/","date":"04-27","excerpt":"","tags":[]},{"title":"唯一索引","text":"在同一张表，唯一索引字段的值都是唯一的 可以为null，且可以为多个null值 通常是非聚簇索引 为什么说通常呢？ 因为我们可能忘了设置主键索引，那么MySQL就会默认选择一个唯一非空索引作为主键，如果没有，就 会使用row_id 是怎么保证唯一性的？ 和主键索引的区别 是否可以为null 是否回表 是否可以有多个 索引类型不同 是否可以为外键 缺点 没有银弹，插入时需要判断是否存在存在 更新索引列字段时，需要先删除原记录，再判断新插入的值是否唯一，再插入（InnoDB帮我们自动完 成的） 这里说的是b+树索引结构的变化 d字段，建了一个索引D，允许为null，那么当 select * from table where d is null，select * from table where d is not null这两条sql，在唯一索引和普通索引下有什么区别？ 首先我们可以把索引中的null看成最小值 那么无论是前者还是后者都可以从左开始扫描。但是全表扫，还是索引扫，得看查询优化器的评估或者是 否可以命中索引覆盖","path":"2025/04/27/MySQL/索引/唯一索引/","date":"04-27","excerpt":"","tags":[]},{"title":"索引下推机制","text":"五分钟搞懂MySQL索引下推 - 三分恶 - 博客园 mysql5.6引入的一种索引优化手段，它就是说MySQL在执行SQL时，会把判断条件传给存储引擎，然后在查 查询过程中直接过滤掉不符合的记录，减少回表产生的磁盘IO 下推的意思是什么？？ 首先我们要清楚没有这个机制下，MySQL是怎么查询的？ 1.存储引擎读取索引记录 2.回表拿到行记录 3.把行记录交给&lt;font style=&quot;color:rgb(199, 37, 78);&quot;&gt;Server&lt;/font&gt;层去检测该记录是否满足&lt;font style=&quot;color:rgb(199, 37, 78);&quot;&gt;WHERE&lt;/font&gt;条件 那么下推的意思就是说 原先服务层做的事情交给引擎层去做 有了该机制后 1.存储引擎读取索引记录 2.根据索引的字段判断是否可以根据where条件过滤掉部分不符合的记录，有就过滤，没有就拉倒。拿到 结果主键 3.回表 4.把行记录返回给server，再做其余where字段的判断","path":"2025/04/27/MySQL/索引/索引下推机制/","date":"04-27","excerpt":"","tags":[]},{"title":"索引跳跃扫描","text":"MySQL8.0引入的一种索引优化手段。它就是说当我们不遵循最左匹配原则时，即缺失聚合索引的最左列， 这个机制会通过枚举的方式帮我们补齐最左列 适用条件 0.查询的字段必须是索引中的列 1.最左列的区分度不大，如果太大，枚举的效率就很低，那么就没意义了。所以到底要不要用还得查询优 化器抉择 2.查询时只能依赖于一张表 3.不可以用group by,DISTINCT 4.表T至少有一个联合索引，但是对于联合索引(A,B,C,D)来说，A和D可以是空的，但B和C必须是 非空的。","path":"2025/04/27/MySQL/索引/索引跳跃扫描/","date":"04-27","excerpt":"","tags":[]},{"title":"非聚簇索引","text":"把数据和索引分开存储，不影响数据的存储结构，而是单独新建一张索引表 非叶子节点是索引，叶子节点存的是索引+主键ID","path":"2025/04/27/MySQL/索引/非聚簇索引/","date":"04-27","excerpt":"","tags":[]},{"title":"聚簇索引（主键索引）","text":"在InnoDB中，聚簇索引指的就是非叶子结点存的是索引，叶子节点存的是行记录 它会按照主键的逻辑顺序将行数据存储在磁盘，这也使得行的物理存储顺序和主键的逻辑顺序一样，查询起来 非常快","path":"2025/04/27/MySQL/索引/聚簇索引（主键索引）/","date":"04-27","excerpt":"","tags":[]},{"title":"页锁","text":"mysql InnoDB无页级锁","path":"2025/04/27/MySQL/锁/页锁/","date":"04-27","excerpt":"","tags":[]},{"title":"锁升级","text":"InnoDB的设计初衷为高并发，在实现的过程中做了很多减少锁粒度的工作。故锁升级这一概念违背了其设计理念","path":"2025/04/27/MySQL/锁/锁升级/","date":"04-27","excerpt":"","tags":[]},{"title":"行级锁","text":"InnoDB引擎特有的 记录锁锁住某行记录，分为读写锁，事务提交后自动释放，例如select * from table_name where id &#x3D; 1 for update;就给id&#x3D;1这行记录上了写锁 间隙锁锁住行与行之间的间隙，防止其它事务在间隙中插入数据，产生幻读，间隙锁是不互斥的（如果涉及到记录锁或者临键锁，还是会互斥阻塞），两个事务可以拥有同一段间隙的间隙锁，但要插入数据时发现这段间隙被其它事务锁上了就插不了了。间隙锁是为了解决幻读，防止其它事务在区间内插入数据 临键锁（间隙+记录锁）加临键锁的时候是先加间隙锁，后加记录锁，这就有可能出现加间隙锁能成功，加记录锁被阻塞，然后间隙锁与其它事务发生死锁 前开后闭区间，锁住某行以及这一行之前的间隙，如(1, 3]，锁住3这一行和1到3行之间的间隙，因为有记录锁，会产生读写互斥，间隙锁之间不互斥 插入意向锁插入意向锁是一个间隙锁，但这个间隙锁实际上锁住的不是一个区间，而是区间中插入的那个点，所以算是一种特殊的间隙锁，插入意向锁和插入意向锁会互斥，即两个事务可以在同一个区间插入，但不能在同一个区间上相同的点插入；插入意向锁与间隙锁互斥，即插入的点所处的区间不能被其它事务的间隙锁锁住 当事务要插入记录时，判断是否有与插入意向锁冲突的锁，如果有，加插入意向锁，进入锁等待，如果没有，什么锁都不加，直接插入数据，就是说不加插入意向锁！ 插入完成后，会给插入的这个数据上个记录锁（其实不会上记录锁，这是个隐式锁，后面会介绍），防止其它事务更改这条数据，直到事务提交后释放这个记录锁 当间隙中存在间隙锁，与插入意向锁冲突 当间隙中存在插入意向锁，间隙锁阻塞 当间隙中存在插入意向锁，但要插入的点和自己不同时，不阻塞（插入意向锁是在间隙中锁住某个点）","path":"2025/04/27/MySQL/锁/行级锁/","date":"04-27","excerpt":"","tags":[]},{"title":"表级锁","text":"对整个表加的锁 意向锁为什么要有这锁？ 如果A对表中的一行上了写锁，这时B对表上了写表锁，表示表里面的每一行都可以修改，这时就矛盾了 虽然B在申请表锁你可以遍历每一行，但这不太现实。 故意向锁就是为了解决这种不同锁粒度之间的并发性问题，有了这锁后，在给表上表锁，就可以直接判断 是否有事务对表中的数据进行操作 意向锁不是锁资源，只是一个通知，且锁是由mysql管理的 上行级共享锁时会先给表上一独占意向锁，上行级独占锁时会先给表上一共享意向锁 意向共享锁和意向独占锁不冲突，但他两和表锁互斥（共享读表锁和意向共享锁不互斥） 元数据锁（字典锁）锁定表的结构数据，防止DDL和DML、DQL起冲突 当进行CURD时，就会给表上 元数据读锁 当进行DDL时即想要修改表的结构时，就会给表上 元数据写锁 元数据锁在事务提交后自动释放 申请元数据锁的事务会进入一个队列，如果出现了申请元数据写锁的请求，就会阻塞后续的事务 AUTO-INC锁保证自增主键能连续自增的锁 当事务执行insert的时候就会给表上这个锁 5.6之前，这个锁的粒度比较大，当事务提交时才会释放，即即使insert后无insert操作了，也不会释放，直到 事务提交 5.6后，事务中的每一次insert结束后就会释放锁（ 插入多行数据时，会加一次自增锁并一次性分配一段连续 ID ） 表级排他or共享锁lock table read 给表上读锁 lock table write 给表上写锁 unlock table 释放当前会话中拥有的所有的锁，会话取消也是会自动释放","path":"2025/04/27/MySQL/锁/表级锁/","date":"04-27","excerpt":"","tags":[]},{"title":"全局锁","text":"全局锁，是一种影响整个MySQL实例的锁 flush tables with read lock，执行此条命令，整个数据库处于只读状态 unlock tables， 释放全局锁，会话断开时，也会自动释放全局锁","path":"2025/04/27/MySQL/锁/全局锁/","date":"04-27","excerpt":"","tags":[]},{"title":"函数","text":"https://zhuanlan.zhihu.com/p/629460362","path":"2025/04/27/MySQL/函数/","date":"04-27","excerpt":"","tags":[]},{"title":"InnoDB vs Myisam","text":"InnoDB： 索引分为聚集索引与二级索引 支持事务 支持行级锁 支持外键 必须有主键，如果没有，会选择第一个非空唯一索引当主键，如果没有非空唯一索引，自动创建隐藏主键 对于自增长字段，InnoDB必须有 只有该字段 的索引 MyISAM： 索引只有一种（索引字段作为索引数据，叶子节点包含了该记录数据页地址），数据页和索引页分开 不支持事务，没有undo 和 redo 仅支持表锁 不支持外键 会保存表的总行数（InnoDB为什么不保存？因为InnoDB支持事务，保存了也不精准，就不这么设计了） 可以没有主键 对于自增长字段，MyISAM可以和其它字段一起建立联合索引 MyISAM数据页和索引页分开","path":"2025/04/27/MySQL/引擎/InnoDB vs Myisam/","date":"04-27","excerpt":"","tags":[]},{"title":"jion","text":"是什么jion 是用来多表关联查询 jion方法有三种：left jion,right jion,innner jion inner jion(等值连接)：获取两个表字段匹配关系的记录，即只有两表的交集 left jion：获取左表的全部记录，即使右边无对应匹配的记录 right jion：获取右边的全部记录，即使左边无对应匹配记录 配合一起使用的还有ON关键字，用来指明查询的条件 为啥大厂不推荐用jion原因是早期MySQL版本，jion的时间复杂读很高。它的实现原理是基于嵌套循环来实现关联查询的。简单地 说就是通过一张表作为外循环，一张表位内循环，然后一一比对，符合条件的就输出。具体算法的实现有三 种，simple nested loop，block nested loop和index nested loop。但效率都不是很高。而且随着你jion表数 量越来越多，时间复杂度以指数级别增长 三种嵌套循环算法simple nested loop 从名字上就看出来，简单除暴，就是全量扫描连接两张表进行数据的两两对比，时间复杂度可以认 为是N*M index nested loop 当内循环（即被驱动表）关联的字段有索引的话，可以用索引进行查数据。因为索引的结构是b+树的， 复杂度可以近视为N*logN block nested loop 其实是引入了一个Buffer，提前把外循环的一部分数据放到JION BUFFER里，然后再一一比对，虽然整 体还是N*M复杂度，但基于内存，效率会高不少 MySQL的驱动表如何选择不用jion如何实现关联查询？ 业务代码层面自己实现 数据冗余，把一些重要数据在表中做冗余 做宽表处理，多张表合并成一张大表 MySQL8.0的Hash JION何方神圣？？？","path":"2025/04/27/MySQL/jion/","date":"04-27","excerpt":"","tags":[]},{"title":"groupby","text":"","path":"2025/04/27/MySQL/groupby/","date":"04-27","excerpt":"","tags":[]},{"title":"orderby","text":"orderby是做排序的，它排序方式有两种，一种是索引排序，一种是filesorted（我们可以在extra中看到提示：using filedsorted），但具体哪种还得看优化器来抉择，而且确定性也不是很强。 在filedsort排序中，如果排序的内容比较少，就会直接内存的sort_buffer进行排序，否则就得使用临时文件了 。且当在sort_buffer排序时，如果排序的字段并不是很长的话，就会使用全字段排序的方式直接在sort_buffer里排好序后返回结果集。但如果字段特别长，就会基于空间考虑，采用（隐藏ID）row_id进行排序，然后回表查询后返回结果集 ps：字段长度指的是 **参与排序的字段 + SELECT 返回的字段的总长度 ** 索引排序索引天然有序的，那么借助索引进行排序自然是最高效的。但这个过程中，是否真的用索引，完全取决于优化 器的选择。查询优化器会根据成本评估来进行选择是否通过索引进行排序 我平时开发比较好奇，就有去测到底哪一种情况最容易做索引排序 1.用到了索引覆盖且遵循最左匹配原则 2.查询条件中有limit，且limit的Size不高，像之前测的时候我80万数据的表，limit超过2w就不会走了 3.用到了索引跳跃机制 filesort排序前面我们知道，filesort 如何排序的内容不多时，会直接在内存的sort_buffer里面排，多的话就基于临时文件 排序了。这种行为是由sort_buffer_size即sort_buffer的大小所决定的。排序的数据量小就在内存，大就在文 件。 filesort是如何进行排序的？ 基于归并排序的算法，把排序的数据拆分成多个临时文件，然后进行一个merge返回给客户端 这里还有一个影响排序算法的重要参数，即max_length_for_size_data，是MySQL中用于控制 用于排序的行数的长度一个字段，默认为1024bit。如果单行的长度大于这个值，就会进行rowId 排序，否则就进行全字段排序 全字段排序实例SQL 12select a,d,f from t2 where a = &quot;Hollis&quot; order by d; row Id 排序 如何选择排序算法速度&gt;内存&gt;一次回表 如何优化using fileSorted 尽量使用索引进行排序 通过sort_buffer_size和max_length_for_size_data进行调优","path":"2025/04/27/MySQL/orderby/","date":"04-27","excerpt":"","tags":[]},{"title":"explain","text":"对select，update，delete（后两个是告诉你他是怎么查找数据的）。对insert无效的 id： 表示单一SQL的执行顺序，该语句的唯一标识。如果explain的结果包括多个id值，则数字越大越先执行；而 对于相同id的行，则表示从上往下依次执行 select_type table 表示当前sql作用的表名 type system：系统表，少量数据，往往不需要进行磁盘IO const：使用常数索引，MySQL 只会在查询时使用常数值进行匹配。 explain select * from t2 where f=&#39;Hollis&#39;; 使用唯一性索引做唯一查询 eq_ref：唯一索引扫描，只会扫描索引树中的一个匹配行。 explain select * from t1 join t2 on t1.id = t2.id where t1.f1 = &#39;s&#39;; 当在连接操作中使用了唯一索引或主键索引，并且连接条件是基于这些索引的等值条件时，MySQL通常会选择 eq_ref 连接类型，以提高查询性能。 ref：非唯一索引扫描， 只会扫描索引树中的一部分来查找匹配的行。 explain select * from t2 where a = &#39;Hollis&#39;; 使用非唯一索引进行查询 range：范围扫描， 只会扫描索引树中的一个范围来查找匹配的行。 explain select * from t2 where a &gt; &#39;a&#39; and a &lt; &#39;c&#39;; 使用索引进行性范围查询 index：全索引扫描， 会遍历索引树来查找匹配的行 explain select c from t2 where b = &#39;s&#39;; 不符合最左前缀匹配的查询 ALL：全表扫描， 将遍历全表来找到匹配的行。 explain select * from t2 where d = &quot;ni&quot;; 使用非索引字段查询 需要注意的是，这里的index表示的是做了索引树扫描，效率并不高。以上类型由快到慢： system&gt; const &gt; eq_ref &gt;**ref&gt;range&gt; index **&gt;ALL possible_keys 展示当前查询可以使用哪些索引，这一列的数据是在优化过程的早期创建的，因此有些索引可能对于后续优化过程是没用的。 key 表示MySQL实际选择的索引 key_len 索引使用的字节数。由于存储格式，当字段允许为NULL时，key_len比不允许为空时大1字节。 filtered 表示符合查询条件的数据占全部数据的百分比，最大100，越高则越好 rows mysql估算会扫描的行数，越小越好 extra（额外信息） Using filesort：当Query 中包含 ORDER BY 操作，而且无法利用索引完成排序操作的时候，MySQL Query Optimizer 不得不选择相应的排序算法来实现。数据较少时从内存排序，否则从磁盘排序。Using tempporary：在对MySQL查询结果进行排序时，使用了临时表，这样的查询效率是比外部排序更低的，常见于order by和group by。 Using index：使用了索引覆盖 Using where：使用了where进行过滤，即使用到了索引，如果没有索引，说明是去聚集索引全盘扫描，说明 没用到where进行过滤，只用where进行判断 Using index condition：使用了索引下推 Using MRR：使用了Multi-Range Read优化 Using join buffer：使用了连接缓存，比如说在查询的时候，多表join的次数非常多，那么将配置文件中的缓 冲区的join buffer调大一些 Distinct：查找distinct值，当找到第一个匹配的行后，就不再搜索了","path":"2025/04/27/MySQL/explain/","date":"04-27","excerpt":"","tags":[]},{"title":"四种事务隔离级别","text":"事务会产升的问题： 脏读：读到其他事务未提交的数据 不可重复读：一个事务里多次针对同数据源的查询不一样 幻读：事务前后针对同一数据源的范围查询的结果条数不一样 查看隔离级别： select @@TRANSACTION_ISOLATION; set global TRANSACTION ISOLATION LEVEL 读未提交读的时候不加锁，也不使用MVCC，能直接读到最新数据，update时加记录锁，事务问题最多 读已提交读的时候有快照读和当前读，快照读使用MVCC，每次快照读都产生新的readview，读的是最新提交的数据 不算脏数据，解决了脏读。update只会加记录锁。 可重复读读的时候跟读已提交差不多，区别是只在第一次快照读时生成readview，后面会复用，解决不可重复读。 update会加间隙锁和临键锁。 序列化读和写都加锁，读都是当前读 RR解决了大部分情况下的幻读快照读通过MVCC RR的快照读只会生成一次readview，那么该事务中途有其他事务插入数据，对当前事务是不可见的， 即避免了幻读 当前读通过加锁 当前读select…for upate会通过加临键锁的方式阻塞其他事务想往锁范围的数据插入数据，直到当前事务 提交结束 但有两种特殊情况 1.当前事务去主动更新“不存在”的记录（这里的不存在指的是对当前事务不存在，其实其他事务已经插入 进来了），然后这条记录就对当前事务可见，于是发生了幻读 2.快照读，然后当前读 RR没解决部分情况下的可重复读第一次快照读，第二次当前读","path":"2025/04/27/MySQL/事务/四种事务隔离级别/","date":"04-27","excerpt":"","tags":[]},{"title":"ACID","text":"A：原子性在数据库层面的原子性指的是要么都成功，要么都失败（不同于并发编程中的原子性：操作不可被打断），它在InnoDB中是由undo log日志来保证的 C：一致性即 事务完成时，修改后的数据要满足数据库对于数据完整性的约束，包括主键约束、约束检查等，同时要满足数据库中业务数据的一致性，比如银行转账，有人多钱就肯定要有人少一样数量的钱 这里是靠原子性，隔离性，持久性一起保证的 分布式理论中也有一致性，但它指的是所有服务节点都保持一致 I：隔离性各个事务并发操作下互不影响 靠MVCC和锁机制来保证的，比如在可重复读的事务隔离级别下，MVCC保证了快照读的隔离性，锁保证了当 前读的隔离性 D：持久性事务一旦提交or回滚，它对数据库的修改是永远不变的 InnoDB是通过redo log来保证事务修改的数据不丢失","path":"2025/04/27/MySQL/事务/ACID/","date":"04-27","excerpt":"","tags":[]},{"title":"平时你是怎么排错的","text":"","path":"2025/04/27/场景题/平时你是怎么排错的/","date":"04-27","excerpt":"","tags":[]},{"title":"MVCC","text":"全称就是 多版本并发控制，是MySQL用来解决读写冲突的一种手段，可以实现读写不阻塞。 存在于读已提交和可重复读的情况下，读未提交不需要加锁直接读最新数据，而串行化普通select都给你加锁 MVCC依赖什么实现的？ 1.数据库的隐藏字段： rollback_pointer 回滚指针 trx_id：最近修改该行数据的事务ID 2.undo log版本链：记录的是事务变更前的数据 3.readView：快照读情况下生成的一个读视图，生成的一个快照，用来解决数据的可见性问题，有以下 字段 trx_ids：生成readview时当前系统还获活跃的事务ID集合 low_limit_id：应该分配给下一个事务的ID up_limit_id：没提交事务中的最小ID creator_trx_id：创建该read view的事务ID ps: trx_ids&#x3D;[up_limit_id,low_limit_id) MVCC是如何判断数据的可见性的？ 1.首先先判断本条数据是否由本事务产生（trx_id&#x3D;creator_trx_id），如果是，那么就一定是可见，毕 竟是自己产生的 2.再判断**本条数据**的事务ID是否小于没提交事务的最小ID，如果是，那就可见，因为说明这数据已经被 其它事务所提交了，本事务是可见的 3.再判断本条数据是否在活跃事务集合中，如果不在，那么说明该数据已经被其他事务所提交 如果本条数据不存在的话，那么就会根据rollback pointer和undo log去找上一个版本的数据，然后重复 以上判断 readview产生时机 1.可重复读的情况下，只在事务第一次快照读时产生readview，后面会复用这个快照如果事务启动时选择 了with consistent snapshot，事务启动时就建立快照 2.读已提交的情况下，每次快照读都产生新的readview 二级索引在索引覆盖时如何使用MVCC？ 隐藏字段在聚簇索引上，所以二级索引不回表要怎么使用MVCC？二级索引中，用了一个额外的名 page_max_trx_id来表示修改过该页的最大事务ID，然后用readview里的up_limit_id即没提交的事务中的 最小ID去和它比对，发现比它大，那么说明该页的数据是可见的。如果不可见，就需要回表。 所以我们可以得出一个结论，即使用到了索引覆盖，也不一定不回表","path":"2025/04/27/MySQL/事务/MVCC/","date":"04-27","excerpt":"","tags":[]},{"title":"消息积压怎么办","text":"","path":"2025/04/27/RabbitMQ/消息积压怎么办/","date":"04-27","excerpt":"","tags":[]},{"title":"惰性队列","text":"","path":"2025/04/27/RabbitMQ/惰性队列/","date":"04-27","excerpt":"","tags":[]},{"title":"如何实现延迟队列","text":"","path":"2025/04/27/RabbitMQ/如何实现延迟队列/","date":"04-27","excerpt":"","tags":[]},{"title":"工作模式","text":"","path":"2025/04/27/RabbitMQ/工作模式/","date":"04-27","excerpt":"","tags":[]},{"title":"MAC地址和IP地址","text":"mac地址是负责两台直连设备之间的设备，而IP地址是负责两台没直连设备之间的通信。在数据传输过程中， 源mac地址和目标mac地址经过中转后就会变化，而IP则不会 为什么有mac地址后，还要有IP地址 mac可以看做是一个人的身份证，IP可以看做是一个人的家庭地址","path":"2025/04/27/计网/IP/MAC地址和IP地址/","date":"04-27","excerpt":"","tags":[]},{"title":"如何解决业务幂等性","text":"幂等问题有两种 请求幂等：每次请求，如果参数一样，结果也要一样 业务幂等：同一次业务请求，推进到最终状态之后的每次请求，结果要保持一致。没推进到最终状态之前，每一次请求都要正常执行业务逻辑，直到推进到最终状态 一般来说我们保证的是业务幂等 口诀：一锁，二判，三更新 锁：锁建议用redis，毕竟它是高性能的互斥非阻塞锁。但锁也不是必须的，如果不是高并发的话，建议直接查，后面通过乐观锁来控制插入or更新 判：是否已经执行过了 更新","path":"2025/04/27/场景题/如何解决业务幂等性/","date":"04-27","excerpt":"","tags":[]},{"title":"ping的原理","text":"它的作用：用来检测两台设备之间是否可以建立连接 为什么ping不需要端口ping是基于IP层的协议实现，即应用层直接使用网络层协议的例子，而端口是传输层的东西，两者不相关，故不需要","path":"2025/04/26/计网/IP/ping的原理/","date":"04-26","excerpt":"","tags":[]},{"title":"浏览器输入网站后发生什么","text":"解析URL，确定好目标web服务器和请求目标的文件，并生成对应请求报文URL结构 请求报文结构和响应报文结构 进行DNS解析，拿到IP地址拿着IP地址，找到服务端，建立TCP连接协议栈？指南小助手。浏览器拿到IP地址后，这时候就可以把HTTP请求的传输工作交给操作系统的协议栈了。这个东西就是说上面的部分会去把任务委托给下面的部分，然后下面的部分就会去执行任务 IP还分为ARP协议 ICMP ARP协议：用来讲IP地址查询局域网中的MAC地址 ICMP协议 网卡驱动程序负责控制网卡，而网卡负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作 朝着IP地址，发送HTTP请求服务器处理请求，关闭TCP连接浏览器解析HTML浏览器渲染资源","path":"2025/04/26/计网/浏览器输入网站后发生什么/","date":"04-26","excerpt":"","tags":[]},{"title":"使用 TCP 的协议有哪些?使用 UDP 的协议有哪些?","text":"TCP：HTTP，HTTPS，SMTP，SSH(远程登录协议) UDP：DNS，DHCP（动态IP协议）","path":"2025/04/26/计网/TCP和UDP/使用 TCP 的协议有哪些!使用 UDP 的协议有哪些/","date":"04-26","excerpt":"","tags":[]},{"title":"常见状态码","text":"状态码： 1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。 「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。 「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。 3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。 「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。 「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。 5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。","path":"2025/04/26/计网/HTTP/常见状态码/","date":"04-26","excerpt":"","tags":[]},{"title":"TCP与UDP的不同之处","text":"TCP和UDP的主要区别在于连接性、可靠性和传输方式。 TCP是面向连接的，提供可靠的数据传输，适用于需要高可靠性的应用；而UDP是无连接的，传输速度快但不可靠，适用于实时性要求高的应用。 此外，TCP具有流量控制和拥塞控制机制，头部开销较大；UDP则没有这些控制机制，头部开销较小。 选择使用哪种协议取决于应用场景的具体需求。 TCP可靠的面向连接的传输方式，UDP不可靠的高效传输方式； 各自的应用之处： UDP和TCP各有其独特的特点和适用场景。 UDP是无连接的，传输速度快、延迟低，但不可靠，适用于对实时性要求高且可容忍少量丢包的应用，如视频会议、在线游戏、DNS查询和VoIP。 而TCP是面向连接的，提供可靠的数据传输，保证数据包的顺序和完整性，适用于对数据可靠性要求高的应用，如网页浏览、电子邮件传输、文件下载和数据库访问。 选择哪种协议主要取决于应用对实时性、可靠性和网络环境的特定需求。对实时性要求高且可以容忍丢包的场景，适合使用UDP。对数据完整性、顺序和可靠性要求高的场景，适合使用TCP 可靠TCP，其它UDP；","path":"2025/04/26/计网/TCP和UDP/TCP与UDP的不同之处/","date":"04-26","excerpt":"","tags":[]},{"title":"DNS","text":"是什么？域名解析服务，把域名解析为目标的IP 解析流程 一开始就会去看浏览器本地缓存是否有 没有就去本地host文件看看有没有 host文件没有的话才会去向本地DNS服务发请求 如果本都DNS服务器有缓存，就返回。没有就会去向根域的DNS服务器发请求，根域名服务器并不负责实际的域名解析，而是告诉本地DNS服务器应该去哪个顶级域的DNS服务器查询 顶级域的DNS服务器也不负责具体的域名解析，而是告诉本地DNS服务器可以去哪个权威DNS服务器查询 本地DNS服务器最后就会向权威DNS服务器发查询请求。权威DNS服务器就是负责将IP地址和域名进行映射存储的服务器，查到了就返回 DNS服务器把IP返回给浏览器后，并且会把查询结果缓存到本地，以便下次快速查询。","path":"2025/04/26/计网/HTTP/DNS/","date":"04-26","excerpt":"","tags":[]},{"title":"HTTPS是怎么建立连接的","text":"整个 HTTPS 的通信过程还是比较复杂的，粗略的来说，可以分成四步。 第一步是 DNS 解析，将域名转换成 IP。 第二步是建立 TCP 连接，也就是三次握手过程。 第三步是在 TCP 的基础上完成 TLS 握手过程。 第四步就是利用 TLS 握手过程交换的密钥进行通信，发送数据的加密，接收数据的解密。 这其中最复杂的就是 TLS 握手过程，具体来说， 首先是打招呼，客户端和服务端就 TLS 版本，加密算法和压缩算法达成一致，并且交换随机数。 其次，服务端发送证书，而客户端验证证书。 第三，客户端再次生成一个随机数 Pre-Master Secret，加密（用CA证书里的公钥）之后发送给服务端，服务端解密（用服务端自己的私钥）就能得到这个随机数。 第四，利用交换的随机数和 Pre-Master Secret，按照算法生成密钥，这个就是会话密钥，后续 HTTPS 数据传输就是用这个密钥。 最后完成握手，双方互相发送 Finished 结束握手过程。 简述一打招呼，二验证书，三换随机数，四生密钥，完成握手； 重点TLS握手过程； 引导DNS解析；三次握手过程 TLS为什么安全，效果更好 从上面的过程也能看出来，TLS握手的安全性源于其多重保障机制： 首先，通过密钥交换和随机数生成确保数据加密，防止窃听； 其次，利用数字证书和证书链验证服务器身份，杜绝中间人攻击； 第三，TLS 每个消息都有一个验证码（MAC），使用消息认证码保护消息完整性； 最后协议的分层设计和版本协商进一步提升安全性，有效抵御重放、时序等常见攻击。 因此虽然看上去 TLS 握手的前面打招呼和证书验证过程是明文传输，但是依靠着证书和三个随机数，还是能够保障很强的安全性 用CA证书里的公钥对 会话密钥进行加密 （非对称加密） 把加密后的 会话密钥发送给服务端，服务端用私钥进行解密 （非对称加密）","path":"2025/04/26/计网/HTTP/HTTPS是怎么建立连接的/","date":"04-26","excerpt":"","tags":[]},{"title":"HTTP基础","text":"状态码….. 常见的状态吗有很多，我列举几个： 200 代表 OK，服务器处理了请求。201 代表已接收，一般是异步接口返回，表达请求已经收到了，但是不一定处理好了。 301 代表永久重定向，302 代表临时重定向 400 是请求有问题，401 是未授权，403 是禁止访问。 500 是系统错误，503 是服务不可用，在触发了熔断的时候可以返回 503。 缓存 Http缓存分为两种，一种是那个强制缓存，一种是协商缓存 强制缓存指的是只要浏览器的缓存没过期，那就使用缓存，决定是否使用缓存的决定权在浏览器这边 浏览器第一次请求服务器的时候，服务器返回请求的同时会在请求头里塞Cache-control这个参数， 这个参数注明了缓存的过期时间 浏览器再次请求时，会先根据请求的时间和Cache-control 计算出缓存是否过期，如果没有就直接访问 本地缓存，如果过期就发请求 服务器收到请求后，会更新请求头里的Cache-control 协商缓存 就是通过服务端协商后，通过协商结果判断是否使用本地缓存 报文格式： HTTP请求报文由四部分组成： 第一部分是请求行，包含请求方法、URI和HTTP版本，如GET &#x2F;index.html HTTP&#x2F;1.1； 第二部分是请求头部，它包含一系列键值对，传递附加信息，如Host: example.com； 第三部分是空行，用来分隔头部和主体请求体； 第四部分是请求体，这一部分是可选的，通常用来传递请求的具体内容； 响应报文也是类似的。第一个部分是状态行，包含HTTP版本、状态码和状态消息，如HTTP&#x2F;1.1 200 OK。后续依次是响应头部、空行和响应体。 请求方式 GET 和 POST 是用得最多的两个方法。 GET 主要用来访问服务器上的资源，并不改变资源的状态。而 POST 则是主要用于向服务端提交数据，更新或者创建资源，但是 POST 可以不是幂等的。 除了这些，PUT 可以用来表达更新或者创建资源，但是操作应该是幂等的，大多数情况下是整体更新。PATCH 也是更新资源，但是一般是代表更新资源的一部分属性。DELETE 则是删除资源。 还有一个很特殊的 OPTIONS，一般是浏览器遇到跨域问题时候发送的预检（preflight）请求就是使用 OPTIONS 方法。 剩下的 HEAD，TRACE，CONNECT 方法就用得比较少了。 HTTP短连接，HTTP长连接 HTTP长连接和短连接主要区别在于TCP连接的持续时间和资源占用。长连接在一个TCP连接上可以发送多个HTTP请求和响应，通过Connection: keep-alive头部来维持连接，适用于频繁请求的场景，如加载多个资源的网页，减少了TCP握手的开销，提高了性能。 而短连接则在每次HTTP请求完成后立即关闭TCP连接，适用于简单查询或对资源占用敏感的场景，虽然每次请求都需要进行TCP握手，但资源释放快。 在 HTTP 1.1 以后就默认使用长连接了，如果没有遇到问题，就不要去修改这个配置。 简述长连接高性能，短连接释放快 HTTP&#x2F;TCP → 通信协议（规定如何传输数据）。 JSON&#x2F;Protobuf → 数据序列化协议（规定数据内容怎么编码）。","path":"2025/04/26/计网/HTTP/HTTP基础/","date":"04-26","excerpt":"","tags":[]},{"title":"cookie，session，Token","text":"他们都是用于管理用户状态和身份验证的技术。因为HTTP通信是无状态的，每次请求都是独立的。所以需要一种技术来存储用户的信息 cookie就是服务器向browser发的一小型文本，存在浏览器，用来存储用户信息。它会在下一次browser向服务器发请求时携带上，进行身份识别 sessionToken简单来说就是一字符串，用于用户的身份鉴权","path":"2025/04/26/计网/cookie，session，Token/","date":"04-26","excerpt":"","tags":[]},{"title":"SSL/TLS","text":"是什么？如何保证安全通信的 内容加密 身份验证：使用数字证书来验证通信双方的身份。但可以伪造证书 内容摘要算法，确保内容在传输过程中不会被篡改or损失 非对称和对称加密的区别对称：加密和解密都是用同一把密钥 非对称：加密和解密不用密钥，一般有公钥和私钥之分，公钥用于加密，私钥用于解密","path":"2025/04/26/计网/SSL!TLS/","date":"04-26","excerpt":"","tags":[]},{"title":"TCP网络拥塞","text":"详解在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大…… 所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。 于是，就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。 为了在「发送方」调节所要发送数据的量，定义了一个叫做「拥塞窗口」的概念。 拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。 我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd &#x3D; min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的较小值。 拥塞窗口 cwnd 变化的规则： 只要网络中没有出现拥塞，cwnd 就会增大； 但网络中出现了拥塞，cwnd 就减少； 只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了拥塞。 拥塞控制算法： 慢启动： 当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1（表示能发送1个MSS大小） 有一个叫慢启动门限 ssthresh （slow start threshold，65535字节）状态变量。 - 当 cwnd &lt; ssthresh 时，使用慢启动算法。 - 当 cwnd &gt;= ssthresh 时，就会使用「拥塞避免算法」。 拥塞避免算法： 每当收到一个 ACK 时，cwnd 增加 1&#x2F;cwnd。 拥塞发生： 当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种： - 超时重传，一直没收到ACK，从丢失的ACK开始超时重传 - 快速重传，收到三个相同的ACK，表明某个包丢失了，快速重传丢失的包 - 当发生了「超时重传」，则就会使用拥塞发生算法 这个时候，ssthresh 和 cwnd 的值会发生变化： * ssthresh 设为 cwnd/2， * cwnd 重置为 1（假设为1，其实是恢复为 cwnd 初始化值，默认初始值为10） 接着，就重新开始慢启动 这种方案会导致如果只丢了一个包，却要立马刹车减速回到解放前， 重新慢启动 - 当发生了「快速重传」，TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 ssthresh 和 cwnd 变化如下： * cwnd = cwnd/2 ，也就是设置为原来的一半; * ssthresh = cwnd; * 进入快速恢复算法 * 即慢启动门限和拥塞窗口都变为拥塞窗口的一半 快速恢复： 快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。算法如下： - 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了），之前设置为ssthresh = cwnd，所以其实这里就是设为cwnd = cwnd/2 + 3;如下图为12变成9 - 重传丢失的数据包； - 如果再收到重复的 ACK，那么 cwnd 增加 1； - 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh （cwnd / 2）的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态； 为什么收到新数据后cwnd变为ssthresh？ 首先，快速恢复是拥塞发生后慢启动的优化，其首要目的仍然是降低 cwnd 来减缓拥塞，所以必然会出现 cwnd 从大到小的改变。 其次，cwnd逐渐加1的存在是为了尽快将丢失的数据包发给目标，从而解决拥塞的根本问题（三次相同的 ACK 导致的快速重传），所以这一过程中 cwnd 反而是逐渐增大的。 面试快答 TCP的拥塞控制主要通过慢启动、拥塞避免、快速重传和快速恢复等机制来运作。 初始阶段，TCP使用慢启动算法，每次收到一个 ACK，窗口大小就翻倍，这个阶段窗口是指数增长。 当拥塞窗口达到慢启动阈值后，进入拥塞避免阶段，此时窗口是线性增长。 如果检测到数据包丢失（通过超时或重复ACK），TCP会启动快速重传机制，立即重传丢失的数据包。 并且窗口会调整为原本窗口的 1&#x2F;2，也就是快开始。 而后进入快速恢复（快开始）阶段，保持窗口线性增长。 这些机制共同作用，确保了TCP在避免网络拥塞的同时，提供稳定可靠的数据传输。 简述慢启动指数增长，拥塞避免线性增长，快速重传窗口减半，快速恢复线性增长；","path":"2025/04/26/计网/TCP和UDP/TCP网络拥塞/","date":"04-26","excerpt":"","tags":[]},{"title":"TCP流量控制","text":"TCP滑动窗口TCP的滑动窗口机制是用于控制数据传输流量和保证数据可靠性的重要机制。它通过动态调整窗口大小，来管理发送方和接收方之间的数据传输。 首先，在 TCP 的发送方和接收方各有一个窗口。并且因为 TCP 是一个全双工通信的协议，所以大多数时候，客户端和服务端都是既有接收窗口，又有发送窗口。 发送窗口整体分为三个部分： 在整个窗口左边的，就是已经发送并且 ACK 的报文。比如说上图中编号小于 100 的报文； 滑动窗口内的报文，又可以分成三部分： 已经收到 ACK 的报文，例如说 101 和 102； 已经发送但是没收到 ACK 的报文，比如说 100， 103 和 104； 还没发送的报文，也就是 105，106 和 107； 在整个窗口右边的，窗口还没滑过去，所以暂时它们不可能被发送，在上图是编号大于 107 的报文； 进一步看，这里有一个细节，就是虽然 100 编号比较小，但是它的 ACK 反而有可能比 101 和 102 后收到。假设说现在收到了 100 的 ACK，那么这时候窗口就要开始滑动了。滑动的距离就是从窗口的左边开始出发，直到遇到第一个还没收到 ACK 的报文，在这里就是 103。 接受窗口而接收窗口，也是类似的： 可以看到，在接收窗口也遇到不连续的问题，比如说先收到了 104。 显然，一旦接收方收到了 100 之后，它的窗口也会开始移动，移动的逻辑是类似的，找到最小的没有收到的报文。如下图。但是要注意到，因为 100 之后的 101 和 102 都收到了，所以实际上它可以直接 ACK 102。 因此你基本上可以想到整个工作流程： 初始化：连接建立时，双方协商初始窗口大小。协商是发生在 TCP 三次握手的第一次握手中。 发送数据：发送方根据窗口大小发送数据包，并等待接收方的确认。 接收确认：接收方收到数据包后，发送ACK确认，并更新接收窗口。 滑动窗口：发送方收到ACK后，滑动窗口向前移动，允许发送新的数据包。 动态调整：根据网络状况和接收方的处理能力，窗口大小可以动态调整。 动态调整窗口（最难）这里的难点就是动态调整的策略。 就接收方来说，它主要是考虑自己的缓冲区。如果要是还有很多空闲缓冲区，那么接收方就可以增大自己的窗口，并且在发给发送方的报文里面带上新的窗口大小。反之则是减小窗口。最极端的情况下，接收方会返回零缓冲区，也就是提醒发送方不要再发了，自己已经没有空闲缓冲区可用了。 而发送方主要是受到两方面的影响。 一方面是受到 TCP 协议内部的慢开始、拥塞避免、快开始、快重传和快恢复策略的影响。另外一方面则是还会受到接收方窗口大小的影响。","path":"2025/04/26/计网/TCP和UDP/TCP流量控制/","date":"04-26","excerpt":"","tags":[]},{"title":"多线程事务解决方案","text":"@Transtional 的实现原理 创建了个了代理对象，然后它就会帮我们创建事务，然后执行方法，最后提交事务，方法报错就可能回滚事务 涉及到事务嵌套场景，默认的事务传播机制为 外层有事务就沿用外层的事务，没有内层就新建事务 而事务是基于JDBC的connection来实现的，当创建事务时，会把connection放到ThreadLocal里。然后内层方法就会去从ThreadLocal拿到connection对象，实现对事务的控制 但由于ThreadLocal每个线程都是独立，那么@ Transitional 在多线程情况下就会失效了。 而我们要解决这个，无法就是解决线程之间connection无法传递的问题。 TransactionSynchronizationManager+方法加注解 @Transactional 缺点就是 事务粒度太大了 123456ConnectionHolder connectionHolder=(ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource); 2PC 成绩分析引入多线程后 事务问题的最终解决方案： 分析内容表脏了没关系，在分析总记录表中加一个字段为status：0表示进行中，1表示已完成 如果分析过程中出错了，那分析记录状态就会一直为0，进行中是不能被查看的，只有已完成的分析才能被查 看。后续会开一个定时任务每天 凌晨 根据分析记录时间和状态去把脏数据清空，即把前天的脏数据清空 类似于事务的两阶段提交","path":"2025/04/26/项目/AI学生发展性评价系统/多线程事务解决方案/","date":"04-26","excerpt":"","tags":[]},{"title":"HTTP各个版本之间的变化","text":"1.0和1.1HTTP&#x2F;1.1相比HTTP&#x2F;1.0带来了多项改进： 首先，HTTP&#x2F;1.1默认启用长连接，减少了TCP握手的开销，这对于频繁交互的应用尤其重要。 其次，在缓存控制方面，HTTP&#x2F;1.1提供了更精细的Cache-Control头部，使得缓存管理更加灵活。 第三 HTTP&#x2F;1.1 通过引入Host头部，支持虚拟主机，这使得多个网站可以共享同一服务器资源，降低了成本。 第四在错误处理方面，HTTP&#x2F;1.1引入了更详细的错误状态码和描述，便于开发者定位和解决问题。 这些改进使得HTTP&#x2F;1.1 的网络通信得到了极大的提升。 但是 HTTP 1.1 虽然有了很多改进，但是这并不是终点，因为 HTTP 1.1 依旧有很多缺点。 最显著的缺点就是请求阻塞，也就是当一个请求在等待服务器响应时，后续请求必须等待，即使它们与前面的请求无关。这导致了队头阻塞，降低了性能。 此外还有头部数据量太大，高并发下长连接容易成为性能瓶颈，并且 HTTP 1.1 是明文传输，不支持服务端主动发送数据等缺点。 所以在后续又引入了 HTTP 2.0，而 HTTP 2.0 则是进一步引入了多路复用，头部压缩 和服务器推送等功能，解决了 HTTP 1.1 的缺点。 1.1和2HTTP&#x2F;2.0相比HTTP&#x2F;1.1带来了多项性能优化和效率提升。 首先，HTTP&#x2F;2.0支持多路复用，允许在单个连接中同时发送多个请求和响应，解决了HTTP&#x2F;1.1中的队头阻塞问题。 其次，HTTP&#x2F;2.0使用HPACK算法压缩请求和响应的头部，减少了冗余数据，提高了传输效率。 第三，HTTP&#x2F;2.0引入了二进制分帧层，将HTTP消息分解为独立的帧，提高了数据传输的效率和解析速度。 第四，HTTP&#x2F;2.0还允许服务器主动向客户端推送资源，减少了客户端需要发送的请求数量，提高了页面加载速度。 最后，HTTP&#x2F;2.0要求使用TLS进行加密传输，增强了安全性，防止了中间人攻击。 这些改进使得HTTP&#x2F;2.0成为现代网络应用的首选协议。 HTTP&#x2F;2.0虽大幅提升了性能，但仍存在依赖TCP导致的建连延迟和队头阻塞问题，且头部压缩复杂、明文传输风险未根除。 而HTTP&#x2F;3.0基于QUIC协议，运行在UDP上，实现更快的建连和彻底解决队头阻塞，采用更高效的QPACK头部压缩，并强制TLS加密，全面提升了传输效率和安全性。 2和3HTTP&#x2F;2.0 和 HTTP&#x2F;3.0 的区别，主要集中在底层协议、并行传输能力、握手效率、头部压缩、网络适应性等层面。 HTTP&#x2F;2.0 是基于 TCP 的，一旦某个数据包丢失就必须等重传，这会造成整个连接里的所有数据流都被阻塞，也就是所谓的队头阻塞问题。HTTP&#x2F;3.0 用的是基于 UDP 的 QUIC 协议，可以把每个数据流都独立分配 ID，只要某个流丢包，就只重传那个流，不会拖慢其它流，这在高丢包或弱网环境下会表现得更好。 HTTP&#x2F;2.0 需要先完成 TCP 三次握手，然后再进行 TLS 握手，如果要恢复会话，也会多一次 RTT。而 QUIC 把传输层和加密层放在一起，相当于只需要一次握手就能建立安全连接，比 HTTP&#x2F;2.0 快了大约一半。更进一步，QUIC 还支持 0-RTT 恢复，如果客户端保存过相关密钥信息，重连时几乎可以立刻发送数据，尤其在网络波动或需要频繁断网重连的场景下非常有效。不过，要注意 0-RTT 可能带来重放攻击风险，服务端通常要配合额外的安全逻辑做校验。 HTTP&#x2F;2.0 使用 HPACK 来压缩头部，但它依赖顺序传输，对网络乱序的容忍度不高。而 HTTP&#x2F;3.0 则是用 QPACK，在无序或丢包的条件下也能更好地解码头部，减少了因为乱序导致的性能损耗。 得益于QUIC使得HTTP&#x2F;3.0在网络适应性上也更突出，它通过 Connection ID 来标识连接，这意味着用户从 Wi-Fi 切到蜂窝网络时，只要保持同一个 Connection ID，连接就能平滑迁移，不用重新握手下载证书。移动端在遇到丢包高或延迟大的情况时，QUIC 的拥塞控制也能更适配弱网环境，实现更流畅的体验。 总而言之，HTTP&#x2F;3.0 的确代表了未来的发展趋势，但如何在实际项目里落地，依然要根据网络环境和服务端能力做通盘考虑。如果是固定网络而且丢包率不高，现有的 HTTP&#x2F;2.0 完全能满足需求。如果业务对实时性要求很高，用户网络情况又比较复杂，比如移动端场景、大规模跨区访问或者弱网环境，HTTP&#x2F;3.0 可以显著改善访问体验。不过在企业内网或对兼容性要求极高的场合，最好采用双协议或者逐步升级的方案，避免因为 UDP 流量受限或中间设备不兼容而导致服务不可用。 http和httpsHTTP与HTTPS的主要区别在于安全性和数据传输的可靠性。 HTTP使用明文传输数据，容易受到中间人攻击，数据可能被窃听或篡改。而HTTPS在HTTP基础上增加了TLS协议，对数据进行加密传输，确保了数据的安全性和完整性，需要使用数字证书来验证服务器身份 虽然HTTPS的加密和解密过程会增加一定的延迟，但现代硬件和优化技术已大幅减少了这种影响。此外，HTTPS有助于提高搜索引擎排名，浏览器显示安全锁标志，增强用户信任。 在实际应用中，尤其是在处理敏感信息如登录凭据、支付信息的场景下，HTTPS是必不可少的。通过使用HTTP&#x2F;2.0和优化TLS配置，可以进一步减少性能开销。 随着互联网安全重要性的提升，HTTPS已成为现代网络应用的标配。 简述安全，安全，还是 TMD 安全；1 HTTPS相比HTTP，在通信步骤中显著增加了TLS握手、证书验证和密钥交换等关键步骤。 具体而言，HTTPS在建立TCP连接后，首先进行TLS握手，客户端发送支持的TLS版本、加密方法和随机数，服务器回应并附上服务器证书； 接着，客户端验证证书合法性，确保通信对方可信； 随后，双方协商生成会话密钥，用于后续数据的加密传输。 这些额外步骤不仅确保了数据的安全性和完整性，还验证了通信双方的身份，显著提升了安全性。","path":"2025/04/25/计网/HTTP/HTTP各个版本之间的变化/","date":"04-25","excerpt":"","tags":[]},{"title":"OSI,TCP/IP","text":"OSI七层模型 TCP&#x2F;IP 应用层： 我们常见的应用就是在应用层，应用层也有应用层协议，如HTTP、DNS、FTP、Telent、SMTP等 应用层不关注数据如何传输，直接把数据的传输交给下一层，即交给传输层，应用层工作于用户态，传输层及以下工作于内核态 为计算机用户服务。应用层工作都是用户态，而传输层及以下的工作则涉及到了内核态 传输层： 为应用层提供网络通信支持，但不涉及网络传输，分为 TCP 和 UDP 两个协议 应用层会把数据包传输给传输层，故传输层是给应用层提高网络支持的，注意不是支持两台设备之间的网络传输。两个重要协议，TCP（传输通知协议），UDP（基于报文传输协议）。因为应用层传过来的数据可能比较大，如果直接传不太好，如果超过MSS（TCP最大报文段长度）就会进行分段。TCP段里包含端口，用于标明传输给应用层哪个应用，接受方的端口是我们指定的，而客户端是随机分配的 网络层： 负责网络包的封装、分片、路由、转发，如IP、ICMP 负责两设备之间的网络传输。最常用的协议就是IP协议，负责寻址，告诉数据包应该往哪里走，而 网络接口层： 负责网络包在物理网络中的传输，比如网络包的封帧、MAC寻址、差错检验等 真正的物理层次传输数据 为网络层提供[链路级别]的传输，负责在WIFI，以太网这样的底层网络上发送原始数据包。 MAC地址为在以太网中寻址提供基础 每层对数据的封装 为什么要分层 各层相互独立，只关心本层的问题，比如 我们的MVC三层架构 高内聚低耦合 功能分解，大问题化为小问题","path":"2025/04/25/计网/网络模型/OSI,TCP!IP/","date":"04-25","excerpt":"","tags":[]},{"title":"bufferpool？","text":"Bufferpool是什么？就是MySQL在启动时向操作系统申请的一片连续的内存空间，用来提升数据库的读写性能，里面存的是一 页一页的数据。 默认大小为128mb，可以通过&lt;font style=&quot;color:rgb(71, 101, 130);&quot;&gt;innodb_buffer_pool_size&lt;/font&gt; 设置，一般建议设置为物理内存的60-70% buffer pool缓存的什么 每个缓存页还会由一个控制块来管理 如何管理buffer poolBufferpool和query cache的区别 Bufferpool是InnoDB特有的，而query Cache是server层的 目的不同，Buffer pool主要是用来缓存表和索引的数据页，从而加速读取操作；而query Cache用于缓存查询结果，减少重复查询的执行时间的 Bufferpool的读写过程读：比较简单，bufferpool里有返回，没有就去磁盘里拉取 写：直接写bufferpool，刷盘是由后台线程来执行的。异步刷新策略 bufferpool里的脏页数据什么时候刷到磁盘里为什么mysql全表扫描时不会污染Bufferpool","path":"2025/04/25/MySQL/bufferpool？/","date":"04-25","excerpt":"","tags":[]},{"title":"Spring循环依赖问题","text":"解决思想 提供一个另外思考的视角，Spring 解决循环依赖的做法是 【图论环检测】 的经典实践。 依赖关系可以表示为一个有向图，Cat -&gt; Dog -&gt; Cat 的依赖关系可以表示为一个【有向图】 ，Bean是怕【顶点】， 依赖关系是【边】。Spring在createBean时会递归构建依赖图 （深度优先遍历DFS) , 如果发现当前路径中某个Bean正在创建中（即存在“正在创建”的顶点被重复访问），则判定存在环 【环检测】 。简化做法是采用二级缓存来获取 Cat 的引用 【在图中引入一个虚拟顶点】， 将环拆解为链式依赖 ，从而避免了无限递归。当所有依赖注入完成，再将真实顶点替换虚拟顶点。故视频中的loadingIoc缓存是用于存放虚拟顶点进行环检测的集合容器，ioc是存放真实顶点的集合容器。 Spring的落地实践解决循环依赖Spring中存在三层缓存，就对于单例对象来说 第一层缓存：单例对象缓存池，已经实例化并且属性赋值，这里的对象是成熟对象 第二层缓存：单例对象缓存池，已经实例化但还没进行属性set，这里的对象是半成品对象 第三层缓存：单例工厂的缓存，里面存放的是工厂对象，实际上是一串lambda表达式，每个工厂都可以创建对应的bean，eg：private Map&lt;String, Supplier&gt; singletonFactories &#x3D; new HashMap&lt;&gt;(); Spring生成Bean的流程 假设A和B 发生了循环依赖 起点：先初始化A 先往creatingSet集合（一个set集合，用于存放正在被创建的bean，便于后续判断是否发生了循环依赖）里放入A 一级缓存找不到A，那么就通过无参构造化实例化A，将和A有关的一串lambda表达式放入三级缓存（此时A的实例化和属性注入就已经分离开了），set属性注入 B creatingSet里找不到B，此时还不知道出现了循环依赖，就去一级缓存找B，找不到，就往creatingSet里找B。通过无参构造实例化B，将和B有关的一串lambda表达式放入三级缓存，进行set属性注入A 通过creatingSet发现了A，就知道发生了循环依赖，然后这时候就会去二级缓存寻找，没找到，去三级缓存找，找到有关A的lambda表达式，执行lambda 如果A需要被AOP，则此时提前对其进行AOP（正常的bean周期应该是初始化后才AOP的），将AOP的代理对象放入二级缓存，并从三级缓存中删除（这样能保证你AOP出来的代理对象是单例的，也就是说你这个lambda表达式是一次性的，同时是会加锁的保证线程安全），并将代理对象放入earlyProxyReference（用于存储哪些对象提前AOP了，后续有用） 如果A不需要AOP，则生成A的普通对象并放入二级缓存，并从三级缓存中删除 OK此时B是已经拿到对象A了（可能是proxy的，也可能是普通的）进行set注入，进行B的其他Bean的声明周期，当Bean成熟之后放入一级缓存，移除二、三级缓存（实际上此时二级缓存中没有B，三级缓存中有B） 此时返回A的初始化过程，A就拿到了B的成熟对象，set注入A中。然后进行A的其他Bean的声明周期 A的其他生命周期包括AOP（是在BeanPostProcessor的after方法执行的），但这时候A可能在lambda表达式那里就提前AOP了，这就需要通过earlyProxyReference判断A是否提前AOP了，即A存不存在。防止重复AOP 将成熟的A放入1缓存，同时删除2,3缓存（实际此时三级缓存已经没有A了，在第4步已经被移除了） 如果A和B发生了循环依赖，然后发现A和C又发生了循环依赖 A和B走完流程要注入C，此时二级缓存其实是有A了，C就直接从二级缓存里拿A set就好了，重复A和B的流 程 各级缓存的作用： 一级缓存就是用来保存Bean单例的，也就是我们getBean的源头 二级缓存用来保证Bean是单例的。因为你三级缓存lambda是一次性消耗品，因此只会生成一份Bean。那么这个生成的半成品Bean就先放入二级缓存。用于存放提前曝光的不成熟的bean 三级缓存则是用来打破循环依赖并出现AOP的情况下的循环依赖的。当发生循环依赖时，可以保证你一定是能从三级缓存获取到Bean的（因为三级缓存都是会在Bean实例化同时存入lambda表达式的）。通过三级缓存，我们可以生成半成品的普通Bean或者proxybean。然后再放入二级缓存，然后把三级缓存删掉，这样能保证Bean是单例的 一级缓存能解决循环依赖吗？ 可以解决普通的循环依赖。但把半成品和完全品都放入一个集合里不是很优雅。AOP的循环依赖没法解决 可不可以使用一、二级缓存解决循环依赖？ 可以，但这样如果出现AOP的话，在对象实例化时就要完成AOP代理，生成代理对象，再进行属性注入，即先创建代理对象，再对代理对象进行属性注入，这与Spring设计理念中“将Bean的初始化和代理解耦”是不符的 那么就可以通过三级缓存中的lambda判断，只有当出现AOP + 循环依赖的时候，才提前创建代理对象，然后进行依赖注入初始化，否则创建普通对象，走正常的Bean生命周期 可不可以使用一、三级缓存解决循环依赖？ 不可以。因为你用三级缓存这套东西的话就说明你的bean是单例的，也就是每次产出半成品都会删除。那这 样的话，你每次都会重新去放入lambda表达式，每次出来的半成品都不是同一个。当出现A与B发生循环依 赖，A与C也发生循环依赖的这种情况，B中的A和C中的A就不是同一个了。必须让三级缓存是单例的，且半 成品对象必须得找个地方存，这个地方就是二级缓存 Spring如何解决循环依赖？ creatingSet（判断是否存在循环依赖）+三级缓存（解决循环依赖问题）+ earlyProxyReference（防止解决循环依赖的过程中重复AOP） 哪些循环依赖默认情况下无法解决？ 构造注入下的循环依赖，因为构造注入是要求强制注入的 123456789101112131415@Componentclass A &#123; private final B b; @Autowired A(B b) &#123; // 构造器注入 this.b = b; &#125;&#125;如果没有 B，A a = new A(null); 都过不去（final 成员必须赋值）。👉 在 对象创建的一瞬间 就要保证依赖存在。没有任何缓冲空间，所以是 强制注入。 两个都是多例对象，因为多例对象根本就没三级缓存这一说，每次getbean都会执行一次构造方法并给属性赋值 其它循环依赖如何解决： @Lazy：","path":"2025/04/25/Spring/Spring循环依赖问题/","date":"04-25","excerpt":"","tags":[]},{"title":"Spring三级缓存","text":"","path":"2025/04/25/Spring/Spring三级缓存/","date":"04-25","excerpt":"","tags":[]},{"title":"如何理解AOP","text":"是什么AOP即面向切面编程，是一种思想，是对OOP的补充。简单的来说就是把公共的逻辑抽离出来， 让开发者可以跟关注于业务逻辑的开发 说简单点AOP就是 在不惊动原有的代码的基础上对功能进行增强操作 概念： 连接点：JIONPoint，可以被AOP控制的方法（运行时刻被拦截到的方法） 通知：advice 增强，切面的具体行为 切入点：决定在哪些方法上生效 切面：描述切入点和通知的关系 通知类型： @Before @After @AfterReturning @AfterThrowing 在抛错之后 @Aroud 环绕通知：在目标方法执行之前和之后都能插入逻辑，甚至可以决定是否执行目标方法。 总结： AOP的底层实现方法一共有三种吧，常见的像代理，还有AspectJ框架提供的两种方法 第一种就是AJC增强，它就是指AJC编译器在编译过程中把通知的增强功能植入目标类的Class文件中 来达到增强的效果，然后它的执行时机就是通知类上有Aspect注解，不需要component注解，该通知类 就没有被Spring所管理。所有AOP的执行底层是通过AJC去修改Class文件，而不是动态代理，这时候没有 Spring容器也可以进行aop增强，但需要用到maven一个插件，这种方式用得很少 第二宗就是通过agent底层来实现aop，它是agent编译器在加载目标类的时候，因为是在加载类的时候么， Class文件已经编译完了，它就在加载目标类的时候修改对应的Class文件，达到增强的功能。它的执行时机 跟AJC编译差不多的，也是通知类上有Aspect注解，不需要component注解。区别就是给JVM加一个参数 - javaagent，后面指定maven目录下的一个jar包路径 第三种就是我们常用的代理增强了。代理的本质就是生成一个代理对象，类似于房东和中介的，中介就是代理 这个代理对象和切入点有着相同的方法，然后代理对象的方法就是根据需求增强过的，然后调用切入点的方法 不走它的方法，而是走代理对象在增强过的方法。而怎么保证代理对象和切入点有着相同的方法呢，这就分为 两派，一种是jdk代理，一种是cglib代理。 jdk代理是Java自带的代理，主要是采用了多态和反射的方式。它是代理对象和目标类实现同一个接口，就可 以保证两者都有同样的方法 jdk代理通过Proxy.newProxyInstance()获取到代理对象 newProxyInstance方法的三个参数： 第一个参数，类加载器 第二个参数，接口集合，因为jdk代理需要目标对象实现接口 第三个参数，一个函数式接口，实现增强方法逻辑，这个函数式接口也有三个参数： 第一个参数，目标对象 第二个参数，需要被增强的方法 第三个参数，方法执行的参数 proxy.newProxyInstance()方法底层会根据传入的接口集合，在运行时在本类目录下生成一个$proxy0类 实现这些方法，然后里面的所有方法都会被InvocationHandler方法给拦截下来进行增强（包括equals和hashcode） 123456789101112131415161718192021222324252627282930public final class $Proxy0 extends Proxy implements Test &#123; private static Method m1; private static Method m2; private static Method m3; // $Proxy0 类的构造方法 // 参数为 invocationHandler public $Proxy0(InvocationHandler invocationHandler) &#123; super(invocationHandler); &#125; static &#123; m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, Class.forName(&quot;java.lang.Object&quot;)); m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;, new Class[0]); m3 = Class.forName(&quot;com.xxx.Test&quot;).getMethod(&quot;test&quot;, new Class[0]); &#125; public final void test() &#123; this.h.invoke(this, m3, null); return; &#125; public final int hashCode() &#123; return this.h.invoke(this, m2, null); &#125; public final boolean equals(Object o) &#123; return this.h.invoke(this, m1, new Object[]&#123;o&#125;); &#125; &#125; cglib代理不是jdk自带的代理，需要导外部依赖，其底层是让代理类继承目标类，通过Enhancer.create获取代理对象 create方法的两个参数： 第一个参数：目标类 第二个参数：一个函数式接口，实现增强方法逻辑，这个函数式接口有四个参数： 第一个参数，代理对象自己 第二个参数，需要被增强的方法 第三个参数，方法执行的参数 第四个参数，MethodProxy，代理不走反射的关键 其实AOP的重点是如何获取目标类的原始方法，并把它放到特定的上下文环境下执行 对于这一点，jdk代理采用的是反射，你看，我都采用反射了，我还拿不到你原始方法吗 而cglib采用的就是继承，我都继承了，我肯定能通过super.xx拿到你的原始方法 还有就是，代理模式则是在运行期生成新的字节码。AspectJ对代码的侵入性很强，因此没有怎么流行 但因为它是在编译器和类加载期修改字节码，故性能较高。且能突破代理只能重写方法来实现增强的限 制，如能增强构造方法，静态方法，final修饰的方法 Spring的AOP是怎么实现的Spring的AOP是采用动态代理实现的 至于是jdk还是cglib，Spring容器代理时，会有一个proxyBean类，这个类会传入目标对象和通知 ，然后这个类还有一个boolean proxyTargetClass，如果设置为false，那就会去检查目标类是否实现了 接口，有就用jdk，无就用cglib。如果为true，那就直接用cglib 一个方法被多个切面AOP了？需要给切面标明@Order（x）x越小，说明你那个优先级越高。 如果无标明，那就会按注册的顺序来执行，但此时是随机的，不可知的 因为 Spring AOP 内部会把所有的切面包装成 Advisor，然后放到一个集合里。虽然这个集合是个List，但 虽然用的是 ArrayList（顺序表），但插入顺序本身没保证稳定，因为： - 不同 BeanFactory 扫描/注册 Bean 的顺序可能不同。 - 不同 JDK、不同文件系统，class 扫描顺序也可能不同。 - 所以“默认顺序”没有规范，才会被说成是 **不可知的**。 123456789101112131415161718192021@Aspect@Componentpublic class LogAspect &#123; @Before(&quot;execution(* com.example.service.*.*(..))&quot;) public void before() &#123; System.out.println(&quot;LogAspect before&quot;); &#125;&#125;@Aspect@Componentpublic class SecurityAspect &#123; @Before(&quot;execution(* com.example.service.*.*(..))&quot;) public void before() &#123; System.out.println(&quot;SecurityAspect before&quot;); &#125;&#125;//执行顺序不一定的 AOP失效？当然这只限于代理类的 类中自调用方法，同一个类中A调用B方法，B方法的AOP不会生效 调用内部类方法 调用静态方法，静态方法不会被AOP 调用final方法，final方法不会被AOP 目标类不符合规则，如jdk代理时没继承接口，cglib代理时是final类 cglib 和jdk代理哪个快 在 JDK1.6、JDK1.7、JDK1.8 逐步对 JDK 动态代理优化之后，在调用次数较少的情况下，JDK 代理效率高于 CGLib 代理效率，只有当进行大量调用的时候，JDK1.6 和 JDK1.7 比 CGLib 代理效率低一点，但是到 JDK1.8 的时候，JDK 代理效率高于 CGLib 代理。所以如果有接口使用 JDK 动态代理，如果没有接口使用 CGLIB 代理。","path":"2025/04/25/Spring/如何理解AOP/","date":"04-25","excerpt":"","tags":[]},{"title":"如何理解IOC","text":"Spring容器启动流程：https://javadoop.com/post/spring-ioc 控制反转，即将我们的对象控制权交给容器 ioc 的启动流程 12345678910init阶段：scanPackage -&gt; scanCreate（判断是否加了@component注解） -&gt; wrapper 成 beanDefinnation（name） create所有非Lazy的 bean阶段：这时候涉及为一二级缓存：1级存放所有初始化好的bean，而2级存放所有半初始化好的bean 即创建好但依赖的组件没注入的bean通过反射 构造方法去create Bean执行一些加载前的执行一些加载后的 手写IOC123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160package com.lkl;import java.io.File;import java.io.IOException;import java.lang.reflect.Constructor;import java.lang.reflect.Field;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import java.net.URI;import java.net.URL;import java.nio.file.*;import java.nio.file.attribute.BasicFileAttributes;import java.util.*;import java.util.stream.Collectors;/** * @author: lkl * @date: 2025/4/6 21:03 */public class ApplicationContext &#123; public ApplicationContext(String packageName) throws Exception &#123; initContext(packageName); &#125; //一级缓存：存放完全初始化的bean private HashMap&lt;String,Object&gt; ioc=new HashMap&lt;&gt;(); //二级缓存：存放还没初始化好的bean,但已经实例化了 private HashMap&lt;String,Object&gt; loadingIoc=new HashMap&lt;&gt;(); private HashMap&lt;String,BeanDefinition&gt; beanDefinitionHashMap=new HashMap&lt;&gt;(); protected Object createBean(BeanDefinition beanDefinition) &#123; String beanName = beanDefinition.getName(); if (ioc.containsKey(beanName))&#123; return ioc.get(beanName); &#125; if (loadingIoc.containsKey(beanName))&#123; return loadingIoc.get(beanName); &#125; //一,二级缓存没有的话，才会去创建bean return doCreateBean(beanDefinition); &#125; private Object doCreateBean(BeanDefinition beanDefinition) &#123; String name = beanDefinition.getName(); Constructor&lt;?&gt; constructor = beanDefinition.getConstructor(); //先默认是无参的 Object bean = null; try &#123; bean = constructor.newInstance(); loadingIoc.put(name,bean); //postProcess //依赖注入 autowiredBean(bean,beanDefinition); //afterProcess //执行postConstructMethod Method postConstructMethod = beanDefinition.getPostConstructMethod(); if (postConstructMethod!=null) &#123; postConstructMethod.invoke(bean); &#125; &#125; catch (InstantiationException | IllegalAccessException | InvocationTargetException e) &#123; throw new RuntimeException(e); &#125; ioc.put(name,loadingIoc.remove(name)); return bean; &#125; private void autowiredBean(Object bean, BeanDefinition beanDefinition) throws IllegalAccessException &#123; for (Field filed : beanDefinition.getAutowiredFields()) &#123; //通过类型 也可以通过名字 filed.setAccessible(true); filed.set(bean,getBean(filed.getType())); &#125; &#125; protected BeanDefinition wrapper(Class&lt;?&gt; type) &#123; BeanDefinition beanDefinition = new BeanDefinition(type); if (beanDefinitionHashMap.containsKey(beanDefinition.getName()))&#123; throw new RuntimeException(&quot;bean name重复----------&quot;); &#125; beanDefinitionHashMap.put(beanDefinition.getName(),beanDefinition); return beanDefinition; &#125; protected void initContext(String packageName) throws Exception &#123; //先把所有的BeanDefinition加载 scanPackage(packageName).stream() .filter(this::scanCreate) .forEach(this::wrapper); //再加载bean beanDefinitionHashMap.values() .forEach(this::createBean); &#125; protected boolean scanCreate(Class&lt;?&gt; type)&#123; return type.isAnnotationPresent(Component.class); &#125; //扫包遍历 private List&lt;Class&lt;?&gt;&gt; scanPackage(String packageName) throws Exception &#123; System.out.println(&quot;start scan package -------------&quot;); URL resource = this.getClass().getClassLoader().getResource(packageName.replace(&quot;.&quot;, File.separator)); Path path = Paths.get(resource.toURI()); List&lt;Class&lt;?&gt;&gt; classList=new ArrayList&lt;&gt;(); Files.walkFileTree(path, new SimpleFileVisitor&lt;&gt;() &#123; @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; Path absolutePath = file.toAbsolutePath(); if (absolutePath.toString().endsWith(&quot;.class&quot;)) &#123; String replaceStr = absolutePath.toString().replace(File.separator, &quot;.&quot;); String className = replaceStr.substring(replaceStr.indexOf(packageName), replaceStr.length()-&quot;.class&quot;.length()); try &#123; classList.add(Class.forName(className)); &#125; catch (ClassNotFoundException e) &#123; throw new RuntimeException(e); &#125; //System.out.println(className); &#125; return FileVisitResult.CONTINUE; &#125; &#125;); return classList; &#125; //根据名字返回bean public Object getBean(String name) &#123; if (name==null) &#123; return null; &#125; Object bean = this.ioc.get(name); if (bean!=null) &#123; return bean; &#125; if (beanDefinitionHashMap.containsKey(name))&#123; return createBean(beanDefinitionHashMap.get(name)); &#125; return null; &#125; //返回类型相同的bean public &lt;T&gt; T getBean(Class&lt;T&gt; beanType) &#123; String beanName = beanDefinitionHashMap.values().stream() .filter(a -&gt; beanType.isAssignableFrom(a.getType())) .map(BeanDefinition::getName) .findFirst() .orElse(null); return (T)getBean(beanName); &#125; public &lt;T&gt; List&lt;T&gt; getBeans(Class&lt;T&gt; beanType) &#123; return beanDefinitionHashMap.values().stream() .filter(a -&gt; beanType.isAssignableFrom(a.getType())) .map(BeanDefinition::getName) .map(this::getBean) .map(bean-&gt;(T)bean) .collect(Collectors.toList()); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.lkl;import com.lkl.sub.AutoWired;import com.lkl.sub.PostConstruct;import java.lang.reflect.Constructor;import java.lang.reflect.Field;import java.lang.reflect.Method;import java.util.Arrays;import java.util.List;import java.util.*;import java.util.stream.Collectors;/** * @author: lkl * @date: 2025/4/6 21:21 */public class BeanDefinition &#123; private final String name; private final Constructor&lt;?&gt; constructor; private final Method postConstructMethod; private final List&lt;Field&gt; autowiredFields; private final Class&lt;?&gt; type; public BeanDefinition(Class&lt;?&gt; type)&#123; this.type=type; Component annotation = type.getDeclaredAnnotation(Component.class); this.name=annotation.name().isEmpty()? type.getName() : annotation.name(); try &#123; this.constructor=type.getConstructor(); this.postConstructMethod= Arrays.stream(type.getDeclaredMethods()) .filter(a-&gt;a.isAnnotationPresent(PostConstruct.class)) .findFirst() .orElse(null); this.autowiredFields = Arrays.stream(type.getDeclaredFields()) .filter(a-&gt;a.isAnnotationPresent(AutoWired.class)) .toList(); &#125; catch (NoSuchMethodException e) &#123; throw new RuntimeException(e); &#125; &#125; public String getName()&#123; return name; &#125; public Constructor&lt;?&gt; getConstructor()&#123; return constructor; &#125; public Method getPostConstructMethod() &#123; return postConstructMethod; &#125; public List&lt;Field&gt; getAutowiredFields() &#123; return autowiredFields; &#125; public Class&lt;?&gt; getType() &#123; return type; &#125;&#125;","path":"2025/04/25/Spring/如何理解IOC/","date":"04-25","excerpt":"","tags":[]},{"title":"面经","text":"","path":"2025/04/25/项目/分布式定时器/面经/","date":"04-25","excerpt":"","tags":[]},{"title":"重试机制","text":"两个重试机制 1.定时脚本从数据库中捞失败的任务重新执行。因为失败是偶然的，所以我们在建表的时候在task表里基于 status字段加了索引，且还会有一个count字段。达到Config里某一次数即会进行一个告警 2.调度模块重试上一分钟的任务分片，这里的设计就是比较巧妙了。 我们调度模块打捞上来的任务分片就会交给触发器从一个zset里每隔1s就会去 zrange，拿到里面的任务，然后交给执行器去触发。如果执行器执行成功了，就会延长分布式锁的时间到2min多一点，保证不会被重复执行。如果执行失败的话，就是不会去延长分布式锁的，下一分钟就会去重试上一分钟 会有重复执行的问题吗？ 目前是有可能的，我们这个项目只能做到至少执行一次，因为这是一个分布式事务的问题。就比如说当我们回 调业务方时，因为网络原因，我们这边以为回调失败了，但其实回调成功了。那这个业务得去做下幂等处理， 比如说回调时把taskid传过去，业务方执行前做下查重","path":"2025/04/25/项目/分布式定时器/重试机制/","date":"04-25","excerpt":"","tags":[]},{"title":"三级缓存","text":"","path":"2025/04/25/项目/分布式定时器/三级缓存/","date":"04-25","excerpt":"","tags":[]},{"title":"动态分桶","text":"","path":"2025/04/25/项目/分布式定时器/动态分桶/","date":"04-25","excerpt":"","tags":[]},{"title":"时间轮算法","text":"Netty时间轮 构造方法 1234567HashedWheelTimer timer = new HashedWheelTimer( myThreadFactory, // 线程工厂 100, // tickDuration：时间间隔（单位见下） TimeUnit.MILLISECONDS, // 单位 512 // 时间轮槽位数（必须是2的幂，越大越精细）); 负责执行定时任务的work线程~~~~默认~~~~是一个jvm的守护线程（是不是守护线程，取决你传入的ThreadFactory） ~~ 这意味着当 JVM 中只剩下这个线程时，进程会自动退出，不会阻止 JVM 停止。 ~~ 123HashedWheelTimer timer = new HashedWheelTimer(); // 默认使用守护线程 使用的是用户线程 12345678910111213141516171819202122232425262728private static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; @SuppressWarnings(&quot;removal&quot;) SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = &quot;pool-&quot; + poolNumber.getAndIncrement() + &quot;-thread-&quot;; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); //!!!!!!!! if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; &#125;","path":"2025/04/25/项目/分布式定时器/时间轮算法/","date":"04-25","excerpt":"","tags":[]},{"title":"异常处理？如何避免重复执行？","text":"","path":"2025/04/25/项目/分布式定时器/异常处理？如何避免重复执行？/","date":"04-25","excerpt":"","tags":[]},{"title":"横向纵向分片","text":"","path":"2025/04/25/项目/分布式定时器/横向纵向分片/","date":"04-25","excerpt":"","tags":[]},{"title":"市面已有的定时任务框架","text":"java timer querz xxljob powerjob 后两种算是比较大的了，","path":"2025/04/25/项目/分布式定时器/市面已有的定时任务框架/","date":"04-25","excerpt":"","tags":[]},{"title":"线程池参数设置","text":"我自己电脑是 24核 如果设置的核心线程数&gt;24 处理耗时都是差不多的 tomcat线程池默认核心线程数配置也是直接干到200的，tomcat线程池可以设置，那普通 线程池也是可以这么设置的，毕竟两者都是差不多的，只不过执行流程不太一样，普通线程池核心线程数满了，它是先入队列，队列满了再做一个非核心线程的扩充，知道达到最大线程数再触发拒绝策略。像tomcat的核心线程池，它最小是10，最大是200，它是当线程数超过10就会直接创建新的线程，达到最大线程数再入队，最后再触发拒绝策略。这两者的差别只有创建新线程树的差别。所以普通线程池和tomcat线程池就可以设置一个200的核心线程数了。 而我之前看八股的时候也是有了解到网上说核心线程数的设置要n+1 或者2n嘛，但当时我结合tomcat线程池的参数设置，就感觉怪怪的。然后有去疯狂谷歌搜索，像知道n+1和2n的说法来自于哪里，它其实是源于2006出版的java并发编程这本书，它里面就明确地提供了这个公式，就是线程池的线程树&#x3D;&#x3D;cpu的核心数*cpu的利用率 *（1+cpu等待时间&#x2F;cpu的计算时间）。然后我们假设CPU的利用率是100%，那么在CPU密集型场景下，，那么等待时间几乎为0，所以线程池的线程数为n，然后+1的话就是为了 说防止某线程假死了or暂停，增加一个冗余线程可以处理任务。如果是IO密集型的话，那他们就假设cpu等待时间&#x2F;cpu的计算&#x3D;1的。那么括弧里就等于2，那么结果自然就是2n。 然后一个就是为什么可以设置这么高 了解到因为长久以来一个一贯的说法就是 上下文切换回带来cpu的控制损耗。但其实这个说法是源自于1961年，有时代的局限性 2000左右的cpu上下文切换大概是5-10微妙，而当代cpu的上下文切换就只有1-3微妙。并且随着cpu超线程的发展，cpu核心数动不动就是64c 128c,除非是极端情况，比如高并发情况下，有几十万个线程正在切换，否则按照我们tomcat一般都是200个线程，甚至1000,2000的配置。这个损耗几乎是不计的。 像IO密集型的话，受限的其实是外部环境，比如数据库连接池的问题 所以如果是 还有就是个人感觉如果是这样的话，之前看过的一篇美团的关于动态线程池的技术博客，其实意义也不算大了，毕竟队列长和核心线程数并无直接关系，IO密集型的往大了调是没关事的，cpu密集型也是，毕竟怎么调大都没用，上下文损耗几乎忽略不计。 如果是生产环境的话，多个接口的话，可能会有线上其他任务抢占cpu调度的场景。那估计可能就会影响了。不过对于高并发服务器来说，其实在上面部署线程池其实是不合适的，IO密集型瓶计不在你，cpu密集型又影响其他。我个人感觉这种场景下MQ和调度任务是替代线程池的最好方案。 目前是根据一个经验值，核心线程数100，队列大小不限制 大概分析了每个线程要完成的工作，都会存在一些IO操作 根据机器2核4G的配置，所以给出一个经验值100 线程监控 beforeExecute() 重试纪元 afterExecute() 做重试逻辑，重试一定次数就报警","path":"2025/04/25/项目/分布式定时器/线程池参数设置/","date":"04-25","excerpt":"","tags":[]},{"title":"项目难点/亮点","text":"整体流程 项目难点我觉得是如何实现一个高精准和高负载，就是说在大任务量的情况如何做到秒级触发。基于这点出发，我当时就在整体的架构设计和存储设计 这两方面下了比较大的功夫。 对于存储设计来说，一开始其实是单单采用MySQL来存储，定时器开启后生成任务就直接放到mysql里。但这样的话 还有这个架构设计。项目之初，我为了解耦各个步骤，就把整个定时任务执行流程给解耦，就把它按照功能拆分成了迁移模块，调度模块，触发模块，执行模块。迁移模块就是在用户开启定时器后根据定时器的配置将任务生成后持久化到任务表中，还有redis。调度模块就是轮询从redis里捞任务片zset，然后交给触发模块去监控这个任务啥时候执行，到点执行了就调用执行模块去回调业务方提供的回调接口，这个回调接口就是具体执行任务的。一开始各个模块之间通信是通过线程池来进行的。但线程池无法实现核心流程的真正解耦以及纵向架构扩展，虽然线程池时进程内的通信，相对于消息队列而言少了一些网络IO，在执行耗时上会有更佳的表现，但这样服务的可用性和整体性能就没那么高了。所以后面架构就打算用消息队列，但我一开始的目标是尽可能的减少外部依赖，那像Rabbitmq，rocketmq对于本项目来说就比较重了。所以就采用了redis的消息队列，本身我们项目就需要redis","path":"2025/04/25/项目/分布式定时器/项目难点!亮点/","date":"04-25","excerpt":"","tags":[]},{"title":"分布式定时器性能？","text":"测试环境：2c2g服务器 因为目前线上就只有这么一台了，所以就只压测了1000笔，2000笔定时器 1000笔 （1）成功率 100% 1000笔定时器（同一时刻有1000笔定时任务触发）全部执行，未发生遗漏； （2）延时指标难看 延时 99 分位线（p99）高达 2.4 s. 即有99%的定时任务延迟低于99s,有1%的定时任务高于99s 根据那个火焰图,可以看出来性能瓶颈主要是因为redis和MySQL性能激增导致的 怎么优化？ 引入连接池，避免重复创建销毁连接，Jedis，Druid连接池 怎么查看性能的，使用了aysnc-profile https://juejin.cn/post/6844904016443342861 2000笔 （1）成功率 100% 2000笔定时器全部执行，未发生遗漏； （2）延时指标难看 延时 99 分位线飙升至 9.1 s. 性能瓶颈也主要是redis和MySQL连接数激增导致的，配置不太行 MySQL，redis，服务都塞到一台服务器上","path":"2025/04/25/项目/分布式定时器/分布式定时器性能？/","date":"04-25","excerpt":"","tags":[]},{"title":"为什么做这个项目","text":"这个主要是跟其他师兄吃饭聊天的时候，听说实验室项目组里搞了个体育馆预约系统，教室预约系统也是，需要预约结束后发送给用通知嘛，有这样的定时任务需求嘛。当时我就就想着能不能做一个通用模块，根据自己的想法去从0到1构想这么一个定时器项目，是一个很好锻炼自己项目设计能力、问题解决能力、编码能力的一个机会 。即使到时候没法上线啥的，也比现在的网上的一些商城，外卖这种项目写到简历上竞争力强。也是当做锻炼自己的项目能力了。 是自己实现的吗？ 有去参考相应的技术博客文章，当时帮助最大的应该是 对项目的要求？ 轻量级，成本低（依赖少） 与业务方 解耦 高负载，高精准（秒级） 代码简单 致敬 快速实现一个分布式定时器-腾讯云开发者社区-腾讯云 https://juejin.cn/post/7116320697139331103 https://juejin.cn/post/7174007780104208392","path":"2025/04/25/项目/分布式定时器/为什么做这个项目/","date":"04-25","excerpt":"","tags":[]},{"title":"面试回答","text":"自我介绍平时你是怎么学习的首先是通过视频入门，视频讲解一般比较生动，有即时反馈，跟着入门不会溜神 然后就是自己再把东西梳理一遍，看下是否有遗漏或者不清楚的点。 然后是关键的点，就是去各大社区平台看技术文章，例如阿里云、腾讯云、博客园或者是一些我觉得是宝藏博主的私人blog平台，还有像公众号的文章和书籍这些，都有看，我觉得看这些文章都是很有意思，广度和深度都很不错的学习方式 一般到了这里，我基本就是能比较完善的学习了，因为我看的文章确实挺广的，然后对于一些特殊的、有意思的东西，我会自己去做实验，比如MySQL里的锁，我就有专门去手动研究测试过。 因为我看的文章广度比较大嘛，所以可能出现有些地方说法不一致的地方，这时候我就得弄清楚到底哪个是真相，这时候我会再去扩大信息来源的广度和深度，不断发掘知识，这里也会结合gpt来进行问，如果感觉还是两种说法都有，搞不清楚，我就启动我的大招，去翻源码了，我看源码的步骤是这样的，我会去问gpt，我这块内容的源码，具体是在哪，然后才去看，比如我记得用源码解决的部分就有这些情况： 一个是RocketMQ的消息重试那块，我们看到的常见的说法是，消息如果消费者那边没响应的话，broker会重复投递消息，会重复投递16次，但是我在一个地方看到的说法又是，如果是在顺序消费的情况下，投递次数超过了，就会丢弃这次的消息到私信队列，然后消费后面的消息，看到这里，我就想，这不就破坏消息顺序消费了吗，比如如果消息顺序是消息1，消息2这样子，消息1重复16次投递不出去，然后就跳过消息1，消费消息2，这就破坏我们说的顺序消息了啊，RocketMQ真的会这么设计吗。然后我就去翻源码进行查看，发现他在源码里面，重复次数其实设置的是-1，并不是16，然后这个字段上面有注释，注释说的是，在并发消费下，-1意味着16，在顺序消费下，-1意味着Integer.MAX_VALUE，然后我去具体的使用上看了，发现确实是会根据不同场景下是不同的重复投递次数的，那么在顺序消费下，其实他就是int的最大值，就是一直投递了，那其实就不会跳过这个消息了，这其实就是通过源码来解决我看过的文章发生冲突的一个例子吧。 还有一个就是我看《深入理解Java虚拟机》上面说，HotSpot新生代晋升老年代的年龄是15岁，但是如果Survivor中相同年龄所有对象大小总和大于Survivor一半，年龄大于或等于该年龄的对象就可以直接进入老年代。但是我又是在其它地方看到了另一种说法，另一种说法是说动态年龄的判断是小于或等于某个年龄的所有对象大小大于总和的一半，那么新的阈值就被设置成这个年龄。那这里其实就是两种说法，我把这两种说法都问了gpt，并让他给出源码坐标，也去源码里面看了下，发现其实是后者说法是正确的，也就是《深入理解Java虚拟机》其实在这个问题上有错，这里其实也是比较惊讶的一点，因为这个书我看了两遍，感觉真的是写JVM非常好的一本书，但真的就是突然感觉还是不能尽信书吧。 还比如说我在学RocketMQ事务消息的时候，就感觉这样真的能保证数据一致吗，我就去考虑极端情况，例如本地事务提交了，但是commit消息还没发送出去，此时生产者又宕机了，那么MQ也反查不到事务信息，这时候会怎样，但是网上没搜到有文章讲这种极端情况，我就去看源码了解RocketMQ是怎么解决的，通过源码我看见，MQ会起一个线程每隔30s轮询一遍事务消息进行状态回查，如果回查次数大于等于最大次数也就是15次，那就会直接丢弃这个消息到一个topic叫TRANS_CHECK_MAXTIME_TOPIC的队列中。所以其实事务消息也并不一定是安全的，也有可能导致数据不一致，但是我当时又顺便看了下它的源码中回查状态的那部分，发现它其实通过生产者组id获取生产者组实例，然后轮询选择出具体的某个实例，来进行状态回查的，也就是回查的机器和发送事务消息的机器不一定是同一个，所以我们生产者组是可以部署集群来提高可用性进而解决这个事务消息可能产生的数据不一致问题的。","path":"2025/04/25/and so on/面试回答/","date":"04-25","excerpt":"","tags":[]},{"title":"update","text":"","path":"2025/04/23/MySQL/SQL语句执行过程/update/","date":"04-23","excerpt":"","tags":[]},{"title":"select","text":"取得连接，会使用到 mysql 中的连接器 还会经历 tcp 三次握手，因为 mysql 是基于 tcp 进行通信的 这个过程会校验用户名和密码是否正确 校验用户权限 查询缓存，key 为 sql 语句，value 为 sql 查询结果，不过在 mysql8.0 后被删掉了 更新比较频繁的表缓存命中率很低，因为只要一个表被更新了，该表的缓存就会被删掉，维护起来就很麻烦 分析器，分为词法分析和语法分析。词法分析就是提取 sql 语句关键字，语法分析就是校验 sql 语法，构建 sql 语法树，方便后面去读取表名，列名，语句类型 执行阶段 预处理 检查 sql 查询语句中的表 or 字段是否存在 把*扩展为表上的所有列 优化阶段 决定如何走索引 如何 jion 执行阶段：根据表的引擎定义，去执行这个引擎提供的接口","path":"2025/04/23/MySQL/SQL语句执行过程/select/","date":"04-23","excerpt":"","tags":[]},{"title":"过期key删除策略","text":"redis会把设置了过期时间的key放到一个过期字典里 定期：每隔一段时间从过期字典里随机取一批key判断是否过期，过期就“删除” 惰性：访问到已经过期的key时就直接删除 redis默认使用的是定期+惰性删除 redis默认每秒进行10次的过期检查，我们可以通过redis.config设置hz。随机抽取的数量是写死的 为20 且这个定期删除不会立马删，而是检测到某些key过期了，会把它放到一个List里，但redis的内存使用率 达到某个阈值后再统一删。 还有就是，被删除的过期key原来占用的空间并不会立马被操作系统回收，而是会标记为可重用的内存， 以此来提高性能。（毕竟向系统申请空间or回收是很耗性能的） 如何设置过期时间 expire ：设置key在n秒后过期 pexpire ：设置key在n毫秒后过期 expireat ：设置key在n时间戳（精确到秒）后过期 pexpireat ：设置key在n时间戳（精确到毫秒）后过期 或者在设置字符串时也可以一起设置： set ex，set px 查看key的过期时间 ttl","path":"2025/04/23/Redis/过期key删除策略/过期key删除策略/","date":"04-23","excerpt":"","tags":[]},{"title":"内存淘汰策略","text":"只有内存满了才会执行 如果从淘汰的对象角度来说的话： 针对所有key 针对设置了ttl的key 如果从淘汰的算法角度来说 LRU LFU 随机选一个删除 不删，直接返回错误信息 如何配置 通过redis的 maxmemory-policy参数来指定 如何选择？ 参考过一些大厂的配置建议 比如腾讯 它是根据redis的使用情况来考虑的， 若你redis当缓存的话，就设置allKeys-lru。会把最近最少使用的key删掉 若你redis当半持久化or半缓存使用，可以使用volatile-lru 不过像腾讯云的redis云产品默认的是不删除 阿里云默认的是volatile-lru LRU变种实现","path":"2025/04/23/Redis/内存淘汰/内存淘汰策略/","date":"04-23","excerpt":"","tags":[]},{"title":"redis的lua脚本","text":"","path":"2025/04/23/Redis/事务/redis的lua脚本/","date":"04-23","excerpt":"","tags":[]},{"title":"redis事务","text":"Redis中的事务，multi表示开启一个事务（类似MySQL中的begin），然后执行一系列命令（放入队列中，提交后依次执行），exec提交（类似MySQL中的commit） 原子性：Redis中的事务不满足原子性，如果命令中有错误指令，如自增一个字符串的key，提交事务后，其它正常的语句仍能执行，事务不会回滚 事务中读请求没有意义，返回值用不了，因为此时命令还没真正执行，只是放到了一个队列中，exec提交后才真正执行；而MySQL开启事务后执行指令，那是真正实打实的执行的 既然不能在事务中读（没有意义），那就得在事务外面读，然后开启事务，再进行写操作，但这样无法保证读+写的原子性，可能读完后，事务提交前有其它连接更改了数据，解决方案： watch命令，用来盯住一个到多个key，如果这些key在事务期间： 没有被其它客户端修改，exec能成功 被其它客户端修改，exec返回nil 例如： 123456watch a b // 监视a b get a // 返回1000 get b // 返回500 multi // 开启事务 set a 500， set b 1000 // a给b转账500 exec 如果第一条指令到最后一条指令期间，有其它客户端修改了a或b的值，exec不会提交事务，返回nil lua脚本（2表示接下来的两个值是key，key后面的是参数，即a和b是key，500是参数）","path":"2025/04/23/Redis/事务/redis事务/","date":"04-23","excerpt":"","tags":[]},{"title":"CAS","text":"为什么要上锁？锁的本质是什么？ 上锁的本质其实就是为了让资源能被正常的修改。为什么不上锁就不行呢？因为在JMM中，存在 着共享内存以及线程私有内存的，线程不是总会把私有内存里的资源立马加载到共享的，存在着时间 差，也就导致了覆盖的问题，此时就是我们常说的线程不安全。这时候我们使用ReentrantLock or · synchronized去包住一段代码，保证 同一时间内只会有一个线程去操作里面的资源，即使不会立马同步 到共享内存，也不会有其他线程来竞争。而且只要代码执行出了锁的范围，就会立马同步到主存 这里的资源是指堆内的，即成员变量 可以看到synchronized和ReentrantLock锁的是比较大的范围，容易误伤 所以我们可以把锁的范围降低，同时并不总是一直会有 对共享资源的访问和修改，我们可以基于一种乐观的 思想，比较资源的现有值和预期值，如果一致，说明没有人访问过，那么我直接修改 预期值和现有值是指什么？ 比如一个对象里有个字段int a，我之前读出来，读出a是2，这个2就是预期值，那么我需要把他加10，更改为12，此时要更改了，我就看他的现有的实际的值，如果还是预期值2，说明在我读出来，再做运算，再到现在打算更改这个过程中，没有其它线程来修改，那么我就可以把它改为12。如果不是2，例如变成5了，那么实际值5，就和预期值2不一样了， 说明这段时间内有其它线程对其修改了，那我就不能动他，否则就产生覆盖了，因为我的12是基于2来计算出来的 即 一起竞争，谁快谁有理 CAS compare And swap 正是这样的锁，其实不只是锁了，更能说是一种思想。但其实也能说是一种锁，毕竟比较和交换这两步得是原子的。 cas基于cpu的一个原子指令来使其原子操作 cmp x chg：cpu执行这条指令时，会自动锁住总线，防止其他cpu访问共享变量；cpu同时自动禁止中断 同时硬件会保证对共享变量的访问是原子的 CAS存在的问题： ABA，但说实在的业务上根本没有这个问题 CAS与悲观锁的区别： 粒度不同，CAS的粒度是针对一个变量的修改， 悲观锁的粒度是一段代码块 思想不同，CAS是乐观的思想，失败了大不了再重试，悲观锁是悲观的思想，我就笃定会有其它线程干扰，直接上锁 场景不同，CAS适用读多写少，悲观锁适用读少写多 开销不同，CAS开销小，悲观锁开销大 有了CAS为什么还要volatile？ CAS只是原子修改，并不能保证可见性，修改完后，其它线程并不一定马上能看到最新值","path":"2025/04/23/JUC/CAS/","date":"04-23","excerpt":"","tags":[]},{"title":"三种持久化策略","text":"AOFps：AOF的诞生是为了解决早期的RDB无法及时持久化的问题 redis执行写命令操作后，会把其命令追加到AOF文件里，AOF是文本格式文件，AOF持久化默认是默认关闭 AOF的刷盘时机有三种，具体是由config里的appendfsync 参数控制的 1.always：每执行一条写命令就写入一次（每次write，每次fsync） 2.Everysec：每秒执行追加到文件一次，会先将命令写到AOF对应的内核缓冲区，后每隔一秒再写入 磁盘中的文件（每次write，每秒fsync） 3.no：由操作系统来决定啥时候刷盘（每次write） AOF重写 它这个就是说当AOF文件大小到达某些阈值后（可配置），会读取redis中的所有键值对，生成命令写入 新的AOF文件里，然后用新的替换旧的 目的：给文件瘦身，比如说一开始有set saki 69，set saki 91两个命令，重写后就只有set saki 91一条 命令了 为什么要用新的文件替换旧的文件，而不是直接覆盖呢 怕重写一般失败了，污染了旧文件 写入是在主线程执行的，因为写入的量不多。但重写是会fork子进程来完成的，这其中会把父进程的数据拷贝一份 ….(待补充) 为了避免子进程在重写时，主进程的数据发生了变化，导致AOF文件里的数据和内存里的对应起来不一致。redis对其进行了一层优化，即将重写阶段新来的数据写入AOF的重写缓冲区里，等到AOF重写完成后，再把AOF重写缓冲区里的数据追加到新的AOF文件中。 RDB快照RDB快照就是指记录某一时间段的内存数据，记录的是实际数据，因此在做内存恢复时效率是要比AOF高不 少的。 RDB可以直接读入内存就好了，不用像AOF那样需要执行命令 RDB是紧凑的二进制文件 RDB还提供了两种命令来生成RDB文件 save：主线程直接执行，会阻塞正常命令的执行 bgsave：操作系统fork子进程执行，可以避免主线程的阻塞 生成RDB时，不会保存过期的key 导入RDB时，主节点会对过期key进行过滤，而从不会 bgsave和AOF重写一致，都会fork子进程，但在bgsave期间新来的数据是不会被保存到此时的RDB的，只能等到下一次RDB 其他生成 正常停机时生成一次RDB 内部触发机制 比如save&#x2F;bgsave 91 1：代表91秒内至少有1个key被修改，就RDB一次 redis默认的持久化策略：采用RDB save 900 1 save 300 10 save 60 10000 appendonly no 注意：这个save不会阻塞主线程，**Redis 自动触发 ****bgsave** 来生成快照 4.x后的混合持久化","path":"2025/04/23/Redis/持久化/三种持久化策略/","date":"04-23","excerpt":"","tags":[]},{"title":"Redisson看门狗机制","text":"原理就是开一个定时任务，,然后每隔10s检查一次，并将其续约恢复至我们设置的lockWatchdogTimeout（默 认是30s） jvm挂了，看门狗会一直续期下去吗挂了的话，不会一直续期的。看门狗是jvm线程，jvm挂了的话，会终止续期的 加锁线程挂了，但jvm没挂，看门狗会一直续期下去吗 看门狗线程本质就是一个守护线程，且这个线程是和加锁线程绑定的，或者说它续期会去判断加锁线程是否存 活，存活才会去续期 并非守护线程 源码解读续期任务调度的实现 这个方法是为锁开启续期任务，且一把锁只会有一个续期任务！！！由第一个持有该锁的线程开启，后续第 n个持有该锁的线程只需要把threadId注册到一个concurrentHashMap里 为什么？ 你续期任务本质就是一个开一个线程不断轮询，那一个线程配一个定时线程这显然是不合理的。肯定 是不合理的，只需要一把锁对应一个续期任务 1234567891011121314151617181920212223242526272829protected void scheduleExpirationRenewal(long threadId) &#123; //new一个续期任务 ExpirationEntry entry = new ExpirationEntry(); //EXPIRATION_RENEWAL_MAP：concurrentHashMap k:锁 v：一个entry field有线程ID //Q：为什么要为concurrentHashMap来保证线程安全呢 //A：因为它是Redisson所有锁的基类，像读写锁这种，可能会有多个线程共同持有锁的情况 //如果这个锁已经有一个续期任务在执行了，就不覆盖，返回旧的 entry；否则返回 null，表示可以放入 ExpirationEntry oldEntry = (ExpirationEntry)EXPIRATION_RENEWAL_MAP.putIfAbsent(this.getEntryName(), entry); //不为空，说明这把锁已经有续期任务了 if (oldEntry != null) &#123; oldEntry.addThreadId(threadId); &#125; else &#123; //首次为这把锁开 续期任务 并把当前线程注册到 entry.addThreadId(threadId); try &#123; //执行续期 this.renewExpiration(); &#125; finally &#123; //如果线程被中断了 就取消续期 //Q：什么情况下，线程会被中断？ if (Thread.currentThread().isInterrupted()) &#123; this.cancelExpirationRenewal(threadId); &#125; &#125; &#125;&#125; 续期的实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * Redisson 分布式锁 —— 看门狗续期核心逻辑 * * 功能： * 1. 定期（默认锁租期的 1/3）检查锁是否仍然被当前线程持有； * 2. 若锁仍在，则延长过期时间（防止业务执行过长锁被自动释放）； * 3. 若锁已不存在，则取消续期任务； * 4. 若发生异常（如 Redis 宕机），则清理当前锁的续期状态。 * * 实现细节： * - 使用 Netty 的时间轮（HashedWheelTimer）定时调度任务； * - 使用异步命令（CompletionStage）执行 Redis 脚本； * - 通过回调 whenComplete 处理续期结果或异常。 */private void renewExpiration() &#123; // 获取当前锁对应的续期任务信息（存放于全局 Map） ExpirationEntry ee = (ExpirationEntry) EXPIRATION_RENEWAL_MAP.get(this.getEntryName()); if (ee != null) &#123; // 使用 Netty 时间轮延迟执行任务（间隔 = 租期时间 / 3） //newTimeout: Timeout task = this.getServiceManager().newTimeout(new TimerTask() &#123; @Override public void run(Timeout timeout) throws Exception &#123; // 再次确认该锁的续期任务仍存在（防止任务被取消） ExpirationEntry ent = (ExpirationEntry) RedissonBaseLock.EXPIRATION_RENEWAL_MAP.get(RedissonBaseLock.this.getEntryName()); if (ent != null) &#123; // 获取该锁第一个持有线程的 threadId（可能是重入锁） Long threadId = ent.getFirstThreadId(); if (threadId != null) &#123; /** * 续期逻辑： * 调用 Lua 脚本检测锁是否仍属于当前线程， * 若是，则执行 pexpire 延长过期时间； * 返回值： * true -&gt; 锁还在，续期成功； * false -&gt; 锁已不存在或非本线程持有。 */ CompletionStage&lt;Boolean&gt; future = RedissonBaseLock.this.renewExpirationAsync(threadId); /** * Q：为什么是异步？ * A： * - renewExpiration() 是周期性执行的； * - 如果同步等待 Redis 响应，Netty 时间轮线程会被阻塞； * - 异步执行可以充分利用线程池，提高续期稳定性； * - 防止 Redis 网络抖动造成时间轮延迟。 */ // 注册异步回调：处理续期结果与异常 future.whenComplete((res, e) -&gt; &#123; /** * e：表示异步任务执行过程中发生的异常（如 Redis 连接错误、脚本超时等） * res：表示 Redis 脚本返回结果（true=锁还在，false=锁不存在） */ if (e != null) &#123; // 出现异常，打印日志 + 清理续期任务（避免死循环） RedissonBaseLock.log.error( &quot;Can&#x27;t update lock &#123;&#125; expiration&quot;, RedissonBaseLock.this.getRawName(), e ); RedissonBaseLock.EXPIRATION_RENEWAL_MAP.remove(RedissonBaseLock.this.getEntryName()); &#125; else &#123; if (res) &#123; // res == true：锁仍被当前线程持有，继续下一次续期 RedissonBaseLock.this.renewExpiration(); &#125; else &#123; // res == false：锁不存在（可能已释放或超时），停止续期任务 RedissonBaseLock.this.cancelExpirationRenewal(null); &#125; &#125; &#125;); &#125; &#125; &#125; &#125;, this.internalLockLeaseTime / 3L, TimeUnit.MILLISECONDS); // 将定时任务句柄存回 ExpirationEntry（便于后续取消） ee.setTimeout(task); &#125;&#125; Redisson的定时任务是基于Netty中的时间轮来实现的 时间轮是什么？时间轮算法 Redisson执行定时任务的work线程 timer就是一个HashedWheelTimer（Netty的时间轮） return 一个Timeout（表示你刚刚注册的这个定时任务，你可以通过这个timeout来查看任务状态等等） newTimeout：往时间轮里面 注册一个定时任务","path":"2025/04/23/Redis/分布式锁/Redisson看门狗机制/","date":"04-23","excerpt":"","tags":[]},{"title":"Redisson分布式锁","text":"使用两个常用API tryLock：非阻塞锁，如果不设置waitTime的话，就直接return了 lock：阻塞锁，线程获取不到锁，会阻塞住 为什么基于lua脚本实现而不是事务？两者都是可以保证原子性的，但 可重入锁？redisson是基于redis的数据结构hash去实现可重入锁的。key为lock，field为线程名，value为count。这个 count就是用来表示一个锁被同一线程持有的情况 加锁流程：就是会先判断锁是否被当前线程持有或者说有没有线程持有，不是就表示加锁失败，是的话，就 count++; 解锁流程：每次执行完毕就count–。直到count&#x3D;&#x3D;0，就把其key删除掉，表示锁完全释放 加锁流程和解锁流程都是基于lua脚本实现的 不止hash结构？ 1.字符串拼接，把count拼进去 2.redis那里还是使用string，服务内部通过concurrentHashMap保存：key为线程唯一标识，value为锁 计数器 123456// 用于保存线程对应的锁和重入次数//外层 String 是线程 ID（可以用 Thread.currentThread().getId() 拼上业务 ID），或 UUID。//内层 Map：key 是 Redis 的锁 key，value 是重入次数。private final ConcurrentHashMap&lt;String, Map&lt;String, Integer&gt;&gt; threadLockMap = new ConcurrentHashMap&lt;&gt;(); 可阻塞锁，可重试锁？Redisson的可阻塞锁是基于Redis的发布订阅模式来实现等待，唤醒，获取锁失败的重试机制的 获取锁失败不是直接重试or返回，而是订阅一下，然后等待 当获取锁成功的线程释放锁后，就会发布一条消息 其他线程就会收到这条消息，从而重新获取锁，获取失败就会继续等待 但也不是无限等待，超过一定时间，就不会继续等了，而是会返回false（针对于tryLock()） 联锁？对于分布式锁在主从架构中的锁丢失问题，Redisson提供了一种联锁机制。它要求Redis使用多主多从或者多 主，那么只有所有Redis主节点都上锁成功，才算上锁成功。这样的话，如果某个主节点宕机了，那么其他主 节点也是有锁的数据的，新线程想要给所有主节点加锁，那还是会加锁失败的 ps：主从架构中的锁丢失问题：当主节点setnx成功后，这时候来没来得及同步就挂了。那么这时候就会重新 选主，但这时候新的主节点是没锁数据的，服务器就会认为锁已经释放了，导致锁的互斥性失效了。 红锁？但对于联锁而言，还可能会存在以下问题 1.所有主节点都得上锁，若某个主节点由于网络原因，导致加锁时间长，加锁失败 2.或者某个主节点宕机了，一直加锁失败 那么如果出现以上情况，就会导致一直加锁失败，失败概率很高，而且加锁失败后是要回滚所有Redis主节点 的数据的，性能很差的。 那么基于以上问题……………… Redis官方提供了一种红锁机制，也要求Redis要多主部署，但加锁时只要半数以上加锁成功就OK了。如果 当前线程加锁加到半数以上，那么其他线程就不可能加锁加到了半数以上了，那么这样就满足了互斥性 但redLock也是有很大问题的， 主要原因是Redis创始人不推荐在严格一致性的分布式情况下使用它 有什么可以替代的吗？业界无公认的方案 我个人的思考 1.使用单实例的Redis锁，虽然会有单节点故障 2.业务做好唯一性校验 3.使用强一致性组件来实现分布式锁，如zookeeper 分布式锁检验死锁？观察看门狗线程，如果出现某两个看门狗线程存活时间过长，则这两个看门狗对应的分布式锁可能产生死锁","path":"2025/04/23/Redis/分布式锁/Redisson分布式锁/","date":"04-23","excerpt":"","tags":[]},{"title":"redis实现悲观锁","text":"如果实现比较简单的悲观锁。基于setnx和lua脚本，这个命令能保证了 加锁流程 set….nx这命令就是说只有当key不存在时才会插入成功，来模拟上锁流程 SET myLock uuid NX PX 10 # 设置过期时间，避免死锁 key：myLock value：uuid 为什么不用线程ID呢，在分布式部署的情况下，线程ID会出现重复的 PX：设置过期时间，保证线程异常了无法执行解锁逻辑，锁也能自动释放 解锁流程 分为三步：拿到锁，判断是否为当前线程上的锁，释放锁 这三步不是原子性的，因此需要用lua脚本来保证原子性 如果持锁线程挂了怎么办？不会自动释放锁！ 如果设置有效期，持锁线程a被阻塞，锁到期了自动释放，其他线程b获取到锁，a使用完后就会释放锁，但这个锁其实是b持有了，这就乱套了 如果添加锁业务标识，不是自己的锁就不释放，因为判断锁是否是自己的和释放锁是两个操作，如果两个操作中间出现了阻塞，仍然有错误释放的可能 那么用lua脚本保证原子性 ，这样是还不错的，但如果真出现了线程a阻塞，锁自动释放，b线程获取到锁，这就相当于临界资源可以进入多个线程了，所以我们最好是锁快过期了能自动续约时长，如果是线程挂了那就不续约了，直接走人。 就像去网吧上网，快下机了但还想玩，那就续费，如果人都直接回家吃饭了，网管肯定把你机子给其它人用了","path":"2025/04/23/Redis/分布式锁/redis实现悲观锁/","date":"04-23","excerpt":"","tags":[]},{"title":"redis实现乐观锁","text":"所谓的乐观锁，其实就是基于CAS机制，即compareAndSwap。就是需要知道一个key在修改前的值，去进行 比较 redis想要实现，可以依赖于Watch命令，这个命令可以实现Watch监视的key在调用exec之前没改变时，才会 去执行后续事务任务 MULTI：开启事务 SET：在事务中添加命令 EXEC：执行事务 12345678910111213141516171819202122232425262728293031323334353637import redis.clients.jedis.Jedis;import redis.clients.jedis.Transaction;public class RedisOptimisticLock &#123; public static void main(String[] args) &#123; // 连接到 Redis Jedis jedis = new Jedis(&quot;localhost&quot;); try &#123; // 监视键 String key = &quot;myKey&quot;; jedis.watch(key); // 模拟从数据库读取最新值 String value = jedis.get(key); int intValue = Integer.parseInt(value); // 开始事务 Transaction t = jedis.multi(); // 在事务中执行操作 t.set(key, String.valueOf(intValue + 1)); // 尝试执行事务 if (t.exec() == null) &#123; System.out.println(&quot;事务执行失败，数据已被其他客户端修改&quot;); &#125; else &#123; System.out.println(&quot;事务执行成功&quot;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; jedis.close(); &#125; &#125;&#125;","path":"2025/04/23/Redis/分布式锁/redis实现乐观锁/","date":"04-23","excerpt":"","tags":[]},{"title":"分布式锁技术选型","text":"常见的有三种：mysql，redis，zookeeper zookeeper和redis分布式锁的技术对比 性能：redis基于内存，zookeeper基于磁盘，所以在性能上redis&gt; zookeeper 自动释放：zookeeper加锁是基于服务端和客户端的连接来保证的，一旦连接断了，那么锁就会自动释放。死锁风险比redis少 一致性和可用性要求：zookeeper本身设计理念就是CP的，它的主从数据同步是基于同步的方式。就是同步的时候主节点会被阻塞住，无法返回客户端响应，更能保证一致性；redis强调可用性，AP 总结 一致性高用 zookeeper 可用高 用 redis 经验之谈 尽量用redis，不要用zk 多实例场景下，RedLock和zk机制很像，都是通过半数以上提交来实现的 redis比较方便 业务上做好幂等校验就行了，业务没问题就行 而且用分布式锁时性能要求肯定高，如果不高的话，你直接用数据库的悲观锁就好了。没必要用分布式锁 如果你实在是接受不了短暂的不一致性，重复加锁的问题，or项目强依赖于zk ps：而且用分布式锁时性能要求肯定高？？？为什么？？ 如果让你自己来实现的话，你会怎么设计？","path":"2025/04/23/Redis/分布式锁/分布式锁技术选型/","date":"04-23","excerpt":"","tags":[]},{"title":"缓存一致性问题","text":"根据业务场景做选择吧，我目前了解的就五种做法 如果要是强一致性的话，那就是加分布式锁，但你引入锁了，性能就很低。这就很矛盾，毕竟你引入缓存是来提升性能的 无锁只能尽可能地保证一样，AP模式 同步双写进行操作更新时，同时操作mysql or redis 。业务用得最多的方案了，适合单机。 mq异步多写适合多机redis 定时任务 db做逻辑删除和updateTime处理 db做而是让定时任务扫描最近变动的数据，然后批量删除key 效率高，但时延时最高的 闪电缓存 缓存过期时间设置很短 只更新db，让缓存自己过期 时延性也还好，看你缓存过期时间的设置， 不过就是给数据库增加了压力 bin log监听 用flink-cdc or canal(阿里已经停止维护了)监听mysql的bin log 解析bin log 好处就是时延低，坏处就是成本高 旁路缓存+延迟双删删完后，隔一段时间再删一次，但间隔时间很难确定 只存在理论 啥时候删，这东西很难确定 高并发不管用，你把缓存删了，然后你让数据库抗高并发","path":"2025/04/23/Redis/缓存问题/缓存一致性问题/","date":"04-23","excerpt":"","tags":[]},{"title":"缓存更新策略","text":"一般有三种：旁路缓存，读穿&#x2F;写穿，写回策略 我们开发中用的也是第一种，其他后两种 旁路缓存策略读策略：缓存读不到，就读数据库然后写入 写策略：先更新数据，再删缓存。 但这种只适合读多写少，且并发量较小的情况。 如果写多读少的话，会导致缓存命中率比较低。这些时候可以采用更新缓存的策略 加锁，只有一个线程去更新缓存 缓存时间设置小一点，即使出现缓存不一致的情况 高并发下，你删key了，那请求不就直接打到数据库了吗？ 参考guava设置 对于toc来说 可以采用互斥锁，保证只有一个线程去更新数据库。其他线程拿到旧值就返回了，等那个线程写回 读穿&#x2F;写穿策略原则就是应用程序只和缓存打交道，而操作数据库是由缓存代理的 redis不支持这种功能 Write Back（写回）策略更新缓存时，不立马写数据库，立马返回。而是异步批量更新 redis同样也不支持批量更新。","path":"2025/04/23/Redis/缓存问题/缓存更新策略/","date":"04-23","excerpt":"","tags":[]},{"title":"缓冲三大问题","text":"缓存穿透恶意请求cache or db 中不存在的数据 做好IP限流，黑名单校验，防止大量恶意请求 做好业务判断 布隆过滤器，不过这可能存在误判，但一定能保证拦截请求不存数据的请求 缓存击穿某一热点key失效，数据库崩 加互斥锁，保证缓存失效时只有一个请求去访问数据库更新缓存，但其他请求会阻塞 提前预热好数据 最重要的是做好降级，熔断。因为某些热点key是不可预判的，比如微博某明星热搜 PS： 缓存雪崩大面积的热点key失效，数据库崩 过期时间错开 多级缓存 雪崩后要做好降级限流熔断处理","path":"2025/04/23/Redis/缓存问题/缓冲三大问题/","date":"04-23","excerpt":"","tags":[]},{"title":"redis的常用以及底层数据结构","text":"四种基本：string hash list set 五种特殊：zset geo hyperloglog stream bitmaps 底层 sds dict ziplist quicklist skiplist SDSc语言string的增强版 常数获取字符串长度 杜绝缓冲区溢出 内存预分配 二进制安全，可存&#x2F;0 string存的最大：521m intsetdictziplist 压缩链表。连续的内存空间，类似于数组 每个节点都存有前一个节点的长度，用于从后往前遍历，存有当前节点长度和类型，用于从前往后遍历。 这样更能节省内存 但会出现级联更新的问题 ziplist如何实现有序性的 插入时保证有序 O(N) 插入时二分查找判断插入节点的位置 移动数组 补充:在 Redis7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了 ListPack ListPack可看做是ziplist的升级，它每个元素没有存储前一个元素的长度，但同样支持反序遍历 skiplist跳表，可实现log(n)查询，即多级索引的链表 思想就是空间换思想，用多级索引去减少检索的路径 为什么zset要基于skiplist实现 首先要明确zset是干什么的?无非就是有序，支持范围查询 那么像这样的数据结构，其实有很多种，数组，列表，多路搜索树Or二叉树 但数组和树结构这种，它增加元素肯定会引发那个数据结构的调整。这种对于追求性能的redis的来说，在内存操作时多余的（ CPU 操作才是瓶颈，结构复杂就显得多余，浪费性能 ） 而对于链表来说，它的查询性能是不行 那怎么优化，无非就是空间换时间，建二级索引，索引建得足够多，那就足够快 跳表就是这个思想 那这时候选择跳表就是一种根据场景权衡利弊出来的选择 空间占用小 ListNode&lt;TreeNode 支持范围搜索 算法实现简单 zset是怎么实现的？版本 3.0：ziplist + skipList 4.0：listpack+skiplist 从元素size角度 少时：用zipList（listPack）来紧凑存元素，节约空间 多时：把ziplist(listPack)里的元素按score 顺序插入 skiplist","path":"2025/04/23/Redis/数据结构/redis的常用以及底层数据结构/","date":"04-23","excerpt":"","tags":[]},{"title":"jedis和Redisson如何选","text":"说人话：根据你的业务要求来，Jedis只是对redis命令进行了简单的封装，没有那么多高级特性。Redisson支持的高级特性就比较多","path":"2025/04/23/Redis/网络模型/基础/jedis和Redisson如何选/","date":"04-23","excerpt":"","tags":[]},{"title":"redis是怎么实现高性能的","text":"性能一般是基于两方面，1是计算，2是读写操作 计算操作 基于内存的，所以计算很快 单线程，所以执行命令很快 为什么？因为你单线程执行的话就不需要去加锁，加锁是很重很耗性能的 读写操作，无非就是磁盘IO，网络IO 磁盘IO优化：rdb持久化，会创建一个子进程（系统级别）来生成rdb文件，这样可以避免主线程的阻塞。这也是一种写入时复制的思想 网络IO优化： io多路复用：select epoll 可以监听多个socket连接 事件派发机制：有很多不同性质的socket，redis有不同的Handler来处理这些socket事件，redis6.0使用多线程来处理这些Handler（多线程是用来处理网络请求的，命令还是由主线程来执行的）","path":"2025/04/23/Redis/网络模型/基础/redis是怎么实现高性能的/","date":"04-23","excerpt":"","tags":[]},{"title":"为什么这么快","text":"https://share.note.youdao.com/ynoteshare/index.html?id=e20f952ed7afde4e9460c3b6db6f107e&amp;type=note&amp;_time&#x3D;1752253213036 存内存操作，比磁盘块 只需要处理的数据量小 合理的数据结构 网络模型使用了NIO 单线程操作，避免了多线程的频繁操作 redis内置了多种优化后的数据结构 首先，io多路复用,并不比传统的阻塞io快，它主要解决了 c10k 问题，所以，epoll 只是在有限的机器资源下,提高了服务端的并发度,使得之前花很多时间阻塞在io上的cpu的利用率提升了。 多路复用对于Redis是为了解决在有限的资源下，解决阻塞IO造成的c10k问题，对单个请求无提升，但提升了整个系统的并发度。 如果可以开无限线程，Redis的网络其实可以设计成多线程的阻塞IO 设计理念就是只需要处理的数据量小，然后用IO多路复用来提高并发，发现单线程也够用，这样足够简单还不用搞多进程处理各种锁之类的 而说单线程没有锁比多线程有锁更快，也是没有根据的。多线程肯定比单线程快，然后花精力在锁设计这块就能解决。比如nginx多进程架构。","path":"2025/04/23/Redis/网络模型/基础/为什么这么快/","date":"04-23","excerpt":"","tags":[]},{"title":"TLS握手","text":"","path":"2024/12/22/计网/TLS握手/","date":"12-22","excerpt":"","tags":[]}],"categories":[],"tags":[]}